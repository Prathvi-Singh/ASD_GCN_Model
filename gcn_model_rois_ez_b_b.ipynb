{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc5d23a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from nilearn import connectome\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "# Reading and computing the input data\n",
    "\n",
    "# Selected pipeline\n",
    "pipeline = 'cpac'\n",
    "\n",
    "# Input data variables\n",
    "root_folder = '../ABIDE/'\n",
    "data_folder = os.path.join(root_folder, 'ABIDE_pcp/cpac/filt_noglobal')\n",
    "phenotype = os.path.join(root_folder, 'ABIDE_pcp/Phenotypic_V1_0b_preprocessed1.csv')\n",
    "\n",
    "\n",
    "def fetch_filenames(subject_IDs, file_type):\n",
    "\n",
    "    \"\"\"\n",
    "        subject_list : list of short subject IDs in string format\n",
    "        file_type    : must be one of the available file types\n",
    "\n",
    "    returns:\n",
    "\n",
    "        filenames    : list of filetypes (same length as subject_list)\n",
    "    \"\"\"\n",
    "\n",
    "    import glob\n",
    "\n",
    "    # Specify file mappings for the possible file types\n",
    "    filemapping = {'func_preproc': '_func_preproc.nii.gz',\n",
    "                   'rois_ho': '_rois_ho.1D'}\n",
    "\n",
    "    # The list to be filled\n",
    "    filenames = []\n",
    "\n",
    "    # Fill list with requested file paths\n",
    "    for i in range(len(subject_IDs)):\n",
    "        os.chdir(data_folder)  # os.path.join(data_folder, subject_IDs[i]))\n",
    "        try:\n",
    "            filenames.append(glob.glob('*' + subject_IDs[i] + filemapping[file_type])[0])\n",
    "        except IndexError:\n",
    "            # Return N/A if subject ID is not found\n",
    "            filenames.append('N/A')\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# Get timeseries arrays for list of subjects\n",
    "def get_timeseries(subject_list, atlas_name):\n",
    "    \"\"\"\n",
    "        subject_list : list of short subject IDs in string format\n",
    "        atlas_name   : the atlas based on which the timeseries are generated e.g. aal, cc200\n",
    "\n",
    "    returns:\n",
    "        time_series  : list of timeseries arrays, each of shape (timepoints x regions)\n",
    "    \"\"\"\n",
    "\n",
    "    timeseries = []\n",
    "    for i in range(len(subject_list)):\n",
    "        subject_folder = os.path.join(data_folder, subject_list[i])\n",
    "        ro_file = [f for f in os.listdir(subject_folder) if f.endswith('_rois_' + atlas_name + '.1D')]\n",
    "        fl = os.path.join(subject_folder, ro_file[0])\n",
    "        print(\"Reading timeseries file %s\" %fl)\n",
    "        timeseries.append(np.loadtxt(fl, skiprows=0))\n",
    "\n",
    "    return timeseries\n",
    "\n",
    "\n",
    "# Compute connectivity matrices\n",
    "def subject_connectivity(timeseries, subject, atlas_name, kind, save=True, save_path=data_folder):\n",
    "    \"\"\"\n",
    "        timeseries   : timeseries table for subject (timepoints x regions)\n",
    "        subject      : the subject ID\n",
    "        atlas_name   : name of the parcellation atlas used\n",
    "        kind         : the kind of connectivity to be used, e.g. lasso, partial correlation, correlation\n",
    "        save         : save the connectivity matrix to a file\n",
    "        save_path    : specify path to save the matrix if different from subject folder\n",
    "\n",
    "    returns:\n",
    "        connectivity : connectivity matrix (regions x regions)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Estimating %s matrix for subject %s\" % (kind, subject))\n",
    "\n",
    "    if kind in ['tangent', 'partial correlation', 'correlation']:\n",
    "        conn_measure = connectome.ConnectivityMeasure(kind=kind)\n",
    "        connectivity = conn_measure.fit_transform([timeseries])[0]\n",
    "\n",
    "    if save:\n",
    "        subject_file = os.path.join(save_path, subject,\n",
    "                                    subject + '_' + atlas_name + '_' + kind.replace(' ', '_') + '.mat')\n",
    "        sio.savemat(subject_file, {'connectivity': connectivity})\n",
    "\n",
    "    return connectivity\n",
    "\n",
    "\n",
    "# Get the list of subject IDs\n",
    "def get_ids(num_subjects=None):\n",
    "    \"\"\"\n",
    "\n",
    "    return:\n",
    "        subject_IDs    : list of all subject IDs\n",
    "    \"\"\"\n",
    "\n",
    "    subject_IDs = np.genfromtxt(os.path.join(data_folder, 'subject_IDs.txt'), dtype=str)\n",
    "\n",
    "    if num_subjects is not None:\n",
    "        subject_IDs = subject_IDs[:num_subjects]\n",
    "\n",
    "    return subject_IDs\n",
    "\n",
    "\n",
    "# Get phenotype values for a list of subjects\n",
    "def get_subject_score(subject_list, score):\n",
    "    scores_dict = {}\n",
    "\n",
    "    with open(phenotype) as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            if row['SUB_ID'] in subject_list:\n",
    "                scores_dict[row['SUB_ID']] = row[score]\n",
    "\n",
    "    return scores_dict\n",
    "\n",
    "# int cnt=0;\n",
    "# Dimensionality reduction step for the feature vector using a ridge classifier\n",
    "def feature_selection(matrix, labels, train_ind, fnum):\n",
    "    \"\"\"\n",
    "        matrix       : feature matrix (num_subjects x num_features)\n",
    "        labels       : ground truth labels (num_subjects x 1)\n",
    "        train_ind    : indices of the training samples\n",
    "        fnum         : size of the feature vector after feature selection\n",
    "\n",
    "    return:\n",
    "        x_data      : feature matrix of lower dimension (num_subjects x fnum)\n",
    "    \"\"\"\n",
    "\n",
    "    estimator = RidgeClassifier()\n",
    "    selector = RFE(estimator, n_features_to_select=fnum, step=100, verbose=1)\n",
    "#     print(cnt+1)\n",
    "#     cnt=cnt+1;\n",
    "    featureX = matrix[train_ind, :]\n",
    "    featureY = labels[train_ind]\n",
    "    selector = selector.fit(featureX, featureY.ravel())\n",
    "    x_data = selector.transform(matrix)\n",
    "\n",
    "    print(\"Number of labeled samples %d\" % len(train_ind))\n",
    "    print(\"Number of features selected %d\" % x_data.shape[1])\n",
    "\n",
    "    return x_data\n",
    "\n",
    "\n",
    "# Make sure each site is represented in the training set when selecting a subset of the training set\n",
    "def site_percentage(train_ind, perc, subject_list):\n",
    "    \"\"\"\n",
    "        train_ind    : indices of the training samples\n",
    "        perc         : percentage of training set used\n",
    "        subject_list : list of subject IDs\n",
    "\n",
    "    return:\n",
    "        labeled_indices      : indices of the subset of training samples\n",
    "    \"\"\"\n",
    "\n",
    "    train_list = subject_list[train_ind]\n",
    "    sites = get_subject_score(train_list, score='SITE_ID')\n",
    "    unique = np.unique(list(sites.values())).tolist()\n",
    "    site = np.array([unique.index(sites[train_list[x]]) for x in range(len(train_list))])\n",
    "\n",
    "    labeled_indices = []\n",
    "\n",
    "    for i in np.unique(site):\n",
    "        id_in_site = np.argwhere(site == i).flatten()\n",
    "\n",
    "        num_nodes = len(id_in_site)\n",
    "        labeled_num = int(round(perc * num_nodes))\n",
    "        labeled_indices.extend(train_ind[id_in_site[:labeled_num]])\n",
    "\n",
    "    return labeled_indices\n",
    "\n",
    "\n",
    "# Load precomputed fMRI connectivity networks\n",
    "def get_networks(subject_list, kind, atlas_name=\"aal\", variable='connectivity'):\n",
    "    \"\"\"\n",
    "        subject_list : list of subject IDs\n",
    "        kind         : the kind of connectivity to be used, e.g. lasso, partial correlation, correlation\n",
    "        atlas_name   : name of the parcellation atlas used\n",
    "        variable     : variable name in the .mat file that has been used to save the precomputed networks\n",
    "\n",
    "\n",
    "    return:\n",
    "        matrix      : feature matrix of connectivity networks (num_subjects x network_size)\n",
    "    \"\"\"\n",
    "\n",
    "    all_networks = []\n",
    "    for subject1 in subject_list:\n",
    "        fl = f'../Datasets/all_fc_matrix_rois_ez/matrix_rois_ez_{subject1}.mat'\n",
    "        try:  \n",
    "            matrix = sio.loadmat(fl)[variable]\n",
    "            all_networks.append(matrix)\n",
    "        except FileNotFoundError:\n",
    "            fl = f'../Datasets/all_fc_matrix_rois_ez/matrix_rois_ez_{50002}.mat'\n",
    "            matrix = sio.loadmat(fl)[variable]\n",
    "            all_networks.append(matrix)\n",
    "            \n",
    "            \n",
    "    # all_networks=np.array(all_networks)\n",
    "\n",
    "    idx = np.triu_indices_from(all_networks[0], 1)\n",
    "#     print(\"idx :- \",idx)\n",
    "    norm_networks = [np.arctanh(mat) if not np.all(np.abs(mat) == 1) else mat for mat in all_networks]\n",
    "#     print(\"norm_networks : \",norm_networks)\n",
    "    vec_networks = [mat[idx] for mat in norm_networks]\n",
    "#     print(\"vec_networks : \",vec_networks)\n",
    "    matrix = np.vstack(vec_networks)\n",
    "#     print(len(matrix) , \" matrix : \",matrix);\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# Construct the adjacency matrix of the population from phenotypic scores\n",
    "def create_affinity_graph_from_scores(scores, pd_dict):\n",
    "    num_nodes = len(pd_dict[scores[0]]) \n",
    "    graph = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    for l in scores:\n",
    "        label_dict = pd_dict[l]\n",
    "\n",
    "        if l in ['AGE_AT_SCAN', 'FIQ']:\n",
    "            for k in range(num_nodes):\n",
    "                for j in range(k + 1, num_nodes):\n",
    "                    try:\n",
    "                        val = abs(float(label_dict[k]) - float(label_dict[j]))\n",
    "                        if val < 2:\n",
    "                            graph[k, j] += 1\n",
    "                            graph[j, k] += 1\n",
    "                    except ValueError:  # missing label\n",
    "                        pass\n",
    "\n",
    "        else:\n",
    "            for k in range(num_nodes):\n",
    "                for j in range(k + 1, num_nodes):\n",
    "                    if label_dict[k] == label_dict[j]:\n",
    "                        graph[k, j] += 1\n",
    "                        graph[j, k] += 1\n",
    "\n",
    "    return graph\n",
    "\n",
    "def get_static_affinity_adj(features, pd_dict):\n",
    "    pd_affinity = create_affinity_graph_from_scores(['SEX', 'SITE_ID'], pd_dict) \n",
    "    distv = distance.pdist(features, metric='correlation') \n",
    "    dist = distance.squareform(distv)  \n",
    "    sigma = np.mean(dist)\n",
    "    feature_sim = np.exp(- dist ** 2 / (2 * sigma ** 2))\n",
    "    adj = pd_affinity * feature_sim  \n",
    "\n",
    "    return adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50e2f282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Local\\Temp\\ipykernel_2032\\3119403776.py:8: DeprecationWarning: Please use `eigsh` from the `scipy.sparse.linalg` namespace, the `scipy.sparse.linalg.eigen` namespace is deprecated.\n",
      "  from scipy.sparse.linalg.eigen import eigsh\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.spatial import distance\n",
    "from scipy.sparse.linalg.eigen import eigsh\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "def get_train_test_masks(labels, idx_train, idx_val, idx_test):\n",
    "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_test = np.zeros(labels.shape)\n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "    return y_train, y_val, y_test, train_mask, val_mask, test_mask\n",
    "\n",
    "def load_data(subject_IDs, params): \n",
    "    \n",
    "    # labels\n",
    "    num_classes = 2\n",
    "    num_nodes = len(subject_IDs)\n",
    "    \n",
    "    # 初始化y_data(), y\n",
    "    y_data = np.zeros([num_nodes, num_classes])\n",
    "    y = np.zeros([num_nodes, 1])\n",
    "    \n",
    "    labels = get_subject_score(subject_IDs, score='DX_GROUP')\n",
    "    features = get_networks(subject_IDs, kind=params['connectivity'], atlas_name=params['atlas'])\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        y_data[i, int(labels[subject_IDs[i]]) - 1] = 1 # (871,2)\n",
    "        y[i] = int(labels[subject_IDs[i]]) # (871,)\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    cv_splits = list(skf.split(features, np.squeeze(y)))\n",
    "    train = cv_splits[params['folds']][0]\n",
    "    test = cv_splits[params['folds']][1]\n",
    "    val = test\n",
    "    \n",
    "    print('Number of train sample:{}' .format(len(train)))\n",
    "        \n",
    "    y_train, y_val, y_test, train_mask, val_mask, test_mask = get_train_test_masks(y_data, train, val, test)\n",
    "    \n",
    "    y_data = torch.LongTensor(np.where(y_data)[1])\n",
    "    y = torch.LongTensor(y)\n",
    "    y_train = torch.LongTensor(y_train[1])\n",
    "    y_val = torch.LongTensor(y_val[1])\n",
    "    y_test = torch.LongTensor(y_test[1])\n",
    "    \n",
    "    train = torch.LongTensor(train)\n",
    "    val = torch.LongTensor(val)\n",
    "    test = torch.LongTensor(test)\n",
    "    train_mask = torch.LongTensor(train_mask)\n",
    "    val_mask = torch.LongTensor(val_mask)\n",
    "    test_mask = torch.LongTensor(test_mask)\n",
    "    \n",
    "    # Eigenvector\n",
    "    labeled_ind = site_percentage(train, params['num_training'], subject_IDs)\n",
    "    x_data = feature_selection(features, y, labeled_ind, params['num_features'])\n",
    "    features = preprocess_features(sp.coo_matrix(x_data).tolil())\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    \n",
    "    # Adjacency matrix\n",
    "    graph = create_affinity_graph_from_scores(['SEX', 'SITE_ID'], subject_IDs)\n",
    "    distv = distance.pdist(x_data, metric='correlation')\n",
    "    dist = distance.squareform(distv)\n",
    "    sigma = np.mean(dist)\n",
    "    sparse_graph = np.exp(- dist ** 2 / (2 * sigma ** 2))\n",
    "    final_graph = graph * sparse_graph\n",
    "\n",
    "    return final_graph, features, y, y_data, y_train, y_val, y_test, train, val, test, train_mask, val_mask, test_mask\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
    "    def to_tuple(mx):\n",
    "        if not sp.isspmatrix_coo(mx):\n",
    "            mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "        values = mx.data\n",
    "        shape = mx.shape\n",
    "        coords = torch.from_numpy(coords)\n",
    "        values = torch.from_numpy(values)\n",
    "        shape = torch.tensor(shape)\n",
    "        return coords, values, shape\n",
    "\n",
    "    if isinstance(sparse_mx, list):\n",
    "        for i in range(len(sparse_mx)):\n",
    "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
    "    else:\n",
    "        sparse_mx = to_tuple(sparse_mx)\n",
    "\n",
    "    return sparse_mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "\n",
    "def preprocess_features(features):\n",
    "    \"\"\"Row-normalize feature matrix\"\"\"\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return features\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    \"\"\"Preprocessing of adjacency matrix for simple GCN model.\"\"\"\n",
    "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    return adj_normalized\n",
    "\n",
    "def chebyshev_polynomials(adj, k):\n",
    "    \"\"\"Calculate Chebyshev polynomials up to order k. Return a list of sparse matrices (tuple representation).\"\"\"\n",
    "    print(\"Calculating Chebyshev polynomials up to order {}...\".format(k))\n",
    "\n",
    "    adj_normalized = normalize_adj(adj)\n",
    "    laplacian = sp.eye(adj.shape[0]) - adj_normalized\n",
    "    largest_eigval, _ = eigsh(laplacian, 1, which='LM')\n",
    "    scaled_laplacian = (2. / largest_eigval[0]) * laplacian - sp.eye(adj.shape[0])\n",
    "\n",
    "    t_k = list()\n",
    "    t_k.append(sp.eye(adj.shape[0]))\n",
    "    t_k.append(scaled_laplacian)\n",
    "\n",
    "    def chebyshev_recurrence(t_k_minus_one, t_k_minus_two, scaled_lap):\n",
    "        s_lap = sp.csr_matrix(scaled_lap, copy=True)\n",
    "        return 2 * s_lap.dot(t_k_minus_one) - t_k_minus_two\n",
    "\n",
    "    for i in range(2, k+1):\n",
    "        t_k.append(chebyshev_recurrence(t_k[-1], t_k[-2], scaled_laplacian))\n",
    "\n",
    "    return t_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7980a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# from utils import preprocess_features\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "class dataloader():\n",
    "    def __init__(self): \n",
    "        self.pd_dict = {}\n",
    "        self.node_ftr_dim = 2000\n",
    "        self.num_classes = 2 \n",
    "\n",
    "    def load_data(self, params, connectivity='correlation', atlas='ho'):\n",
    "        ''' load multimodal data from ABIDE\n",
    "        return: imaging features (raw), labels, non-image data\n",
    "        '''\n",
    "        subject_IDs = get_ids()\n",
    "        labels = get_subject_score(subject_IDs, score='DX_GROUP')\n",
    "        num_nodes = len(subject_IDs)\n",
    "\n",
    "        sites = get_subject_score(subject_IDs, score='SITE_ID')\n",
    "        unique = np.unique(list(sites.values())).tolist()\n",
    "        ages = get_subject_score(subject_IDs, score='AGE_AT_SCAN')\n",
    "        genders = get_subject_score(subject_IDs, score='SEX') \n",
    "\n",
    "        y_onehot = np.zeros([num_nodes, self.num_classes])\n",
    "        y = np.zeros([num_nodes])\n",
    "        site = np.zeros([num_nodes], dtype=int)\n",
    "        age = np.zeros([num_nodes], dtype=np.float32)\n",
    "        gender = np.zeros([num_nodes], dtype=int)\n",
    "        for i in range(num_nodes):\n",
    "            y_onehot[i, int(labels[subject_IDs[i]])-1] = 1\n",
    "            y[i] = int(labels[subject_IDs[i]])\n",
    "            site[i] = unique.index(sites[subject_IDs[i]])\n",
    "            age[i] = float(ages[subject_IDs[i]])\n",
    "            gender[i] = genders[subject_IDs[i]]\n",
    "        \n",
    "        self.y = y -1  \n",
    "\n",
    "        self.raw_features = get_networks(subject_IDs, kind=connectivity, atlas_name=atlas)\n",
    "\n",
    "        phonetic_data = np.zeros([num_nodes, 3], dtype=np.float32)\n",
    "        phonetic_data[:,0] = site \n",
    "        phonetic_data[:,1] = gender \n",
    "        phonetic_data[:,2] = age \n",
    "\n",
    "        self.pd_dict['SITE_ID'] = np.copy(phonetic_data[:,0])\n",
    "        self.pd_dict['SEX'] = np.copy(phonetic_data[:,1])\n",
    "        self.pd_dict['AGE_AT_SCAN'] = np.copy(phonetic_data[:,2]) \n",
    "        \n",
    "        return self.raw_features, self.y, phonetic_data\n",
    "\n",
    "    def data_split(self, n_folds):\n",
    "        # split data by k-fold CV\n",
    "        skf = StratifiedKFold(n_splits=n_folds)\n",
    "        print(\"skf : \",skf)\n",
    "        cv_splits = list(skf.split(self.raw_features, self.y))\n",
    "#         print(\"cv_splits : \",len(cv_splits))\n",
    "#         x=len(cv_splits);\n",
    "#         for i in range(x):\n",
    "#             y=len(cv_splits[i]);\n",
    "#             for j in range(y):\n",
    "#                 z=len(cv_splits[i][j])\n",
    "#                 print(z)\n",
    "            \n",
    "#         print(\"cv_splits : \",cv_splits  )\n",
    "        return cv_splits \n",
    "\n",
    "    def get_node_features(self, train_ind):\n",
    "        '''preprocess node features for wl-deepgcn\n",
    "        '''\n",
    "        node_ftr = feature_selection(self.raw_features, self.y, train_ind, self.node_ftr_dim)\n",
    "        self.node_ftr = preprocess_features(node_ftr) \n",
    "        return self.node_ftr\n",
    "\n",
    "    def get_WL_inputs(self, nonimg):\n",
    "        '''get WL inputs for wl-deepgcn \n",
    "        '''\n",
    "        # construct edge network inputs \n",
    "        n = self.node_ftr.shape[0] \n",
    "        num_edge = n*(1+n)//2 - n  # n*(n-1)//2,HO=6105\n",
    "        pd_ftr_dim = nonimg.shape[1]\n",
    "        edge_index = np.zeros([2, num_edge], dtype=np.int64) \n",
    "        edgenet_input = np.zeros([num_edge, 2*pd_ftr_dim], dtype=np.float32)  \n",
    "        aff_score = np.zeros(num_edge, dtype=np.float32)\n",
    "        # static affinity score used to pre-prune edges \n",
    "        aff_adj = get_static_affinity_adj(self.node_ftr, self.pd_dict)  \n",
    "        flatten_ind = 0 \n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                edge_index[:,flatten_ind] = [i,j]\n",
    "                edgenet_input[flatten_ind]  = np.concatenate((nonimg[i], nonimg[j]))\n",
    "                aff_score[flatten_ind] = aff_adj[i][j]  \n",
    "                flatten_ind +=1\n",
    "\n",
    "        assert flatten_ind == num_edge, \"Error in computing edge input\"\n",
    "        \n",
    "        keep_ind = np.where(aff_score > 1.1)[0]  \n",
    "        edge_index = edge_index[:, keep_ind]\n",
    "        edgenet_input = edgenet_input[keep_ind]\n",
    "\n",
    "        return edge_index, edgenet_input\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abc69f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn import Linear as Lin, Sequential as Seq\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class WL(torch.nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.3):\n",
    "        super(WL, self).__init__()\n",
    "        h1=256\n",
    "        h2=128\n",
    "        self.parser =nn.Sequential(\n",
    "                nn.Linear(input_dim, h1, bias=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.BatchNorm1d(h1),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(h1, h2, bias=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.BatchNorm1d(h2),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(h2, h2, bias=True),\n",
    "                )\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-8)\n",
    "        self.input_dim = input_dim\n",
    "        self.model_init()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.elu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = x[:,0:self.input_dim]\n",
    "        x2 = x[:,self.input_dim:]\n",
    "        h1 = self.parser(x1) \n",
    "        h2 = self.parser(x2) \n",
    "        p = (self.cos(h1,h2) + 1)*0.5\n",
    "        return p\n",
    "\n",
    "    def model_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Lin):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                m.weight.requires_grad = True\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    m.bias.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6db8243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import Linear as Lin, Sequential as Seq\n",
    "import torch_geometric as tg\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, nhid):\n",
    "        super(MLP,self).__init__()\n",
    "        self.cls = nn.Sequential(\n",
    "            torch.nn.Linear(input_dim,nhid))\n",
    "        \n",
    "    def forward(self, features):\n",
    "        output = self.cls(features)\n",
    "        return output\n",
    "            \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, nhid, num_classes, ngl, dropout, edge_dropout, edgenet_input_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        print(\"phele init mai\")\n",
    "        K=3   \n",
    "        hidden = [nhid for i in range(ngl)] \n",
    "        self.dropout = dropout\n",
    "        self.edge_dropout = edge_dropout \n",
    "        bias = False \n",
    "        self.relu = torch.nn.ReLU(inplace=True) \n",
    "        self.ngl = ngl \n",
    "        self.gconv = nn.ModuleList()\n",
    "        for i in range(ngl):\n",
    "            in_channels = input_dim if i==0  else hidden[i-1]\n",
    "            print(i,\" -- \",in_channels)\n",
    "            self.gconv.append(tg.nn.ChebConv(in_channels, hidden[i], K, normalization='sym', bias=bias)) \n",
    "        print(\"start\")  \n",
    "        self.cls = nn.Sequential(\n",
    "                torch.nn.Linear(16, 128),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(128), \n",
    "                torch.nn.Linear(128, num_classes))\n",
    "        print(\"end\")\n",
    "        self.edge_net = WL(input_dim=edgenet_input_dim//2, dropout=dropout)\n",
    "        self.model_init()\n",
    "\n",
    "    def model_init(self):\n",
    "        print(\"welecome in model_init\")\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Lin):\n",
    "                torch.nn.init.kaiming_normal_(m.weight) # He init\n",
    "                m.weight.requires_grad = True\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    m.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, features, edge_index, edgenet_input, enforce_edropout=False): \n",
    "        print(\"welcome in forward\")\n",
    "        if self.edge_dropout>0:\n",
    "            if enforce_edropout or self.training:\n",
    "                one_mask = torch.ones([edgenet_input.shape[0],1])\n",
    "                self.drop_mask = F.dropout(one_mask, self.edge_dropout, True)\n",
    "                self.bool_mask = torch.squeeze(self.drop_mask.type(torch.bool))\n",
    "                edge_index = edge_index[:, self.bool_mask] \n",
    "                edgenet_input = edgenet_input[self.bool_mask] # Weights\n",
    "            \n",
    "        edge_weight = torch.squeeze(self.edge_net(edgenet_input))\n",
    "        \n",
    "\n",
    "        # GCN residual connection\n",
    "        # input layer\n",
    "        print(\"welcome in input layer\")\n",
    "        features = F.dropout(features, self.dropout, self.training)\n",
    "        x = self.relu(self.gconv[0](features, edge_index, edge_weight)) \n",
    "        x_temp = x\n",
    "        \n",
    "        # hidden layers\n",
    "        print(\"hidden layer\")\n",
    "        for i in range(1, self.ngl - 1): # self.ngl→7\n",
    "            x = F.dropout(x_temp, self.dropout, self.training)\n",
    "            x = self.relu(self.gconv[i](x, edge_index, edge_weight)) \n",
    "            x_temp = x_temp + x # ([871,64])\n",
    "\n",
    "        # output layer\n",
    "        print(\"output layer\")\n",
    "        x = F.dropout(x_temp, self.dropout, self.training)\n",
    "        x = self.relu(self.gconv[self.ngl - 1](x, edge_index, edge_weight))\n",
    "        x_temp = x_temp + x\n",
    "\n",
    "        output = x # Final output is not cumulative\n",
    "        output = self.cls(output) \n",
    "        print(output ,  edge_weight)        \n",
    "        return output, edge_weight\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "165d107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5856d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import MulticlassSpecificity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def torchmetrics_accuracy(preds, labels):\n",
    "    acc = torchmetrics.functional.accuracy(preds, labels,task=\"multiclass\", num_classes=2)\n",
    "    return acc\n",
    "\n",
    "def torchmetrics_spef(preds, labels):\n",
    "    metric = MulticlassSpecificity(num_classes=2)\n",
    "    spef = metric(preds, labels)\n",
    "    return spef\n",
    "\n",
    "def torchmetrics_auc(preds, labels):\n",
    "    auc = torchmetrics.functional.auroc(preds, labels, task=\"multiclass\", num_classes=2)\n",
    "    return auc\n",
    "\n",
    "def confusion_matrix(preds, labels):\n",
    "    conf_matrix = torch.zeros(2, 2)\n",
    "    preds = torch.argmax(preds, 1)\n",
    "    for p, t in zip(preds, labels):\n",
    "        conf_matrix[t, p] += 1 \n",
    "    return conf_matrix\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    Input\n",
    "    - cm : computer the value of confusion matrix\n",
    "    - normalize : True: %, False: 123\n",
    "    \"\"\"\n",
    "    classes = ['0:ASD','1:TC']\n",
    "    if normalize:\n",
    "        cm = cm.numpy()\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def correct_num(preds, labels):\n",
    "    \"\"\"Accuracy, auc with masking.Acc of the masked samples\"\"\"\n",
    "    correct_prediction = np.equal(np.argmax(preds, 1), labels).astype(np.float32)\n",
    "    return np.sum(correct_prediction)\n",
    "\n",
    "def prf(preds, labels, is_logit=True):\n",
    "    ''' input: logits, labels  ''' \n",
    "    pred_lab= np.argmax(preds, 1)\n",
    "    p,r,f,s  = precision_recall_fscore_support(labels, pred_lab, average='binary')\n",
    "    return [p,r,f]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae068d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ba9682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "no_cuda: False\n",
      "seed: 46\n",
      "epochs: 10\n",
      "lr: 0.001\n",
      "weight_decay: 5e-05\n",
      "hidden: 16\n",
      "dropout: 0.2\n",
      "atlas: ez\n",
      "num_features: 2000\n",
      "folds: 2\n",
      "connectivity: correlation\n",
      "max_degree: 3\n",
      "ngl: 8\n",
      "edropout: 0.3\n",
      "train: 1\n",
      "ckpt_path: ../folds/rois_ez_pth_b\n",
      "early_stopping: True\n",
      "early_stopping_patience: 20\n",
      "cuda: False\n",
      "  Loading dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Local\\Temp\\ipykernel_2032\\4253426024.py:218: RuntimeWarning: divide by zero encountered in arctanh\n",
      "  norm_networks = [np.arctanh(mat) if not np.all(np.abs(mat) == 1) else mat for mat in all_networks]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skf :  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "Size of the 1-fold Training, Validation, and Test Sets:500,56,556\n",
      " Starting the 1-1 Fold:：\n",
      "Fitting estimator with 4656 features.\n",
      "Fitting estimator with 4556 features.\n",
      "Fitting estimator with 4456 features.\n",
      "Fitting estimator with 4356 features.\n",
      "Fitting estimator with 4256 features.\n",
      "Fitting estimator with 4156 features.\n",
      "Fitting estimator with 4056 features.\n",
      "Fitting estimator with 3956 features.\n",
      "Fitting estimator with 3856 features.\n",
      "Fitting estimator with 3756 features.\n",
      "Fitting estimator with 3656 features.\n",
      "Fitting estimator with 3556 features.\n",
      "Fitting estimator with 3456 features.\n",
      "Fitting estimator with 3356 features.\n",
      "Fitting estimator with 3256 features.\n",
      "Fitting estimator with 3156 features.\n",
      "Fitting estimator with 3056 features.\n",
      "Fitting estimator with 2956 features.\n",
      "Fitting estimator with 2856 features.\n",
      "Fitting estimator with 2756 features.\n",
      "Fitting estimator with 2656 features.\n",
      "Fitting estimator with 2556 features.\n",
      "Fitting estimator with 2456 features.\n",
      "Fitting estimator with 2356 features.\n",
      "Fitting estimator with 2256 features.\n",
      "Fitting estimator with 2156 features.\n",
      "Fitting estimator with 2056 features.\n",
      "Number of labeled samples 500\n",
      "Number of features selected 2000\n",
      "phele init mai\n",
      "0  --  2000\n",
      "1  --  16\n",
      "2  --  16\n",
      "3  --  16\n",
      "4  --  16\n",
      "5  --  16\n",
      "6  --  16\n",
      "7  --  16\n",
      "start\n",
      "end\n",
      "welecome in model_init\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1975,  0.0553],\n",
      "        [ 0.1455, -0.0450],\n",
      "        [ 0.1465, -0.0017],\n",
      "        ...,\n",
      "        [-0.1387,  0.1572],\n",
      "        [ 0.3346, -0.1061],\n",
      "        [ 0.3390,  0.0486]], grad_fn=<AddmmBackward0>) tensor([0.6872, 0.5068, 0.5149,  ..., 0.6384, 0.7894, 0.6033],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0047, -0.0049],\n",
      "        [ 0.0069, -0.0054],\n",
      "        [ 0.0073, -0.0070],\n",
      "        ...,\n",
      "        [ 0.0043, -0.0077],\n",
      "        [ 0.0074, -0.0082],\n",
      "        [ 0.0074, -0.0059]]) tensor([0.5879, 0.7095, 0.5122,  ..., 0.9993, 0.9951, 0.9905])\n",
      "Epoch:0001\n",
      "acc_train:0.4840 pre_train:0.5041 recall_train:0.4692 F1_train:0.4861 AUC_train:0.4878\n",
      "acc_val:0.6607 pre_val:0.5952 recall_val:0.9259 F1_val:0.724638 AUC_val:0.8059\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.5945, -0.1837],\n",
      "        [ 0.0576, -0.2589],\n",
      "        [-0.1864, -0.2923],\n",
      "        ...,\n",
      "        [ 0.2319, -0.2671],\n",
      "        [-0.1864, -0.3924],\n",
      "        [-0.1184, -0.3533]], grad_fn=<AddmmBackward0>) tensor([0.6793, 0.6814, 0.5128,  ..., 0.8009, 0.6667, 0.8316],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0212, -0.0028],\n",
      "        [ 0.0234, -0.0049],\n",
      "        [ 0.0234, -0.0044],\n",
      "        ...,\n",
      "        [ 0.0209, -0.0049],\n",
      "        [ 0.0235, -0.0056],\n",
      "        [ 0.0239, -0.0061]]) tensor([0.4862, 0.6332, 0.3453,  ..., 0.9978, 0.9836, 0.9693])\n",
      "Epoch:0002\n",
      "acc_train:0.5600 pre_train:0.6190 recall_train:0.4000 F1_train:0.4860 AUC_train:0.5581\n",
      "acc_val:0.6607 pre_val:0.6000 recall_val:0.8889 F1_val:0.716418 AUC_val:0.8289\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.3469, -0.2682],\n",
      "        [ 0.1512, -0.2032],\n",
      "        [ 0.4558, -0.4862],\n",
      "        ...,\n",
      "        [-0.2932, -0.5074],\n",
      "        [ 1.0030, -0.2928],\n",
      "        [-0.2052, -0.5427]], grad_fn=<AddmmBackward0>) tensor([0.5132, 0.6984, 0.6342,  ..., 0.7323, 0.7630, 0.6626],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0438,  0.0004],\n",
      "        [ 0.0454, -0.0044],\n",
      "        [ 0.0449, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0444, -0.0027],\n",
      "        [ 0.0455, -0.0033],\n",
      "        [ 0.0458, -0.0071]]) tensor([0.5717, 0.6529, 0.3580,  ..., 0.9951, 0.9599, 0.9287])\n",
      "Epoch:0003\n",
      "acc_train:0.5880 pre_train:0.6406 recall_train:0.4731 F1_train:0.5442 AUC_train:0.6136\n",
      "acc_val:0.6786 pre_val:0.6154 recall_val:0.8889 F1_val:0.727273 AUC_val:0.8276\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.3233, -0.3524],\n",
      "        [-0.0633, -0.5271],\n",
      "        [-0.0706, -0.1863],\n",
      "        ...,\n",
      "        [ 0.4473, -0.3979],\n",
      "        [ 0.1277,  0.0571],\n",
      "        [-0.4927, -0.7238]], grad_fn=<AddmmBackward0>) tensor([0.6186, 0.5824, 0.7626,  ..., 0.6842, 0.5950, 0.6760],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0668, -0.0096],\n",
      "        [ 0.0660, -0.0123],\n",
      "        [ 0.0658, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0659, -0.0108],\n",
      "        [ 0.0667, -0.0117],\n",
      "        [ 0.0663, -0.0157]]) tensor([0.6562, 0.6788, 0.4072,  ..., 0.9912, 0.9395, 0.8867])\n",
      "Epoch:0004\n",
      "acc_train:0.5860 pre_train:0.6345 recall_train:0.4808 F1_train:0.5470 AUC_train:0.5918\n",
      "acc_val:0.6607 pre_val:0.6053 recall_val:0.8519 F1_val:0.707692 AUC_val:0.8250\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1419, -0.2736],\n",
      "        [ 0.9410, -0.5761],\n",
      "        [-0.1475, -0.6157],\n",
      "        ...,\n",
      "        [ 0.4489, -0.1795],\n",
      "        [ 0.2149, -0.0792],\n",
      "        [ 0.4621, -0.6366]], grad_fn=<AddmmBackward0>) tensor([0.6143, 0.5745, 0.5853,  ..., 0.7492, 0.7647, 0.6707],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0971, -0.0233],\n",
      "        [ 0.0950, -0.0237],\n",
      "        [ 0.0950, -0.0200],\n",
      "        ...,\n",
      "        [ 0.0951, -0.0223],\n",
      "        [ 0.0966, -0.0262],\n",
      "        [ 0.0955, -0.0291]]) tensor([0.7176, 0.7005, 0.4618,  ..., 0.9865, 0.9295, 0.8572])\n",
      "Epoch:0005\n",
      "acc_train:0.6440 pre_train:0.7071 recall_train:0.5385 F1_train:0.6114 AUC_train:0.6720\n",
      "acc_val:0.7321 pre_val:0.7000 recall_val:0.7778 F1_val:0.736842 AUC_val:0.8263\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.5371, -0.6663],\n",
      "        [ 0.2442, -0.9947],\n",
      "        [-0.5454, -0.9854],\n",
      "        ...,\n",
      "        [ 0.0746, -0.4942],\n",
      "        [-0.0652, -0.6120],\n",
      "        [ 0.3103, -0.9187]], grad_fn=<AddmmBackward0>) tensor([0.6382, 0.6427, 0.5148,  ..., 0.7706, 0.6784, 0.6319],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1224, -0.0408],\n",
      "        [ 0.1189, -0.0394],\n",
      "        [ 0.1189, -0.0366],\n",
      "        ...,\n",
      "        [ 0.1193, -0.0382],\n",
      "        [ 0.1217, -0.0436],\n",
      "        [ 0.1199, -0.0459]]) tensor([0.7578, 0.7122, 0.5059,  ..., 0.9826, 0.9255, 0.8411])\n",
      "Epoch:0006\n",
      "acc_train:0.6480 pre_train:0.7100 recall_train:0.5462 F1_train:0.6174 AUC_train:0.6765\n",
      "acc_val:0.8036 pre_val:0.8333 recall_val:0.7407 F1_val:0.784314 AUC_val:0.8289\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.8890, -0.3336],\n",
      "        [ 0.7972, -0.5253],\n",
      "        [ 0.1994, -0.0353],\n",
      "        ...,\n",
      "        [ 0.8680, -0.7549],\n",
      "        [ 0.8583, -0.0761],\n",
      "        [ 0.3881, -0.5336]], grad_fn=<AddmmBackward0>) tensor([0.7648, 0.5075, 0.6260,  ..., 0.7189, 0.7165, 0.6884],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1441, -0.0596],\n",
      "        [ 0.1390, -0.0569],\n",
      "        [ 0.1388, -0.0541],\n",
      "        ...,\n",
      "        [ 0.1401, -0.0560],\n",
      "        [ 0.1426, -0.0621],\n",
      "        [ 0.1404, -0.0643]]) tensor([0.7850, 0.7154, 0.5438,  ..., 0.9797, 0.9258, 0.8350])\n",
      "Epoch:0007\n",
      "acc_train:0.6780 pre_train:0.7705 recall_train:0.5423 F1_train:0.6366 AUC_train:0.7013\n",
      "acc_val:0.8036 pre_val:0.8333 recall_val:0.7407 F1_val:0.784314 AUC_val:0.8263\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1178, -0.9079],\n",
      "        [ 0.1122, -0.5012],\n",
      "        [ 0.6405, -0.5348],\n",
      "        ...,\n",
      "        [ 0.1599, -0.6665],\n",
      "        [ 0.8398, -0.4430],\n",
      "        [ 0.2760, -0.2399]], grad_fn=<AddmmBackward0>) tensor([0.6684, 0.6295, 0.5391,  ..., 0.7022, 0.7905, 0.6981],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1627, -0.0800],\n",
      "        [ 0.1562, -0.0761],\n",
      "        [ 0.1557, -0.0733],\n",
      "        ...,\n",
      "        [ 0.1576, -0.0752],\n",
      "        [ 0.1601, -0.0818],\n",
      "        [ 0.1580, -0.0846]]) tensor([0.7995, 0.7128, 0.5731,  ..., 0.9788, 0.9292, 0.8373])\n",
      "Epoch:0008\n",
      "acc_train:0.6940 pre_train:0.7610 recall_train:0.6000 F1_train:0.6710 AUC_train:0.7343\n",
      "acc_val:0.8036 pre_val:0.8333 recall_val:0.7407 F1_val:0.784314 AUC_val:0.8276\n",
      "welcome in forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.4437, -0.6517],\n",
      "        [ 0.2119, -0.1788],\n",
      "        [ 0.6277, -0.3773],\n",
      "        ...,\n",
      "        [ 0.7843, -0.3126],\n",
      "        [ 0.2980, -0.6912],\n",
      "        [ 0.9487, -0.3802]], grad_fn=<AddmmBackward0>) tensor([0.6565, 0.5817, 0.5389,  ..., 0.6978, 0.7676, 0.7022],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1787, -0.1002],\n",
      "        [ 0.1705, -0.0949],\n",
      "        [ 0.1694, -0.0917],\n",
      "        ...,\n",
      "        [ 0.1717, -0.0937],\n",
      "        [ 0.1745, -0.1010],\n",
      "        [ 0.1729, -0.1042]]) tensor([0.8082, 0.7037, 0.5938,  ..., 0.9797, 0.9340, 0.8447])\n",
      "Epoch:0009\n",
      "acc_train:0.6840 pre_train:0.7297 recall_train:0.6231 F1_train:0.6722 AUC_train:0.7295\n",
      "acc_val:0.8036 pre_val:0.8333 recall_val:0.7407 F1_val:0.784314 AUC_val:0.8314\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.3452, -0.3379],\n",
      "        [ 0.5369, -0.3754],\n",
      "        [ 1.3657, -0.1921],\n",
      "        ...,\n",
      "        [-0.0524, -0.4106],\n",
      "        [ 0.2373, -0.2868],\n",
      "        [ 0.2991, -0.3006]], grad_fn=<AddmmBackward0>) tensor([0.7690, 0.5501, 0.6501,  ..., 0.7971, 0.7940, 0.7123],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1884, -0.1179],\n",
      "        [ 0.1777, -0.1096],\n",
      "        [ 0.1761, -0.1057],\n",
      "        ...,\n",
      "        [ 0.1783, -0.1080],\n",
      "        [ 0.1821, -0.1168],\n",
      "        [ 0.1810, -0.1200]]) tensor([0.8150, 0.6955, 0.6106,  ..., 0.9804, 0.9390, 0.8534])\n",
      "Epoch:0010\n",
      "acc_train:0.6800 pre_train:0.7212 recall_train:0.6269 F1_train:0.6708 AUC_train:0.7277\n",
      "acc_val:0.8036 pre_val:0.8333 recall_val:0.7407 F1_val:0.784314 AUC_val:0.8314\n",
      " Starting the 1-2 Fold:：\n",
      "Fitting estimator with 4656 features.\n",
      "Fitting estimator with 4556 features.\n",
      "Fitting estimator with 4456 features.\n",
      "Fitting estimator with 4356 features.\n",
      "Fitting estimator with 4256 features.\n",
      "Fitting estimator with 4156 features.\n",
      "Fitting estimator with 4056 features.\n",
      "Fitting estimator with 3956 features.\n",
      "Fitting estimator with 3856 features.\n",
      "Fitting estimator with 3756 features.\n",
      "Fitting estimator with 3656 features.\n",
      "Fitting estimator with 3556 features.\n",
      "Fitting estimator with 3456 features.\n",
      "Fitting estimator with 3356 features.\n",
      "Fitting estimator with 3256 features.\n",
      "Fitting estimator with 3156 features.\n",
      "Fitting estimator with 3056 features.\n",
      "Fitting estimator with 2956 features.\n",
      "Fitting estimator with 2856 features.\n",
      "Fitting estimator with 2756 features.\n",
      "Fitting estimator with 2656 features.\n",
      "Fitting estimator with 2556 features.\n",
      "Fitting estimator with 2456 features.\n",
      "Fitting estimator with 2356 features.\n",
      "Fitting estimator with 2256 features.\n",
      "Fitting estimator with 2156 features.\n",
      "Fitting estimator with 2056 features.\n",
      "Number of labeled samples 500\n",
      "Number of features selected 2000\n",
      "phele init mai\n",
      "0  --  2000\n",
      "1  --  16\n",
      "2  --  16\n",
      "3  --  16\n",
      "4  --  16\n",
      "5  --  16\n",
      "6  --  16\n",
      "7  --  16\n",
      "start\n",
      "end\n",
      "welecome in model_init\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-1.2105,  0.1402],\n",
      "        [-0.4175,  0.3259],\n",
      "        [-0.2190,  0.6708],\n",
      "        ...,\n",
      "        [ 0.8429, -0.5906],\n",
      "        [ 1.6779, -0.2660],\n",
      "        [ 0.0911,  0.3428]], grad_fn=<AddmmBackward0>) tensor([0.7332, 0.6639, 0.5161,  ..., 0.8333, 0.7291, 0.6629],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0907, -0.0078],\n",
      "        [ 0.0551, -0.0049],\n",
      "        [ 0.0743, -0.0074],\n",
      "        ...,\n",
      "        [ 0.0541, -0.0038],\n",
      "        [ 0.1279, -0.0108],\n",
      "        [ 0.0506, -0.0057]]) tensor([0.6559, 0.5892, 0.5873,  ..., 0.9994, 0.9961, 0.9922])\n",
      "Epoch:0001\n",
      "acc_train:0.5300 pre_train:0.5405 recall_train:0.6423 F1_train:0.5870 AUC_train:0.5438\n",
      "acc_val:0.5179 pre_val:0.0000 recall_val:0.0000 F1_val:0.000000 AUC_val:0.3384\n",
      "welcome in forward\n",
      "welcome in input layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.5973,  0.6137],\n",
      "        [ 0.2363, -0.1736],\n",
      "        [ 1.8892, -0.5434],\n",
      "        ...,\n",
      "        [-0.1248, -0.4763],\n",
      "        [ 2.1963, -2.1081],\n",
      "        [-0.1464,  0.4845]], grad_fn=<AddmmBackward0>) tensor([0.6863, 0.5224, 0.5971,  ..., 0.8317, 0.7391, 0.6792],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1181, -0.0234],\n",
      "        [ 0.0896, -0.0166],\n",
      "        [ 0.0898, -0.0184],\n",
      "        ...,\n",
      "        [ 0.0615, -0.0160],\n",
      "        [ 0.1564, -0.0205],\n",
      "        [ 0.0684, -0.0203]]) tensor([0.5562, 0.4831, 0.4223,  ..., 0.9983, 0.9889, 0.9780])\n",
      "Epoch:0002\n",
      "acc_train:0.5800 pre_train:0.5801 recall_train:0.6962 F1_train:0.6329 AUC_train:0.6168\n",
      "acc_val:0.5179 pre_val:0.0000 recall_val:0.0000 F1_val:0.000000 AUC_val:0.3142\n",
      "welcome in forward\n",
      "welcome in input layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 1.5703,  0.0848],\n",
      "        [ 1.7390, -0.6462],\n",
      "        [ 0.5184,  0.2027],\n",
      "        ...,\n",
      "        [ 0.3871, -0.3928],\n",
      "        [ 2.4983, -1.2167],\n",
      "        [ 1.2144, -1.4207]], grad_fn=<AddmmBackward0>) tensor([0.7447, 0.5780, 0.5589,  ..., 0.7094, 0.7464, 0.7163],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1778, -0.0279],\n",
      "        [ 0.1541, -0.0224],\n",
      "        [ 0.1439, -0.0246],\n",
      "        ...,\n",
      "        [ 0.0777, -0.0241],\n",
      "        [ 0.2111, -0.0243],\n",
      "        [ 0.1207, -0.0264]]) tensor([0.5895, 0.5275, 0.4021,  ..., 0.9966, 0.9789, 0.9581])\n",
      "Epoch:0003\n",
      "acc_train:0.5820 pre_train:0.5882 recall_train:0.6538 F1_train:0.6193 AUC_train:0.6375\n",
      "acc_val:0.5179 pre_val:0.0000 recall_val:0.0000 F1_val:0.000000 AUC_val:0.3244\n",
      "welcome in forward\n",
      "welcome in input layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0300, -0.6459],\n",
      "        [ 0.4036,  0.0843],\n",
      "        [ 0.3603, -1.5889],\n",
      "        ...,\n",
      "        [-0.1808,  0.2828],\n",
      "        [ 1.0418, -0.8661],\n",
      "        [ 0.6910, -0.6123]], grad_fn=<AddmmBackward0>) tensor([0.6930, 0.6262, 0.5536,  ..., 0.8390, 0.7009, 0.7082],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.2245, -0.0223],\n",
      "        [ 0.1930, -0.0184],\n",
      "        [ 0.1878, -0.0207],\n",
      "        ...,\n",
      "        [ 0.1150, -0.0247],\n",
      "        [ 0.2496, -0.0175],\n",
      "        [ 0.1655, -0.0251]]) tensor([0.6467, 0.5742, 0.4239,  ..., 0.9946, 0.9676, 0.9354])\n",
      "Epoch:0004\n",
      "acc_train:0.6100 pre_train:0.6117 recall_train:0.6846 F1_train:0.6461 AUC_train:0.6858\n",
      "acc_val:0.5000 pre_val:0.3333 recall_val:0.0370 F1_val:0.066667 AUC_val:0.3512\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0398, -3.5150],\n",
      "        [ 1.2396, -0.8540],\n",
      "        [-0.0764, -0.5226],\n",
      "        ...,\n",
      "        [ 1.0984,  0.1374],\n",
      "        [-0.2559, -0.6945],\n",
      "        [ 1.2042, -0.4282]], grad_fn=<AddmmBackward0>) tensor([0.7574, 0.5643, 0.5063,  ..., 0.7367, 0.8277, 0.5818],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.2677, -0.0175],\n",
      "        [ 0.2290, -0.0151],\n",
      "        [ 0.2227, -0.0186],\n",
      "        ...,\n",
      "        [ 0.1540, -0.0269],\n",
      "        [ 0.2902, -0.0121],\n",
      "        [ 0.2009, -0.0240]]) tensor([0.6994, 0.6003, 0.4579,  ..., 0.9927, 0.9564, 0.9135])\n",
      "Epoch:0005\n",
      "acc_train:0.6500 pre_train:0.6545 recall_train:0.6923 F1_train:0.6729 AUC_train:0.7050\n",
      "acc_val:0.4286 pre_val:0.1429 recall_val:0.0370 F1_val:0.058824 AUC_val:0.3985\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 1.3899, -1.1781],\n",
      "        [ 0.7879,  0.1887],\n",
      "        [ 0.7365, -0.8386],\n",
      "        ...,\n",
      "        [ 0.2254, -0.0588],\n",
      "        [ 1.0765, -1.3870],\n",
      "        [ 1.1157, -1.1035]], grad_fn=<AddmmBackward0>) tensor([0.6337, 0.5809, 0.7881,  ..., 0.7989, 0.6474, 0.6466],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.2911, -0.0310],\n",
      "        [ 0.2539, -0.0294],\n",
      "        [ 0.2493, -0.0339],\n",
      "        ...,\n",
      "        [ 0.1827, -0.0427],\n",
      "        [ 0.3156, -0.0250],\n",
      "        [ 0.2265, -0.0401]]) tensor([0.7407, 0.6144, 0.4934,  ..., 0.9906, 0.9466, 0.8932])\n",
      "Epoch:0006\n",
      "acc_train:0.6460 pre_train:0.6370 recall_train:0.7423 F1_train:0.6856 AUC_train:0.7096\n",
      "acc_val:0.5000 pre_val:0.4545 recall_val:0.1852 F1_val:0.263158 AUC_val:0.4623\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.5832,  0.4287],\n",
      "        [ 0.2938,  0.0954],\n",
      "        [ 0.3106, -2.5723],\n",
      "        ...,\n",
      "        [ 1.4903, -0.7408],\n",
      "        [ 1.4095, -0.7229],\n",
      "        [ 0.0349, -0.0242]], grad_fn=<AddmmBackward0>) tensor([0.6945, 0.5599, 0.5990,  ..., 0.8135, 0.7532, 0.6618],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.3152, -0.0276],\n",
      "        [ 0.2760, -0.0270],\n",
      "        [ 0.2725, -0.0321],\n",
      "        ...,\n",
      "        [ 0.2130, -0.0481],\n",
      "        [ 0.3391, -0.0197],\n",
      "        [ 0.2523, -0.0421]]) tensor([0.7693, 0.6221, 0.5248,  ..., 0.9887, 0.9400, 0.8778])\n",
      "Epoch:0007\n",
      "acc_train:0.6200 pre_train:0.6144 recall_train:0.7231 F1_train:0.6643 AUC_train:0.6940\n",
      "acc_val:0.5357 pre_val:0.5714 recall_val:0.1481 F1_val:0.235294 AUC_val:0.4700\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 1.4491, -1.4301],\n",
      "        [ 0.1439, -1.9930],\n",
      "        [ 1.0631, -0.9161],\n",
      "        ...,\n",
      "        [ 0.9037, -1.3947],\n",
      "        [ 0.0284, -1.2855],\n",
      "        [ 0.3859, -0.3582]], grad_fn=<AddmmBackward0>) tensor([0.6042, 0.6168, 0.5750,  ..., 0.7116, 0.7582, 0.6978],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.3444, -0.0635],\n",
      "        [ 0.3035, -0.0602],\n",
      "        [ 0.3007, -0.0650],\n",
      "        ...,\n",
      "        [ 0.2492, -0.0815],\n",
      "        [ 0.3652, -0.0573],\n",
      "        [ 0.2796, -0.0749]]) tensor([0.7985, 0.6309, 0.5605,  ..., 0.9865, 0.9338, 0.8627])\n",
      "Epoch:0008\n",
      "acc_train:0.6640 pre_train:0.6631 recall_train:0.7192 F1_train:0.6900 AUC_train:0.7262\n",
      "acc_val:0.5357 pre_val:0.5556 recall_val:0.1852 F1_val:0.277778 AUC_val:0.5670\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.2142, -0.3051],\n",
      "        [ 0.1276, -0.9349],\n",
      "        [ 0.5412, -0.1938],\n",
      "        ...,\n",
      "        [ 0.5496, -0.6239],\n",
      "        [ 1.0695, -0.5115],\n",
      "        [ 0.4803, -2.6582]], grad_fn=<AddmmBackward0>) tensor([0.6752, 0.6302, 0.5427,  ..., 0.8250, 0.7341, 0.7764],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.3668, -0.0665],\n",
      "        [ 0.3267, -0.0641],\n",
      "        [ 0.3252, -0.0687],\n",
      "        ...,\n",
      "        [ 0.2755, -0.0896],\n",
      "        [ 0.3834, -0.0598],\n",
      "        [ 0.3023, -0.0807]]) tensor([0.8189, 0.6378, 0.5898,  ..., 0.9845, 0.9299, 0.8512])\n",
      "Epoch:0009\n",
      "acc_train:0.6480 pre_train:0.6500 recall_train:0.7000 F1_train:0.6741 AUC_train:0.7181\n",
      "acc_val:0.5714 pre_val:1.0000 recall_val:0.1111 F1_val:0.200000 AUC_val:0.6756\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0677,  0.0123],\n",
      "        [ 0.4674, -0.2061],\n",
      "        [ 0.1721, -0.7417],\n",
      "        ...,\n",
      "        [ 0.6285, -0.8212],\n",
      "        [ 1.3767, -1.2145],\n",
      "        [-0.0264, -0.1606]], grad_fn=<AddmmBackward0>) tensor([0.6916, 0.5981, 0.5994,  ..., 0.8075, 0.7711, 0.7030],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.3641, -0.0809],\n",
      "        [ 0.3271, -0.0795],\n",
      "        [ 0.3254, -0.0838],\n",
      "        ...,\n",
      "        [ 0.2771, -0.1063],\n",
      "        [ 0.3781, -0.0736],\n",
      "        [ 0.3010, -0.0959]]) tensor([0.8327, 0.6400, 0.6136,  ..., 0.9828, 0.9285, 0.8438])\n",
      "Epoch:0010\n",
      "acc_train:0.6820 pre_train:0.6772 recall_train:0.7423 F1_train:0.7083 AUC_train:0.7280\n",
      "acc_val:0.5714 pre_val:0.8000 recall_val:0.1481 F1_val:0.250000 AUC_val:0.7382\n",
      "=================================================================== 0 _ 1\n",
      "Loading the Model for the 1-th Fold:... ... Size of samples in the test set:556\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.5316, -0.5412],\n",
      "        [-0.5020,  0.2665],\n",
      "        [ 0.0162, -0.0422],\n",
      "        ...,\n",
      "        [-0.2632,  0.1246],\n",
      "        [ 0.9741, -0.9401],\n",
      "        [ 0.3031, -0.2736]]) tensor([0.4505, 0.7978, 0.3136,  ..., 0.9952, 0.9737, 0.9468])\n",
      "Fold 1 Results: test acc:0.5234 test_pre:0.5399 test_recall:0.4965 test_F1:0.5173 test_AUC:0.5288 time:19.978s\n",
      "Size of the 2-fold Training, Validation, and Test Sets:500,56,556\n",
      " Starting the 2-1 Fold:：\n",
      "Fitting estimator with 4656 features.\n",
      "Fitting estimator with 4556 features.\n",
      "Fitting estimator with 4456 features.\n",
      "Fitting estimator with 4356 features.\n",
      "Fitting estimator with 4256 features.\n",
      "Fitting estimator with 4156 features.\n",
      "Fitting estimator with 4056 features.\n",
      "Fitting estimator with 3956 features.\n",
      "Fitting estimator with 3856 features.\n",
      "Fitting estimator with 3756 features.\n",
      "Fitting estimator with 3656 features.\n",
      "Fitting estimator with 3556 features.\n",
      "Fitting estimator with 3456 features.\n",
      "Fitting estimator with 3356 features.\n",
      "Fitting estimator with 3256 features.\n",
      "Fitting estimator with 3156 features.\n",
      "Fitting estimator with 3056 features.\n",
      "Fitting estimator with 2956 features.\n",
      "Fitting estimator with 2856 features.\n",
      "Fitting estimator with 2756 features.\n",
      "Fitting estimator with 2656 features.\n",
      "Fitting estimator with 2556 features.\n",
      "Fitting estimator with 2456 features.\n",
      "Fitting estimator with 2356 features.\n",
      "Fitting estimator with 2256 features.\n",
      "Fitting estimator with 2156 features.\n",
      "Fitting estimator with 2056 features.\n",
      "Number of labeled samples 500\n",
      "Number of features selected 2000\n",
      "phele init mai\n",
      "0  --  2000\n",
      "1  --  16\n",
      "2  --  16\n",
      "3  --  16\n",
      "4  --  16\n",
      "5  --  16\n",
      "6  --  16\n",
      "7  --  16\n",
      "start\n",
      "end\n",
      "welecome in model_init\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.3040,  0.0652],\n",
      "        [-0.0639, -0.0356],\n",
      "        [-0.2737, -0.1384],\n",
      "        ...,\n",
      "        [ 0.4698,  1.6267],\n",
      "        [-0.1767, -0.2681],\n",
      "        [-0.1160,  0.0331]], grad_fn=<AddmmBackward0>) tensor([0.5991, 0.4993, 0.5099,  ..., 0.8318, 0.8251, 0.7302],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0010,  0.0181],\n",
      "        [-0.0084,  0.0089],\n",
      "        [-0.0058,  0.0108],\n",
      "        ...,\n",
      "        [-0.0145,  0.0043],\n",
      "        [ 0.0019,  0.0140],\n",
      "        [-0.0065,  0.0113]]) tensor([0.6641, 0.5815, 0.5747,  ..., 0.9990, 0.9936, 0.9874])\n",
      "Epoch:0001\n",
      "acc_train:0.5040 pre_train:0.5309 recall_train:0.3962 F1_train:0.4537 AUC_train:0.5058\n",
      "acc_val:0.4464 pre_val:0.4390 recall_val:0.6923 F1_val:0.537313 AUC_val:0.3923\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1898, -0.5184],\n",
      "        [-0.1639, -0.3310],\n",
      "        [-0.4258,  0.3434],\n",
      "        ...,\n",
      "        [-1.3482,  1.3675],\n",
      "        [-0.2268, -0.5480],\n",
      "        [-0.1805, -0.4697]], grad_fn=<AddmmBackward0>) tensor([0.6791, 0.4807, 0.7850,  ..., 0.8055, 0.7414, 0.7547],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0235,  0.0135],\n",
      "        [-0.0286,  0.0100],\n",
      "        [-0.0264,  0.0104],\n",
      "        ...,\n",
      "        [-0.0371,  0.0062],\n",
      "        [-0.0200,  0.0123],\n",
      "        [-0.0229,  0.0144]]) tensor([0.5758, 0.4135, 0.4011,  ..., 0.9975, 0.9813, 0.9644])\n",
      "Epoch:0002\n",
      "acc_train:0.4820 pre_train:0.5026 recall_train:0.3769 F1_train:0.4308 AUC_train:0.4720\n",
      "acc_val:0.5357 pre_val:0.5000 recall_val:0.9231 F1_val:0.648649 AUC_val:0.5949\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1787, -0.3160],\n",
      "        [-0.1018, -0.1364],\n",
      "        [-0.5020, -0.1866],\n",
      "        ...,\n",
      "        [-0.0750,  0.2394],\n",
      "        [-0.2795, -0.0404],\n",
      "        [-0.7382, -0.5370]], grad_fn=<AddmmBackward0>) tensor([0.7546, 0.6104, 0.5985,  ..., 0.7584, 0.7421, 0.7584],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0501,  0.0102],\n",
      "        [-0.0559,  0.0070],\n",
      "        [-0.0522,  0.0076],\n",
      "        ...,\n",
      "        [-0.0634,  0.0035],\n",
      "        [-0.0469,  0.0080],\n",
      "        [-0.0488,  0.0108]]) tensor([0.6084, 0.3821, 0.3654,  ..., 0.9951, 0.9620, 0.9296])\n",
      "Epoch:0003\n",
      "acc_train:0.4880 pre_train:0.5095 recall_train:0.4115 F1_train:0.4553 AUC_train:0.5122\n",
      "acc_val:0.5357 pre_val:0.5000 recall_val:1.0000 F1_val:0.666667 AUC_val:0.6936\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1375,  1.1490],\n",
      "        [ 0.1739,  0.2098],\n",
      "        [-0.1767, -0.0216],\n",
      "        ...,\n",
      "        [-0.2138, -0.2880],\n",
      "        [ 0.0698,  0.2247],\n",
      "        [ 0.1671,  0.7390]], grad_fn=<AddmmBackward0>) tensor([0.4629, 0.7286, 0.7116,  ..., 0.7808, 0.7169, 0.6985],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0663,  0.0080],\n",
      "        [-0.0719,  0.0066],\n",
      "        [-0.0692,  0.0059],\n",
      "        ...,\n",
      "        [-0.0792,  0.0014],\n",
      "        [-0.0686,  0.0024],\n",
      "        [-0.0677,  0.0075]]) tensor([0.6544, 0.3810, 0.3598,  ..., 0.9921, 0.9385, 0.8870])\n",
      "Epoch:0004\n",
      "acc_train:0.5180 pre_train:0.5503 recall_train:0.4000 F1_train:0.4633 AUC_train:0.5503\n",
      "acc_val:0.5179 pre_val:0.4906 recall_val:1.0000 F1_val:0.658228 AUC_val:0.6821\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.3903, -0.1139],\n",
      "        [-0.1568, -0.0725],\n",
      "        [-0.1599, -0.1159],\n",
      "        ...,\n",
      "        [-0.2147, -0.2463],\n",
      "        [-0.2137, -0.3893],\n",
      "        [-0.1830, -0.0898]], grad_fn=<AddmmBackward0>) tensor([0.7231, 0.6945, 0.7605,  ..., 0.7450, 0.6697, 0.7076],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0864,  0.0108],\n",
      "        [-0.0918,  0.0074],\n",
      "        [-0.0894,  0.0090],\n",
      "        ...,\n",
      "        [-0.0974,  0.0042],\n",
      "        [-0.0878,  0.0082],\n",
      "        [-0.0882,  0.0103]]) tensor([0.6995, 0.3946, 0.3699,  ..., 0.9886, 0.9183, 0.8486])\n",
      "Epoch:0005\n",
      "acc_train:0.5160 pre_train:0.5363 recall_train:0.5115 F1_train:0.5236 AUC_train:0.5115\n",
      "acc_val:0.5179 pre_val:0.4906 recall_val:1.0000 F1_val:0.658228 AUC_val:0.7372\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.1772,  1.0336],\n",
      "        [-0.5213, -0.1993],\n",
      "        [-0.1894, -0.2555],\n",
      "        ...,\n",
      "        [-0.1850, -0.2544],\n",
      "        [-0.2207, -0.1927],\n",
      "        [-0.1615, -0.2661]], grad_fn=<AddmmBackward0>) tensor([0.4962, 0.5762, 0.7730,  ..., 0.7883, 0.7139, 0.7195],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1039,  0.0137],\n",
      "        [-0.1083,  0.0102],\n",
      "        [-0.1063,  0.0120],\n",
      "        ...,\n",
      "        [-0.1120,  0.0068],\n",
      "        [-0.1029,  0.0138],\n",
      "        [-0.1050,  0.0133]]) tensor([0.7230, 0.4015, 0.3743,  ..., 0.9858, 0.9020, 0.8183])\n",
      "Epoch:0006\n",
      "acc_train:0.5240 pre_train:0.5447 recall_train:0.5154 F1_train:0.5296 AUC_train:0.5465\n",
      "acc_val:0.5179 pre_val:0.4906 recall_val:1.0000 F1_val:0.658228 AUC_val:0.7115\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.5379, -0.1531],\n",
      "        [-0.2582, -0.1797],\n",
      "        [-0.2700, -0.2799],\n",
      "        ...,\n",
      "        [-0.2279, -0.1492],\n",
      "        [-0.5593,  0.0159],\n",
      "        [-0.4115, -0.2644]], grad_fn=<AddmmBackward0>) tensor([0.6673, 0.4114, 0.8308,  ..., 0.8207, 0.7731, 0.6360],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1219,  0.0104],\n",
      "        [-0.1258,  0.0069],\n",
      "        [-0.1243,  0.0080],\n",
      "        ...,\n",
      "        [-0.1299,  0.0029],\n",
      "        [-0.1214,  0.0094],\n",
      "        [-0.1231,  0.0096]]) tensor([0.7435, 0.4104, 0.3805,  ..., 0.9829, 0.8878, 0.7920])\n",
      "Epoch:0007\n",
      "acc_train:0.4980 pre_train:0.5158 recall_train:0.5654 F1_train:0.5394 AUC_train:0.4865\n",
      "acc_val:0.5536 pre_val:0.5098 recall_val:1.0000 F1_val:0.675325 AUC_val:0.7154\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0165,  0.1755],\n",
      "        [-0.0934,  0.0998],\n",
      "        [-0.4304, -0.3537],\n",
      "        ...,\n",
      "        [-0.2922,  0.0595],\n",
      "        [-0.2724, -0.1996],\n",
      "        [ 0.0029,  0.3762]], grad_fn=<AddmmBackward0>) tensor([0.6589, 0.3362, 0.4596,  ..., 0.6091, 0.7141, 0.5965],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1306,  0.0063],\n",
      "        [-0.1343,  0.0015],\n",
      "        [-0.1330,  0.0028],\n",
      "        ...,\n",
      "        [-0.1390, -0.0027],\n",
      "        [-0.1302,  0.0042],\n",
      "        [-0.1319,  0.0041]]) tensor([0.7586, 0.4215, 0.3901,  ..., 0.9806, 0.8770, 0.7720])\n",
      "Epoch:0008\n",
      "acc_train:0.5260 pre_train:0.5324 recall_train:0.7269 F1_train:0.6146 AUC_train:0.5343\n",
      "acc_val:0.5357 pre_val:0.5000 recall_val:0.9615 F1_val:0.657895 AUC_val:0.7013\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.8815, -0.1175],\n",
      "        [-0.1567, -0.0610],\n",
      "        [-0.1352, -0.0762],\n",
      "        ...,\n",
      "        [-0.0621,  0.1011],\n",
      "        [-0.1193, -0.0705],\n",
      "        [-0.0436,  0.0176]], grad_fn=<AddmmBackward0>) tensor([0.4918, 0.4954, 0.8341,  ..., 0.7411, 0.7650, 0.6472],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1268,  0.0123],\n",
      "        [-0.1307,  0.0067],\n",
      "        [-0.1295,  0.0074],\n",
      "        ...,\n",
      "        [-0.1362,  0.0012],\n",
      "        [-0.1264,  0.0095],\n",
      "        [-0.1282,  0.0093]]) tensor([0.7667, 0.4308, 0.3961,  ..., 0.9793, 0.8694, 0.7580])\n",
      "Epoch:0009\n",
      "acc_train:0.4900 pre_train:0.5059 recall_train:0.8269 F1_train:0.6277 AUC_train:0.4826\n",
      "acc_val:0.5357 pre_val:0.5000 recall_val:0.9615 F1_val:0.657895 AUC_val:0.6987\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.2357, -0.1972],\n",
      "        [-0.1649,  0.1862],\n",
      "        [-0.2264,  0.1212],\n",
      "        ...,\n",
      "        [-0.2309, -0.2713],\n",
      "        [-0.3055,  0.0016],\n",
      "        [-0.2674, -0.2736]], grad_fn=<AddmmBackward0>) tensor([0.4546, 0.4950, 0.8306,  ..., 0.8238, 0.6078, 0.7180],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1397,  0.0020],\n",
      "        [-0.1431, -0.0036],\n",
      "        [-0.1420, -0.0033],\n",
      "        ...,\n",
      "        [-0.1479, -0.0096],\n",
      "        [-0.1388, -0.0006],\n",
      "        [-0.1407, -0.0011]]) tensor([0.7743, 0.4414, 0.4052,  ..., 0.9775, 0.8629, 0.7445])\n",
      "Epoch:0010\n",
      "acc_train:0.4960 pre_train:0.5109 recall_train:0.7231 F1_train:0.5987 AUC_train:0.4957\n",
      "acc_val:0.5357 pre_val:0.5000 recall_val:0.9615 F1_val:0.657895 AUC_val:0.6923\n",
      " Starting the 2-2 Fold:：\n",
      "Fitting estimator with 4656 features.\n",
      "Fitting estimator with 4556 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 4456 features.\n",
      "Fitting estimator with 4356 features.\n",
      "Fitting estimator with 4256 features.\n",
      "Fitting estimator with 4156 features.\n",
      "Fitting estimator with 4056 features.\n",
      "Fitting estimator with 3956 features.\n",
      "Fitting estimator with 3856 features.\n",
      "Fitting estimator with 3756 features.\n",
      "Fitting estimator with 3656 features.\n",
      "Fitting estimator with 3556 features.\n",
      "Fitting estimator with 3456 features.\n",
      "Fitting estimator with 3356 features.\n",
      "Fitting estimator with 3256 features.\n",
      "Fitting estimator with 3156 features.\n",
      "Fitting estimator with 3056 features.\n",
      "Fitting estimator with 2956 features.\n",
      "Fitting estimator with 2856 features.\n",
      "Fitting estimator with 2756 features.\n",
      "Fitting estimator with 2656 features.\n",
      "Fitting estimator with 2556 features.\n",
      "Fitting estimator with 2456 features.\n",
      "Fitting estimator with 2356 features.\n",
      "Fitting estimator with 2256 features.\n",
      "Fitting estimator with 2156 features.\n",
      "Fitting estimator with 2056 features.\n",
      "Number of labeled samples 500\n",
      "Number of features selected 2000\n",
      "phele init mai\n",
      "0  --  2000\n",
      "1  --  16\n",
      "2  --  16\n",
      "3  --  16\n",
      "4  --  16\n",
      "5  --  16\n",
      "6  --  16\n",
      "7  --  16\n",
      "start\n",
      "end\n",
      "welecome in model_init\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.4559, -0.1256],\n",
      "        [ 0.0989,  0.1162],\n",
      "        [ 0.1207, -0.1854],\n",
      "        ...,\n",
      "        [-0.5677, -0.6327],\n",
      "        [ 2.1124, -2.4376],\n",
      "        [-0.2088, -0.0790]], grad_fn=<AddmmBackward0>) tensor([0.4114, 0.8540, 0.6751,  ..., 0.7245, 0.7960, 0.6496],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0005,  0.0185],\n",
      "        [-0.0021,  0.0244],\n",
      "        [-0.0009,  0.0261],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0189],\n",
      "        [-0.0030,  0.0349],\n",
      "        [-0.0006,  0.0189]]) tensor([0.5288, 0.4470, 0.4420,  ..., 0.9996, 0.9968, 0.9938])\n",
      "Epoch:0001\n",
      "acc_train:0.4980 pre_train:0.5150 recall_train:0.5962 F1_train:0.5526 AUC_train:0.4910\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5679\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0288, -0.7073],\n",
      "        [-0.0364, -0.1156],\n",
      "        [-0.1790, -0.4383],\n",
      "        ...,\n",
      "        [-0.5793, -0.8219],\n",
      "        [-0.0877, -0.3172],\n",
      "        [-0.0754, -0.1709]], grad_fn=<AddmmBackward0>) tensor([0.5457, 0.7208, 0.6584,  ..., 0.8083, 0.7199, 0.6693],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0045,  0.0164],\n",
      "        [-0.0045,  0.0202],\n",
      "        [-0.0050,  0.0263],\n",
      "        ...,\n",
      "        [-0.0041,  0.0176],\n",
      "        [-0.0062,  0.0260],\n",
      "        [-0.0058,  0.0238]]) tensor([0.4290, 0.2904, 0.2823,  ..., 0.9985, 0.9884, 0.9785])\n",
      "Epoch:0002\n",
      "acc_train:0.5000 pre_train:0.5227 recall_train:0.4423 F1_train:0.4792 AUC_train:0.4767\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5897\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0733, -0.1350],\n",
      "        [ 0.0131,  0.0340],\n",
      "        [ 0.0276,  0.0052],\n",
      "        ...,\n",
      "        [ 0.0186, -0.0557],\n",
      "        [-0.4265, -0.5498],\n",
      "        [-0.6487, -0.5593]], grad_fn=<AddmmBackward0>) tensor([0.4667, 0.8620, 0.6713,  ..., 0.6271, 0.7550, 0.6360],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0076,  0.0136],\n",
      "        [-0.0088,  0.0178],\n",
      "        [-0.0082,  0.0199],\n",
      "        ...,\n",
      "        [-0.0078,  0.0173],\n",
      "        [-0.0088,  0.0221],\n",
      "        [-0.0077,  0.0172]]) tensor([0.5058, 0.2886, 0.2759,  ..., 0.9967, 0.9712, 0.9482])\n",
      "Epoch:0003\n",
      "acc_train:0.4620 pre_train:0.4802 recall_train:0.4192 F1_train:0.4476 AUC_train:0.4826\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5936\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.2698, -0.4535],\n",
      "        [-0.0313, -0.0672],\n",
      "        [-0.3072, -0.4194],\n",
      "        ...,\n",
      "        [ 0.0348, -0.0157],\n",
      "        [ 0.1670, -0.0543],\n",
      "        [-0.0657, -0.1255]], grad_fn=<AddmmBackward0>) tensor([0.6917, 0.8054, 0.8211,  ..., 0.7737, 0.7686, 0.8190],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0166,  0.0076],\n",
      "        [-0.0174,  0.0096],\n",
      "        [-0.0154,  0.0108],\n",
      "        ...,\n",
      "        [-0.0166,  0.0105],\n",
      "        [-0.0165,  0.0158],\n",
      "        [-0.0151,  0.0079]]) tensor([0.6073, 0.3176, 0.3013,  ..., 0.9943, 0.9475, 0.9074])\n",
      "Epoch:0004\n",
      "acc_train:0.5000 pre_train:0.5281 recall_train:0.3615 F1_train:0.4292 AUC_train:0.4961\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5936\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.2279, -0.0523],\n",
      "        [-0.3844, -0.3114],\n",
      "        [-0.0226,  0.0517],\n",
      "        ...,\n",
      "        [ 0.0656,  0.1162],\n",
      "        [-0.1092, -0.0289],\n",
      "        [-0.0148,  0.1309]], grad_fn=<AddmmBackward0>) tensor([0.6623, 0.5106, 0.5437,  ..., 0.7821, 0.7283, 0.5182],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0314,  0.0269],\n",
      "        [-0.0313,  0.0282],\n",
      "        [-0.0296,  0.0271],\n",
      "        ...,\n",
      "        [-0.0297,  0.0277],\n",
      "        [-0.0287,  0.0293],\n",
      "        [-0.0294,  0.0250]]) tensor([0.6807, 0.3442, 0.3245,  ..., 0.9915, 0.9228, 0.8646])\n",
      "Epoch:0005\n",
      "acc_train:0.5300 pre_train:0.5293 recall_train:0.8692 F1_train:0.6579 AUC_train:0.5285\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5910\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1536,  0.0158],\n",
      "        [-0.0750,  0.0244],\n",
      "        [-0.0637,  0.0323],\n",
      "        ...,\n",
      "        [-0.1177,  0.0025],\n",
      "        [-0.0922,  0.0401],\n",
      "        [-0.0574, -0.0038]], grad_fn=<AddmmBackward0>) tensor([0.7028, 0.5070, 0.7618,  ..., 0.7788, 0.7165, 0.5777],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0462,  0.0219],\n",
      "        [-0.0454,  0.0226],\n",
      "        [-0.0438,  0.0217],\n",
      "        ...,\n",
      "        [-0.0445,  0.0222],\n",
      "        [-0.0433,  0.0232],\n",
      "        [-0.0439,  0.0201]]) tensor([0.7302, 0.3684, 0.3448,  ..., 0.9886, 0.9003, 0.8248])\n",
      "Epoch:0006\n",
      "acc_train:0.5020 pre_train:0.5126 recall_train:0.8615 F1_train:0.6428 AUC_train:0.4895\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5897\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.2087, -0.0678],\n",
      "        [-0.4292, -0.2345],\n",
      "        [ 0.0280,  0.0507],\n",
      "        ...,\n",
      "        [-0.0522,  0.0221],\n",
      "        [ 0.0129,  0.0582],\n",
      "        [-0.0748, -0.0028]], grad_fn=<AddmmBackward0>) tensor([0.7331, 0.7134, 0.8622,  ..., 0.7903, 0.7650, 0.6094],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0536,  0.0218],\n",
      "        [-0.0529,  0.0226],\n",
      "        [-0.0513,  0.0205],\n",
      "        ...,\n",
      "        [-0.0521,  0.0213],\n",
      "        [-0.0510,  0.0213],\n",
      "        [-0.0516,  0.0195]]) tensor([0.7625, 0.3881, 0.3612,  ..., 0.9857, 0.8817, 0.7911])\n",
      "Epoch:0007\n",
      "acc_train:0.4800 pre_train:0.5000 recall_train:0.7808 F1_train:0.6096 AUC_train:0.4669\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5897\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.3851, -0.1635],\n",
      "        [-0.1352,  0.0458],\n",
      "        [-0.1156, -0.0696],\n",
      "        ...,\n",
      "        [-0.0808, -0.0636],\n",
      "        [-0.0446,  0.0793],\n",
      "        [-0.1408, -0.0143]], grad_fn=<AddmmBackward0>) tensor([0.5532, 0.5922, 0.7913,  ..., 0.7297, 0.7645, 0.7847],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0737,  0.0188],\n",
      "        [-0.0732,  0.0198],\n",
      "        [-0.0717,  0.0175],\n",
      "        ...,\n",
      "        [-0.0723,  0.0180],\n",
      "        [-0.0712,  0.0167],\n",
      "        [-0.0719,  0.0165]]) tensor([0.7735, 0.4010, 0.3722,  ..., 0.9837, 0.8746, 0.7752])\n",
      "Epoch:0008\n",
      "acc_train:0.5040 pre_train:0.5144 recall_train:0.8269 F1_train:0.6342 AUC_train:0.4822\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5974\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.1570,  0.1212],\n",
      "        [-0.0563,  0.2455],\n",
      "        [-0.0485,  0.2295],\n",
      "        ...,\n",
      "        [-0.5392, -0.1494],\n",
      "        [-0.5974, -0.1084],\n",
      "        [-0.0673,  0.1767]], grad_fn=<AddmmBackward0>) tensor([0.7741, 0.6338, 0.6191,  ..., 0.7502, 0.6795, 0.7805],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0785,  0.0247],\n",
      "        [-0.0783,  0.0259],\n",
      "        [-0.0768,  0.0222],\n",
      "        ...,\n",
      "        [-0.0768,  0.0231],\n",
      "        [-0.0761,  0.0211],\n",
      "        [-0.0771,  0.0210]]) tensor([0.7777, 0.4104, 0.3810,  ..., 0.9821, 0.8721, 0.7674])\n",
      "Epoch:0009\n",
      "acc_train:0.5340 pre_train:0.5308 recall_train:0.8962 F1_train:0.6667 AUC_train:0.5370\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5872\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[ 0.0362,  0.0245],\n",
      "        [-0.0036,  0.0422],\n",
      "        [ 0.0245,  0.0172],\n",
      "        ...,\n",
      "        [ 0.1995, -0.0631],\n",
      "        [ 0.0291,  0.0671],\n",
      "        [-0.0340,  0.1000]], grad_fn=<AddmmBackward0>) tensor([0.7313, 0.5379, 0.4908,  ..., 0.7779, 0.7943, 0.7283],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[-0.0772,  0.0203],\n",
      "        [-0.0774,  0.0215],\n",
      "        [-0.0765,  0.0178],\n",
      "        ...,\n",
      "        [-0.0757,  0.0185],\n",
      "        [-0.0755,  0.0166],\n",
      "        [-0.0768,  0.0163]]) tensor([0.7793, 0.4165, 0.3865,  ..., 0.9812, 0.8726, 0.7659])\n",
      "Epoch:0010\n",
      "acc_train:0.5260 pre_train:0.5293 recall_train:0.8000 F1_train:0.6371 AUC_train:0.4838\n",
      "acc_val:0.4643 pre_val:0.4643 recall_val:1.0000 F1_val:0.634146 AUC_val:0.5846\n",
      "=================================================================== 1 _ 1\n",
      "Loading the Model for the 2-th Fold:... ... Size of samples in the test set:556\n",
      "welcome in forward\n",
      "welcome in input layer\n",
      "hidden layer\n",
      "output layer\n",
      "tensor([[0.1899, 0.0285],\n",
      "        [0.1916, 0.0481],\n",
      "        [0.1893, 0.0396],\n",
      "        ...,\n",
      "        [0.1909, 0.0998],\n",
      "        [0.1865, 0.0324],\n",
      "        [0.1937, 0.0521]]) tensor([0.6257, 0.3639, 0.3434,  ..., 0.9927, 0.9417, 0.8987])\n",
      "Fold 2 Results: test acc:0.7410 test_pre:0.7407 test_recall:0.7666 test_F1:0.7534 test_AUC:0.7961 time:20.130s\n",
      "\n",
      "======Finish Results for Nested 10-fold cross-validation======\n",
      "Test: acc:0.6321942446043165 precision:0.6403323411941528 recall:0.6315270066261292 F1:0.6353644132614136 AUC:0.6624937057495117\n",
      "Total duration:40.10804605484009\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import io\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "# from dataloader import dataloader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "if hasattr(sys.stdout, 'buffer'):\n",
    "    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.no_cuda = False\n",
    "        self.seed = 46\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.001\n",
    "        self.weight_decay = 5e-5\n",
    "        self.hidden = 16\n",
    "        self.dropout = 0.2\n",
    "        self.atlas = 'ez'\n",
    "        self.num_features = 2000\n",
    "        self.folds = 2\n",
    "        self.connectivity = 'correlation'\n",
    "        self.max_degree = 3\n",
    "        self.ngl = 8\n",
    "        self.edropout = 0.3\n",
    "        self.train = 1\n",
    "        self.ckpt_path = '../folds/rois_ez_pth_b'\n",
    "        self.early_stopping = True\n",
    "        self.early_stopping_patience = 20\n",
    "\n",
    "# Instantiate Args class\n",
    "args = Args()\n",
    "\n",
    "# Check if CUDA is available\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# Create params dictionary\n",
    "params = vars(args)\n",
    "\n",
    "# Print Hyperparameters\n",
    "print('Hyperparameters:')\n",
    "for key, value in params.items():\n",
    "    print(key + \":\", value)\n",
    "\n",
    "corrects = np.zeros(args.folds, dtype=np.int32) \n",
    "accs = np.zeros(args.folds, dtype=np.float32) \n",
    "aucs = np.zeros(args.folds, dtype=np.float32)\n",
    "prfs = np.zeros([args.folds,3], dtype=np.float32) # Save Precision, Recall, F1\n",
    "test_num = np.zeros(args.folds, dtype=np.float32)\n",
    "\n",
    "\n",
    "print('  Loading dataset ...')\n",
    "dataloader = dataloader()\n",
    "raw_features, y, nonimg = dataloader.load_data(params) \n",
    "cv_splits = dataloader.data_split(args.folds)\n",
    "\n",
    "features=raw_features\n",
    "\n",
    "t1 = time.time()\n",
    "count=1;\n",
    "for i in range(args.folds):\n",
    "    \n",
    "    \n",
    "    \n",
    "    t_start = time.time()\n",
    "    train_ind, test_ind = cv_splits[i]\n",
    "\n",
    "    train_ind, valid_ind = train_test_split(train_ind, test_size=0.1, random_state = 24)\n",
    "    \n",
    "    cv_splits[i] = (train_ind, valid_ind)\n",
    "    cv_splits[i] = cv_splits[i] + (test_ind,)\n",
    "    print('Size of the {}-fold Training, Validation, and Test Sets:{},{},{}' .format(i+1, len(cv_splits[i][0]), len(cv_splits[i][1]), len(cv_splits[i][2])))\n",
    "\n",
    "    if args.train == 1:\n",
    "        for j in range(args.folds):\n",
    "            print(' Starting the {}-{} Fold:：'.format(i+1,j+1))\n",
    "            node_ftr = dataloader.get_node_features(train_ind)\n",
    "            edge_index, edgenet_input = dataloader.get_WL_inputs(nonimg)\n",
    "            edgenet_input = (edgenet_input - edgenet_input.mean(axis=0)) / edgenet_input.std(axis=0)\n",
    "            \n",
    "            model = GCN(input_dim = args.num_features,\n",
    "                        nhid = args.hidden, \n",
    "                        num_classes = 2, \n",
    "                        ngl = args.ngl, \n",
    "                        dropout = args.dropout, \n",
    "                        edge_dropout = args.edropout, \n",
    "                        edgenet_input_dim = 2*nonimg.shape[1])\n",
    "            optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "            \n",
    "#             if args.cuda:\n",
    "            model\n",
    "            features = torch.tensor(node_ftr, dtype=torch.float32)\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "            edgenet_input = torch.tensor(edgenet_input, dtype=torch.float32)\n",
    "            labels = torch.tensor(y, dtype=torch.long)\n",
    "            fold_model_path = args.ckpt_path + \"/fold{}.pth\".format(i+1)\n",
    "                \n",
    "            acc = 0\n",
    "            best_val_loss = float('inf') # early stoppping: Initialized to positive infinity\n",
    "            current_patience = 0 # early stopping: Used to record the epochs of the current early stopping\n",
    "            \n",
    "            epoch_store = []\n",
    "            acc_train_store =[]        \n",
    "            pre_train_store =[]\n",
    "            recall_train_store =[]\n",
    "            F1_train_store =[]\n",
    "            AUC_train_store =[]\n",
    "            acc_val_store=[]\n",
    "            pre_val_store=[]\n",
    "            recall_val_store=[]\n",
    "            F1_val_store=[]\n",
    "            AUC_val_store=[]\n",
    "            \n",
    "            for epoch in range(args.epochs):\n",
    "                # train\n",
    "                model.train()\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    optimizer.zero_grad()\n",
    "                    output, edge_weights = model(features, edge_index, edgenet_input)\n",
    "                    loss_train = torch.nn.CrossEntropyLoss()(output[train_ind], labels[train_ind])\n",
    "                    loss_train.backward()\n",
    "                    optimizer.step()\n",
    "                acc_train = torchmetrics_accuracy(output[train_ind], labels[train_ind])\n",
    "                auc_train = torchmetrics_auc(output[train_ind], labels[train_ind])\n",
    "                logits_train = output[train_ind].detach().cpu().numpy()\n",
    "                prf_train = prf(logits_train, y[train_ind])\n",
    "\n",
    "                \n",
    "                # valid\n",
    "                model.eval()\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    output, edge_weights = model(features, edge_index, edgenet_input)\n",
    "                loss_val = torch.nn.CrossEntropyLoss()(output[valid_ind], labels[valid_ind])\n",
    "                acc_val = torchmetrics_accuracy(output[valid_ind], labels[valid_ind])\n",
    "                auc_val = torchmetrics_auc(output[valid_ind], labels[valid_ind])\n",
    "                logits_val = output[valid_ind].detach().cpu().numpy()\n",
    "                prf_val = prf(logits_val, y[valid_ind])\n",
    "\n",
    "                \n",
    "                print('Epoch:{:04d}'.format(epoch+1))\n",
    "                print('acc_train:{:.4f}'.format(acc_train),\n",
    "                      'pre_train:{:.4f}'.format(prf_train[0]),\n",
    "                      'recall_train:{:.4f}'.format(prf_train[1]),\n",
    "                      'F1_train:{:.4f}'.format(prf_train[2]),\n",
    "                      'AUC_train:{:.4f}'.format(auc_train))\n",
    "                print('acc_val:{:.4f}'.format(acc_val),\n",
    "                      'pre_val:{:.4f}'.format(prf_val[0]),\n",
    "                      'recall_val:{:.4f}'.format(prf_val[1]),\n",
    "                      'F1_val:{:4f}'.format(prf_val[2]),\n",
    "                      'AUC_val:{:.4f}'.format(auc_val))\n",
    "                \n",
    "                epoch_store.append(epoch+1)\n",
    "                acc_train_store.append(acc_train)       \n",
    "                pre_train_store.append(prf_train[0])\n",
    "                recall_train_store.append(prf_train[1])\n",
    "                F1_train_store.append(prf_train[2])\n",
    "                AUC_train_store.append(auc_train)\n",
    "                acc_val_store.append(acc_val)\n",
    "                pre_val_store.append(prf_val[0])\n",
    "                recall_val_store.append(prf_val[1])\n",
    "                F1_val_store.append(prf_val[2])\n",
    "                AUC_val_store.append(auc_val)\n",
    "                \n",
    "                # save pth\n",
    "                if acc_val > acc and epoch > 50:\n",
    "                    acc = acc_val\n",
    "                    if args.ckpt_path != '':\n",
    "                        if not os.path.exists(args.ckpt_path):\n",
    "                            os.makedirs(args.ckpt_path)\n",
    "                        torch.save(model.state_dict(), fold_model_path)\n",
    "                \n",
    "                # Early Stopping\n",
    "                if epoch > 50 and args.early_stopping == True:\n",
    "                    if loss_val < best_val_loss:\n",
    "                        best_val_loss = loss_val\n",
    "                        current_patience = 0\n",
    "                    else:\n",
    "                        current_patience += 1\n",
    "                    if current_patience >= args.early_stopping_patience:\n",
    "                        print('Early Stopping!!! epoch：{}'.format(epoch))\n",
    "                        break\n",
    "        print(\"===================================================================\",i,\"_\",j)\n",
    "        data  = { \n",
    "              \"epoch\" : epoch_store ,\n",
    "              \"acc_train\" : acc_train_store ,        \n",
    "              \"pre_train\" : pre_train_store ,\n",
    "              \"recall_train\" : recall_train_store ,\n",
    "              \"F1_train\" : F1_train_store ,\n",
    "              \"AUC_train\" : AUC_train_store ,\n",
    "              \"acc_val\" : acc_val_store,\n",
    "               \"pre_val\" : pre_val_store ,\n",
    "              \"recall_val\" : recall_val_store ,\n",
    "              \"F1_val\" : F1_val_store ,\n",
    "              \"AUC_val\" : AUC_val_store  \n",
    "        }\n",
    "        \n",
    "        \n",
    "#         epoch_file_path =  f'../files/rois_ez/file_{i}_{j}_{count}.csv'\n",
    "#         data_file = pd.DataFrame(data);\n",
    "#         data_file.to_csv(epoch_file_path , index=False);\n",
    "#         count=count+1;\n",
    "        # test\n",
    "        print(\"Loading the Model for the {}-th Fold:... ...\".format(i+1),\n",
    "              \"Size of samples in the test set:{}\".format(len(test_ind)))\n",
    "        model.load_state_dict(torch.load(fold_model_path))\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            output, edge_weights = model(features, edge_index, edgenet_input)\n",
    "        acc_test = torchmetrics_accuracy(output[test_ind], labels[test_ind])\n",
    "        auc_test = torchmetrics_auc(output[test_ind], labels[test_ind])\n",
    "        logits_test = output[test_ind].detach().cpu().numpy()\n",
    "        correct_test = correct_num(logits_test, y[test_ind])\n",
    "        prf_test =  prf(logits_test, y[test_ind])\n",
    "        \n",
    "        t_end = time.time()\n",
    "        t = t_end - t_start\n",
    "        print('Fold {} Results:'.format(i+1),\n",
    "              'test acc:{:.4f}'.format(acc_test),\n",
    "              'test_pre:{:.4f}'.format(prf_test[0]),\n",
    "              'test_recall:{:.4f}'.format(prf_test[1]),\n",
    "              'test_F1:{:.4f}'.format(prf_test[2]),\n",
    "              'test_AUC:{:.4f}'.format(auc_test),\n",
    "              'time:{:.3f}s'.format(t))\n",
    "        \n",
    "        correct = correct_test\n",
    "        aucs[i] = auc_test\n",
    "        prfs[i] = prf_test\n",
    "        corrects[i] = correct\n",
    "        test_num[i] = len(test_ind)\n",
    "    \n",
    "    \n",
    "    if args.train == 0:\n",
    "        node_ftr = dataloader.get_node_features(train_ind)\n",
    "        edge_index, edgenet_input = dataloader.get_WL_inputs(nonimg)\n",
    "        edgenet_input = (edgenet_input - edgenet_input.mean(axis=0)) / edgenet_input.std(axis=0)\n",
    "        \n",
    "        model = GCN(input_dim = args.num_features,\n",
    "                    nhid = args.hidden, \n",
    "                    num_classes = 2, \n",
    "                    ngl = args.ngl, \n",
    "                    dropout = args.dropout, \n",
    "                    edge_dropout = args.edropout, \n",
    "                    edgenet_input_dim = 2*nonimg.shape[1])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "        \n",
    "#         if args.cuda\n",
    "        model\n",
    "        features = torch.tensor(node_ftr, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        edgenet_input = torch.tensor(edgenet_input, dtype=torch.float32)\n",
    "        labels = torch.tensor(y, dtype=torch.long)\n",
    "        fold_model_path = args.ckpt_path + \"/fold{}.pth\".format(i+1)\n",
    "        \n",
    "        model.load_state_dict(torch.load(fold_model_path))\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            output, edge_weights = model(features, edge_index, edgenet_input)\n",
    "        acc_test = torchmetrics_accuracy(output[test_ind], labels[test_ind])\n",
    "        auc_test = torchmetrics_auc(output[test_ind], labels[test_ind])\n",
    "        logits_test = output[test_ind].detach().cpu().numpy()\n",
    "        correct_test = correct_num(logits_test, y[test_ind])\n",
    "        prf_test =  prf(logits_test, y[test_ind])\n",
    "        \n",
    "        t_end = time.time()\n",
    "        t = t_end - t_start\n",
    "        print('Fold {} Results:'.format(i+1),\n",
    "              'test acc:{:.4f}'.format(acc_test),\n",
    "              'test_pre:{:.4f}'.format(prf_test[0]),\n",
    "              'test_recall:{:.4f}'.format(prf_test[1]),\n",
    "              'test_F1:{:.4f}'.format(prf_test[2]),\n",
    "              'test_AUC:{:.4f}'.format(auc_test),\n",
    "              'time:{:.3f}s'.format(t))\n",
    "        \n",
    "        correct = correct_test\n",
    "        aucs[i] = auc_test\n",
    "        prfs[i] = prf_test\n",
    "        corrects[i] = correct\n",
    "        test_num[i] = len(test_ind)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print('\\r\\n======Finish Results for Nested 10-fold cross-validation======')\n",
    "Nested10kCV_acc = np.sum(corrects) / np.sum(test_num)\n",
    "Nested10kCV_auc = np.mean(aucs)\n",
    "Nested10kCV_precision, Nested10kCV_recall, Nested10kCV_F1 = np.mean(prfs, axis=0)\n",
    "print('Test:',\n",
    "      'acc:{}'.format(Nested10kCV_acc),\n",
    "      'precision:{}'.format(Nested10kCV_precision),\n",
    "      'recall:{}'.format(Nested10kCV_recall),\n",
    "      'F1:{}'.format(Nested10kCV_F1),\n",
    "      'AUC:{}'.format(Nested10kCV_auc))\n",
    "print('Total duration:{}'.format(t2 - t1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d845c726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03838a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
