{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc5d23a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from nilearn import connectome\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "# Reading and computing the input data\n",
    "\n",
    "# Selected pipeline\n",
    "pipeline = 'cpac'\n",
    "\n",
    "# Input data variables\n",
    "root_folder = '../ABIDE/'\n",
    "data_folder = os.path.join(root_folder, 'ABIDE_pcp/cpac/filt_noglobal')\n",
    "phenotype = os.path.join(root_folder, 'ABIDE_pcp/Phenotypic_V1_0b_preprocessed1.csv')\n",
    "\n",
    "\n",
    "def fetch_filenames(subject_IDs, file_type):\n",
    "\n",
    "    \"\"\"\n",
    "        subject_list : list of short subject IDs in string format\n",
    "        file_type    : must be one of the available file types\n",
    "\n",
    "    returns:\n",
    "\n",
    "        filenames    : list of filetypes (same length as subject_list)\n",
    "    \"\"\"\n",
    "\n",
    "    import glob\n",
    "\n",
    "    # Specify file mappings for the possible file types\n",
    "    filemapping = {'func_preproc': '_func_preproc.nii.gz',\n",
    "                   'rois_ho': '_rois_ho.1D'}\n",
    "\n",
    "    # The list to be filled\n",
    "    filenames = []\n",
    "\n",
    "    # Fill list with requested file paths\n",
    "    for i in range(len(subject_IDs)):\n",
    "        os.chdir(data_folder)  # os.path.join(data_folder, subject_IDs[i]))\n",
    "        try:\n",
    "            filenames.append(glob.glob('*' + subject_IDs[i] + filemapping[file_type])[0])\n",
    "        except IndexError:\n",
    "            # Return N/A if subject ID is not found\n",
    "            filenames.append('N/A')\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# Get timeseries arrays for list of subjects\n",
    "def get_timeseries(subject_list, atlas_name):\n",
    "    \"\"\"\n",
    "        subject_list : list of short subject IDs in string format\n",
    "        atlas_name   : the atlas based on which the timeseries are generated e.g. aal, cc200\n",
    "\n",
    "    returns:\n",
    "        time_series  : list of timeseries arrays, each of shape (timepoints x regions)\n",
    "    \"\"\"\n",
    "\n",
    "    timeseries = []\n",
    "    for i in range(len(subject_list)):\n",
    "        subject_folder = os.path.join(data_folder, subject_list[i])\n",
    "        ro_file = [f for f in os.listdir(subject_folder) if f.endswith('_rois_' + atlas_name + '.1D')]\n",
    "        fl = os.path.join(subject_folder, ro_file[0])\n",
    "        print(\"Reading timeseries file %s\" %fl)\n",
    "        timeseries.append(np.loadtxt(fl, skiprows=0))\n",
    "\n",
    "    return timeseries\n",
    "\n",
    "\n",
    "# Compute connectivity matrices\n",
    "def subject_connectivity(timeseries, subject, atlas_name, kind, save=True, save_path=data_folder):\n",
    "    \"\"\"\n",
    "        timeseries   : timeseries table for subject (timepoints x regions)\n",
    "        subject      : the subject ID\n",
    "        atlas_name   : name of the parcellation atlas used\n",
    "        kind         : the kind of connectivity to be used, e.g. lasso, partial correlation, correlation\n",
    "        save         : save the connectivity matrix to a file\n",
    "        save_path    : specify path to save the matrix if different from subject folder\n",
    "\n",
    "    returns:\n",
    "        connectivity : connectivity matrix (regions x regions)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Estimating %s matrix for subject %s\" % (kind, subject))\n",
    "\n",
    "    if kind in ['tangent', 'partial correlation', 'correlation']:\n",
    "        conn_measure = connectome.ConnectivityMeasure(kind=kind)\n",
    "        connectivity = conn_measure.fit_transform([timeseries])[0]\n",
    "\n",
    "    if save:\n",
    "        subject_file = os.path.join(save_path, subject,\n",
    "                                    subject + '_' + atlas_name + '_' + kind.replace(' ', '_') + '.mat')\n",
    "        sio.savemat(subject_file, {'connectivity': connectivity})\n",
    "\n",
    "    return connectivity\n",
    "\n",
    "\n",
    "# Get the list of subject IDs\n",
    "def get_ids(num_subjects=None):\n",
    "    \"\"\"\n",
    "\n",
    "    return:\n",
    "        subject_IDs    : list of all subject IDs\n",
    "    \"\"\"\n",
    "\n",
    "    subject_IDs = np.genfromtxt(os.path.join(data_folder, 'subject_IDs.txt'), dtype=str)\n",
    "\n",
    "    if num_subjects is not None:\n",
    "        subject_IDs = subject_IDs[:num_subjects]\n",
    "\n",
    "    return subject_IDs\n",
    "\n",
    "\n",
    "# Get phenotype values for a list of subjects\n",
    "def get_subject_score(subject_list, score):\n",
    "    scores_dict = {}\n",
    "\n",
    "    with open(phenotype) as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            if row['SUB_ID'] in subject_list:\n",
    "                scores_dict[row['SUB_ID']] = row[score]\n",
    "\n",
    "    return scores_dict\n",
    "\n",
    "\n",
    "# Dimensionality reduction step for the feature vector using a ridge classifier\n",
    "def feature_selection(matrix, labels, train_ind, fnum):\n",
    "    \"\"\"\n",
    "        matrix       : feature matrix (num_subjects x num_features)\n",
    "        labels       : ground truth labels (num_subjects x 1)\n",
    "        train_ind    : indices of the training samples\n",
    "        fnum         : size of the feature vector after feature selection\n",
    "\n",
    "    return:\n",
    "        x_data      : feature matrix of lower dimension (num_subjects x fnum)\n",
    "    \"\"\"\n",
    "\n",
    "    estimator = RidgeClassifier()\n",
    "    selector = RFE(estimator, n_features_to_select=fnum, step=100, verbose=1)\n",
    "\n",
    "    featureX = matrix[train_ind, :]\n",
    "    featureY = labels[train_ind]\n",
    "    selector = selector.fit(featureX, featureY.ravel())\n",
    "    x_data = selector.transform(matrix)\n",
    "\n",
    "    print(\"Number of labeled samples %d\" % len(train_ind))\n",
    "    print(\"Number of features selected %d\" % x_data.shape[1])\n",
    "\n",
    "    return x_data\n",
    "\n",
    "\n",
    "# Make sure each site is represented in the training set when selecting a subset of the training set\n",
    "def site_percentage(train_ind, perc, subject_list):\n",
    "    \"\"\"\n",
    "        train_ind    : indices of the training samples\n",
    "        perc         : percentage of training set used\n",
    "        subject_list : list of subject IDs\n",
    "\n",
    "    return:\n",
    "        labeled_indices      : indices of the subset of training samples\n",
    "    \"\"\"\n",
    "\n",
    "    train_list = subject_list[train_ind]\n",
    "    sites = get_subject_score(train_list, score='SITE_ID')\n",
    "    unique = np.unique(list(sites.values())).tolist()\n",
    "    site = np.array([unique.index(sites[train_list[x]]) for x in range(len(train_list))])\n",
    "\n",
    "    labeled_indices = []\n",
    "\n",
    "    for i in np.unique(site):\n",
    "        id_in_site = np.argwhere(site == i).flatten()\n",
    "\n",
    "        num_nodes = len(id_in_site)\n",
    "        labeled_num = int(round(perc * num_nodes))\n",
    "        labeled_indices.extend(train_ind[id_in_site[:labeled_num]])\n",
    "\n",
    "    return labeled_indices\n",
    "\n",
    "\n",
    "# Load precomputed fMRI connectivity networks\n",
    "def get_networks(subject_list, kind, atlas_name=\"aal\", variable='connectivity'):\n",
    "    \"\"\"\n",
    "        subject_list : list of subject IDs\n",
    "        kind         : the kind of connectivity to be used, e.g. lasso, partial correlation, correlation\n",
    "        atlas_name   : name of the parcellation atlas used\n",
    "        variable     : variable name in the .mat file that has been used to save the precomputed networks\n",
    "\n",
    "\n",
    "    return:\n",
    "        matrix      : feature matrix of connectivity networks (num_subjects x network_size)\n",
    "    \"\"\"\n",
    "\n",
    "    all_networks = []\n",
    "    for subject1 in subject_list:\n",
    "        fl = f'../Datasets/all_fc_matrix_rois_cc200/matrix_{subject1}.mat'\n",
    "        try:  \n",
    "            matrix = sio.loadmat(fl)[variable]\n",
    "            all_networks.append(matrix)\n",
    "        except FileNotFoundError:\n",
    "            fl = f'../Datasets/all_fc_matrix_rois_cc200/matrix_{50002}.mat'\n",
    "            matrix = sio.loadmat(fl)[variable]\n",
    "            all_networks.append(matrix)\n",
    "            \n",
    "            \n",
    "    # all_networks=np.array(all_networks)\n",
    "\n",
    "    idx = np.triu_indices_from(all_networks[0], 1)\n",
    "    norm_networks = [np.arctanh(mat) if not np.all(np.abs(mat) == 1) else mat for mat in all_networks]\n",
    "    vec_networks = [mat[idx] for mat in norm_networks]\n",
    "    matrix = np.vstack(vec_networks)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# Construct the adjacency matrix of the population from phenotypic scores\n",
    "def create_affinity_graph_from_scores(scores, pd_dict):\n",
    "    num_nodes = len(pd_dict[scores[0]]) \n",
    "    graph = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    for l in scores:\n",
    "        label_dict = pd_dict[l]\n",
    "\n",
    "        if l in ['AGE_AT_SCAN', 'FIQ']:\n",
    "            for k in range(num_nodes):\n",
    "                for j in range(k + 1, num_nodes):\n",
    "                    try:\n",
    "                        val = abs(float(label_dict[k]) - float(label_dict[j]))\n",
    "                        if val < 2:\n",
    "                            graph[k, j] += 1\n",
    "                            graph[j, k] += 1\n",
    "                    except ValueError:  # missing label\n",
    "                        pass\n",
    "\n",
    "        else:\n",
    "            for k in range(num_nodes):\n",
    "                for j in range(k + 1, num_nodes):\n",
    "                    if label_dict[k] == label_dict[j]:\n",
    "                        graph[k, j] += 1\n",
    "                        graph[j, k] += 1\n",
    "\n",
    "    return graph\n",
    "\n",
    "def get_static_affinity_adj(features, pd_dict):\n",
    "    pd_affinity = create_affinity_graph_from_scores(['SEX', 'SITE_ID'], pd_dict) \n",
    "    distv = distance.pdist(features, metric='correlation') \n",
    "    dist = distance.squareform(distv)  \n",
    "    sigma = np.mean(dist)\n",
    "    feature_sim = np.exp(- dist ** 2 / (2 * sigma ** 2))\n",
    "    adj = pd_affinity * feature_sim  \n",
    "\n",
    "    return adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50e2f282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Local\\Temp\\ipykernel_7028\\3119403776.py:8: DeprecationWarning: Please use `eigsh` from the `scipy.sparse.linalg` namespace, the `scipy.sparse.linalg.eigen` namespace is deprecated.\n",
      "  from scipy.sparse.linalg.eigen import eigsh\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.spatial import distance\n",
    "from scipy.sparse.linalg.eigen import eigsh\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "def get_train_test_masks(labels, idx_train, idx_val, idx_test):\n",
    "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_test = np.zeros(labels.shape)\n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "    return y_train, y_val, y_test, train_mask, val_mask, test_mask\n",
    "\n",
    "def load_data(subject_IDs, params): \n",
    "    \n",
    "    # labels\n",
    "    num_classes = 2\n",
    "    num_nodes = len(subject_IDs)\n",
    "    \n",
    "    # 初始化y_data(), y\n",
    "    y_data = np.zeros([num_nodes, num_classes])\n",
    "    y = np.zeros([num_nodes, 1])\n",
    "    \n",
    "    labels = get_subject_score(subject_IDs, score='DX_GROUP')\n",
    "    features = get_networks(subject_IDs, kind=params['connectivity'], atlas_name=params['atlas'])\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        y_data[i, int(labels[subject_IDs[i]]) - 1] = 1 # (871,2)\n",
    "        y[i] = int(labels[subject_IDs[i]]) # (871,)\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    cv_splits = list(skf.split(features, np.squeeze(y)))\n",
    "    train = cv_splits[params['folds']][0]\n",
    "    test = cv_splits[params['folds']][1]\n",
    "    val = test\n",
    "    \n",
    "    print('Number of train sample:{}' .format(len(train)))\n",
    "        \n",
    "    y_train, y_val, y_test, train_mask, val_mask, test_mask = get_train_test_masks(y_data, train, val, test)\n",
    "    \n",
    "    y_data = torch.LongTensor(np.where(y_data)[1])\n",
    "    y = torch.LongTensor(y)\n",
    "    y_train = torch.LongTensor(y_train[1])\n",
    "    y_val = torch.LongTensor(y_val[1])\n",
    "    y_test = torch.LongTensor(y_test[1])\n",
    "    \n",
    "    train = torch.LongTensor(train)\n",
    "    val = torch.LongTensor(val)\n",
    "    test = torch.LongTensor(test)\n",
    "    train_mask = torch.LongTensor(train_mask)\n",
    "    val_mask = torch.LongTensor(val_mask)\n",
    "    test_mask = torch.LongTensor(test_mask)\n",
    "    \n",
    "    # Eigenvector\n",
    "    labeled_ind = site_percentage(train, params['num_training'], subject_IDs)\n",
    "    x_data = feature_selection(features, y, labeled_ind, params['num_features'])\n",
    "    features = preprocess_features(sp.coo_matrix(x_data).tolil())\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    \n",
    "    # Adjacency matrix\n",
    "    graph = create_affinity_graph_from_scores(['SEX', 'SITE_ID'], subject_IDs)\n",
    "    distv = distance.pdist(x_data, metric='correlation')\n",
    "    dist = distance.squareform(distv)\n",
    "    sigma = np.mean(dist)\n",
    "    sparse_graph = np.exp(- dist ** 2 / (2 * sigma ** 2))\n",
    "    final_graph = graph * sparse_graph\n",
    "\n",
    "    return final_graph, features, y, y_data, y_train, y_val, y_test, train, val, test, train_mask, val_mask, test_mask\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
    "    def to_tuple(mx):\n",
    "        if not sp.isspmatrix_coo(mx):\n",
    "            mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "        values = mx.data\n",
    "        shape = mx.shape\n",
    "        coords = torch.from_numpy(coords)\n",
    "        values = torch.from_numpy(values)\n",
    "        shape = torch.tensor(shape)\n",
    "        return coords, values, shape\n",
    "\n",
    "    if isinstance(sparse_mx, list):\n",
    "        for i in range(len(sparse_mx)):\n",
    "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
    "    else:\n",
    "        sparse_mx = to_tuple(sparse_mx)\n",
    "\n",
    "    return sparse_mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "\n",
    "def preprocess_features(features):\n",
    "    \"\"\"Row-normalize feature matrix\"\"\"\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return features\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    \"\"\"Preprocessing of adjacency matrix for simple GCN model.\"\"\"\n",
    "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    return adj_normalized\n",
    "\n",
    "def chebyshev_polynomials(adj, k):\n",
    "    \"\"\"Calculate Chebyshev polynomials up to order k. Return a list of sparse matrices (tuple representation).\"\"\"\n",
    "    print(\"Calculating Chebyshev polynomials up to order {}...\".format(k))\n",
    "\n",
    "    adj_normalized = normalize_adj(adj)\n",
    "    laplacian = sp.eye(adj.shape[0]) - adj_normalized\n",
    "    largest_eigval, _ = eigsh(laplacian, 1, which='LM')\n",
    "    scaled_laplacian = (2. / largest_eigval[0]) * laplacian - sp.eye(adj.shape[0])\n",
    "\n",
    "    t_k = list()\n",
    "    t_k.append(sp.eye(adj.shape[0]))\n",
    "    t_k.append(scaled_laplacian)\n",
    "\n",
    "    def chebyshev_recurrence(t_k_minus_one, t_k_minus_two, scaled_lap):\n",
    "        s_lap = sp.csr_matrix(scaled_lap, copy=True)\n",
    "        return 2 * s_lap.dot(t_k_minus_one) - t_k_minus_two\n",
    "\n",
    "    for i in range(2, k+1):\n",
    "        t_k.append(chebyshev_recurrence(t_k[-1], t_k[-2], scaled_laplacian))\n",
    "\n",
    "    return t_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7980a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# from utils import preprocess_features\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "class dataloader():\n",
    "    def __init__(self): \n",
    "        self.pd_dict = {}\n",
    "        self.node_ftr_dim = 2000\n",
    "        self.num_classes = 2 \n",
    "\n",
    "    def load_data(self, params, connectivity='correlation', atlas='ho'):\n",
    "        ''' load multimodal data from ABIDE\n",
    "        return: imaging features (raw), labels, non-image data\n",
    "        '''\n",
    "        subject_IDs = get_ids()\n",
    "        labels = get_subject_score(subject_IDs, score='DX_GROUP')\n",
    "        num_nodes = len(subject_IDs)\n",
    "\n",
    "        sites = get_subject_score(subject_IDs, score='SITE_ID')\n",
    "        unique = np.unique(list(sites.values())).tolist()\n",
    "        ages = get_subject_score(subject_IDs, score='AGE_AT_SCAN')\n",
    "        genders = get_subject_score(subject_IDs, score='SEX') \n",
    "\n",
    "        y_onehot = np.zeros([num_nodes, self.num_classes])\n",
    "        y = np.zeros([num_nodes])\n",
    "        site = np.zeros([num_nodes], dtype=int)\n",
    "        age = np.zeros([num_nodes], dtype=np.float32)\n",
    "        gender = np.zeros([num_nodes], dtype=int)\n",
    "        for i in range(num_nodes):\n",
    "            y_onehot[i, int(labels[subject_IDs[i]])-1] = 1\n",
    "            y[i] = int(labels[subject_IDs[i]])\n",
    "            site[i] = unique.index(sites[subject_IDs[i]])\n",
    "            age[i] = float(ages[subject_IDs[i]])\n",
    "            gender[i] = genders[subject_IDs[i]]\n",
    "        \n",
    "        self.y = y -1  \n",
    "\n",
    "        self.raw_features = get_networks(subject_IDs, kind=connectivity, atlas_name=atlas)\n",
    "\n",
    "        phonetic_data = np.zeros([num_nodes, 3], dtype=np.float32)\n",
    "        phonetic_data[:,0] = site \n",
    "        phonetic_data[:,1] = gender \n",
    "        phonetic_data[:,2] = age \n",
    "\n",
    "        self.pd_dict['SITE_ID'] = np.copy(phonetic_data[:,0])\n",
    "        self.pd_dict['SEX'] = np.copy(phonetic_data[:,1])\n",
    "        self.pd_dict['AGE_AT_SCAN'] = np.copy(phonetic_data[:,2]) \n",
    "        \n",
    "        return self.raw_features, self.y, phonetic_data\n",
    "\n",
    "    def data_split(self, n_folds):\n",
    "        # split data by k-fold CV\n",
    "        skf = StratifiedKFold(n_splits=n_folds)\n",
    "        cv_splits = list(skf.split(self.raw_features, self.y))\n",
    "        return cv_splits \n",
    "\n",
    "    def get_node_features(self, train_ind):\n",
    "        '''preprocess node features for wl-deepgcn\n",
    "        '''\n",
    "        node_ftr = feature_selection(self.raw_features, self.y, train_ind, self.node_ftr_dim)\n",
    "        self.node_ftr = preprocess_features(node_ftr) \n",
    "        return self.node_ftr\n",
    "\n",
    "    def get_WL_inputs(self, nonimg):\n",
    "        '''get WL inputs for wl-deepgcn \n",
    "        '''\n",
    "        # construct edge network inputs \n",
    "        n = self.node_ftr.shape[0] \n",
    "        num_edge = n*(1+n)//2 - n  # n*(n-1)//2,HO=6105\n",
    "        pd_ftr_dim = nonimg.shape[1]\n",
    "        edge_index = np.zeros([2, num_edge], dtype=np.int64) \n",
    "        edgenet_input = np.zeros([num_edge, 2*pd_ftr_dim], dtype=np.float32)  \n",
    "        aff_score = np.zeros(num_edge, dtype=np.float32)\n",
    "        # static affinity score used to pre-prune edges \n",
    "        aff_adj = get_static_affinity_adj(self.node_ftr, self.pd_dict)  \n",
    "        flatten_ind = 0 \n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                edge_index[:,flatten_ind] = [i,j]\n",
    "                edgenet_input[flatten_ind]  = np.concatenate((nonimg[i], nonimg[j]))\n",
    "                aff_score[flatten_ind] = aff_adj[i][j]  \n",
    "                flatten_ind +=1\n",
    "\n",
    "        assert flatten_ind == num_edge, \"Error in computing edge input\"\n",
    "        \n",
    "        keep_ind = np.where(aff_score > 1.1)[0]  \n",
    "        edge_index = edge_index[:, keep_ind]\n",
    "        edgenet_input = edgenet_input[keep_ind]\n",
    "\n",
    "        return edge_index, edgenet_input\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abc69f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn import Linear as Lin, Sequential as Seq\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class WL(torch.nn.Module):\n",
    "    def __init__(self, input_dim, dropout=0.3):\n",
    "        super(WL, self).__init__()\n",
    "        h1=256\n",
    "        h2=128\n",
    "        self.parser =nn.Sequential(\n",
    "                nn.Linear(input_dim, h1, bias=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.BatchNorm1d(h1),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(h1, h2, bias=True),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.BatchNorm1d(h2),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(h2, h2, bias=True),\n",
    "                )\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-8)\n",
    "        self.input_dim = input_dim\n",
    "        self.model_init()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.elu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = x[:,0:self.input_dim]\n",
    "        x2 = x[:,self.input_dim:]\n",
    "        h1 = self.parser(x1) \n",
    "        h2 = self.parser(x2) \n",
    "        p = (self.cos(h1,h2) + 1)*0.5\n",
    "        return p\n",
    "\n",
    "    def model_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Lin):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                m.weight.requires_grad = True\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    m.bias.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6db8243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import Linear as Lin, Sequential as Seq\n",
    "import torch_geometric as tg\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, nhid):\n",
    "        super(MLP,self).__init__()\n",
    "        self.cls = nn.Sequential(\n",
    "            torch.nn.Linear(input_dim,nhid))\n",
    "        \n",
    "    def forward(self, features):\n",
    "        output = self.cls(features)\n",
    "        return output\n",
    "            \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, nhid, num_classes, ngl, dropout, edge_dropout, edgenet_input_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        K=3   \n",
    "        hidden = [nhid for i in range(ngl)] \n",
    "        self.dropout = dropout\n",
    "        self.edge_dropout = edge_dropout \n",
    "        bias = False \n",
    "        self.relu = torch.nn.ReLU(inplace=True) \n",
    "        self.ngl = ngl \n",
    "        self.gconv = nn.ModuleList()\n",
    "        for i in range(ngl):\n",
    "            in_channels = input_dim if i==0  else hidden[i-1]\n",
    "            self.gconv.append(tg.nn.ChebConv(in_channels, hidden[i], K, normalization='sym', bias=bias)) \n",
    "          \n",
    "        self.cls = nn.Sequential(\n",
    "                torch.nn.Linear(16, 128),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm1d(128), \n",
    "                torch.nn.Linear(128, num_classes))\n",
    "\n",
    "        self.edge_net = WL(input_dim=edgenet_input_dim//2, dropout=dropout)\n",
    "        self.model_init()\n",
    "\n",
    "    def model_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Lin):\n",
    "                torch.nn.init.kaiming_normal_(m.weight) # He init\n",
    "                m.weight.requires_grad = True\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    m.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, features, edge_index, edgenet_input, enforce_edropout=False): \n",
    "        if self.edge_dropout>0:\n",
    "            if enforce_edropout or self.training:\n",
    "                one_mask = torch.ones([edgenet_input.shape[0],1])\n",
    "                self.drop_mask = F.dropout(one_mask, self.edge_dropout, True)\n",
    "                self.bool_mask = torch.squeeze(self.drop_mask.type(torch.bool))\n",
    "                edge_index = edge_index[:, self.bool_mask] \n",
    "                edgenet_input = edgenet_input[self.bool_mask] # Weights\n",
    "            \n",
    "        edge_weight = torch.squeeze(self.edge_net(edgenet_input))\n",
    "        \n",
    "\n",
    "        # GCN residual connection\n",
    "        # input layer\n",
    "        features = F.dropout(features, self.dropout, self.training)\n",
    "        x = self.relu(self.gconv[0](features, edge_index, edge_weight)) \n",
    "        x_temp = x\n",
    "        \n",
    "        # hidden layers\n",
    "        for i in range(1, self.ngl - 1): # self.ngl→7\n",
    "            x = F.dropout(x_temp, self.dropout, self.training)\n",
    "            x = self.relu(self.gconv[i](x, edge_index, edge_weight)) \n",
    "            x_temp = x_temp + x # ([871,64])\n",
    "\n",
    "        # output layer\n",
    "        x = F.dropout(x_temp, self.dropout, self.training)\n",
    "        x = self.relu(self.gconv[self.ngl - 1](x, edge_index, edge_weight))\n",
    "        x_temp = x_temp + x\n",
    "\n",
    "        output = x # Final output is not cumulative\n",
    "        output = self.cls(output) \n",
    "        \n",
    "        return output, edge_weight\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "165d107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5856d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import MulticlassSpecificity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def torchmetrics_accuracy(preds, labels):\n",
    "    acc = torchmetrics.functional.accuracy(preds, labels,task=\"multiclass\", num_classes=2)\n",
    "    return acc\n",
    "\n",
    "def torchmetrics_spef(preds, labels):\n",
    "    metric = MulticlassSpecificity(num_classes=2)\n",
    "    spef = metric(preds, labels)\n",
    "    return spef\n",
    "\n",
    "def torchmetrics_auc(preds, labels):\n",
    "    auc = torchmetrics.functional.auroc(preds, labels, task=\"multiclass\", num_classes=2)\n",
    "    return auc\n",
    "\n",
    "def confusion_matrix(preds, labels):\n",
    "    conf_matrix = torch.zeros(2, 2)\n",
    "    preds = torch.argmax(preds, 1)\n",
    "    for p, t in zip(preds, labels):\n",
    "        conf_matrix[t, p] += 1 \n",
    "    return conf_matrix\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    Input\n",
    "    - cm : computer the value of confusion matrix\n",
    "    - normalize : True: %, False: 123\n",
    "    \"\"\"\n",
    "    classes = ['0:ASD','1:TC']\n",
    "    if normalize:\n",
    "        cm = cm.numpy()\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def correct_num(preds, labels):\n",
    "    \"\"\"Accuracy, auc with masking.Acc of the masked samples\"\"\"\n",
    "    correct_prediction = np.equal(np.argmax(preds, 1), labels).astype(np.float32)\n",
    "    return np.sum(correct_prediction)\n",
    "\n",
    "def prf(preds, labels, is_logit=True):\n",
    "    ''' input: logits, labels  ''' \n",
    "    pred_lab= np.argmax(preds, 1)\n",
    "    p,r,f,s  = precision_recall_fscore_support(labels, pred_lab, average='binary')\n",
    "    return [p,r,f]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae068d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ba9682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "no_cuda: False\n",
      "seed: 46\n",
      "epochs: 200\n",
      "lr: 0.001\n",
      "weight_decay: 5e-05\n",
      "hidden: 16\n",
      "dropout: 0.2\n",
      "atlas: cc200\n",
      "num_features: 2000\n",
      "folds: 5\n",
      "connectivity: correlation\n",
      "max_degree: 3\n",
      "ngl: 8\n",
      "edropout: 0.3\n",
      "train: 1\n",
      "ckpt_path: ../folds/rois_cc200_pth_2\n",
      "early_stopping: True\n",
      "early_stopping_patience: 20\n",
      "cuda: False\n",
      "  Loading dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Local\\Temp\\ipykernel_7028\\3229437123.py:216: RuntimeWarning: divide by zero encountered in arctanh\n",
      "  norm_networks = [np.arctanh(mat) if not np.all(np.abs(mat) == 1) else mat for mat in all_networks]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the 1-fold Training, Validation, and Test Sets:800,89,223\n",
      " Starting the 1-1 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4800 pre_train:0.4954 recall_train:0.5218 F1_train:0.5083 AUC_train:0.4771\n",
      "acc_val:0.6292 pre_val:0.6066 recall_val:0.8043 F1_val:0.691589 AUC_val:0.7356\n",
      "Epoch:0002\n",
      "acc_train:0.5500 pre_train:0.5760 recall_train:0.4782 F1_train:0.5225 AUC_train:0.5605\n",
      "acc_val:0.6292 pre_val:0.6327 recall_val:0.6739 F1_val:0.652632 AUC_val:0.6876\n",
      "Epoch:0003\n",
      "acc_train:0.5150 pre_train:0.5335 recall_train:0.4636 F1_train:0.4961 AUC_train:0.5246\n",
      "acc_val:0.6404 pre_val:0.7188 recall_val:0.5000 F1_val:0.589744 AUC_val:0.6871\n",
      "Epoch:0004\n",
      "acc_train:0.5275 pre_train:0.5515 recall_train:0.4417 F1_train:0.4906 AUC_train:0.5408\n",
      "acc_val:0.6629 pre_val:0.7857 recall_val:0.4783 F1_val:0.594595 AUC_val:0.6916\n",
      "Epoch:0005\n",
      "acc_train:0.5063 pre_train:0.5227 recall_train:0.4757 F1_train:0.4981 AUC_train:0.5214\n",
      "acc_val:0.6629 pre_val:0.8077 recall_val:0.4565 F1_val:0.583333 AUC_val:0.6891\n",
      "Epoch:0006\n",
      "acc_train:0.5325 pre_train:0.5543 recall_train:0.4709 F1_train:0.5092 AUC_train:0.5490\n",
      "acc_val:0.6517 pre_val:0.7778 recall_val:0.4565 F1_val:0.575342 AUC_val:0.6936\n",
      "Epoch:0007\n",
      "acc_train:0.5550 pre_train:0.5909 recall_train:0.4417 F1_train:0.5056 AUC_train:0.5603\n",
      "acc_val:0.6629 pre_val:0.7857 recall_val:0.4783 F1_val:0.594595 AUC_val:0.7053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0008\n",
      "acc_train:0.5325 pre_train:0.5549 recall_train:0.4660 F1_train:0.5066 AUC_train:0.5275\n",
      "acc_val:0.6742 pre_val:0.7429 recall_val:0.5652 F1_val:0.641975 AUC_val:0.7204\n",
      "Epoch:0009\n",
      "acc_train:0.5925 pre_train:0.6424 recall_train:0.4709 F1_train:0.5434 AUC_train:0.6119\n",
      "acc_val:0.6629 pre_val:0.7353 recall_val:0.5435 F1_val:0.625000 AUC_val:0.7275\n",
      "Epoch:0010\n",
      "acc_train:0.6150 pre_train:0.6576 recall_train:0.5267 F1_train:0.5849 AUC_train:0.6249\n",
      "acc_val:0.6742 pre_val:0.7297 recall_val:0.5870 F1_val:0.650602 AUC_val:0.7144\n",
      "Epoch:0011\n",
      "acc_train:0.5050 pre_train:0.5156 recall_train:0.6408 F1_train:0.5714 AUC_train:0.5090\n",
      "acc_val:0.6404 pre_val:0.6346 recall_val:0.7174 F1_val:0.673469 AUC_val:0.7154\n",
      "Epoch:0012\n",
      "acc_train:0.5763 pre_train:0.6409 recall_train:0.4029 F1_train:0.4948 AUC_train:0.5959\n",
      "acc_val:0.6854 pre_val:0.6875 recall_val:0.7174 F1_val:0.702128 AUC_val:0.7214\n",
      "Epoch:0013\n",
      "acc_train:0.5813 pre_train:0.6136 recall_train:0.5049 F1_train:0.5539 AUC_train:0.6082\n",
      "acc_val:0.7079 pre_val:0.7273 recall_val:0.6957 F1_val:0.711111 AUC_val:0.7300\n",
      "Epoch:0014\n",
      "acc_train:0.5625 pre_train:0.5767 recall_train:0.5655 F1_train:0.5711 AUC_train:0.5857\n",
      "acc_val:0.6854 pre_val:0.6957 recall_val:0.6957 F1_val:0.695652 AUC_val:0.7285\n",
      "Epoch:0015\n",
      "acc_train:0.5688 pre_train:0.6113 recall_train:0.4466 F1_train:0.5161 AUC_train:0.5706\n",
      "acc_val:0.7303 pre_val:0.7500 recall_val:0.7174 F1_val:0.733333 AUC_val:0.7503\n",
      "Epoch:0016\n",
      "acc_train:0.5688 pre_train:0.6031 recall_train:0.4757 F1_train:0.5319 AUC_train:0.5931\n",
      "acc_val:0.7303 pre_val:0.7619 recall_val:0.6957 F1_val:0.727273 AUC_val:0.7497\n",
      "Epoch:0017\n",
      "acc_train:0.5550 pre_train:0.5722 recall_train:0.5388 F1_train:0.5550 AUC_train:0.5746\n",
      "acc_val:0.7303 pre_val:0.7750 recall_val:0.6739 F1_val:0.720930 AUC_val:0.7518\n",
      "Epoch:0018\n",
      "acc_train:0.5875 pre_train:0.6139 recall_train:0.5364 F1_train:0.5725 AUC_train:0.6007\n",
      "acc_val:0.6966 pre_val:0.7714 recall_val:0.5870 F1_val:0.666667 AUC_val:0.7518\n",
      "Epoch:0019\n",
      "acc_train:0.5975 pre_train:0.6324 recall_train:0.5218 F1_train:0.5718 AUC_train:0.6056\n",
      "acc_val:0.6966 pre_val:0.7568 recall_val:0.6087 F1_val:0.674699 AUC_val:0.7497\n",
      "Epoch:0020\n",
      "acc_train:0.5888 pre_train:0.6254 recall_train:0.5024 F1_train:0.5572 AUC_train:0.6139\n",
      "acc_val:0.7079 pre_val:0.8125 recall_val:0.5652 F1_val:0.666667 AUC_val:0.7553\n",
      "Epoch:0021\n",
      "acc_train:0.5838 pre_train:0.6119 recall_train:0.5243 F1_train:0.5647 AUC_train:0.5910\n",
      "acc_val:0.6966 pre_val:0.8065 recall_val:0.5435 F1_val:0.649351 AUC_val:0.7609\n",
      "Epoch:0022\n",
      "acc_train:0.6062 pre_train:0.6611 recall_train:0.4830 F1_train:0.5582 AUC_train:0.6506\n",
      "acc_val:0.6966 pre_val:0.8065 recall_val:0.5435 F1_val:0.649351 AUC_val:0.7644\n",
      "Epoch:0023\n",
      "acc_train:0.5925 pre_train:0.6303 recall_train:0.5049 F1_train:0.5606 AUC_train:0.6112\n",
      "acc_val:0.7191 pre_val:0.8621 recall_val:0.5435 F1_val:0.666667 AUC_val:0.7685\n",
      "Epoch:0024\n",
      "acc_train:0.5775 pre_train:0.6225 recall_train:0.4563 F1_train:0.5266 AUC_train:0.6057\n",
      "acc_val:0.7079 pre_val:0.8571 recall_val:0.5217 F1_val:0.648649 AUC_val:0.7695\n",
      "Epoch:0025\n",
      "acc_train:0.5913 pre_train:0.6421 recall_train:0.4660 F1_train:0.5401 AUC_train:0.6153\n",
      "acc_val:0.7079 pre_val:0.8571 recall_val:0.5217 F1_val:0.648649 AUC_val:0.7599\n",
      "Epoch:0026\n",
      "acc_train:0.6137 pre_train:0.6373 recall_train:0.5801 F1_train:0.6074 AUC_train:0.6462\n",
      "acc_val:0.7191 pre_val:0.8621 recall_val:0.5435 F1_val:0.666667 AUC_val:0.7710\n",
      "Epoch:0027\n",
      "acc_train:0.6187 pre_train:0.6667 recall_train:0.5194 F1_train:0.5839 AUC_train:0.6362\n",
      "acc_val:0.7079 pre_val:0.8571 recall_val:0.5217 F1_val:0.648649 AUC_val:0.7710\n",
      "Epoch:0028\n",
      "acc_train:0.5838 pre_train:0.6193 recall_train:0.4976 F1_train:0.5518 AUC_train:0.6107\n",
      "acc_val:0.7191 pre_val:0.8621 recall_val:0.5435 F1_val:0.666667 AUC_val:0.7659\n",
      "Epoch:0029\n",
      "acc_train:0.5587 pre_train:0.5736 recall_train:0.5583 F1_train:0.5658 AUC_train:0.5952\n",
      "acc_val:0.7191 pre_val:0.8621 recall_val:0.5435 F1_val:0.666667 AUC_val:0.7791\n",
      "Epoch:0030\n",
      "acc_train:0.5938 pre_train:0.6495 recall_train:0.4587 F1_train:0.5377 AUC_train:0.6085\n",
      "acc_val:0.7079 pre_val:0.8571 recall_val:0.5217 F1_val:0.648649 AUC_val:0.7745\n",
      "Epoch:0031\n",
      "acc_train:0.5788 pre_train:0.6161 recall_train:0.4830 F1_train:0.5415 AUC_train:0.6086\n",
      "acc_val:0.6966 pre_val:0.8519 recall_val:0.5000 F1_val:0.630137 AUC_val:0.7765\n",
      "Epoch:0032\n",
      "acc_train:0.5950 pre_train:0.6294 recall_train:0.5194 F1_train:0.5691 AUC_train:0.6224\n",
      "acc_val:0.7079 pre_val:0.8571 recall_val:0.5217 F1_val:0.648649 AUC_val:0.7755\n",
      "Epoch:0033\n",
      "acc_train:0.5325 pre_train:0.5490 recall_train:0.5170 F1_train:0.5325 AUC_train:0.5618\n",
      "acc_val:0.7191 pre_val:0.8621 recall_val:0.5435 F1_val:0.666667 AUC_val:0.7558\n",
      "Epoch:0034\n",
      "acc_train:0.6075 pre_train:0.6531 recall_train:0.5073 F1_train:0.5710 AUC_train:0.6210\n",
      "acc_val:0.6742 pre_val:0.8148 recall_val:0.4783 F1_val:0.602740 AUC_val:0.7442\n",
      "Epoch:0035\n",
      "acc_train:0.5788 pre_train:0.5979 recall_train:0.5558 F1_train:0.5761 AUC_train:0.5905\n",
      "acc_val:0.6854 pre_val:0.8462 recall_val:0.4783 F1_val:0.611111 AUC_val:0.7417\n",
      "Epoch:0036\n",
      "acc_train:0.5612 pre_train:0.5735 recall_train:0.5777 F1_train:0.5756 AUC_train:0.6041\n",
      "acc_val:0.6966 pre_val:0.8519 recall_val:0.5000 F1_val:0.630137 AUC_val:0.7548\n",
      "Epoch:0037\n",
      "acc_train:0.5850 pre_train:0.6282 recall_train:0.4757 F1_train:0.5414 AUC_train:0.5898\n",
      "acc_val:0.6854 pre_val:0.8462 recall_val:0.4783 F1_val:0.611111 AUC_val:0.7619\n",
      "Epoch:0038\n",
      "acc_train:0.5925 pre_train:0.6361 recall_train:0.4879 F1_train:0.5522 AUC_train:0.6178\n",
      "acc_val:0.6854 pre_val:0.8462 recall_val:0.4783 F1_val:0.611111 AUC_val:0.7664\n",
      "Epoch:0039\n",
      "acc_train:0.5838 pre_train:0.6254 recall_train:0.4782 F1_train:0.5420 AUC_train:0.6031\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7594\n",
      "Epoch:0040\n",
      "acc_train:0.5900 pre_train:0.6280 recall_train:0.5000 F1_train:0.5568 AUC_train:0.5998\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7624\n",
      "Epoch:0041\n",
      "acc_train:0.6112 pre_train:0.6700 recall_train:0.4830 F1_train:0.5614 AUC_train:0.6302\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7624\n",
      "Epoch:0042\n",
      "acc_train:0.5925 pre_train:0.6369 recall_train:0.4854 F1_train:0.5510 AUC_train:0.6240\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7583\n",
      "Epoch:0043\n",
      "acc_train:0.5962 pre_train:0.6450 recall_train:0.4806 F1_train:0.5508 AUC_train:0.6345\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7781\n",
      "Epoch:0044\n",
      "acc_train:0.6087 pre_train:0.6452 recall_train:0.5340 F1_train:0.5843 AUC_train:0.6404\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7674\n",
      "Epoch:0045\n",
      "acc_train:0.6012 pre_train:0.6632 recall_train:0.4587 F1_train:0.5423 AUC_train:0.6228\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7705\n",
      "Epoch:0046\n",
      "acc_train:0.5875 pre_train:0.6213 recall_train:0.5097 F1_train:0.5600 AUC_train:0.6387\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7816\n",
      "Epoch:0047\n",
      "acc_train:0.6137 pre_train:0.6886 recall_train:0.4563 F1_train:0.5489 AUC_train:0.6263\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.7978\n",
      "Epoch:0048\n",
      "acc_train:0.6187 pre_train:0.6918 recall_train:0.4684 F1_train:0.5586 AUC_train:0.6421\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.8023\n",
      "Epoch:0049\n",
      "acc_train:0.6225 pre_train:0.6858 recall_train:0.4927 F1_train:0.5734 AUC_train:0.6322\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.8033\n",
      "Epoch:0050\n",
      "acc_train:0.6263 pre_train:0.6902 recall_train:0.4976 F1_train:0.5783 AUC_train:0.6572\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.8064\n",
      "Epoch:0051\n",
      "acc_train:0.6225 pre_train:0.6833 recall_train:0.4976 F1_train:0.5758 AUC_train:0.6630\n",
      "acc_val:0.6742 pre_val:0.8400 recall_val:0.4565 F1_val:0.591549 AUC_val:0.8043\n",
      "Epoch:0052\n",
      "acc_train:0.6300 pre_train:0.7101 recall_train:0.4757 F1_train:0.5698 AUC_train:0.6570\n",
      "acc_val:0.6629 pre_val:0.8077 recall_val:0.4565 F1_val:0.583333 AUC_val:0.8150\n",
      "Epoch:0053\n",
      "acc_train:0.6200 pre_train:0.6915 recall_train:0.4733 F1_train:0.5620 AUC_train:0.6540\n",
      "acc_val:0.6629 pre_val:0.8077 recall_val:0.4565 F1_val:0.583333 AUC_val:0.8165\n",
      "Epoch:0054\n",
      "acc_train:0.6012 pre_train:0.6388 recall_train:0.5194 F1_train:0.5730 AUC_train:0.6666\n",
      "acc_val:0.6629 pre_val:0.8077 recall_val:0.4565 F1_val:0.583333 AUC_val:0.8225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0055\n",
      "acc_train:0.6100 pre_train:0.6634 recall_train:0.4927 F1_train:0.5655 AUC_train:0.6437\n",
      "acc_val:0.6854 pre_val:0.8214 recall_val:0.5000 F1_val:0.621622 AUC_val:0.8220\n",
      "Epoch:0056\n",
      "acc_train:0.6012 pre_train:0.6274 recall_train:0.5558 F1_train:0.5894 AUC_train:0.6579\n",
      "acc_val:0.6966 pre_val:0.8276 recall_val:0.5217 F1_val:0.640000 AUC_val:0.8342\n",
      "Epoch:0057\n",
      "acc_train:0.5925 pre_train:0.6208 recall_train:0.5364 F1_train:0.5755 AUC_train:0.6878\n",
      "acc_val:0.7191 pre_val:0.8387 recall_val:0.5652 F1_val:0.675325 AUC_val:0.8433\n",
      "Epoch:0058\n",
      "acc_train:0.5962 pre_train:0.6290 recall_train:0.5267 F1_train:0.5733 AUC_train:0.6624\n",
      "acc_val:0.7303 pre_val:0.8438 recall_val:0.5870 F1_val:0.692308 AUC_val:0.8453\n",
      "Epoch:0059\n",
      "acc_train:0.6250 pre_train:0.6582 recall_train:0.5655 F1_train:0.6084 AUC_train:0.7073\n",
      "acc_val:0.7303 pre_val:0.8438 recall_val:0.5870 F1_val:0.692308 AUC_val:0.8539\n",
      "Epoch:0060\n",
      "acc_train:0.6137 pre_train:0.6594 recall_train:0.5170 F1_train:0.5796 AUC_train:0.6732\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8579\n",
      "Epoch:0061\n",
      "acc_train:0.6050 pre_train:0.6437 recall_train:0.5218 F1_train:0.5764 AUC_train:0.7059\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8610\n",
      "Epoch:0062\n",
      "acc_train:0.6375 pre_train:0.6837 recall_train:0.5510 F1_train:0.6102 AUC_train:0.6964\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8665\n",
      "Epoch:0063\n",
      "acc_train:0.6075 pre_train:0.6476 recall_train:0.5218 F1_train:0.5780 AUC_train:0.6913\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8680\n",
      "Epoch:0064\n",
      "acc_train:0.6137 pre_train:0.6510 recall_train:0.5388 F1_train:0.5896 AUC_train:0.6964\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8675\n",
      "Epoch:0065\n",
      "acc_train:0.6025 pre_train:0.6306 recall_train:0.5510 F1_train:0.5881 AUC_train:0.6885\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8711\n",
      "Epoch:0066\n",
      "acc_train:0.6187 pre_train:0.6667 recall_train:0.5194 F1_train:0.5839 AUC_train:0.7017\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8696\n",
      "Epoch:0067\n",
      "acc_train:0.6000 pre_train:0.6314 recall_train:0.5364 F1_train:0.5801 AUC_train:0.7030\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8731\n",
      "Epoch:0068\n",
      "acc_train:0.6187 pre_train:0.6607 recall_train:0.5340 F1_train:0.5906 AUC_train:0.7174\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8782\n",
      "Epoch:0069\n",
      "acc_train:0.6175 pre_train:0.6587 recall_train:0.5340 F1_train:0.5898 AUC_train:0.7084\n",
      "acc_val:0.7528 pre_val:0.8529 recall_val:0.6304 F1_val:0.725000 AUC_val:0.8827\n",
      "Epoch:0070\n",
      "acc_train:0.6275 pre_train:0.6707 recall_train:0.5437 F1_train:0.6005 AUC_train:0.7262\n",
      "acc_val:0.7528 pre_val:0.8529 recall_val:0.6304 F1_val:0.725000 AUC_val:0.8857\n",
      "Epoch:0071\n",
      "acc_train:0.6175 pre_train:0.6541 recall_train:0.5461 F1_train:0.5952 AUC_train:0.7250\n",
      "acc_val:0.7640 pre_val:0.8788 recall_val:0.6304 F1_val:0.734177 AUC_val:0.8933\n",
      "Epoch:0072\n",
      "acc_train:0.6637 pre_train:0.7214 recall_train:0.5655 F1_train:0.6340 AUC_train:0.7555\n",
      "acc_val:0.7640 pre_val:0.8788 recall_val:0.6304 F1_val:0.734177 AUC_val:0.9019\n",
      "Epoch:0073\n",
      "acc_train:0.6500 pre_train:0.7025 recall_train:0.5558 F1_train:0.6206 AUC_train:0.7716\n",
      "acc_val:0.7753 pre_val:0.8824 recall_val:0.6522 F1_val:0.750000 AUC_val:0.9044\n",
      "Epoch:0074\n",
      "acc_train:0.6637 pre_train:0.6917 recall_train:0.6262 F1_train:0.6573 AUC_train:0.7727\n",
      "acc_val:0.7753 pre_val:0.8824 recall_val:0.6522 F1_val:0.750000 AUC_val:0.9100\n",
      "Epoch:0075\n",
      "acc_train:0.6350 pre_train:0.6786 recall_train:0.5534 F1_train:0.6096 AUC_train:0.7859\n",
      "acc_val:0.7865 pre_val:0.9091 recall_val:0.6522 F1_val:0.759494 AUC_val:0.9237\n",
      "Epoch:0076\n",
      "acc_train:0.6388 pre_train:0.6814 recall_train:0.5607 F1_train:0.6152 AUC_train:0.7894\n",
      "acc_val:0.7978 pre_val:0.9375 recall_val:0.6522 F1_val:0.769231 AUC_val:0.9282\n",
      "Epoch:0077\n",
      "acc_train:0.6837 pre_train:0.7590 recall_train:0.5655 F1_train:0.6481 AUC_train:0.8184\n",
      "acc_val:0.7865 pre_val:0.9091 recall_val:0.6522 F1_val:0.759494 AUC_val:0.9272\n",
      "Epoch:0078\n",
      "acc_train:0.6825 pre_train:0.7705 recall_train:0.5461 F1_train:0.6392 AUC_train:0.8192\n",
      "acc_val:0.7865 pre_val:0.9091 recall_val:0.6522 F1_val:0.759494 AUC_val:0.9333\n",
      "Epoch:0079\n",
      "acc_train:0.6712 pre_train:0.7492 recall_train:0.5437 F1_train:0.6301 AUC_train:0.8138\n",
      "acc_val:0.8315 pre_val:0.9429 recall_val:0.7174 F1_val:0.814815 AUC_val:0.9469\n",
      "Epoch:0080\n",
      "acc_train:0.7287 pre_train:0.7327 recall_train:0.7451 F1_train:0.7389 AUC_train:0.8249\n",
      "acc_val:0.8876 pre_val:0.9286 recall_val:0.8478 F1_val:0.886364 AUC_val:0.9520\n",
      "Epoch:0081\n",
      "acc_train:0.7625 pre_train:0.7876 recall_train:0.7379 F1_train:0.7619 AUC_train:0.8487\n",
      "acc_val:0.9101 pre_val:0.9130 recall_val:0.9130 F1_val:0.913043 AUC_val:0.9489\n",
      "Epoch:0082\n",
      "acc_train:0.7750 pre_train:0.7533 recall_train:0.8374 F1_train:0.7931 AUC_train:0.8529\n",
      "acc_val:0.8989 pre_val:0.8776 recall_val:0.9348 F1_val:0.905263 AUC_val:0.9484\n",
      "Epoch:0083\n",
      "acc_train:0.7713 pre_train:0.7720 recall_train:0.7888 F1_train:0.7803 AUC_train:0.8605\n",
      "acc_val:0.8876 pre_val:0.8600 recall_val:0.9348 F1_val:0.895833 AUC_val:0.9464\n",
      "Epoch:0084\n",
      "acc_train:0.8025 pre_train:0.7714 recall_train:0.8762 F1_train:0.8205 AUC_train:0.8765\n",
      "acc_val:0.8876 pre_val:0.8600 recall_val:0.9348 F1_val:0.895833 AUC_val:0.9479\n",
      "Epoch:0085\n",
      "acc_train:0.8075 pre_train:0.7804 recall_train:0.8714 F1_train:0.8234 AUC_train:0.8829\n",
      "acc_val:0.8876 pre_val:0.8600 recall_val:0.9348 F1_val:0.895833 AUC_val:0.9489\n",
      "Epoch:0086\n",
      "acc_train:0.8125 pre_train:0.7741 recall_train:0.8981 F1_train:0.8315 AUC_train:0.8967\n",
      "acc_val:0.8764 pre_val:0.8431 recall_val:0.9348 F1_val:0.886598 AUC_val:0.9560\n",
      "Epoch:0087\n",
      "acc_train:0.8425 pre_train:0.8265 recall_train:0.8786 F1_train:0.8518 AUC_train:0.8912\n",
      "acc_val:0.8876 pre_val:0.8600 recall_val:0.9348 F1_val:0.895833 AUC_val:0.9560\n",
      "Epoch:0088\n",
      "acc_train:0.8163 pre_train:0.7837 recall_train:0.8883 F1_train:0.8328 AUC_train:0.8943\n",
      "acc_val:0.8989 pre_val:0.8627 recall_val:0.9565 F1_val:0.907216 AUC_val:0.9585\n",
      "Epoch:0089\n",
      "acc_train:0.8313 pre_train:0.8031 recall_train:0.8908 F1_train:0.8446 AUC_train:0.9069\n",
      "acc_val:0.8989 pre_val:0.8627 recall_val:0.9565 F1_val:0.907216 AUC_val:0.9560\n",
      "Epoch:0090\n",
      "acc_train:0.8500 pre_train:0.8288 recall_train:0.8932 F1_train:0.8598 AUC_train:0.9083\n",
      "acc_val:0.8989 pre_val:0.8627 recall_val:0.9565 F1_val:0.907216 AUC_val:0.9596\n",
      "Epoch:0091\n",
      "acc_train:0.8450 pre_train:0.8144 recall_train:0.9053 F1_train:0.8575 AUC_train:0.9233\n",
      "acc_val:0.8764 pre_val:0.8302 recall_val:0.9565 F1_val:0.888889 AUC_val:0.9580\n",
      "Epoch:0092\n",
      "acc_train:0.8213 pre_train:0.7796 recall_train:0.9102 F1_train:0.8399 AUC_train:0.9237\n",
      "acc_val:0.8764 pre_val:0.8302 recall_val:0.9565 F1_val:0.888889 AUC_val:0.9590\n",
      "Epoch:0093\n",
      "acc_train:0.8150 pre_train:0.7857 recall_train:0.8811 F1_train:0.8307 AUC_train:0.8958\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9596\n",
      "Epoch:0094\n",
      "acc_train:0.8413 pre_train:0.8160 recall_train:0.8932 F1_train:0.8528 AUC_train:0.9279\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9585\n",
      "Epoch:0095\n",
      "acc_train:0.8300 pre_train:0.7816 recall_train:0.9296 F1_train:0.8492 AUC_train:0.9264\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9560\n",
      "Epoch:0096\n",
      "acc_train:0.8338 pre_train:0.7900 recall_train:0.9223 F1_train:0.8511 AUC_train:0.9339\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9520\n",
      "Epoch:0097\n",
      "acc_train:0.8225 pre_train:0.7836 recall_train:0.9053 F1_train:0.8401 AUC_train:0.9188\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9505\n",
      "Epoch:0098\n",
      "acc_train:0.8512 pre_train:0.8110 recall_train:0.9272 F1_train:0.8652 AUC_train:0.9286\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9505\n",
      "Epoch:0099\n",
      "acc_train:0.8562 pre_train:0.8100 recall_train:0.9417 F1_train:0.8709 AUC_train:0.9476\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9489\n",
      "Epoch:0100\n",
      "acc_train:0.8512 pre_train:0.8021 recall_train:0.9442 F1_train:0.8673 AUC_train:0.9422\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9469\n",
      "Epoch:0101\n",
      "acc_train:0.8450 pre_train:0.8025 recall_train:0.9272 F1_train:0.8604 AUC_train:0.9415\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0102\n",
      "acc_train:0.8475 pre_train:0.7984 recall_train:0.9417 F1_train:0.8641 AUC_train:0.9408\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9464\n",
      "Epoch:0103\n",
      "acc_train:0.8462 pre_train:0.7967 recall_train:0.9417 F1_train:0.8632 AUC_train:0.9535\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9444\n",
      "Epoch:0104\n",
      "acc_train:0.8487 pre_train:0.8000 recall_train:0.9417 F1_train:0.8651 AUC_train:0.9489\n",
      "acc_val:0.8539 pre_val:0.8113 recall_val:0.9348 F1_val:0.868687 AUC_val:0.9429\n",
      "Epoch:0105\n",
      "acc_train:0.8763 pre_train:0.8410 recall_train:0.9369 F1_train:0.8863 AUC_train:0.9584\n",
      "acc_val:0.8652 pre_val:0.8269 recall_val:0.9348 F1_val:0.877551 AUC_val:0.9419\n",
      "Epoch:0106\n",
      "acc_train:0.8675 pre_train:0.8326 recall_train:0.9296 F1_train:0.8784 AUC_train:0.9431\n",
      "acc_val:0.8652 pre_val:0.8269 recall_val:0.9348 F1_val:0.877551 AUC_val:0.9403\n",
      "Epoch:0107\n",
      "acc_train:0.8637 pre_train:0.8272 recall_train:0.9296 F1_train:0.8754 AUC_train:0.9523\n",
      "acc_val:0.8427 pre_val:0.7963 recall_val:0.9348 F1_val:0.860000 AUC_val:0.9414\n",
      "Epoch:0108\n",
      "acc_train:0.8788 pre_train:0.8446 recall_train:0.9369 F1_train:0.8884 AUC_train:0.9612\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9398\n",
      "Epoch:0109\n",
      "acc_train:0.8813 pre_train:0.8423 recall_train:0.9466 F1_train:0.8914 AUC_train:0.9613\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9393\n",
      "Epoch:0110\n",
      "acc_train:0.8963 pre_train:0.8584 recall_train:0.9563 F1_train:0.9047 AUC_train:0.9650\n",
      "acc_val:0.8427 pre_val:0.7963 recall_val:0.9348 F1_val:0.860000 AUC_val:0.9383\n",
      "Epoch:0111\n",
      "acc_train:0.9000 pre_train:0.8739 recall_train:0.9417 F1_train:0.9065 AUC_train:0.9695\n",
      "acc_val:0.8539 pre_val:0.8113 recall_val:0.9348 F1_val:0.868687 AUC_val:0.9378\n",
      "Epoch:0112\n",
      "acc_train:0.8863 pre_train:0.8393 recall_train:0.9636 F1_train:0.8972 AUC_train:0.9690\n",
      "acc_val:0.8539 pre_val:0.8113 recall_val:0.9348 F1_val:0.868687 AUC_val:0.9398\n",
      "Epoch:0113\n",
      "acc_train:0.8950 pre_train:0.8661 recall_train:0.9417 F1_train:0.9023 AUC_train:0.9639\n",
      "acc_val:0.8539 pre_val:0.8113 recall_val:0.9348 F1_val:0.868687 AUC_val:0.9419\n",
      "Epoch:0114\n",
      "acc_train:0.8950 pre_train:0.8661 recall_train:0.9417 F1_train:0.9023 AUC_train:0.9725\n",
      "acc_val:0.8427 pre_val:0.7963 recall_val:0.9348 F1_val:0.860000 AUC_val:0.9429\n",
      "Epoch:0115\n",
      "acc_train:0.9112 pre_train:0.8902 recall_train:0.9442 F1_train:0.9164 AUC_train:0.9721\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9383\n",
      "Epoch:0116\n",
      "acc_train:0.9062 pre_train:0.8804 recall_train:0.9466 F1_train:0.9123 AUC_train:0.9713\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9368\n",
      "Epoch:0117\n",
      "acc_train:0.9175 pre_train:0.8844 recall_train:0.9660 F1_train:0.9234 AUC_train:0.9706\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9353\n",
      "Epoch:0118\n",
      "acc_train:0.9200 pre_train:0.8955 recall_train:0.9563 F1_train:0.9249 AUC_train:0.9683\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9469\n",
      "Epoch:0119\n",
      "acc_train:0.9187 pre_train:0.8916 recall_train:0.9587 F1_train:0.9240 AUC_train:0.9762\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9494\n",
      "Epoch:0120\n",
      "acc_train:0.9262 pre_train:0.9114 recall_train:0.9490 F1_train:0.9298 AUC_train:0.9745\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9479\n",
      "Epoch:0121\n",
      "acc_train:0.9237 pre_train:0.8962 recall_train:0.9636 F1_train:0.9287 AUC_train:0.9787\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9484\n",
      "Epoch:0122\n",
      "acc_train:0.9162 pre_train:0.8912 recall_train:0.9539 F1_train:0.9215 AUC_train:0.9804\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9429\n",
      "Epoch:0123\n",
      "acc_train:0.9287 pre_train:0.9176 recall_train:0.9466 F1_train:0.9319 AUC_train:0.9816\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9383\n",
      "Epoch:0124\n",
      "acc_train:0.9450 pre_train:0.9279 recall_train:0.9684 F1_train:0.9477 AUC_train:0.9865\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9333\n",
      "Epoch:0125\n",
      "acc_train:0.9300 pre_train:0.9027 recall_train:0.9684 F1_train:0.9344 AUC_train:0.9751\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9328\n",
      "Epoch:0126\n",
      "acc_train:0.9425 pre_train:0.9296 recall_train:0.9612 F1_train:0.9451 AUC_train:0.9729\n",
      "acc_val:0.8764 pre_val:0.8302 recall_val:0.9565 F1_val:0.888889 AUC_val:0.9376\n",
      "Epoch:0127\n",
      "acc_train:0.9275 pre_train:0.8951 recall_train:0.9733 F1_train:0.9326 AUC_train:0.9827\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9444\n",
      "Epoch:0128\n",
      "acc_train:0.9375 pre_train:0.9171 recall_train:0.9660 F1_train:0.9409 AUC_train:0.9721\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9479\n",
      "Epoch:0129\n",
      "acc_train:0.9337 pre_train:0.9089 recall_train:0.9684 F1_train:0.9377 AUC_train:0.9800\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9550\n",
      "Epoch:0130\n",
      "acc_train:0.9413 pre_train:0.9294 recall_train:0.9587 F1_train:0.9438 AUC_train:0.9874\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9545\n",
      "Epoch:0131\n",
      "acc_train:0.9337 pre_train:0.9204 recall_train:0.9539 F1_train:0.9368 AUC_train:0.9812\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9575\n",
      "Epoch:0132\n",
      "acc_train:0.9513 pre_train:0.9287 recall_train:0.9806 F1_train:0.9540 AUC_train:0.9854\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9550\n",
      "Epoch:0133\n",
      "acc_train:0.9488 pre_train:0.9406 recall_train:0.9612 F1_train:0.9508 AUC_train:0.9840\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9671\n",
      "Epoch:0134\n",
      "acc_train:0.9500 pre_train:0.9306 recall_train:0.9757 F1_train:0.9526 AUC_train:0.9845\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9692\n",
      "Epoch:0135\n",
      "acc_train:0.9463 pre_train:0.9281 recall_train:0.9709 F1_train:0.9490 AUC_train:0.9899\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9702\n",
      "Epoch:0136\n",
      "acc_train:0.9588 pre_train:0.9317 recall_train:0.9927 F1_train:0.9612 AUC_train:0.9914\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9692\n",
      "Epoch:0137\n",
      "acc_train:0.9475 pre_train:0.9302 recall_train:0.9709 F1_train:0.9501 AUC_train:0.9882\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9661\n",
      "Epoch:0138\n",
      "acc_train:0.9463 pre_train:0.9241 recall_train:0.9757 F1_train:0.9492 AUC_train:0.9854\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9656\n",
      "Epoch:0139\n",
      "acc_train:0.9650 pre_train:0.9507 recall_train:0.9830 F1_train:0.9666 AUC_train:0.9889\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9565\n",
      "Epoch:0140\n",
      "acc_train:0.9500 pre_train:0.9366 recall_train:0.9684 F1_train:0.9523 AUC_train:0.9864\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9505\n",
      "Epoch:0141\n",
      "acc_train:0.9500 pre_train:0.9471 recall_train:0.9563 F1_train:0.9517 AUC_train:0.9883\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9489\n",
      "Epoch:0142\n",
      "acc_train:0.9563 pre_train:0.9499 recall_train:0.9660 F1_train:0.9579 AUC_train:0.9910\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9474\n",
      "Epoch:0143\n",
      "acc_train:0.9663 pre_train:0.9684 recall_train:0.9660 F1_train:0.9672 AUC_train:0.9927\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9499\n",
      "Epoch:0144\n",
      "acc_train:0.9638 pre_train:0.9570 recall_train:0.9733 F1_train:0.9651 AUC_train:0.9881\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9540\n",
      "Epoch:0145\n",
      "acc_train:0.9600 pre_train:0.9502 recall_train:0.9733 F1_train:0.9616 AUC_train:0.9901\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9611\n",
      "Epoch:0146\n",
      "acc_train:0.9588 pre_train:0.9376 recall_train:0.9854 F1_train:0.9609 AUC_train:0.9914\n",
      "acc_val:0.8764 pre_val:0.8182 recall_val:0.9783 F1_val:0.891089 AUC_val:0.9681\n",
      "Epoch:0147\n",
      "acc_train:0.9513 pre_train:0.9368 recall_train:0.9709 F1_train:0.9535 AUC_train:0.9884\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9707\n",
      "Epoch:0148\n",
      "acc_train:0.9588 pre_train:0.9336 recall_train:0.9903 F1_train:0.9611 AUC_train:0.9907\n",
      "acc_val:0.8876 pre_val:0.8462 recall_val:0.9565 F1_val:0.897959 AUC_val:0.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0149\n",
      "acc_train:0.9600 pre_train:0.9398 recall_train:0.9854 F1_train:0.9621 AUC_train:0.9893\n",
      "acc_val:0.8876 pre_val:0.8462 recall_val:0.9565 F1_val:0.897959 AUC_val:0.9722\n",
      "Epoch:0150\n",
      "acc_train:0.9575 pre_train:0.9437 recall_train:0.9757 F1_train:0.9594 AUC_train:0.9919\n",
      "acc_val:0.8876 pre_val:0.8333 recall_val:0.9783 F1_val:0.900000 AUC_val:0.9717\n",
      "Epoch:0151\n",
      "acc_train:0.9513 pre_train:0.9327 recall_train:0.9757 F1_train:0.9537 AUC_train:0.9907\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9671\n",
      "Epoch:0152\n",
      "acc_train:0.9688 pre_train:0.9596 recall_train:0.9806 F1_train:0.9700 AUC_train:0.9889\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9606\n",
      "Epoch:0153\n",
      "acc_train:0.9775 pre_train:0.9713 recall_train:0.9854 F1_train:0.9783 AUC_train:0.9965\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9520\n",
      "Epoch:0154\n",
      "acc_train:0.9775 pre_train:0.9713 recall_train:0.9854 F1_train:0.9783 AUC_train:0.9958\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9489\n",
      "Epoch:0155\n",
      "acc_train:0.9700 pre_train:0.9597 recall_train:0.9830 F1_train:0.9712 AUC_train:0.9905\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9499\n",
      "Epoch:0156\n",
      "acc_train:0.9688 pre_train:0.9640 recall_train:0.9757 F1_train:0.9698 AUC_train:0.9960\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9530\n",
      "Epoch:0157\n",
      "acc_train:0.9725 pre_train:0.9643 recall_train:0.9830 F1_train:0.9736 AUC_train:0.9926\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9575\n",
      "Epoch:0158\n",
      "acc_train:0.9712 pre_train:0.9664 recall_train:0.9782 F1_train:0.9723 AUC_train:0.9968\n",
      "acc_val:0.8989 pre_val:0.8491 recall_val:0.9783 F1_val:0.909091 AUC_val:0.9646\n",
      "Epoch:0159\n",
      "acc_train:0.9725 pre_train:0.9599 recall_train:0.9879 F1_train:0.9737 AUC_train:0.9938\n",
      "acc_val:0.8989 pre_val:0.8491 recall_val:0.9783 F1_val:0.909091 AUC_val:0.9671\n",
      "Epoch:0160\n",
      "acc_train:0.9712 pre_train:0.9598 recall_train:0.9854 F1_train:0.9725 AUC_train:0.9976\n",
      "acc_val:0.8764 pre_val:0.8302 recall_val:0.9565 F1_val:0.888889 AUC_val:0.9692\n",
      "Epoch:0161\n",
      "acc_train:0.9762 pre_train:0.9602 recall_train:0.9951 F1_train:0.9774 AUC_train:0.9967\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9697\n",
      "Epoch:0162\n",
      "acc_train:0.9737 pre_train:0.9666 recall_train:0.9830 F1_train:0.9747 AUC_train:0.9939\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9692\n",
      "Epoch:0163\n",
      "acc_train:0.9688 pre_train:0.9532 recall_train:0.9879 F1_train:0.9702 AUC_train:0.9915\n",
      "acc_val:0.8764 pre_val:0.8182 recall_val:0.9783 F1_val:0.891089 AUC_val:0.9687\n",
      "Epoch:0164\n",
      "acc_train:0.9762 pre_train:0.9645 recall_train:0.9903 F1_train:0.9772 AUC_train:0.9939\n",
      "acc_val:0.8764 pre_val:0.8182 recall_val:0.9783 F1_val:0.891089 AUC_val:0.9661\n",
      "Epoch:0165\n",
      "acc_train:0.9663 pre_train:0.9572 recall_train:0.9782 F1_train:0.9676 AUC_train:0.9923\n",
      "acc_val:0.8876 pre_val:0.8333 recall_val:0.9783 F1_val:0.900000 AUC_val:0.9666\n",
      "Epoch:0166\n",
      "acc_train:0.9762 pre_train:0.9690 recall_train:0.9854 F1_train:0.9771 AUC_train:0.9921\n",
      "acc_val:0.8764 pre_val:0.8182 recall_val:0.9783 F1_val:0.891089 AUC_val:0.9601\n",
      "Epoch:0167\n",
      "acc_train:0.9737 pre_train:0.9711 recall_train:0.9782 F1_train:0.9746 AUC_train:0.9946\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9585\n",
      "Epoch:0168\n",
      "acc_train:0.9700 pre_train:0.9641 recall_train:0.9782 F1_train:0.9711 AUC_train:0.9908\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9580\n",
      "Epoch:0169\n",
      "acc_train:0.9787 pre_train:0.9714 recall_train:0.9879 F1_train:0.9795 AUC_train:0.9972\n",
      "acc_val:0.8652 pre_val:0.8148 recall_val:0.9565 F1_val:0.880000 AUC_val:0.9585\n",
      "Early Stopping!!! epoch：168\n",
      " Starting the 1-2 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4950 pre_train:0.5145 recall_train:0.3447 F1_train:0.4128 AUC_train:0.4748\n",
      "acc_val:0.5169 pre_val:0.5169 recall_val:1.0000 F1_val:0.681481 AUC_val:0.6122\n",
      "Epoch:0002\n",
      "acc_train:0.5163 pre_train:0.5556 recall_train:0.3034 F1_train:0.3925 AUC_train:0.5169\n",
      "acc_val:0.5169 pre_val:0.5169 recall_val:1.0000 F1_val:0.681481 AUC_val:0.6229\n",
      "Epoch:0003\n",
      "acc_train:0.5250 pre_train:0.5755 recall_train:0.2961 F1_train:0.3910 AUC_train:0.5388\n",
      "acc_val:0.5281 pre_val:0.5227 recall_val:1.0000 F1_val:0.686567 AUC_val:0.6203\n",
      "Epoch:0004\n",
      "acc_train:0.5250 pre_train:0.5684 recall_train:0.3228 F1_train:0.4118 AUC_train:0.5089\n",
      "acc_val:0.5281 pre_val:0.5233 recall_val:0.9783 F1_val:0.681818 AUC_val:0.6390\n",
      "Epoch:0005\n",
      "acc_train:0.5612 pre_train:0.6309 recall_train:0.3568 F1_train:0.4558 AUC_train:0.5846\n",
      "acc_val:0.5506 pre_val:0.5366 recall_val:0.9565 F1_val:0.687500 AUC_val:0.6572\n",
      "Epoch:0006\n",
      "acc_train:0.5825 pre_train:0.6625 recall_train:0.3859 F1_train:0.4877 AUC_train:0.5813\n",
      "acc_val:0.5506 pre_val:0.5375 recall_val:0.9348 F1_val:0.682540 AUC_val:0.6663\n",
      "Epoch:0007\n",
      "acc_train:0.5537 pre_train:0.6267 recall_train:0.3301 F1_train:0.4324 AUC_train:0.5707\n",
      "acc_val:0.5506 pre_val:0.5441 recall_val:0.8043 F1_val:0.649123 AUC_val:0.6739\n",
      "Epoch:0008\n",
      "acc_train:0.5738 pre_train:0.6578 recall_train:0.3592 F1_train:0.4647 AUC_train:0.5946\n",
      "acc_val:0.6067 pre_val:0.5965 recall_val:0.7391 F1_val:0.660194 AUC_val:0.6946\n",
      "Epoch:0009\n",
      "acc_train:0.5813 pre_train:0.6624 recall_train:0.3811 F1_train:0.4838 AUC_train:0.6054\n",
      "acc_val:0.6517 pre_val:0.6364 recall_val:0.7609 F1_val:0.693069 AUC_val:0.7108\n",
      "Epoch:0010\n",
      "acc_train:0.6025 pre_train:0.7009 recall_train:0.3981 F1_train:0.5077 AUC_train:0.6548\n",
      "acc_val:0.6517 pre_val:0.6596 recall_val:0.6739 F1_val:0.666667 AUC_val:0.7179\n",
      "Epoch:0011\n",
      "acc_train:0.6000 pre_train:0.7035 recall_train:0.3859 F1_train:0.4984 AUC_train:0.6037\n",
      "acc_val:0.6966 pre_val:0.7317 recall_val:0.6522 F1_val:0.689655 AUC_val:0.7361\n",
      "Epoch:0012\n",
      "acc_train:0.5938 pre_train:0.6747 recall_train:0.4078 F1_train:0.5083 AUC_train:0.6354\n",
      "acc_val:0.6742 pre_val:0.7179 recall_val:0.6087 F1_val:0.658824 AUC_val:0.7427\n",
      "Epoch:0013\n",
      "acc_train:0.5987 pre_train:0.6872 recall_train:0.4053 F1_train:0.5099 AUC_train:0.6349\n",
      "acc_val:0.6517 pre_val:0.7027 recall_val:0.5652 F1_val:0.626506 AUC_val:0.7391\n",
      "Epoch:0014\n",
      "acc_train:0.5975 pre_train:0.6692 recall_train:0.4320 F1_train:0.5251 AUC_train:0.6128\n",
      "acc_val:0.7191 pre_val:0.7333 recall_val:0.7174 F1_val:0.725275 AUC_val:0.7417\n",
      "Epoch:0015\n",
      "acc_train:0.6325 pre_train:0.7107 recall_train:0.4830 F1_train:0.5751 AUC_train:0.6841\n",
      "acc_val:0.6966 pre_val:0.6792 recall_val:0.7826 F1_val:0.727273 AUC_val:0.7487\n",
      "Epoch:0016\n",
      "acc_train:0.6275 pre_train:0.7021 recall_train:0.4806 F1_train:0.5706 AUC_train:0.6879\n",
      "acc_val:0.7191 pre_val:0.7143 recall_val:0.7609 F1_val:0.736842 AUC_val:0.7599\n",
      "Epoch:0017\n",
      "acc_train:0.6562 pre_train:0.7387 recall_train:0.5146 F1_train:0.6066 AUC_train:0.7020\n",
      "acc_val:0.7079 pre_val:0.7000 recall_val:0.7609 F1_val:0.729167 AUC_val:0.7659\n",
      "Epoch:0018\n",
      "acc_train:0.6562 pre_train:0.7203 recall_train:0.5437 F1_train:0.6196 AUC_train:0.6700\n",
      "acc_val:0.6966 pre_val:0.6939 recall_val:0.7391 F1_val:0.715789 AUC_val:0.7720\n",
      "Epoch:0019\n",
      "acc_train:0.6325 pre_train:0.6756 recall_train:0.5510 F1_train:0.6070 AUC_train:0.6617\n",
      "acc_val:0.7079 pre_val:0.6667 recall_val:0.8696 F1_val:0.754717 AUC_val:0.7836\n",
      "Epoch:0020\n",
      "acc_train:0.6513 pre_train:0.7254 recall_train:0.5194 F1_train:0.6054 AUC_train:0.6981\n",
      "acc_val:0.6966 pre_val:0.6792 recall_val:0.7826 F1_val:0.727273 AUC_val:0.7710\n",
      "Epoch:0021\n",
      "acc_train:0.6363 pre_train:0.6667 recall_train:0.5874 F1_train:0.6245 AUC_train:0.6591\n",
      "acc_val:0.6966 pre_val:0.6792 recall_val:0.7826 F1_val:0.727273 AUC_val:0.7750\n",
      "Epoch:0022\n",
      "acc_train:0.6488 pre_train:0.7015 recall_train:0.5534 F1_train:0.6187 AUC_train:0.6867\n",
      "acc_val:0.7079 pre_val:0.7000 recall_val:0.7609 F1_val:0.729167 AUC_val:0.7816\n",
      "Epoch:0023\n",
      "acc_train:0.6475 pre_train:0.6847 recall_train:0.5850 F1_train:0.6309 AUC_train:0.6927\n",
      "acc_val:0.7303 pre_val:0.7200 recall_val:0.7826 F1_val:0.750000 AUC_val:0.7952\n",
      "Epoch:0024\n",
      "acc_train:0.6388 pre_train:0.7085 recall_train:0.5073 F1_train:0.5912 AUC_train:0.6802\n",
      "acc_val:0.7640 pre_val:0.7907 recall_val:0.7391 F1_val:0.764045 AUC_val:0.7988\n",
      "Epoch:0025\n",
      "acc_train:0.6400 pre_train:0.7053 recall_train:0.5170 F1_train:0.5966 AUC_train:0.7055\n",
      "acc_val:0.7528 pre_val:0.7857 recall_val:0.7174 F1_val:0.750000 AUC_val:0.7993\n",
      "Epoch:0026\n",
      "acc_train:0.6600 pre_train:0.7465 recall_train:0.5146 F1_train:0.6092 AUC_train:0.7501\n",
      "acc_val:0.7528 pre_val:0.8158 recall_val:0.6739 F1_val:0.738095 AUC_val:0.8038\n",
      "Epoch:0027\n",
      "acc_train:0.6637 pre_train:0.7544 recall_train:0.5146 F1_train:0.6118 AUC_train:0.7279\n",
      "acc_val:0.7416 pre_val:0.7949 recall_val:0.6739 F1_val:0.729412 AUC_val:0.8054\n",
      "Epoch:0028\n",
      "acc_train:0.6450 pre_train:0.7254 recall_train:0.5000 F1_train:0.5920 AUC_train:0.7235\n",
      "acc_val:0.7640 pre_val:0.8205 recall_val:0.6957 F1_val:0.752941 AUC_val:0.8109\n",
      "Epoch:0029\n",
      "acc_train:0.6725 pre_train:0.7660 recall_train:0.5243 F1_train:0.6225 AUC_train:0.7399\n",
      "acc_val:0.7528 pre_val:0.8158 recall_val:0.6739 F1_val:0.738095 AUC_val:0.8079\n",
      "Epoch:0030\n",
      "acc_train:0.6675 pre_train:0.7386 recall_train:0.5485 F1_train:0.6295 AUC_train:0.7078\n",
      "acc_val:0.7865 pre_val:0.8462 recall_val:0.7174 F1_val:0.776471 AUC_val:0.8109\n",
      "Epoch:0031\n",
      "acc_train:0.6787 pre_train:0.7739 recall_train:0.5316 F1_train:0.6302 AUC_train:0.7433\n",
      "acc_val:0.7416 pre_val:0.8108 recall_val:0.6522 F1_val:0.722892 AUC_val:0.8049\n",
      "Epoch:0032\n",
      "acc_train:0.6637 pre_train:0.7563 recall_train:0.5121 F1_train:0.6107 AUC_train:0.7315\n",
      "acc_val:0.7416 pre_val:0.8286 recall_val:0.6304 F1_val:0.716049 AUC_val:0.8064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0033\n",
      "acc_train:0.7038 pre_train:0.8028 recall_train:0.5631 F1_train:0.6619 AUC_train:0.7855\n",
      "acc_val:0.7416 pre_val:0.8286 recall_val:0.6304 F1_val:0.716049 AUC_val:0.8246\n",
      "Epoch:0034\n",
      "acc_train:0.6888 pre_train:0.7672 recall_train:0.5680 F1_train:0.6527 AUC_train:0.7641\n",
      "acc_val:0.7416 pre_val:0.8286 recall_val:0.6304 F1_val:0.716049 AUC_val:0.8392\n",
      "Epoch:0035\n",
      "acc_train:0.7038 pre_train:0.8007 recall_train:0.5655 F1_train:0.6629 AUC_train:0.7814\n",
      "acc_val:0.7528 pre_val:0.8529 recall_val:0.6304 F1_val:0.725000 AUC_val:0.8514\n",
      "Epoch:0036\n",
      "acc_train:0.7300 pre_train:0.8289 recall_train:0.5995 F1_train:0.6958 AUC_train:0.8187\n",
      "acc_val:0.7528 pre_val:0.8529 recall_val:0.6304 F1_val:0.725000 AUC_val:0.8534\n",
      "Epoch:0037\n",
      "acc_train:0.7013 pre_train:0.7952 recall_train:0.5655 F1_train:0.6610 AUC_train:0.7697\n",
      "acc_val:0.7753 pre_val:0.8824 recall_val:0.6522 F1_val:0.750000 AUC_val:0.8600\n",
      "Epoch:0038\n",
      "acc_train:0.7150 pre_train:0.8309 recall_train:0.5607 F1_train:0.6696 AUC_train:0.7937\n",
      "acc_val:0.7528 pre_val:0.8750 recall_val:0.6087 F1_val:0.717949 AUC_val:0.8564\n",
      "Epoch:0039\n",
      "acc_train:0.7412 pre_train:0.8405 recall_train:0.6141 F1_train:0.7097 AUC_train:0.8387\n",
      "acc_val:0.7528 pre_val:0.9000 recall_val:0.5870 F1_val:0.710526 AUC_val:0.8620\n",
      "Epoch:0040\n",
      "acc_train:0.7287 pre_train:0.8261 recall_train:0.5995 F1_train:0.6948 AUC_train:0.8049\n",
      "acc_val:0.7528 pre_val:0.9615 recall_val:0.5435 F1_val:0.694444 AUC_val:0.8883\n",
      "Epoch:0041\n",
      "acc_train:0.7325 pre_train:0.8390 recall_train:0.5947 F1_train:0.6960 AUC_train:0.8415\n",
      "acc_val:0.7528 pre_val:0.9615 recall_val:0.5435 F1_val:0.694444 AUC_val:0.9019\n",
      "Epoch:0042\n",
      "acc_train:0.7550 pre_train:0.8600 recall_train:0.6262 F1_train:0.7247 AUC_train:0.8598\n",
      "acc_val:0.7416 pre_val:0.9600 recall_val:0.5217 F1_val:0.676056 AUC_val:0.9070\n",
      "Epoch:0043\n",
      "acc_train:0.7375 pre_train:0.8531 recall_train:0.5922 F1_train:0.6991 AUC_train:0.8504\n",
      "acc_val:0.7303 pre_val:0.9583 recall_val:0.5000 F1_val:0.657143 AUC_val:0.9166\n",
      "Epoch:0044\n",
      "acc_train:0.7812 pre_train:0.8810 recall_train:0.6650 F1_train:0.7580 AUC_train:0.8813\n",
      "acc_val:0.7303 pre_val:0.9583 recall_val:0.5000 F1_val:0.657143 AUC_val:0.9211\n",
      "Epoch:0045\n",
      "acc_train:0.7650 pre_train:0.8758 recall_train:0.6335 F1_train:0.7352 AUC_train:0.8794\n",
      "acc_val:0.7303 pre_val:0.9583 recall_val:0.5000 F1_val:0.657143 AUC_val:0.9237\n",
      "Epoch:0046\n",
      "acc_train:0.7775 pre_train:0.8953 recall_train:0.6432 F1_train:0.7486 AUC_train:0.8888\n",
      "acc_val:0.7191 pre_val:0.9565 recall_val:0.4783 F1_val:0.637681 AUC_val:0.9206\n",
      "Epoch:0047\n",
      "acc_train:0.8025 pre_train:0.9045 recall_train:0.6893 F1_train:0.7824 AUC_train:0.9089\n",
      "acc_val:0.7079 pre_val:0.9545 recall_val:0.4565 F1_val:0.617647 AUC_val:0.9242\n",
      "Epoch:0048\n",
      "acc_train:0.7937 pre_train:0.9158 recall_train:0.6602 F1_train:0.7673 AUC_train:0.9012\n",
      "acc_val:0.7191 pre_val:0.9565 recall_val:0.4783 F1_val:0.637681 AUC_val:0.9221\n",
      "Epoch:0049\n",
      "acc_train:0.7962 pre_train:0.8952 recall_train:0.6845 F1_train:0.7758 AUC_train:0.8964\n",
      "acc_val:0.7416 pre_val:0.9600 recall_val:0.5217 F1_val:0.676056 AUC_val:0.9171\n",
      "Epoch:0050\n",
      "acc_train:0.8225 pre_train:0.9327 recall_train:0.7063 F1_train:0.8039 AUC_train:0.9224\n",
      "acc_val:0.7303 pre_val:0.9583 recall_val:0.5000 F1_val:0.657143 AUC_val:0.9130\n",
      "Epoch:0051\n",
      "acc_train:0.8375 pre_train:0.9299 recall_train:0.7403 F1_train:0.8243 AUC_train:0.9234\n",
      "acc_val:0.7303 pre_val:0.9583 recall_val:0.5000 F1_val:0.657143 AUC_val:0.9130\n",
      "Epoch:0052\n",
      "acc_train:0.8175 pre_train:0.8982 recall_train:0.7282 F1_train:0.8043 AUC_train:0.9184\n",
      "acc_val:0.6966 pre_val:0.9524 recall_val:0.4348 F1_val:0.597015 AUC_val:0.9090\n",
      "Epoch:0053\n",
      "acc_train:0.8512 pre_train:0.9198 recall_train:0.7791 F1_train:0.8436 AUC_train:0.9353\n",
      "acc_val:0.6966 pre_val:0.9524 recall_val:0.4348 F1_val:0.597015 AUC_val:0.9070\n",
      "Epoch:0054\n",
      "acc_train:0.8375 pre_train:0.9352 recall_train:0.7354 F1_train:0.8234 AUC_train:0.9293\n",
      "acc_val:0.6854 pre_val:0.9500 recall_val:0.4130 F1_val:0.575758 AUC_val:0.9090\n",
      "Epoch:0055\n",
      "acc_train:0.8438 pre_train:0.9362 recall_train:0.7476 F1_train:0.8313 AUC_train:0.9372\n",
      "acc_val:0.6966 pre_val:0.9524 recall_val:0.4348 F1_val:0.597015 AUC_val:0.9125\n",
      "Epoch:0056\n",
      "acc_train:0.8687 pre_train:0.9582 recall_train:0.7791 F1_train:0.8594 AUC_train:0.9572\n",
      "acc_val:0.7079 pre_val:0.9545 recall_val:0.4565 F1_val:0.617647 AUC_val:0.9141\n",
      "Epoch:0057\n",
      "acc_train:0.8587 pre_train:0.9544 recall_train:0.7621 F1_train:0.8475 AUC_train:0.9560\n",
      "acc_val:0.7079 pre_val:0.9545 recall_val:0.4565 F1_val:0.617647 AUC_val:0.9176\n",
      "Epoch:0058\n",
      "acc_train:0.8675 pre_train:0.9527 recall_train:0.7816 F1_train:0.8587 AUC_train:0.9510\n",
      "acc_val:0.7191 pre_val:0.9565 recall_val:0.4783 F1_val:0.637681 AUC_val:0.9186\n",
      "Epoch:0059\n",
      "acc_train:0.8875 pre_train:0.9497 recall_train:0.8252 F1_train:0.8831 AUC_train:0.9602\n",
      "acc_val:0.7079 pre_val:0.9545 recall_val:0.4565 F1_val:0.617647 AUC_val:0.9151\n",
      "Epoch:0060\n",
      "acc_train:0.8712 pre_train:0.9452 recall_train:0.7961 F1_train:0.8643 AUC_train:0.9531\n",
      "acc_val:0.7303 pre_val:0.9583 recall_val:0.5000 F1_val:0.657143 AUC_val:0.8953\n",
      "Epoch:0061\n",
      "acc_train:0.8850 pre_train:0.9545 recall_train:0.8155 F1_train:0.8796 AUC_train:0.9649\n",
      "acc_val:0.7416 pre_val:0.9600 recall_val:0.5217 F1_val:0.676056 AUC_val:0.8948\n",
      "Epoch:0062\n",
      "acc_train:0.8763 pre_train:0.9617 recall_train:0.7913 F1_train:0.8682 AUC_train:0.9625\n",
      "acc_val:0.7528 pre_val:0.9615 recall_val:0.5435 F1_val:0.694444 AUC_val:0.8938\n",
      "Epoch:0063\n",
      "acc_train:0.8875 pre_train:0.9708 recall_train:0.8058 F1_train:0.8806 AUC_train:0.9634\n",
      "acc_val:0.7640 pre_val:0.9630 recall_val:0.5652 F1_val:0.712329 AUC_val:0.8994\n",
      "Epoch:0064\n",
      "acc_train:0.8913 pre_train:0.9765 recall_train:0.8083 F1_train:0.8845 AUC_train:0.9712\n",
      "acc_val:0.7753 pre_val:0.9643 recall_val:0.5870 F1_val:0.729730 AUC_val:0.9039\n",
      "Epoch:0065\n",
      "acc_train:0.8900 pre_train:0.9821 recall_train:0.8010 F1_train:0.8824 AUC_train:0.9752\n",
      "acc_val:0.7978 pre_val:0.9667 recall_val:0.6304 F1_val:0.763158 AUC_val:0.9019\n",
      "Epoch:0066\n",
      "acc_train:0.8813 pre_train:0.9676 recall_train:0.7961 F1_train:0.8735 AUC_train:0.9682\n",
      "acc_val:0.7978 pre_val:0.9667 recall_val:0.6304 F1_val:0.763158 AUC_val:0.8989\n",
      "Epoch:0067\n",
      "acc_train:0.8913 pre_train:0.9630 recall_train:0.8204 F1_train:0.8860 AUC_train:0.9689\n",
      "acc_val:0.7865 pre_val:0.9355 recall_val:0.6304 F1_val:0.753247 AUC_val:0.8984\n",
      "Epoch:0068\n",
      "acc_train:0.8988 pre_train:0.9882 recall_train:0.8131 F1_train:0.8921 AUC_train:0.9742\n",
      "acc_val:0.8090 pre_val:0.9394 recall_val:0.6739 F1_val:0.784810 AUC_val:0.8971\n",
      "Epoch:0069\n",
      "acc_train:0.9050 pre_train:0.9746 recall_train:0.8374 F1_train:0.9008 AUC_train:0.9730\n",
      "acc_val:0.8202 pre_val:0.9412 recall_val:0.6957 F1_val:0.800000 AUC_val:0.8996\n",
      "Epoch:0070\n",
      "acc_train:0.8950 pre_train:0.9659 recall_train:0.8252 F1_train:0.8901 AUC_train:0.9746\n",
      "acc_val:0.8315 pre_val:0.9429 recall_val:0.7174 F1_val:0.814815 AUC_val:0.9004\n",
      "Epoch:0071\n",
      "acc_train:0.9175 pre_train:0.9887 recall_train:0.8495 F1_train:0.9138 AUC_train:0.9837\n",
      "acc_val:0.8427 pre_val:0.9444 recall_val:0.7391 F1_val:0.829268 AUC_val:0.8996\n",
      "Epoch:0072\n",
      "acc_train:0.9162 pre_train:0.9832 recall_train:0.8519 F1_train:0.9129 AUC_train:0.9856\n",
      "acc_val:0.8427 pre_val:0.9444 recall_val:0.7391 F1_val:0.829268 AUC_val:0.8964\n",
      "Epoch:0073\n",
      "acc_train:0.9212 pre_train:0.9807 recall_train:0.8641 F1_train:0.9187 AUC_train:0.9813\n",
      "acc_val:0.8427 pre_val:0.9444 recall_val:0.7391 F1_val:0.829268 AUC_val:0.8969\n",
      "Epoch:0074\n",
      "acc_train:0.9237 pre_train:0.9835 recall_train:0.8665 F1_train:0.9213 AUC_train:0.9784\n",
      "acc_val:0.8427 pre_val:0.9444 recall_val:0.7391 F1_val:0.829268 AUC_val:0.8948\n",
      "Epoch:0075\n",
      "acc_train:0.9137 pre_train:0.9699 recall_train:0.8592 F1_train:0.9112 AUC_train:0.9810\n",
      "acc_val:0.8315 pre_val:0.9429 recall_val:0.7174 F1_val:0.814815 AUC_val:0.8895\n",
      "Epoch:0076\n",
      "acc_train:0.9250 pre_train:0.9809 recall_train:0.8714 F1_train:0.9229 AUC_train:0.9798\n",
      "acc_val:0.8315 pre_val:0.9189 recall_val:0.7391 F1_val:0.819277 AUC_val:0.8959\n",
      "Epoch:0077\n",
      "acc_train:0.9225 pre_train:0.9679 recall_train:0.8786 F1_train:0.9211 AUC_train:0.9781\n",
      "acc_val:0.8315 pre_val:0.9189 recall_val:0.7391 F1_val:0.819277 AUC_val:0.9022\n",
      "Epoch:0078\n",
      "acc_train:0.9425 pre_train:0.9791 recall_train:0.9078 F1_train:0.9421 AUC_train:0.9859\n",
      "acc_val:0.8090 pre_val:0.9143 recall_val:0.6957 F1_val:0.790123 AUC_val:0.9032\n",
      "Epoch:0079\n",
      "acc_train:0.9388 pre_train:0.9866 recall_train:0.8932 F1_train:0.9376 AUC_train:0.9870\n",
      "acc_val:0.8202 pre_val:0.9167 recall_val:0.7174 F1_val:0.804878 AUC_val:0.9042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0080\n",
      "acc_train:0.9362 pre_train:0.9763 recall_train:0.8981 F1_train:0.9355 AUC_train:0.9877\n",
      "acc_val:0.7978 pre_val:0.9118 recall_val:0.6739 F1_val:0.775000 AUC_val:0.9002\n",
      "Epoch:0081\n",
      "acc_train:0.9375 pre_train:0.9788 recall_train:0.8981 F1_train:0.9367 AUC_train:0.9849\n",
      "acc_val:0.7753 pre_val:0.9062 recall_val:0.6304 F1_val:0.743590 AUC_val:0.8999\n",
      "Epoch:0082\n",
      "acc_train:0.9325 pre_train:0.9637 recall_train:0.9029 F1_train:0.9323 AUC_train:0.9844\n",
      "acc_val:0.7865 pre_val:0.9091 recall_val:0.6522 F1_val:0.759494 AUC_val:0.9009\n",
      "Epoch:0083\n",
      "acc_train:0.9337 pre_train:0.9662 recall_train:0.9029 F1_train:0.9335 AUC_train:0.9848\n",
      "acc_val:0.7978 pre_val:0.9118 recall_val:0.6739 F1_val:0.775000 AUC_val:0.9007\n",
      "Epoch:0084\n",
      "acc_train:0.9325 pre_train:0.9711 recall_train:0.8956 F1_train:0.9318 AUC_train:0.9875\n",
      "acc_val:0.7978 pre_val:0.9118 recall_val:0.6739 F1_val:0.775000 AUC_val:0.9007\n",
      "Epoch:0085\n",
      "acc_train:0.9513 pre_train:0.9746 recall_train:0.9296 F1_train:0.9516 AUC_train:0.9898\n",
      "acc_val:0.7978 pre_val:0.9118 recall_val:0.6739 F1_val:0.775000 AUC_val:0.8986\n",
      "Epoch:0086\n",
      "acc_train:0.9375 pre_train:0.9814 recall_train:0.8956 F1_train:0.9365 AUC_train:0.9895\n",
      "acc_val:0.8090 pre_val:0.9143 recall_val:0.6957 F1_val:0.790123 AUC_val:0.8946\n",
      "Epoch:0087\n",
      "acc_train:0.9500 pre_train:0.9673 recall_train:0.9345 F1_train:0.9506 AUC_train:0.9861\n",
      "acc_val:0.8202 pre_val:0.9167 recall_val:0.7174 F1_val:0.804878 AUC_val:0.8933\n",
      "Epoch:0088\n",
      "acc_train:0.9425 pre_train:0.9893 recall_train:0.8981 F1_train:0.9415 AUC_train:0.9911\n",
      "acc_val:0.7978 pre_val:0.9118 recall_val:0.6739 F1_val:0.775000 AUC_val:0.8908\n",
      "Epoch:0089\n",
      "acc_train:0.9475 pre_train:0.9894 recall_train:0.9078 F1_train:0.9468 AUC_train:0.9901\n",
      "acc_val:0.7865 pre_val:0.9091 recall_val:0.6522 F1_val:0.759494 AUC_val:0.8979\n",
      "Epoch:0090\n",
      "acc_train:0.9413 pre_train:0.9815 recall_train:0.9029 F1_train:0.9406 AUC_train:0.9911\n",
      "acc_val:0.7640 pre_val:0.9032 recall_val:0.6087 F1_val:0.727273 AUC_val:0.8984\n",
      "Epoch:0091\n",
      "acc_train:0.9362 pre_train:0.9788 recall_train:0.8956 F1_train:0.9354 AUC_train:0.9882\n",
      "acc_val:0.7753 pre_val:0.9062 recall_val:0.6304 F1_val:0.743590 AUC_val:0.9004\n",
      "Epoch:0092\n",
      "acc_train:0.9538 pre_train:0.9747 recall_train:0.9345 F1_train:0.9542 AUC_train:0.9918\n",
      "acc_val:0.7865 pre_val:0.9091 recall_val:0.6522 F1_val:0.759494 AUC_val:0.9037\n",
      "Epoch:0093\n",
      "acc_train:0.9575 pre_train:0.9797 recall_train:0.9369 F1_train:0.9578 AUC_train:0.9926\n",
      "acc_val:0.7753 pre_val:0.9062 recall_val:0.6304 F1_val:0.743590 AUC_val:0.9093\n",
      "Epoch:0094\n",
      "acc_train:0.9638 pre_train:0.9824 recall_train:0.9466 F1_train:0.9642 AUC_train:0.9923\n",
      "acc_val:0.7640 pre_val:0.9032 recall_val:0.6087 F1_val:0.727273 AUC_val:0.8974\n",
      "Epoch:0095\n",
      "acc_train:0.9513 pre_train:0.9722 recall_train:0.9320 F1_train:0.9517 AUC_train:0.9931\n",
      "acc_val:0.7528 pre_val:0.9000 recall_val:0.5870 F1_val:0.710526 AUC_val:0.9024\n",
      "Epoch:0096\n",
      "acc_train:0.9500 pre_train:0.9769 recall_train:0.9248 F1_train:0.9501 AUC_train:0.9888\n",
      "acc_val:0.7753 pre_val:0.9062 recall_val:0.6304 F1_val:0.743590 AUC_val:0.9024\n",
      "Epoch:0097\n",
      "acc_train:0.9663 pre_train:0.9974 recall_train:0.9369 F1_train:0.9662 AUC_train:0.9939\n",
      "acc_val:0.7865 pre_val:0.9091 recall_val:0.6522 F1_val:0.759494 AUC_val:0.9050\n",
      "Epoch:0098\n",
      "acc_train:0.9563 pre_train:0.9772 recall_train:0.9369 F1_train:0.9566 AUC_train:0.9927\n",
      "acc_val:0.8090 pre_val:0.9143 recall_val:0.6957 F1_val:0.790123 AUC_val:0.9070\n",
      "Early Stopping!!! epoch：97\n",
      " Starting the 1-3 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.5638 pre_train:0.5994 recall_train:0.4612 F1_train:0.5213 AUC_train:0.5940\n",
      "acc_val:0.6629 pre_val:0.8333 recall_val:0.4348 F1_val:0.571429 AUC_val:0.7164\n",
      "Epoch:0002\n",
      "acc_train:0.5700 pre_train:0.6043 recall_train:0.4782 F1_train:0.5339 AUC_train:0.5977\n",
      "acc_val:0.6854 pre_val:0.8462 recall_val:0.4783 F1_val:0.611111 AUC_val:0.7523\n",
      "Epoch:0003\n",
      "acc_train:0.5638 pre_train:0.6047 recall_train:0.4417 F1_train:0.5105 AUC_train:0.6023\n",
      "acc_val:0.6742 pre_val:0.8148 recall_val:0.4783 F1_val:0.602740 AUC_val:0.7578\n",
      "Epoch:0004\n",
      "acc_train:0.5825 pre_train:0.6048 recall_train:0.5461 F1_train:0.5740 AUC_train:0.6108\n",
      "acc_val:0.6854 pre_val:0.8214 recall_val:0.5000 F1_val:0.621622 AUC_val:0.7851\n",
      "Epoch:0005\n",
      "acc_train:0.5525 pre_train:0.5678 recall_train:0.5485 F1_train:0.5580 AUC_train:0.5842\n",
      "acc_val:0.7191 pre_val:0.8387 recall_val:0.5652 F1_val:0.675325 AUC_val:0.7927\n",
      "Epoch:0006\n",
      "acc_train:0.5725 pre_train:0.5871 recall_train:0.5728 F1_train:0.5799 AUC_train:0.6031\n",
      "acc_val:0.7191 pre_val:0.8387 recall_val:0.5652 F1_val:0.675325 AUC_val:0.7958\n",
      "Epoch:0007\n",
      "acc_train:0.6037 pre_train:0.6498 recall_train:0.5000 F1_train:0.5652 AUC_train:0.6256\n",
      "acc_val:0.7191 pre_val:0.8387 recall_val:0.5652 F1_val:0.675325 AUC_val:0.7968\n",
      "Epoch:0008\n",
      "acc_train:0.5975 pre_train:0.6308 recall_train:0.5267 F1_train:0.5741 AUC_train:0.6566\n",
      "acc_val:0.7079 pre_val:0.7941 recall_val:0.5870 F1_val:0.675000 AUC_val:0.7993\n",
      "Epoch:0009\n",
      "acc_train:0.6313 pre_train:0.6396 recall_train:0.6505 F1_train:0.6450 AUC_train:0.6679\n",
      "acc_val:0.7191 pre_val:0.8000 recall_val:0.6087 F1_val:0.691358 AUC_val:0.8119\n",
      "Epoch:0010\n",
      "acc_train:0.6062 pre_train:0.6633 recall_train:0.4782 F1_train:0.5557 AUC_train:0.6526\n",
      "acc_val:0.7191 pre_val:0.8000 recall_val:0.6087 F1_val:0.691358 AUC_val:0.7922\n",
      "Epoch:0011\n",
      "acc_train:0.6125 pre_train:0.6244 recall_train:0.6214 F1_train:0.6229 AUC_train:0.6596\n",
      "acc_val:0.7416 pre_val:0.8108 recall_val:0.6522 F1_val:0.722892 AUC_val:0.8038\n",
      "Epoch:0012\n",
      "acc_train:0.6413 pre_train:0.6574 recall_train:0.6335 F1_train:0.6452 AUC_train:0.7097\n",
      "acc_val:0.7416 pre_val:0.8108 recall_val:0.6522 F1_val:0.722892 AUC_val:0.8185\n",
      "Epoch:0013\n",
      "acc_train:0.6388 pre_train:0.6454 recall_train:0.6626 F1_train:0.6539 AUC_train:0.7014\n",
      "acc_val:0.7303 pre_val:0.7895 recall_val:0.6522 F1_val:0.714286 AUC_val:0.8306\n",
      "Epoch:0014\n",
      "acc_train:0.6050 pre_train:0.6231 recall_train:0.5898 F1_train:0.6060 AUC_train:0.6850\n",
      "acc_val:0.7191 pre_val:0.7838 recall_val:0.6304 F1_val:0.698795 AUC_val:0.8413\n",
      "Epoch:0015\n",
      "acc_train:0.6325 pre_train:0.6536 recall_train:0.6092 F1_train:0.6307 AUC_train:0.7141\n",
      "acc_val:0.7303 pre_val:0.8056 recall_val:0.6304 F1_val:0.707317 AUC_val:0.8524\n",
      "Epoch:0016\n",
      "acc_train:0.6662 pre_train:0.6690 recall_train:0.6966 F1_train:0.6825 AUC_train:0.7384\n",
      "acc_val:0.7640 pre_val:0.8205 recall_val:0.6957 F1_val:0.752941 AUC_val:0.8862\n",
      "Epoch:0017\n",
      "acc_train:0.6650 pre_train:0.6856 recall_train:0.6456 F1_train:0.6650 AUC_train:0.7601\n",
      "acc_val:0.7416 pre_val:0.8108 recall_val:0.6522 F1_val:0.722892 AUC_val:0.8908\n",
      "Epoch:0018\n",
      "acc_train:0.6812 pre_train:0.6977 recall_train:0.6723 F1_train:0.6848 AUC_train:0.7670\n",
      "acc_val:0.7416 pre_val:0.8108 recall_val:0.6522 F1_val:0.722892 AUC_val:0.8959\n",
      "Epoch:0019\n",
      "acc_train:0.7300 pre_train:0.7197 recall_train:0.7791 F1_train:0.7483 AUC_train:0.8054\n",
      "acc_val:0.7640 pre_val:0.8205 recall_val:0.6957 F1_val:0.752941 AUC_val:0.9009\n",
      "Epoch:0020\n",
      "acc_train:0.7500 pre_train:0.7199 recall_train:0.8422 F1_train:0.7763 AUC_train:0.8046\n",
      "acc_val:0.7865 pre_val:0.8140 recall_val:0.7609 F1_val:0.786517 AUC_val:0.9110\n",
      "Epoch:0021\n",
      "acc_train:0.7613 pre_train:0.7494 recall_train:0.8058 F1_train:0.7766 AUC_train:0.8215\n",
      "acc_val:0.7978 pre_val:0.8182 recall_val:0.7826 F1_val:0.800000 AUC_val:0.9201\n",
      "Epoch:0022\n",
      "acc_train:0.7788 pre_train:0.7571 recall_train:0.8398 F1_train:0.7963 AUC_train:0.8473\n",
      "acc_val:0.7978 pre_val:0.8043 recall_val:0.8043 F1_val:0.804348 AUC_val:0.9277\n",
      "Epoch:0023\n",
      "acc_train:0.7763 pre_train:0.7505 recall_train:0.8471 F1_train:0.7959 AUC_train:0.8626\n",
      "acc_val:0.8539 pre_val:0.8511 recall_val:0.8696 F1_val:0.860215 AUC_val:0.9393\n",
      "Epoch:0024\n",
      "acc_train:0.7812 pre_train:0.7413 recall_train:0.8835 F1_train:0.8062 AUC_train:0.8631\n",
      "acc_val:0.8652 pre_val:0.8542 recall_val:0.8913 F1_val:0.872340 AUC_val:0.9499\n",
      "Epoch:0025\n",
      "acc_train:0.7937 pre_train:0.7600 recall_train:0.8762 F1_train:0.8140 AUC_train:0.8722\n",
      "acc_val:0.8764 pre_val:0.8571 recall_val:0.9130 F1_val:0.884211 AUC_val:0.9545\n",
      "Epoch:0026\n",
      "acc_train:0.8213 pre_train:0.7808 recall_train:0.9078 F1_train:0.8395 AUC_train:0.8932\n",
      "acc_val:0.8764 pre_val:0.8431 recall_val:0.9348 F1_val:0.886598 AUC_val:0.9464\n",
      "Epoch:0027\n",
      "acc_train:0.8225 pre_train:0.7812 recall_train:0.9102 F1_train:0.8408 AUC_train:0.9054\n",
      "acc_val:0.8764 pre_val:0.8431 recall_val:0.9348 F1_val:0.886598 AUC_val:0.9484\n",
      "Epoch:0028\n",
      "acc_train:0.8150 pre_train:0.7651 recall_train:0.9248 F1_train:0.8374 AUC_train:0.8953\n",
      "acc_val:0.8764 pre_val:0.8431 recall_val:0.9348 F1_val:0.886598 AUC_val:0.9499\n",
      "Epoch:0029\n",
      "acc_train:0.8263 pre_train:0.7703 recall_train:0.9442 F1_train:0.8484 AUC_train:0.9118\n",
      "acc_val:0.8764 pre_val:0.8431 recall_val:0.9348 F1_val:0.886598 AUC_val:0.9575\n",
      "Epoch:0030\n",
      "acc_train:0.8350 pre_train:0.7893 recall_train:0.9272 F1_train:0.8527 AUC_train:0.9189\n",
      "acc_val:0.8764 pre_val:0.8302 recall_val:0.9565 F1_val:0.888889 AUC_val:0.9687\n",
      "Epoch:0031\n",
      "acc_train:0.8475 pre_train:0.8021 recall_train:0.9345 F1_train:0.8632 AUC_train:0.9274\n",
      "acc_val:0.8989 pre_val:0.8627 recall_val:0.9565 F1_val:0.907216 AUC_val:0.9757\n",
      "Epoch:0032\n",
      "acc_train:0.8537 pre_train:0.8132 recall_train:0.9296 F1_train:0.8675 AUC_train:0.9375\n",
      "acc_val:0.8989 pre_val:0.8491 recall_val:0.9783 F1_val:0.909091 AUC_val:0.9752\n",
      "Epoch:0033\n",
      "acc_train:0.8475 pre_train:0.7996 recall_train:0.9393 F1_train:0.8638 AUC_train:0.9239\n",
      "acc_val:0.8989 pre_val:0.8491 recall_val:0.9783 F1_val:0.909091 AUC_val:0.9798\n",
      "Epoch:0034\n",
      "acc_train:0.8625 pre_train:0.8240 recall_train:0.9320 F1_train:0.8747 AUC_train:0.9477\n",
      "acc_val:0.9101 pre_val:0.8519 recall_val:1.0000 F1_val:0.920000 AUC_val:0.9798\n",
      "Epoch:0035\n",
      "acc_train:0.8763 pre_train:0.8395 recall_train:0.9393 F1_train:0.8866 AUC_train:0.9473\n",
      "acc_val:0.8989 pre_val:0.8627 recall_val:0.9565 F1_val:0.907216 AUC_val:0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0036\n",
      "acc_train:0.8725 pre_train:0.8355 recall_train:0.9369 F1_train:0.8833 AUC_train:0.9462\n",
      "acc_val:0.9101 pre_val:0.8800 recall_val:0.9565 F1_val:0.916667 AUC_val:0.9869\n",
      "Epoch:0037\n",
      "acc_train:0.8813 pre_train:0.8394 recall_train:0.9515 F1_train:0.8919 AUC_train:0.9568\n",
      "acc_val:0.9101 pre_val:0.8800 recall_val:0.9565 F1_val:0.916667 AUC_val:0.9808\n",
      "Epoch:0038\n",
      "acc_train:0.8863 pre_train:0.8482 recall_train:0.9490 F1_train:0.8958 AUC_train:0.9558\n",
      "acc_val:0.9213 pre_val:0.8980 recall_val:0.9565 F1_val:0.926316 AUC_val:0.9813\n",
      "Epoch:0039\n",
      "acc_train:0.8725 pre_train:0.8202 recall_train:0.9636 F1_train:0.8862 AUC_train:0.9591\n",
      "acc_val:0.9101 pre_val:0.8800 recall_val:0.9565 F1_val:0.916667 AUC_val:0.9775\n",
      "Epoch:0040\n",
      "acc_train:0.8863 pre_train:0.8393 recall_train:0.9636 F1_train:0.8972 AUC_train:0.9595\n",
      "acc_val:0.9213 pre_val:0.8980 recall_val:0.9565 F1_val:0.926316 AUC_val:0.9805\n",
      "Epoch:0041\n",
      "acc_train:0.8875 pre_train:0.8470 recall_train:0.9539 F1_train:0.8973 AUC_train:0.9540\n",
      "acc_val:0.9213 pre_val:0.8980 recall_val:0.9565 F1_val:0.926316 AUC_val:0.9815\n",
      "Epoch:0042\n",
      "acc_train:0.9050 pre_train:0.8717 recall_train:0.9563 F1_train:0.9120 AUC_train:0.9699\n",
      "acc_val:0.9101 pre_val:0.8800 recall_val:0.9565 F1_val:0.916667 AUC_val:0.9810\n",
      "Epoch:0043\n",
      "acc_train:0.9275 pre_train:0.9005 recall_train:0.9660 F1_train:0.9321 AUC_train:0.9760\n",
      "acc_val:0.9101 pre_val:0.8800 recall_val:0.9565 F1_val:0.916667 AUC_val:0.9793\n",
      "Epoch:0044\n",
      "acc_train:0.9162 pre_train:0.8859 recall_train:0.9612 F1_train:0.9220 AUC_train:0.9739\n",
      "acc_val:0.8989 pre_val:0.8776 recall_val:0.9348 F1_val:0.905263 AUC_val:0.9778\n",
      "Epoch:0045\n",
      "acc_train:0.9312 pre_train:0.9122 recall_train:0.9587 F1_train:0.9349 AUC_train:0.9776\n",
      "acc_val:0.8989 pre_val:0.8776 recall_val:0.9348 F1_val:0.905263 AUC_val:0.9772\n",
      "Epoch:0046\n",
      "acc_train:0.9275 pre_train:0.9097 recall_train:0.9539 F1_train:0.9313 AUC_train:0.9704\n",
      "acc_val:0.9213 pre_val:0.9149 recall_val:0.9348 F1_val:0.924731 AUC_val:0.9775\n",
      "Epoch:0047\n",
      "acc_train:0.9275 pre_train:0.9214 recall_train:0.9393 F1_train:0.9303 AUC_train:0.9764\n",
      "acc_val:0.9213 pre_val:0.9149 recall_val:0.9348 F1_val:0.924731 AUC_val:0.9740\n",
      "Epoch:0048\n",
      "acc_train:0.9200 pre_train:0.9163 recall_train:0.9296 F1_train:0.9229 AUC_train:0.9724\n",
      "acc_val:0.9213 pre_val:0.9149 recall_val:0.9348 F1_val:0.924731 AUC_val:0.9745\n",
      "Epoch:0049\n",
      "acc_train:0.9300 pre_train:0.9178 recall_train:0.9490 F1_train:0.9332 AUC_train:0.9822\n",
      "acc_val:0.9213 pre_val:0.9149 recall_val:0.9348 F1_val:0.924731 AUC_val:0.9714\n",
      "Epoch:0050\n",
      "acc_train:0.9337 pre_train:0.9108 recall_train:0.9660 F1_train:0.9376 AUC_train:0.9714\n",
      "acc_val:0.9213 pre_val:0.9149 recall_val:0.9348 F1_val:0.924731 AUC_val:0.9714\n",
      "Epoch:0051\n",
      "acc_train:0.9250 pre_train:0.9037 recall_train:0.9563 F1_train:0.9292 AUC_train:0.9748\n",
      "acc_val:0.9213 pre_val:0.9149 recall_val:0.9348 F1_val:0.924731 AUC_val:0.9709\n",
      "Epoch:0052\n",
      "acc_train:0.9212 pre_train:0.8869 recall_train:0.9709 F1_train:0.9270 AUC_train:0.9822\n",
      "acc_val:0.8989 pre_val:0.8776 recall_val:0.9348 F1_val:0.905263 AUC_val:0.9714\n",
      "Epoch:0053\n",
      "acc_train:0.9325 pre_train:0.9202 recall_train:0.9515 F1_train:0.9356 AUC_train:0.9828\n",
      "acc_val:0.8876 pre_val:0.8600 recall_val:0.9348 F1_val:0.895833 AUC_val:0.9760\n",
      "Epoch:0054\n",
      "acc_train:0.9350 pre_train:0.9128 recall_train:0.9660 F1_train:0.9387 AUC_train:0.9834\n",
      "acc_val:0.8876 pre_val:0.8600 recall_val:0.9348 F1_val:0.895833 AUC_val:0.9785\n",
      "Epoch:0055\n",
      "acc_train:0.9375 pre_train:0.9151 recall_train:0.9684 F1_train:0.9410 AUC_train:0.9851\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9778\n",
      "Epoch:0056\n",
      "acc_train:0.9513 pre_train:0.9307 recall_train:0.9782 F1_train:0.9538 AUC_train:0.9866\n",
      "acc_val:0.8539 pre_val:0.7895 recall_val:0.9783 F1_val:0.873786 AUC_val:0.9742\n",
      "Epoch:0057\n",
      "acc_train:0.9375 pre_train:0.9171 recall_train:0.9660 F1_train:0.9409 AUC_train:0.9836\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9752\n",
      "Epoch:0058\n",
      "acc_train:0.9400 pre_train:0.9099 recall_train:0.9806 F1_train:0.9439 AUC_train:0.9818\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9747\n",
      "Epoch:0059\n",
      "acc_train:0.9300 pre_train:0.8973 recall_train:0.9757 F1_train:0.9349 AUC_train:0.9888\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9722\n",
      "Epoch:0060\n",
      "acc_train:0.9262 pre_train:0.9095 recall_train:0.9515 F1_train:0.9300 AUC_train:0.9829\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9707\n",
      "Epoch:0061\n",
      "acc_train:0.9563 pre_train:0.9353 recall_train:0.9830 F1_train:0.9586 AUC_train:0.9907\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9727\n",
      "Epoch:0062\n",
      "acc_train:0.9400 pre_train:0.9174 recall_train:0.9709 F1_train:0.9434 AUC_train:0.9881\n",
      "acc_val:0.8427 pre_val:0.7963 recall_val:0.9348 F1_val:0.860000 AUC_val:0.9687\n",
      "Epoch:0063\n",
      "acc_train:0.9563 pre_train:0.9374 recall_train:0.9806 F1_train:0.9585 AUC_train:0.9904\n",
      "acc_val:0.8539 pre_val:0.8113 recall_val:0.9348 F1_val:0.868687 AUC_val:0.9671\n",
      "Epoch:0064\n",
      "acc_train:0.9413 pre_train:0.9234 recall_train:0.9660 F1_train:0.9442 AUC_train:0.9880\n",
      "acc_val:0.8876 pre_val:0.8462 recall_val:0.9565 F1_val:0.897959 AUC_val:0.9644\n",
      "Epoch:0065\n",
      "acc_train:0.9638 pre_train:0.9485 recall_train:0.9830 F1_train:0.9654 AUC_train:0.9917\n",
      "acc_val:0.8876 pre_val:0.8462 recall_val:0.9565 F1_val:0.897959 AUC_val:0.9616\n",
      "Epoch:0066\n",
      "acc_train:0.9600 pre_train:0.9460 recall_train:0.9782 F1_train:0.9618 AUC_train:0.9872\n",
      "acc_val:0.8764 pre_val:0.8431 recall_val:0.9348 F1_val:0.886598 AUC_val:0.9613\n",
      "Epoch:0067\n",
      "acc_train:0.9625 pre_train:0.9421 recall_train:0.9879 F1_train:0.9645 AUC_train:0.9925\n",
      "acc_val:0.8764 pre_val:0.8431 recall_val:0.9348 F1_val:0.886598 AUC_val:0.9633\n",
      "Epoch:0068\n",
      "acc_train:0.9588 pre_train:0.9438 recall_train:0.9782 F1_train:0.9607 AUC_train:0.9868\n",
      "acc_val:0.8764 pre_val:0.8431 recall_val:0.9348 F1_val:0.886598 AUC_val:0.9608\n",
      "Epoch:0069\n",
      "acc_train:0.9625 pre_train:0.9614 recall_train:0.9660 F1_train:0.9637 AUC_train:0.9937\n",
      "acc_val:0.8876 pre_val:0.8600 recall_val:0.9348 F1_val:0.895833 AUC_val:0.9611\n",
      "Epoch:0070\n",
      "acc_train:0.9588 pre_train:0.9356 recall_train:0.9879 F1_train:0.9610 AUC_train:0.9937\n",
      "acc_val:0.8876 pre_val:0.8600 recall_val:0.9348 F1_val:0.895833 AUC_val:0.9606\n",
      "Epoch:0071\n",
      "acc_train:0.9638 pre_train:0.9637 recall_train:0.9660 F1_train:0.9648 AUC_train:0.9950\n",
      "acc_val:0.9101 pre_val:0.8958 recall_val:0.9348 F1_val:0.914894 AUC_val:0.9608\n",
      "Epoch:0072\n",
      "acc_train:0.9737 pre_train:0.9578 recall_train:0.9927 F1_train:0.9750 AUC_train:0.9955\n",
      "acc_val:0.8989 pre_val:0.8776 recall_val:0.9348 F1_val:0.905263 AUC_val:0.9601\n",
      "Epoch:0073\n",
      "acc_train:0.9575 pre_train:0.9500 recall_train:0.9684 F1_train:0.9591 AUC_train:0.9854\n",
      "acc_val:0.8989 pre_val:0.8776 recall_val:0.9348 F1_val:0.905263 AUC_val:0.9613\n",
      "Epoch:0074\n",
      "acc_train:0.9588 pre_train:0.9397 recall_train:0.9830 F1_train:0.9609 AUC_train:0.9954\n",
      "acc_val:0.8652 pre_val:0.8269 recall_val:0.9348 F1_val:0.877551 AUC_val:0.9603\n",
      "Epoch:0075\n",
      "acc_train:0.9688 pre_train:0.9553 recall_train:0.9854 F1_train:0.9701 AUC_train:0.9939\n",
      "acc_val:0.8652 pre_val:0.8269 recall_val:0.9348 F1_val:0.877551 AUC_val:0.9590\n",
      "Epoch:0076\n",
      "acc_train:0.9638 pre_train:0.9506 recall_train:0.9806 F1_train:0.9654 AUC_train:0.9919\n",
      "acc_val:0.8652 pre_val:0.8269 recall_val:0.9348 F1_val:0.877551 AUC_val:0.9512\n",
      "Epoch:0077\n",
      "acc_train:0.9688 pre_train:0.9574 recall_train:0.9830 F1_train:0.9701 AUC_train:0.9949\n",
      "acc_val:0.8539 pre_val:0.8113 recall_val:0.9348 F1_val:0.868687 AUC_val:0.9502\n",
      "Epoch:0078\n",
      "acc_train:0.9613 pre_train:0.9441 recall_train:0.9830 F1_train:0.9631 AUC_train:0.9950\n",
      "acc_val:0.8427 pre_val:0.7963 recall_val:0.9348 F1_val:0.860000 AUC_val:0.9482\n",
      "Epoch:0079\n",
      "acc_train:0.9638 pre_train:0.9485 recall_train:0.9830 F1_train:0.9654 AUC_train:0.9942\n",
      "acc_val:0.8427 pre_val:0.7963 recall_val:0.9348 F1_val:0.860000 AUC_val:0.9462\n",
      "Epoch:0080\n",
      "acc_train:0.9675 pre_train:0.9595 recall_train:0.9782 F1_train:0.9688 AUC_train:0.9950\n",
      "acc_val:0.8427 pre_val:0.7963 recall_val:0.9348 F1_val:0.860000 AUC_val:0.9446\n",
      "Epoch:0081\n",
      "acc_train:0.9737 pre_train:0.9711 recall_train:0.9782 F1_train:0.9746 AUC_train:0.9954\n",
      "acc_val:0.8315 pre_val:0.7818 recall_val:0.9348 F1_val:0.851485 AUC_val:0.9439\n",
      "Epoch:0082\n",
      "acc_train:0.9638 pre_train:0.9485 recall_train:0.9830 F1_train:0.9654 AUC_train:0.9960\n",
      "acc_val:0.8090 pre_val:0.7544 recall_val:0.9348 F1_val:0.834951 AUC_val:0.9431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0083\n",
      "acc_train:0.9625 pre_train:0.9463 recall_train:0.9830 F1_train:0.9643 AUC_train:0.9940\n",
      "acc_val:0.8202 pre_val:0.7679 recall_val:0.9348 F1_val:0.843137 AUC_val:0.9449\n",
      "Epoch:0084\n",
      "acc_train:0.9750 pre_train:0.9667 recall_train:0.9854 F1_train:0.9760 AUC_train:0.9978\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9451\n",
      "Epoch:0085\n",
      "acc_train:0.9737 pre_train:0.9666 recall_train:0.9830 F1_train:0.9747 AUC_train:0.9951\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9522\n",
      "Epoch:0086\n",
      "acc_train:0.9737 pre_train:0.9600 recall_train:0.9903 F1_train:0.9749 AUC_train:0.9968\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9522\n",
      "Epoch:0087\n",
      "acc_train:0.9762 pre_train:0.9758 recall_train:0.9782 F1_train:0.9770 AUC_train:0.9965\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9522\n",
      "Epoch:0088\n",
      "acc_train:0.9737 pre_train:0.9622 recall_train:0.9879 F1_train:0.9749 AUC_train:0.9961\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9535\n",
      "Epoch:0089\n",
      "acc_train:0.9775 pre_train:0.9736 recall_train:0.9830 F1_train:0.9783 AUC_train:0.9933\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9540\n",
      "Epoch:0090\n",
      "acc_train:0.9812 pre_train:0.9693 recall_train:0.9951 F1_train:0.9820 AUC_train:0.9976\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9535\n",
      "Epoch:0091\n",
      "acc_train:0.9812 pre_train:0.9715 recall_train:0.9927 F1_train:0.9820 AUC_train:0.9977\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9540\n",
      "Early Stopping!!! epoch：90\n",
      " Starting the 1-4 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.5038 pre_train:0.5232 recall_train:0.4102 F1_train:0.4599 AUC_train:0.4696\n",
      "acc_val:0.5955 pre_val:0.6087 recall_val:0.6087 F1_val:0.608696 AUC_val:0.5642\n",
      "Epoch:0002\n",
      "acc_train:0.5250 pre_train:0.5305 recall_train:0.6748 F1_train:0.5940 AUC_train:0.5366\n",
      "acc_val:0.6292 pre_val:0.6512 recall_val:0.6087 F1_val:0.629213 AUC_val:0.6426\n",
      "Epoch:0003\n",
      "acc_train:0.5462 pre_train:0.5529 recall_train:0.6214 F1_train:0.5851 AUC_train:0.5581\n",
      "acc_val:0.6404 pre_val:0.6667 recall_val:0.6087 F1_val:0.636364 AUC_val:0.6835\n",
      "Epoch:0004\n",
      "acc_train:0.5288 pre_train:0.5361 recall_train:0.6311 F1_train:0.5797 AUC_train:0.5518\n",
      "acc_val:0.6742 pre_val:0.7073 recall_val:0.6304 F1_val:0.666667 AUC_val:0.7063\n",
      "Epoch:0005\n",
      "acc_train:0.5300 pre_train:0.5407 recall_train:0.5801 F1_train:0.5597 AUC_train:0.5624\n",
      "acc_val:0.6854 pre_val:0.8214 recall_val:0.5000 F1_val:0.621622 AUC_val:0.7255\n",
      "Epoch:0006\n",
      "acc_train:0.5325 pre_train:0.5424 recall_train:0.5898 F1_train:0.5651 AUC_train:0.5538\n",
      "acc_val:0.6966 pre_val:0.8800 recall_val:0.4783 F1_val:0.619718 AUC_val:0.7315\n",
      "Epoch:0007\n",
      "acc_train:0.5400 pre_train:0.5502 recall_train:0.5850 F1_train:0.5671 AUC_train:0.5633\n",
      "acc_val:0.6966 pre_val:0.8800 recall_val:0.4783 F1_val:0.619718 AUC_val:0.7336\n",
      "Epoch:0008\n",
      "acc_train:0.5512 pre_train:0.5858 recall_train:0.4393 F1_train:0.5021 AUC_train:0.5648\n",
      "acc_val:0.6966 pre_val:0.8065 recall_val:0.5435 F1_val:0.649351 AUC_val:0.6886\n",
      "Epoch:0009\n",
      "acc_train:0.5412 pre_train:0.5584 recall_train:0.5218 F1_train:0.5395 AUC_train:0.5570\n",
      "acc_val:0.6966 pre_val:0.8065 recall_val:0.5435 F1_val:0.649351 AUC_val:0.6997\n",
      "Epoch:0010\n",
      "acc_train:0.5375 pre_train:0.5547 recall_train:0.5170 F1_train:0.5352 AUC_train:0.5490\n",
      "acc_val:0.6742 pre_val:0.8148 recall_val:0.4783 F1_val:0.602740 AUC_val:0.7149\n",
      "Epoch:0011\n",
      "acc_train:0.5838 pre_train:0.6158 recall_train:0.5097 F1_train:0.5578 AUC_train:0.6195\n",
      "acc_val:0.6742 pre_val:0.8148 recall_val:0.4783 F1_val:0.602740 AUC_val:0.7118\n",
      "Epoch:0012\n",
      "acc_train:0.5625 pre_train:0.5803 recall_train:0.5437 F1_train:0.5614 AUC_train:0.5938\n",
      "acc_val:0.6742 pre_val:0.8148 recall_val:0.4783 F1_val:0.602740 AUC_val:0.7048\n",
      "Epoch:0013\n",
      "acc_train:0.5750 pre_train:0.6040 recall_train:0.5073 F1_train:0.5515 AUC_train:0.6124\n",
      "acc_val:0.6854 pre_val:0.8214 recall_val:0.5000 F1_val:0.621622 AUC_val:0.7240\n",
      "Epoch:0014\n",
      "acc_train:0.5675 pre_train:0.5813 recall_train:0.5728 F1_train:0.5770 AUC_train:0.6008\n",
      "acc_val:0.6854 pre_val:0.8462 recall_val:0.4783 F1_val:0.611111 AUC_val:0.7224\n",
      "Epoch:0015\n",
      "acc_train:0.5763 pre_train:0.5875 recall_train:0.5947 F1_train:0.5911 AUC_train:0.6047\n",
      "acc_val:0.6966 pre_val:0.8519 recall_val:0.5000 F1_val:0.630137 AUC_val:0.7128\n",
      "Epoch:0016\n",
      "acc_train:0.5713 pre_train:0.5966 recall_train:0.5170 F1_train:0.5540 AUC_train:0.6022\n",
      "acc_val:0.6854 pre_val:0.8214 recall_val:0.5000 F1_val:0.621622 AUC_val:0.7174\n",
      "Epoch:0017\n",
      "acc_train:0.5788 pre_train:0.5940 recall_train:0.5752 F1_train:0.5845 AUC_train:0.6242\n",
      "acc_val:0.6854 pre_val:0.8462 recall_val:0.4783 F1_val:0.611111 AUC_val:0.7209\n",
      "Epoch:0018\n",
      "acc_train:0.5875 pre_train:0.5981 recall_train:0.6068 F1_train:0.6024 AUC_train:0.6225\n",
      "acc_val:0.6854 pre_val:0.8462 recall_val:0.4783 F1_val:0.611111 AUC_val:0.7245\n",
      "Epoch:0019\n",
      "acc_train:0.5775 pre_train:0.6285 recall_train:0.4393 F1_train:0.5171 AUC_train:0.6195\n",
      "acc_val:0.6854 pre_val:0.8462 recall_val:0.4783 F1_val:0.611111 AUC_val:0.7295\n",
      "Epoch:0020\n",
      "acc_train:0.6075 pre_train:0.6441 recall_train:0.5316 F1_train:0.5824 AUC_train:0.6383\n",
      "acc_val:0.7191 pre_val:0.8387 recall_val:0.5652 F1_val:0.675325 AUC_val:0.7376\n",
      "Epoch:0021\n",
      "acc_train:0.5775 pre_train:0.5781 recall_train:0.6650 F1_train:0.6185 AUC_train:0.6292\n",
      "acc_val:0.7079 pre_val:0.7941 recall_val:0.5870 F1_val:0.675000 AUC_val:0.7508\n",
      "Epoch:0022\n",
      "acc_train:0.6225 pre_train:0.6341 recall_train:0.6311 F1_train:0.6326 AUC_train:0.6637\n",
      "acc_val:0.6854 pre_val:0.7500 recall_val:0.5870 F1_val:0.658537 AUC_val:0.7553\n",
      "Epoch:0023\n",
      "acc_train:0.5938 pre_train:0.6225 recall_train:0.5364 F1_train:0.5763 AUC_train:0.6345\n",
      "acc_val:0.6854 pre_val:0.7500 recall_val:0.5870 F1_val:0.658537 AUC_val:0.7594\n",
      "Epoch:0024\n",
      "acc_train:0.5838 pre_train:0.5857 recall_train:0.6553 F1_train:0.6186 AUC_train:0.6438\n",
      "acc_val:0.7191 pre_val:0.7442 recall_val:0.6957 F1_val:0.719101 AUC_val:0.7639\n",
      "Epoch:0025\n",
      "acc_train:0.5962 pre_train:0.6469 recall_train:0.4757 F1_train:0.5483 AUC_train:0.6137\n",
      "acc_val:0.7079 pre_val:0.7273 recall_val:0.6957 F1_val:0.711111 AUC_val:0.7664\n",
      "Epoch:0026\n",
      "acc_train:0.5462 pre_train:0.5633 recall_train:0.5291 F1_train:0.5457 AUC_train:0.5748\n",
      "acc_val:0.7191 pre_val:0.7561 recall_val:0.6739 F1_val:0.712644 AUC_val:0.7462\n",
      "Epoch:0027\n",
      "acc_train:0.5838 pre_train:0.5733 recall_train:0.7500 F1_train:0.6498 AUC_train:0.6473\n",
      "acc_val:0.6854 pre_val:0.6731 recall_val:0.7609 F1_val:0.714286 AUC_val:0.7583\n",
      "Epoch:0028\n",
      "acc_train:0.5950 pre_train:0.5978 recall_train:0.6529 F1_train:0.6241 AUC_train:0.6510\n",
      "acc_val:0.6854 pre_val:0.6800 recall_val:0.7391 F1_val:0.708333 AUC_val:0.7700\n",
      "Epoch:0029\n",
      "acc_train:0.5738 pre_train:0.5913 recall_train:0.5583 F1_train:0.5743 AUC_train:0.6327\n",
      "acc_val:0.7191 pre_val:0.7059 recall_val:0.7826 F1_val:0.742268 AUC_val:0.7983\n",
      "Epoch:0030\n",
      "acc_train:0.6025 pre_train:0.5971 recall_train:0.7015 F1_train:0.6451 AUC_train:0.6603\n",
      "acc_val:0.7191 pre_val:0.7059 recall_val:0.7826 F1_val:0.742268 AUC_val:0.8049\n",
      "Epoch:0031\n",
      "acc_train:0.6200 pre_train:0.6436 recall_train:0.5874 F1_train:0.6142 AUC_train:0.6892\n",
      "acc_val:0.7191 pre_val:0.7059 recall_val:0.7826 F1_val:0.742268 AUC_val:0.8109\n",
      "Epoch:0032\n",
      "acc_train:0.6025 pre_train:0.6013 recall_train:0.6772 F1_train:0.6370 AUC_train:0.6655\n",
      "acc_val:0.7303 pre_val:0.7200 recall_val:0.7826 F1_val:0.750000 AUC_val:0.8180\n",
      "Epoch:0033\n",
      "acc_train:0.6062 pre_train:0.6209 recall_train:0.6044 F1_train:0.6125 AUC_train:0.6790\n",
      "acc_val:0.7303 pre_val:0.7292 recall_val:0.7609 F1_val:0.744681 AUC_val:0.8251\n",
      "Epoch:0034\n",
      "acc_train:0.6012 pre_train:0.6202 recall_train:0.5825 F1_train:0.6008 AUC_train:0.6685\n",
      "acc_val:0.7416 pre_val:0.7447 recall_val:0.7609 F1_val:0.752688 AUC_val:0.8276\n",
      "Epoch:0035\n",
      "acc_train:0.6338 pre_train:0.6192 recall_train:0.7500 F1_train:0.6784 AUC_train:0.6959\n",
      "acc_val:0.7416 pre_val:0.7447 recall_val:0.7609 F1_val:0.752688 AUC_val:0.8347\n",
      "Epoch:0036\n",
      "acc_train:0.6300 pre_train:0.6422 recall_train:0.6359 F1_train:0.6390 AUC_train:0.7112\n",
      "acc_val:0.7416 pre_val:0.7556 recall_val:0.7391 F1_val:0.747253 AUC_val:0.8423\n",
      "Epoch:0037\n",
      "acc_train:0.6187 pre_train:0.6156 recall_train:0.6917 F1_train:0.6514 AUC_train:0.6905\n",
      "acc_val:0.7528 pre_val:0.7609 recall_val:0.7609 F1_val:0.760870 AUC_val:0.8559\n",
      "Epoch:0038\n",
      "acc_train:0.6288 pre_train:0.6340 recall_train:0.6602 F1_train:0.6468 AUC_train:0.6960\n",
      "acc_val:0.7528 pre_val:0.7609 recall_val:0.7609 F1_val:0.760870 AUC_val:0.8595\n",
      "Epoch:0039\n",
      "acc_train:0.6250 pre_train:0.6466 recall_train:0.5995 F1_train:0.6222 AUC_train:0.7332\n",
      "acc_val:0.7753 pre_val:0.7955 recall_val:0.7609 F1_val:0.777778 AUC_val:0.8655\n",
      "Epoch:0040\n",
      "acc_train:0.6388 pre_train:0.6565 recall_train:0.6262 F1_train:0.6410 AUC_train:0.7026\n",
      "acc_val:0.7640 pre_val:0.7551 recall_val:0.8043 F1_val:0.778947 AUC_val:0.8696\n",
      "Epoch:0041\n",
      "acc_train:0.6575 pre_train:0.6533 recall_train:0.7136 F1_train:0.6821 AUC_train:0.7427\n",
      "acc_val:0.7865 pre_val:0.7872 recall_val:0.8043 F1_val:0.795699 AUC_val:0.8862\n",
      "Epoch:0042\n",
      "acc_train:0.6988 pre_train:0.6680 recall_train:0.8252 F1_train:0.7383 AUC_train:0.7511\n",
      "acc_val:0.7978 pre_val:0.7917 recall_val:0.8261 F1_val:0.808511 AUC_val:0.9044\n",
      "Epoch:0043\n",
      "acc_train:0.6963 pre_train:0.6680 recall_train:0.8155 F1_train:0.7344 AUC_train:0.7641\n",
      "acc_val:0.8090 pre_val:0.7636 recall_val:0.9130 F1_val:0.831683 AUC_val:0.9024\n",
      "Epoch:0044\n",
      "acc_train:0.7387 pre_train:0.7059 recall_train:0.8447 F1_train:0.7691 AUC_train:0.7945\n",
      "acc_val:0.7978 pre_val:0.7500 recall_val:0.9130 F1_val:0.823529 AUC_val:0.9019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0045\n",
      "acc_train:0.7487 pre_train:0.7184 recall_train:0.8422 F1_train:0.7754 AUC_train:0.8139\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9080\n",
      "Epoch:0046\n",
      "acc_train:0.7675 pre_train:0.7198 recall_train:0.8981 F1_train:0.7991 AUC_train:0.8418\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9151\n",
      "Epoch:0047\n",
      "acc_train:0.7900 pre_train:0.7480 recall_train:0.8932 F1_train:0.8142 AUC_train:0.8626\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9135\n",
      "Epoch:0048\n",
      "acc_train:0.7713 pre_train:0.7189 recall_train:0.9126 F1_train:0.8043 AUC_train:0.8456\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9120\n",
      "Epoch:0049\n",
      "acc_train:0.8100 pre_train:0.7549 recall_train:0.9345 F1_train:0.8351 AUC_train:0.8749\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9146\n",
      "Epoch:0050\n",
      "acc_train:0.7937 pre_train:0.7317 recall_train:0.9466 F1_train:0.8254 AUC_train:0.8603\n",
      "acc_val:0.8090 pre_val:0.7544 recall_val:0.9348 F1_val:0.834951 AUC_val:0.9151\n",
      "Epoch:0051\n",
      "acc_train:0.7987 pre_train:0.7400 recall_train:0.9393 F1_train:0.8278 AUC_train:0.8819\n",
      "acc_val:0.7978 pre_val:0.7500 recall_val:0.9130 F1_val:0.823529 AUC_val:0.9211\n",
      "Epoch:0052\n",
      "acc_train:0.8012 pre_train:0.7476 recall_train:0.9272 F1_train:0.8277 AUC_train:0.8750\n",
      "acc_val:0.8090 pre_val:0.7544 recall_val:0.9348 F1_val:0.834951 AUC_val:0.9242\n",
      "Epoch:0053\n",
      "acc_train:0.8075 pre_train:0.7520 recall_train:0.9345 F1_train:0.8333 AUC_train:0.8649\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9292\n",
      "Epoch:0054\n",
      "acc_train:0.8012 pre_train:0.7373 recall_train:0.9539 F1_train:0.8317 AUC_train:0.8790\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9302\n",
      "Epoch:0055\n",
      "acc_train:0.8263 pre_train:0.7682 recall_train:0.9490 F1_train:0.8491 AUC_train:0.9049\n",
      "acc_val:0.8090 pre_val:0.7302 recall_val:1.0000 F1_val:0.844037 AUC_val:0.9292\n",
      "Epoch:0056\n",
      "acc_train:0.8350 pre_train:0.7789 recall_train:0.9490 F1_train:0.8556 AUC_train:0.9136\n",
      "acc_val:0.7978 pre_val:0.7188 recall_val:1.0000 F1_val:0.836364 AUC_val:0.9368\n",
      "Epoch:0057\n",
      "acc_train:0.8537 pre_train:0.7909 recall_train:0.9733 F1_train:0.8727 AUC_train:0.9263\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9444\n",
      "Epoch:0058\n",
      "acc_train:0.8413 pre_train:0.7778 recall_train:0.9684 F1_train:0.8627 AUC_train:0.9219\n",
      "acc_val:0.7978 pre_val:0.7188 recall_val:1.0000 F1_val:0.836364 AUC_val:0.9398\n",
      "Epoch:0059\n",
      "acc_train:0.8712 pre_train:0.8186 recall_train:0.9636 F1_train:0.8852 AUC_train:0.9285\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.9403\n",
      "Epoch:0060\n",
      "acc_train:0.8525 pre_train:0.7871 recall_train:0.9782 F1_train:0.8723 AUC_train:0.9194\n",
      "acc_val:0.7865 pre_val:0.7213 recall_val:0.9565 F1_val:0.822430 AUC_val:0.9408\n",
      "Epoch:0061\n",
      "acc_train:0.8612 pre_train:0.7945 recall_train:0.9854 F1_train:0.8797 AUC_train:0.9399\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9424\n",
      "Epoch:0062\n",
      "acc_train:0.8500 pre_train:0.7852 recall_train:0.9757 F1_train:0.8701 AUC_train:0.9313\n",
      "acc_val:0.8315 pre_val:0.7541 recall_val:1.0000 F1_val:0.859813 AUC_val:0.9580\n",
      "Epoch:0063\n",
      "acc_train:0.8612 pre_train:0.8004 recall_train:0.9733 F1_train:0.8784 AUC_train:0.9418\n",
      "acc_val:0.8202 pre_val:0.7419 recall_val:1.0000 F1_val:0.851852 AUC_val:0.9616\n",
      "Epoch:0064\n",
      "acc_train:0.8475 pre_train:0.7888 recall_train:0.9612 F1_train:0.8665 AUC_train:0.9422\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9606\n",
      "Epoch:0065\n",
      "acc_train:0.8737 pre_train:0.8301 recall_train:0.9490 F1_train:0.8856 AUC_train:0.9417\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9525\n",
      "Epoch:0066\n",
      "acc_train:0.8775 pre_train:0.8165 recall_train:0.9830 F1_train:0.8921 AUC_train:0.9511\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9393\n",
      "Epoch:0067\n",
      "acc_train:0.9025 pre_train:0.8538 recall_train:0.9782 F1_train:0.9118 AUC_train:0.9629\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9368\n",
      "Epoch:0068\n",
      "acc_train:0.8963 pre_train:0.8406 recall_train:0.9854 F1_train:0.9073 AUC_train:0.9544\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9368\n",
      "Epoch:0069\n",
      "acc_train:0.8975 pre_train:0.8526 recall_train:0.9684 F1_train:0.9068 AUC_train:0.9554\n",
      "acc_val:0.7978 pre_val:0.7333 recall_val:0.9565 F1_val:0.830189 AUC_val:0.9459\n",
      "Epoch:0070\n",
      "acc_train:0.9112 pre_train:0.8667 recall_train:0.9782 F1_train:0.9190 AUC_train:0.9634\n",
      "acc_val:0.7978 pre_val:0.7333 recall_val:0.9565 F1_val:0.830189 AUC_val:0.9494\n",
      "Epoch:0071\n",
      "acc_train:0.9150 pre_train:0.8691 recall_train:0.9830 F1_train:0.9226 AUC_train:0.9621\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9651\n",
      "Epoch:0072\n",
      "acc_train:0.9175 pre_train:0.8761 recall_train:0.9782 F1_train:0.9243 AUC_train:0.9486\n",
      "acc_val:0.7978 pre_val:0.7333 recall_val:0.9565 F1_val:0.830189 AUC_val:0.9671\n",
      "Epoch:0073\n",
      "acc_train:0.8925 pre_train:0.8424 recall_train:0.9733 F1_train:0.9032 AUC_train:0.9660\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9616\n",
      "Epoch:0074\n",
      "acc_train:0.9175 pre_train:0.8777 recall_train:0.9757 F1_train:0.9241 AUC_train:0.9651\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9580\n",
      "Epoch:0075\n",
      "acc_train:0.8975 pre_train:0.8541 recall_train:0.9660 F1_train:0.9066 AUC_train:0.9532\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9510\n",
      "Epoch:0076\n",
      "acc_train:0.9137 pre_train:0.8641 recall_train:0.9879 F1_train:0.9219 AUC_train:0.9705\n",
      "acc_val:0.8315 pre_val:0.7925 recall_val:0.9130 F1_val:0.848485 AUC_val:0.9464\n",
      "Epoch:0077\n",
      "acc_train:0.8988 pre_train:0.8559 recall_train:0.9660 F1_train:0.9076 AUC_train:0.9645\n",
      "acc_val:0.8202 pre_val:0.7778 recall_val:0.9130 F1_val:0.840000 AUC_val:0.9474\n",
      "Epoch:0078\n",
      "acc_train:0.8988 pre_train:0.8484 recall_train:0.9782 F1_train:0.9087 AUC_train:0.9668\n",
      "acc_val:0.8090 pre_val:0.7544 recall_val:0.9348 F1_val:0.834951 AUC_val:0.9459\n",
      "Epoch:0079\n",
      "acc_train:0.9075 pre_train:0.8642 recall_train:0.9733 F1_train:0.9155 AUC_train:0.9708\n",
      "acc_val:0.7865 pre_val:0.7213 recall_val:0.9565 F1_val:0.822430 AUC_val:0.9414\n",
      "Epoch:0080\n",
      "acc_train:0.9237 pre_train:0.8790 recall_train:0.9879 F1_train:0.9303 AUC_train:0.9759\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.9414\n",
      "Epoch:0081\n",
      "acc_train:0.9013 pre_train:0.8565 recall_train:0.9709 F1_train:0.9101 AUC_train:0.9678\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.9408\n",
      "Epoch:0082\n",
      "acc_train:0.9212 pre_train:0.8785 recall_train:0.9830 F1_train:0.9278 AUC_train:0.9784\n",
      "acc_val:0.7640 pre_val:0.6923 recall_val:0.9783 F1_val:0.810811 AUC_val:0.9439\n",
      "Epoch:0083\n",
      "acc_train:0.9325 pre_train:0.8996 recall_train:0.9782 F1_train:0.9372 AUC_train:0.9782\n",
      "acc_val:0.7753 pre_val:0.6970 recall_val:1.0000 F1_val:0.821429 AUC_val:0.9444\n",
      "Epoch:0084\n",
      "acc_train:0.9325 pre_train:0.8925 recall_train:0.9879 F1_train:0.9378 AUC_train:0.9798\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9449\n",
      "Epoch:0085\n",
      "acc_train:0.9275 pre_train:0.8831 recall_train:0.9903 F1_train:0.9336 AUC_train:0.9820\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9499\n",
      "Epoch:0086\n",
      "acc_train:0.9312 pre_train:0.8940 recall_train:0.9830 F1_train:0.9364 AUC_train:0.9773\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9550\n",
      "Epoch:0087\n",
      "acc_train:0.9237 pre_train:0.8742 recall_train:0.9951 F1_train:0.9308 AUC_train:0.9755\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9565\n",
      "Epoch:0088\n",
      "acc_train:0.9337 pre_train:0.8945 recall_train:0.9879 F1_train:0.9389 AUC_train:0.9860\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9606\n",
      "Epoch:0089\n",
      "acc_train:0.9300 pre_train:0.8870 recall_train:0.9903 F1_train:0.9358 AUC_train:0.9817\n",
      "acc_val:0.8427 pre_val:0.7759 recall_val:0.9783 F1_val:0.865385 AUC_val:0.9631\n",
      "Epoch:0090\n",
      "acc_train:0.9362 pre_train:0.9020 recall_train:0.9830 F1_train:0.9408 AUC_train:0.9721\n",
      "acc_val:0.8427 pre_val:0.7759 recall_val:0.9783 F1_val:0.865385 AUC_val:0.9631\n",
      "Epoch:0091\n",
      "acc_train:0.9388 pre_train:0.9024 recall_train:0.9879 F1_train:0.9432 AUC_train:0.9884\n",
      "acc_val:0.8427 pre_val:0.7759 recall_val:0.9783 F1_val:0.865385 AUC_val:0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0092\n",
      "acc_train:0.9325 pre_train:0.8978 recall_train:0.9806 F1_train:0.9374 AUC_train:0.9773\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9631\n",
      "Epoch:0093\n",
      "acc_train:0.9413 pre_train:0.9029 recall_train:0.9927 F1_train:0.9457 AUC_train:0.9851\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9593\n",
      "Epoch:0094\n",
      "acc_train:0.9463 pre_train:0.9222 recall_train:0.9782 F1_train:0.9494 AUC_train:0.9830\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9583\n",
      "Epoch:0095\n",
      "acc_train:0.9463 pre_train:0.9146 recall_train:0.9879 F1_train:0.9498 AUC_train:0.9884\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9578\n",
      "Epoch:0096\n",
      "acc_train:0.9550 pre_train:0.9253 recall_train:0.9927 F1_train:0.9578 AUC_train:0.9947\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9553\n",
      "Epoch:0097\n",
      "acc_train:0.9450 pre_train:0.9126 recall_train:0.9879 F1_train:0.9487 AUC_train:0.9917\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9545\n",
      "Epoch:0098\n",
      "acc_train:0.9438 pre_train:0.9087 recall_train:0.9903 F1_train:0.9477 AUC_train:0.9820\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9520\n",
      "Epoch:0099\n",
      "acc_train:0.9525 pre_train:0.9174 recall_train:0.9976 F1_train:0.9558 AUC_train:0.9911\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9489\n",
      "Epoch:0100\n",
      "acc_train:0.9538 pre_train:0.9371 recall_train:0.9757 F1_train:0.9560 AUC_train:0.9883\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9449\n",
      "Epoch:0101\n",
      "acc_train:0.9550 pre_train:0.9292 recall_train:0.9879 F1_train:0.9576 AUC_train:0.9884\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9403\n",
      "Epoch:0102\n",
      "acc_train:0.9513 pre_train:0.9248 recall_train:0.9854 F1_train:0.9542 AUC_train:0.9864\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.9328\n",
      "Epoch:0103\n",
      "acc_train:0.9638 pre_train:0.9485 recall_train:0.9830 F1_train:0.9654 AUC_train:0.9870\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9290\n",
      "Epoch:0104\n",
      "acc_train:0.9613 pre_train:0.9400 recall_train:0.9879 F1_train:0.9633 AUC_train:0.9867\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.9328\n",
      "Epoch:0105\n",
      "acc_train:0.9575 pre_train:0.9355 recall_train:0.9854 F1_train:0.9598 AUC_train:0.9931\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9358\n",
      "Epoch:0106\n",
      "acc_train:0.9600 pre_train:0.9439 recall_train:0.9806 F1_train:0.9619 AUC_train:0.9897\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9429\n",
      "Epoch:0107\n",
      "acc_train:0.9400 pre_train:0.9118 recall_train:0.9782 F1_train:0.9438 AUC_train:0.9868\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9436\n",
      "Epoch:0108\n",
      "acc_train:0.9575 pre_train:0.9295 recall_train:0.9927 F1_train:0.9601 AUC_train:0.9855\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9436\n",
      "Epoch:0109\n",
      "acc_train:0.9588 pre_train:0.9356 recall_train:0.9879 F1_train:0.9610 AUC_train:0.9880\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.9403\n",
      "Epoch:0110\n",
      "acc_train:0.9588 pre_train:0.9376 recall_train:0.9854 F1_train:0.9609 AUC_train:0.9909\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.9373\n",
      "Epoch:0111\n",
      "acc_train:0.9638 pre_train:0.9443 recall_train:0.9879 F1_train:0.9656 AUC_train:0.9937\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9411\n",
      "Early Stopping!!! epoch：110\n",
      " Starting the 1-5 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4950 pre_train:0.5101 recall_train:0.4903 F1_train:0.5000 AUC_train:0.4961\n",
      "acc_val:0.4944 pre_val:0.5122 recall_val:0.4565 F1_val:0.482759 AUC_val:0.5066\n",
      "Epoch:0002\n",
      "acc_train:0.4837 pre_train:0.4989 recall_train:0.5316 F1_train:0.5147 AUC_train:0.4861\n",
      "acc_val:0.4607 pre_val:0.4722 recall_val:0.3696 F1_val:0.414634 AUC_val:0.4434\n",
      "Epoch:0003\n",
      "acc_train:0.4725 pre_train:0.4895 recall_train:0.5631 F1_train:0.5237 AUC_train:0.4676\n",
      "acc_val:0.4382 pre_val:0.4000 recall_val:0.1739 F1_val:0.242424 AUC_val:0.4681\n",
      "Epoch:0004\n",
      "acc_train:0.4900 pre_train:0.5043 recall_train:0.5704 F1_train:0.5353 AUC_train:0.4967\n",
      "acc_val:0.5169 pre_val:0.5429 recall_val:0.4130 F1_val:0.469136 AUC_val:0.5693\n",
      "Epoch:0005\n",
      "acc_train:0.5188 pre_train:0.5316 recall_train:0.5510 F1_train:0.5411 AUC_train:0.5285\n",
      "acc_val:0.6742 pre_val:0.6735 recall_val:0.7174 F1_val:0.694737 AUC_val:0.7356\n",
      "Epoch:0006\n",
      "acc_train:0.5575 pre_train:0.5721 recall_train:0.5583 F1_train:0.5651 AUC_train:0.5863\n",
      "acc_val:0.6404 pre_val:0.6458 recall_val:0.6739 F1_val:0.659574 AUC_val:0.7432\n",
      "Epoch:0007\n",
      "acc_train:0.5638 pre_train:0.5924 recall_train:0.4903 F1_train:0.5365 AUC_train:0.5799\n",
      "acc_val:0.6742 pre_val:0.6545 recall_val:0.7826 F1_val:0.712871 AUC_val:0.7487\n",
      "Epoch:0008\n",
      "acc_train:0.5700 pre_train:0.5876 recall_train:0.5534 F1_train:0.5700 AUC_train:0.6150\n",
      "acc_val:0.6517 pre_val:0.6471 recall_val:0.7174 F1_val:0.680412 AUC_val:0.7558\n",
      "Epoch:0009\n",
      "acc_train:0.5700 pre_train:0.5983 recall_train:0.5024 F1_train:0.5462 AUC_train:0.6000\n",
      "acc_val:0.6629 pre_val:0.6600 recall_val:0.7174 F1_val:0.687500 AUC_val:0.7543\n",
      "Epoch:0010\n",
      "acc_train:0.5625 pre_train:0.5812 recall_train:0.5388 F1_train:0.5592 AUC_train:0.5960\n",
      "acc_val:0.6629 pre_val:0.6600 recall_val:0.7174 F1_val:0.687500 AUC_val:0.7528\n",
      "Epoch:0011\n",
      "acc_train:0.5700 pre_train:0.5837 recall_train:0.5752 F1_train:0.5795 AUC_train:0.6188\n",
      "acc_val:0.6517 pre_val:0.6531 recall_val:0.6957 F1_val:0.673684 AUC_val:0.7583\n",
      "Epoch:0012\n",
      "acc_train:0.5663 pre_train:0.5815 recall_train:0.5631 F1_train:0.5721 AUC_train:0.6034\n",
      "acc_val:0.6629 pre_val:0.6481 recall_val:0.7609 F1_val:0.700000 AUC_val:0.7548\n",
      "Epoch:0013\n",
      "acc_train:0.5863 pre_train:0.5890 recall_train:0.6505 F1_train:0.6182 AUC_train:0.6319\n",
      "acc_val:0.6517 pre_val:0.6415 recall_val:0.7391 F1_val:0.686869 AUC_val:0.7578\n",
      "Epoch:0014\n",
      "acc_train:0.5638 pre_train:0.5741 recall_train:0.5922 F1_train:0.5830 AUC_train:0.6054\n",
      "acc_val:0.6966 pre_val:0.7021 recall_val:0.7174 F1_val:0.709677 AUC_val:0.7619\n",
      "Epoch:0015\n",
      "acc_train:0.5913 pre_train:0.6177 recall_train:0.5413 F1_train:0.5770 AUC_train:0.6180\n",
      "acc_val:0.6966 pre_val:0.7021 recall_val:0.7174 F1_val:0.709677 AUC_val:0.7609\n",
      "Epoch:0016\n",
      "acc_train:0.5800 pre_train:0.5960 recall_train:0.5728 F1_train:0.5842 AUC_train:0.6202\n",
      "acc_val:0.6404 pre_val:0.6346 recall_val:0.7174 F1_val:0.673469 AUC_val:0.7401\n",
      "Epoch:0017\n",
      "acc_train:0.6187 pre_train:0.6578 recall_train:0.5413 F1_train:0.5939 AUC_train:0.6549\n",
      "acc_val:0.6854 pre_val:0.6875 recall_val:0.7174 F1_val:0.702128 AUC_val:0.7609\n",
      "Epoch:0018\n",
      "acc_train:0.5900 pre_train:0.6173 recall_train:0.5364 F1_train:0.5740 AUC_train:0.6420\n",
      "acc_val:0.6742 pre_val:0.6809 recall_val:0.6957 F1_val:0.688172 AUC_val:0.7391\n",
      "Epoch:0019\n",
      "acc_train:0.5813 pre_train:0.5941 recall_train:0.5898 F1_train:0.5920 AUC_train:0.6425\n",
      "acc_val:0.7079 pre_val:0.7500 recall_val:0.6522 F1_val:0.697674 AUC_val:0.7568\n",
      "Epoch:0020\n",
      "acc_train:0.6025 pre_train:0.6250 recall_train:0.5704 F1_train:0.5964 AUC_train:0.6646\n",
      "acc_val:0.7303 pre_val:0.7895 recall_val:0.6522 F1_val:0.714286 AUC_val:0.7639\n",
      "Epoch:0021\n",
      "acc_train:0.6037 pre_train:0.6287 recall_train:0.5631 F1_train:0.5941 AUC_train:0.6608\n",
      "acc_val:0.7191 pre_val:0.7692 recall_val:0.6522 F1_val:0.705882 AUC_val:0.7730\n",
      "Epoch:0022\n",
      "acc_train:0.6150 pre_train:0.6436 recall_train:0.5655 F1_train:0.6021 AUC_train:0.6731\n",
      "acc_val:0.7303 pre_val:0.7895 recall_val:0.6522 F1_val:0.714286 AUC_val:0.7851\n",
      "Epoch:0023\n",
      "acc_train:0.6075 pre_train:0.6172 recall_train:0.6262 F1_train:0.6217 AUC_train:0.6665\n",
      "acc_val:0.7303 pre_val:0.7895 recall_val:0.6522 F1_val:0.714286 AUC_val:0.8069\n",
      "Epoch:0024\n",
      "acc_train:0.6150 pre_train:0.6405 recall_train:0.5752 F1_train:0.6061 AUC_train:0.6674\n",
      "acc_val:0.7528 pre_val:0.8158 recall_val:0.6739 F1_val:0.738095 AUC_val:0.8402\n",
      "Epoch:0025\n",
      "acc_train:0.6363 pre_train:0.6622 recall_train:0.5995 F1_train:0.6293 AUC_train:0.6924\n",
      "acc_val:0.7753 pre_val:0.8421 recall_val:0.6957 F1_val:0.761905 AUC_val:0.8595\n",
      "Epoch:0026\n",
      "acc_train:0.6313 pre_train:0.6696 recall_train:0.5607 F1_train:0.6103 AUC_train:0.6917\n",
      "acc_val:0.7753 pre_val:0.8421 recall_val:0.6957 F1_val:0.761905 AUC_val:0.8610\n",
      "Epoch:0027\n",
      "acc_train:0.6388 pre_train:0.6482 recall_train:0.6529 F1_train:0.6505 AUC_train:0.7108\n",
      "acc_val:0.7753 pre_val:0.8421 recall_val:0.6957 F1_val:0.761905 AUC_val:0.8746\n",
      "Epoch:0028\n",
      "acc_train:0.6313 pre_train:0.6410 recall_train:0.6456 F1_train:0.6433 AUC_train:0.7159\n",
      "acc_val:0.7865 pre_val:0.8649 recall_val:0.6957 F1_val:0.771084 AUC_val:0.8847\n",
      "Epoch:0029\n",
      "acc_train:0.6363 pre_train:0.6417 recall_train:0.6650 F1_train:0.6532 AUC_train:0.7015\n",
      "acc_val:0.7978 pre_val:0.8684 recall_val:0.7174 F1_val:0.785714 AUC_val:0.8989\n",
      "Epoch:0030\n",
      "acc_train:0.6725 pre_train:0.6720 recall_train:0.7112 F1_train:0.6910 AUC_train:0.7456\n",
      "acc_val:0.7865 pre_val:0.8462 recall_val:0.7174 F1_val:0.776471 AUC_val:0.9050\n",
      "Epoch:0031\n",
      "acc_train:0.6750 pre_train:0.7021 recall_train:0.6408 F1_train:0.6701 AUC_train:0.7478\n",
      "acc_val:0.7978 pre_val:0.8500 recall_val:0.7391 F1_val:0.790698 AUC_val:0.9115\n",
      "Epoch:0032\n",
      "acc_train:0.7225 pre_train:0.7340 recall_train:0.7233 F1_train:0.7286 AUC_train:0.7883\n",
      "acc_val:0.8202 pre_val:0.8571 recall_val:0.7826 F1_val:0.818182 AUC_val:0.9095\n",
      "Epoch:0033\n",
      "acc_train:0.7275 pre_train:0.7266 recall_train:0.7549 F1_train:0.7405 AUC_train:0.7875\n",
      "acc_val:0.8202 pre_val:0.8409 recall_val:0.8043 F1_val:0.822222 AUC_val:0.9120\n",
      "Epoch:0034\n",
      "acc_train:0.6500 pre_train:0.6919 recall_train:0.5777 F1_train:0.6296 AUC_train:0.7556\n",
      "acc_val:0.8202 pre_val:0.8409 recall_val:0.8043 F1_val:0.822222 AUC_val:0.9095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0035\n",
      "acc_train:0.7312 pre_train:0.7244 recall_train:0.7718 F1_train:0.7474 AUC_train:0.7960\n",
      "acc_val:0.8315 pre_val:0.8444 recall_val:0.8261 F1_val:0.835165 AUC_val:0.8999\n",
      "Epoch:0036\n",
      "acc_train:0.7337 pre_train:0.7506 recall_train:0.7233 F1_train:0.7367 AUC_train:0.8073\n",
      "acc_val:0.8202 pre_val:0.8261 recall_val:0.8261 F1_val:0.826087 AUC_val:0.8964\n",
      "Epoch:0037\n",
      "acc_train:0.7337 pre_train:0.7256 recall_train:0.7767 F1_train:0.7503 AUC_train:0.7882\n",
      "acc_val:0.8315 pre_val:0.8444 recall_val:0.8261 F1_val:0.835165 AUC_val:0.8943\n",
      "Epoch:0038\n",
      "acc_train:0.7575 pre_train:0.7300 recall_train:0.8398 F1_train:0.7810 AUC_train:0.7992\n",
      "acc_val:0.8315 pre_val:0.8298 recall_val:0.8478 F1_val:0.838710 AUC_val:0.8908\n",
      "Epoch:0039\n",
      "acc_train:0.7538 pre_train:0.7273 recall_train:0.8350 F1_train:0.7774 AUC_train:0.8107\n",
      "acc_val:0.8315 pre_val:0.8298 recall_val:0.8478 F1_val:0.838710 AUC_val:0.8948\n",
      "Epoch:0040\n",
      "acc_train:0.7600 pre_train:0.7254 recall_train:0.8592 F1_train:0.7867 AUC_train:0.8106\n",
      "acc_val:0.8202 pre_val:0.8000 recall_val:0.8696 F1_val:0.833333 AUC_val:0.9004\n",
      "Epoch:0041\n",
      "acc_train:0.7738 pre_train:0.7333 recall_train:0.8811 F1_train:0.8004 AUC_train:0.8370\n",
      "acc_val:0.8202 pre_val:0.7778 recall_val:0.9130 F1_val:0.840000 AUC_val:0.9060\n",
      "Epoch:0042\n",
      "acc_train:0.8225 pre_train:0.7755 recall_train:0.9223 F1_train:0.8426 AUC_train:0.8905\n",
      "acc_val:0.7978 pre_val:0.7500 recall_val:0.9130 F1_val:0.823529 AUC_val:0.9075\n",
      "Epoch:0043\n",
      "acc_train:0.8225 pre_train:0.7744 recall_train:0.9248 F1_train:0.8429 AUC_train:0.8775\n",
      "acc_val:0.7978 pre_val:0.7500 recall_val:0.9130 F1_val:0.823529 AUC_val:0.9065\n",
      "Epoch:0044\n",
      "acc_train:0.8213 pre_train:0.7773 recall_train:0.9150 F1_train:0.8406 AUC_train:0.8821\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9080\n",
      "Epoch:0045\n",
      "acc_train:0.8325 pre_train:0.7837 recall_train:0.9320 F1_train:0.8514 AUC_train:0.8913\n",
      "acc_val:0.7978 pre_val:0.7333 recall_val:0.9565 F1_val:0.830189 AUC_val:0.9080\n",
      "Epoch:0046\n",
      "acc_train:0.8363 pre_train:0.7862 recall_train:0.9369 F1_train:0.8549 AUC_train:0.9052\n",
      "acc_val:0.7978 pre_val:0.7333 recall_val:0.9565 F1_val:0.830189 AUC_val:0.9085\n",
      "Epoch:0047\n",
      "acc_train:0.8438 pre_train:0.7983 recall_train:0.9320 F1_train:0.8600 AUC_train:0.9153\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9171\n",
      "Epoch:0048\n",
      "acc_train:0.8587 pre_train:0.8134 recall_train:0.9417 F1_train:0.8729 AUC_train:0.9086\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9282\n",
      "Epoch:0049\n",
      "acc_train:0.8650 pre_train:0.8248 recall_train:0.9369 F1_train:0.8773 AUC_train:0.9186\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9353\n",
      "Epoch:0050\n",
      "acc_train:0.8650 pre_train:0.8154 recall_train:0.9539 F1_train:0.8792 AUC_train:0.9266\n",
      "acc_val:0.8427 pre_val:0.7759 recall_val:0.9783 F1_val:0.865385 AUC_val:0.9343\n",
      "Epoch:0051\n",
      "acc_train:0.8788 pre_train:0.8274 recall_train:0.9660 F1_train:0.8914 AUC_train:0.9383\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9454\n",
      "Epoch:0052\n",
      "acc_train:0.8662 pre_train:0.8308 recall_train:0.9296 F1_train:0.8774 AUC_train:0.9316\n",
      "acc_val:0.8539 pre_val:0.7895 recall_val:0.9783 F1_val:0.873786 AUC_val:0.9517\n",
      "Epoch:0053\n",
      "acc_train:0.8838 pre_train:0.8316 recall_train:0.9709 F1_train:0.8959 AUC_train:0.9505\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9593\n",
      "Epoch:0054\n",
      "acc_train:0.8863 pre_train:0.8365 recall_train:0.9684 F1_train:0.8976 AUC_train:0.9515\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9689\n",
      "Epoch:0055\n",
      "acc_train:0.9187 pre_train:0.8780 recall_train:0.9782 F1_train:0.9254 AUC_train:0.9670\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9704\n",
      "Epoch:0056\n",
      "acc_train:0.8925 pre_train:0.8498 recall_train:0.9612 F1_train:0.9021 AUC_train:0.9533\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9724\n",
      "Epoch:0057\n",
      "acc_train:0.9137 pre_train:0.8889 recall_train:0.9515 F1_train:0.9191 AUC_train:0.9598\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9714\n",
      "Epoch:0058\n",
      "acc_train:0.9262 pre_train:0.8914 recall_train:0.9757 F1_train:0.9316 AUC_train:0.9663\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9719\n",
      "Epoch:0059\n",
      "acc_train:0.9175 pre_train:0.8777 recall_train:0.9757 F1_train:0.9241 AUC_train:0.9681\n",
      "acc_val:0.8427 pre_val:0.7759 recall_val:0.9783 F1_val:0.865385 AUC_val:0.9702\n",
      "Epoch:0060\n",
      "acc_train:0.9175 pre_train:0.8827 recall_train:0.9684 F1_train:0.9236 AUC_train:0.9722\n",
      "acc_val:0.8427 pre_val:0.7759 recall_val:0.9783 F1_val:0.865385 AUC_val:0.9659\n",
      "Epoch:0061\n",
      "acc_train:0.9262 pre_train:0.8966 recall_train:0.9684 F1_train:0.9312 AUC_train:0.9701\n",
      "acc_val:0.8652 pre_val:0.8036 recall_val:0.9783 F1_val:0.882353 AUC_val:0.9618\n",
      "Epoch:0062\n",
      "acc_train:0.9300 pre_train:0.9064 recall_train:0.9636 F1_train:0.9341 AUC_train:0.9759\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9596\n",
      "Epoch:0063\n",
      "acc_train:0.9300 pre_train:0.9027 recall_train:0.9684 F1_train:0.9344 AUC_train:0.9739\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9525\n",
      "Epoch:0064\n",
      "acc_train:0.9425 pre_train:0.9122 recall_train:0.9830 F1_train:0.9463 AUC_train:0.9709\n",
      "acc_val:0.8427 pre_val:0.7857 recall_val:0.9565 F1_val:0.862745 AUC_val:0.9525\n",
      "Epoch:0065\n",
      "acc_train:0.9388 pre_train:0.9153 recall_train:0.9709 F1_train:0.9423 AUC_train:0.9756\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9530\n",
      "Epoch:0066\n",
      "acc_train:0.9388 pre_train:0.9097 recall_train:0.9782 F1_train:0.9427 AUC_train:0.9775\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9530\n",
      "Epoch:0067\n",
      "acc_train:0.9425 pre_train:0.9256 recall_train:0.9660 F1_train:0.9454 AUC_train:0.9843\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9540\n",
      "Epoch:0068\n",
      "acc_train:0.9425 pre_train:0.9122 recall_train:0.9830 F1_train:0.9463 AUC_train:0.9806\n",
      "acc_val:0.8539 pre_val:0.8000 recall_val:0.9565 F1_val:0.871287 AUC_val:0.9515\n",
      "Epoch:0069\n",
      "acc_train:0.9362 pre_train:0.9056 recall_train:0.9782 F1_train:0.9405 AUC_train:0.9786\n",
      "acc_val:0.8315 pre_val:0.7818 recall_val:0.9348 F1_val:0.851485 AUC_val:0.9517\n",
      "Epoch:0070\n",
      "acc_train:0.9262 pre_train:0.9039 recall_train:0.9587 F1_train:0.9305 AUC_train:0.9752\n",
      "acc_val:0.8315 pre_val:0.7925 recall_val:0.9130 F1_val:0.848485 AUC_val:0.9426\n",
      "Epoch:0071\n",
      "acc_train:0.9250 pre_train:0.9000 recall_train:0.9612 F1_train:0.9296 AUC_train:0.9716\n",
      "acc_val:0.8315 pre_val:0.7925 recall_val:0.9130 F1_val:0.848485 AUC_val:0.9401\n",
      "Epoch:0072\n",
      "acc_train:0.9463 pre_train:0.9184 recall_train:0.9830 F1_train:0.9496 AUC_train:0.9792\n",
      "acc_val:0.8090 pre_val:0.7636 recall_val:0.9130 F1_val:0.831683 AUC_val:0.9355\n",
      "Epoch:0073\n",
      "acc_train:0.9300 pre_train:0.9045 recall_train:0.9660 F1_train:0.9343 AUC_train:0.9659\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9267\n",
      "Epoch:0074\n",
      "acc_train:0.9563 pre_train:0.9274 recall_train:0.9927 F1_train:0.9590 AUC_train:0.9870\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9282\n",
      "Epoch:0075\n",
      "acc_train:0.9575 pre_train:0.9395 recall_train:0.9806 F1_train:0.9596 AUC_train:0.9904\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9292\n",
      "Epoch:0076\n",
      "acc_train:0.9450 pre_train:0.9201 recall_train:0.9782 F1_train:0.9482 AUC_train:0.9833\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9439\n",
      "Epoch:0077\n",
      "acc_train:0.9488 pre_train:0.9264 recall_train:0.9782 F1_train:0.9516 AUC_train:0.9888\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9517\n",
      "Epoch:0078\n",
      "acc_train:0.9513 pre_train:0.9347 recall_train:0.9733 F1_train:0.9536 AUC_train:0.9836\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9585\n",
      "Epoch:0079\n",
      "acc_train:0.9500 pre_train:0.9189 recall_train:0.9903 F1_train:0.9533 AUC_train:0.9838\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9593\n",
      "Epoch:0080\n",
      "acc_train:0.9488 pre_train:0.9264 recall_train:0.9782 F1_train:0.9516 AUC_train:0.9907\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9588\n",
      "Epoch:0081\n",
      "acc_train:0.9563 pre_train:0.9374 recall_train:0.9806 F1_train:0.9585 AUC_train:0.9891\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0082\n",
      "acc_train:0.9575 pre_train:0.9437 recall_train:0.9757 F1_train:0.9594 AUC_train:0.9915\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9563\n",
      "Epoch:0083\n",
      "acc_train:0.9575 pre_train:0.9355 recall_train:0.9854 F1_train:0.9598 AUC_train:0.9921\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9553\n",
      "Epoch:0084\n",
      "acc_train:0.9638 pre_train:0.9443 recall_train:0.9879 F1_train:0.9656 AUC_train:0.9913\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9548\n",
      "Epoch:0085\n",
      "acc_train:0.9600 pre_train:0.9398 recall_train:0.9854 F1_train:0.9621 AUC_train:0.9935\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9535\n",
      "Epoch:0086\n",
      "acc_train:0.9538 pre_train:0.9310 recall_train:0.9830 F1_train:0.9563 AUC_train:0.9909\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9515\n",
      "Epoch:0087\n",
      "acc_train:0.9775 pre_train:0.9624 recall_train:0.9951 F1_train:0.9785 AUC_train:0.9952\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9464\n",
      "Epoch:0088\n",
      "acc_train:0.9650 pre_train:0.9486 recall_train:0.9854 F1_train:0.9667 AUC_train:0.9941\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9424\n",
      "Epoch:0089\n",
      "acc_train:0.9563 pre_train:0.9353 recall_train:0.9830 F1_train:0.9586 AUC_train:0.9900\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9358\n",
      "Epoch:0090\n",
      "acc_train:0.9650 pre_train:0.9528 recall_train:0.9806 F1_train:0.9665 AUC_train:0.9890\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9290\n",
      "Epoch:0091\n",
      "acc_train:0.9725 pre_train:0.9621 recall_train:0.9854 F1_train:0.9736 AUC_train:0.9907\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9330\n",
      "Epoch:0092\n",
      "acc_train:0.9700 pre_train:0.9575 recall_train:0.9854 F1_train:0.9713 AUC_train:0.9914\n",
      "acc_val:0.8315 pre_val:0.7719 recall_val:0.9565 F1_val:0.854369 AUC_val:0.9391\n",
      "Epoch:0093\n",
      "acc_train:0.9650 pre_train:0.9571 recall_train:0.9757 F1_train:0.9663 AUC_train:0.9928\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9497\n",
      "Epoch:0094\n",
      "acc_train:0.9700 pre_train:0.9597 recall_train:0.9830 F1_train:0.9712 AUC_train:0.9904\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9537\n",
      "Epoch:0095\n",
      "acc_train:0.9700 pre_train:0.9533 recall_train:0.9903 F1_train:0.9714 AUC_train:0.9955\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9542\n",
      "Epoch:0096\n",
      "acc_train:0.9700 pre_train:0.9597 recall_train:0.9830 F1_train:0.9712 AUC_train:0.9925\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9527\n",
      "Epoch:0097\n",
      "acc_train:0.9725 pre_train:0.9643 recall_train:0.9830 F1_train:0.9736 AUC_train:0.9924\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9525\n",
      "Epoch:0098\n",
      "acc_train:0.9688 pre_train:0.9469 recall_train:0.9951 F1_train:0.9704 AUC_train:0.9892\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9550\n",
      "Epoch:0099\n",
      "acc_train:0.9700 pre_train:0.9554 recall_train:0.9879 F1_train:0.9714 AUC_train:0.9900\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9550\n",
      "Epoch:0100\n",
      "acc_train:0.9700 pre_train:0.9663 recall_train:0.9757 F1_train:0.9710 AUC_train:0.9954\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9565\n",
      "Epoch:0101\n",
      "acc_train:0.9750 pre_train:0.9645 recall_train:0.9879 F1_train:0.9760 AUC_train:0.9937\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9560\n",
      "Epoch:0102\n",
      "acc_train:0.9688 pre_train:0.9618 recall_train:0.9782 F1_train:0.9699 AUC_train:0.9950\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9575\n",
      "Epoch:0103\n",
      "acc_train:0.9787 pre_train:0.9759 recall_train:0.9830 F1_train:0.9794 AUC_train:0.9949\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9570\n",
      "Epoch:0104\n",
      "acc_train:0.9712 pre_train:0.9598 recall_train:0.9854 F1_train:0.9725 AUC_train:0.9911\n",
      "acc_val:0.8315 pre_val:0.7627 recall_val:0.9783 F1_val:0.857143 AUC_val:0.9578\n",
      "Epoch:0105\n",
      "acc_train:0.9700 pre_train:0.9597 recall_train:0.9830 F1_train:0.9712 AUC_train:0.9938\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9578\n",
      "Epoch:0106\n",
      "acc_train:0.9663 pre_train:0.9594 recall_train:0.9757 F1_train:0.9675 AUC_train:0.9940\n",
      "acc_val:0.8090 pre_val:0.7302 recall_val:1.0000 F1_val:0.844037 AUC_val:0.9580\n",
      "Epoch:0107\n",
      "acc_train:0.9725 pre_train:0.9577 recall_train:0.9903 F1_train:0.9737 AUC_train:0.9958\n",
      "acc_val:0.7978 pre_val:0.7188 recall_val:1.0000 F1_val:0.836364 AUC_val:0.9578\n",
      "Epoch:0108\n",
      "acc_train:0.9750 pre_train:0.9579 recall_train:0.9951 F1_train:0.9762 AUC_train:0.9963\n",
      "acc_val:0.8090 pre_val:0.7302 recall_val:1.0000 F1_val:0.844037 AUC_val:0.9573\n",
      "Epoch:0109\n",
      "acc_train:0.9700 pre_train:0.9597 recall_train:0.9830 F1_train:0.9712 AUC_train:0.9941\n",
      "acc_val:0.8090 pre_val:0.7302 recall_val:1.0000 F1_val:0.844037 AUC_val:0.9585\n",
      "Epoch:0110\n",
      "acc_train:0.9787 pre_train:0.9669 recall_train:0.9927 F1_train:0.9796 AUC_train:0.9968\n",
      "acc_val:0.8090 pre_val:0.7302 recall_val:1.0000 F1_val:0.844037 AUC_val:0.9575\n",
      "Epoch:0111\n",
      "acc_train:0.9750 pre_train:0.9689 recall_train:0.9830 F1_train:0.9759 AUC_train:0.9943\n",
      "acc_val:0.8090 pre_val:0.7302 recall_val:1.0000 F1_val:0.844037 AUC_val:0.9573\n",
      "Epoch:0112\n",
      "acc_train:0.9725 pre_train:0.9643 recall_train:0.9830 F1_train:0.9736 AUC_train:0.9934\n",
      "acc_val:0.8090 pre_val:0.7302 recall_val:1.0000 F1_val:0.844037 AUC_val:0.9548\n",
      "Epoch:0113\n",
      "acc_train:0.9762 pre_train:0.9624 recall_train:0.9927 F1_train:0.9773 AUC_train:0.9910\n",
      "acc_val:0.7978 pre_val:0.7188 recall_val:1.0000 F1_val:0.836364 AUC_val:0.9512\n",
      "Epoch:0114\n",
      "acc_train:0.9762 pre_train:0.9667 recall_train:0.9879 F1_train:0.9772 AUC_train:0.9983\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9497\n",
      "Epoch:0115\n",
      "acc_train:0.9787 pre_train:0.9647 recall_train:0.9951 F1_train:0.9797 AUC_train:0.9967\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9482\n",
      "Epoch:0116\n",
      "acc_train:0.9737 pre_train:0.9688 recall_train:0.9806 F1_train:0.9747 AUC_train:0.9954\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9497\n",
      "Epoch:0117\n",
      "acc_train:0.9737 pre_train:0.9600 recall_train:0.9903 F1_train:0.9749 AUC_train:0.9960\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9489\n",
      "Epoch:0118\n",
      "acc_train:0.9787 pre_train:0.9691 recall_train:0.9903 F1_train:0.9796 AUC_train:0.9935\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9487\n",
      "Epoch:0119\n",
      "acc_train:0.9712 pre_train:0.9642 recall_train:0.9806 F1_train:0.9723 AUC_train:0.9948\n",
      "acc_val:0.7978 pre_val:0.7188 recall_val:1.0000 F1_val:0.836364 AUC_val:0.9457\n",
      "Epoch:0120\n",
      "acc_train:0.9800 pre_train:0.9714 recall_train:0.9903 F1_train:0.9808 AUC_train:0.9936\n",
      "acc_val:0.8202 pre_val:0.7419 recall_val:1.0000 F1_val:0.851852 AUC_val:0.9446\n",
      "Epoch:0121\n",
      "acc_train:0.9850 pre_train:0.9785 recall_train:0.9927 F1_train:0.9855 AUC_train:0.9967\n",
      "acc_val:0.8202 pre_val:0.7500 recall_val:0.9783 F1_val:0.849057 AUC_val:0.9472\n",
      "Early Stopping!!! epoch：120\n",
      "Loading the Model for the 1-th Fold:... ... Size of samples in the test set:223\n",
      "Fold 1 Results: test acc:0.6592 test_pre:0.6242 test_recall:0.8522 test_F1:0.7206 test_AUC:0.7548 time:446.325s\n",
      "Size of the 2-fold Training, Validation, and Test Sets:800,89,223\n",
      " Starting the 2-1 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4288 pre_train:0.4555 recall_train:0.5448 F1_train:0.4961 AUC_train:0.4011\n",
      "acc_val:0.5506 pre_val:0.6923 recall_val:0.2000 F1_val:0.310345 AUC_val:0.4177\n",
      "Epoch:0002\n",
      "acc_train:0.4900 pre_train:0.5061 recall_train:0.4988 F1_train:0.5024 AUC_train:0.4545\n",
      "acc_val:0.4831 pre_val:0.4815 recall_val:0.2889 F1_val:0.361111 AUC_val:0.4561\n",
      "Epoch:0003\n",
      "acc_train:0.4812 pre_train:0.4975 recall_train:0.4746 F1_train:0.4857 AUC_train:0.4887\n",
      "acc_val:0.5056 pre_val:0.5128 recall_val:0.4444 F1_val:0.476190 AUC_val:0.4889\n",
      "Epoch:0004\n",
      "acc_train:0.5213 pre_train:0.5393 recall_train:0.4988 F1_train:0.5182 AUC_train:0.4993\n",
      "acc_val:0.5506 pre_val:0.5610 recall_val:0.5111 F1_val:0.534884 AUC_val:0.5520\n",
      "Epoch:0005\n",
      "acc_train:0.5113 pre_train:0.5281 recall_train:0.5012 F1_train:0.5143 AUC_train:0.4946\n",
      "acc_val:0.5169 pre_val:0.5192 recall_val:0.6000 F1_val:0.556701 AUC_val:0.5778\n",
      "Epoch:0006\n",
      "acc_train:0.5000 pre_train:0.5174 recall_train:0.4673 F1_train:0.4911 AUC_train:0.4969\n",
      "acc_val:0.5169 pre_val:0.5156 recall_val:0.7333 F1_val:0.605505 AUC_val:0.6177\n",
      "Epoch:0007\n",
      "acc_train:0.5525 pre_train:0.5659 recall_train:0.5714 F1_train:0.5687 AUC_train:0.5525\n",
      "acc_val:0.5056 pre_val:0.5079 recall_val:0.7111 F1_val:0.592593 AUC_val:0.6394\n",
      "Epoch:0008\n",
      "acc_train:0.5750 pre_train:0.5859 recall_train:0.6029 F1_train:0.5943 AUC_train:0.5849\n",
      "acc_val:0.5281 pre_val:0.5231 recall_val:0.7556 F1_val:0.618182 AUC_val:0.6510\n",
      "Epoch:0009\n",
      "acc_train:0.5500 pre_train:0.5642 recall_train:0.5642 F1_train:0.5642 AUC_train:0.5806\n",
      "acc_val:0.5281 pre_val:0.5231 recall_val:0.7556 F1_val:0.618182 AUC_val:0.6530\n",
      "Epoch:0010\n",
      "acc_train:0.5863 pre_train:0.5976 recall_train:0.6077 F1_train:0.6026 AUC_train:0.6080\n",
      "acc_val:0.5169 pre_val:0.5152 recall_val:0.7556 F1_val:0.612613 AUC_val:0.6515\n",
      "Epoch:0011\n",
      "acc_train:0.5350 pre_train:0.5519 recall_train:0.5278 F1_train:0.5396 AUC_train:0.5546\n",
      "acc_val:0.5169 pre_val:0.5152 recall_val:0.7556 F1_val:0.612613 AUC_val:0.6500\n",
      "Epoch:0012\n",
      "acc_train:0.5362 pre_train:0.5451 recall_train:0.6150 F1_train:0.5779 AUC_train:0.5582\n",
      "acc_val:0.5169 pre_val:0.5147 recall_val:0.7778 F1_val:0.619469 AUC_val:0.6596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0013\n",
      "acc_train:0.5813 pre_train:0.5911 recall_train:0.6126 F1_train:0.6017 AUC_train:0.5796\n",
      "acc_val:0.5056 pre_val:0.5075 recall_val:0.7556 F1_val:0.607143 AUC_val:0.6485\n",
      "Epoch:0014\n",
      "acc_train:0.6037 pre_train:0.6116 recall_train:0.6368 F1_train:0.6240 AUC_train:0.5923\n",
      "acc_val:0.5056 pre_val:0.5077 recall_val:0.7333 F1_val:0.600000 AUC_val:0.6576\n",
      "Epoch:0015\n",
      "acc_train:0.5412 pre_train:0.5477 recall_train:0.6392 F1_train:0.5899 AUC_train:0.5597\n",
      "acc_val:0.4944 pre_val:0.5000 recall_val:0.7333 F1_val:0.594595 AUC_val:0.6540\n",
      "Epoch:0016\n",
      "acc_train:0.5425 pre_train:0.5592 recall_train:0.5375 F1_train:0.5481 AUC_train:0.5529\n",
      "acc_val:0.4944 pre_val:0.5000 recall_val:0.7111 F1_val:0.587156 AUC_val:0.6460\n",
      "Epoch:0017\n",
      "acc_train:0.5475 pre_train:0.5617 recall_train:0.5617 F1_train:0.5617 AUC_train:0.5639\n",
      "acc_val:0.4944 pre_val:0.5000 recall_val:0.7111 F1_val:0.587156 AUC_val:0.6399\n",
      "Epoch:0018\n",
      "acc_train:0.5825 pre_train:0.5929 recall_train:0.6102 F1_train:0.6014 AUC_train:0.5920\n",
      "acc_val:0.5281 pre_val:0.5246 recall_val:0.7111 F1_val:0.603774 AUC_val:0.6323\n",
      "Epoch:0019\n",
      "acc_train:0.5975 pre_train:0.6112 recall_train:0.6053 F1_train:0.6083 AUC_train:0.6254\n",
      "acc_val:0.5506 pre_val:0.5424 recall_val:0.7111 F1_val:0.615385 AUC_val:0.6323\n",
      "Epoch:0020\n",
      "acc_train:0.6450 pre_train:0.6903 recall_train:0.5666 F1_train:0.6223 AUC_train:0.6546\n",
      "acc_val:0.6292 pre_val:0.6304 recall_val:0.6444 F1_val:0.637363 AUC_val:0.6601\n",
      "Epoch:0021\n",
      "acc_train:0.6062 pre_train:0.6283 recall_train:0.5811 F1_train:0.6038 AUC_train:0.6107\n",
      "acc_val:0.6629 pre_val:0.6829 recall_val:0.6222 F1_val:0.651163 AUC_val:0.6667\n",
      "Epoch:0022\n",
      "acc_train:0.6050 pre_train:0.6273 recall_train:0.5787 F1_train:0.6020 AUC_train:0.6395\n",
      "acc_val:0.6742 pre_val:0.6905 recall_val:0.6444 F1_val:0.666667 AUC_val:0.6828\n",
      "Epoch:0023\n",
      "acc_train:0.6062 pre_train:0.6561 recall_train:0.4988 F1_train:0.5667 AUC_train:0.6114\n",
      "acc_val:0.6966 pre_val:0.7368 recall_val:0.6222 F1_val:0.674699 AUC_val:0.6763\n",
      "Epoch:0024\n",
      "acc_train:0.6000 pre_train:0.6310 recall_train:0.5424 F1_train:0.5833 AUC_train:0.6103\n",
      "acc_val:0.6854 pre_val:0.7179 recall_val:0.6222 F1_val:0.666667 AUC_val:0.6808\n",
      "Epoch:0025\n",
      "acc_train:0.6413 pre_train:0.6853 recall_train:0.5642 F1_train:0.6189 AUC_train:0.6516\n",
      "acc_val:0.5843 pre_val:0.5800 recall_val:0.6444 F1_val:0.610526 AUC_val:0.6465\n",
      "Epoch:0026\n",
      "acc_train:0.6325 pre_train:0.6514 recall_train:0.6199 F1_train:0.6352 AUC_train:0.6589\n",
      "acc_val:0.6067 pre_val:0.6087 recall_val:0.6222 F1_val:0.615385 AUC_val:0.6535\n",
      "Epoch:0027\n",
      "acc_train:0.5850 pre_train:0.5886 recall_train:0.6513 F1_train:0.6184 AUC_train:0.6322\n",
      "acc_val:0.7303 pre_val:0.7838 recall_val:0.6444 F1_val:0.707317 AUC_val:0.7091\n",
      "Epoch:0028\n",
      "acc_train:0.6450 pre_train:0.6702 recall_train:0.6150 F1_train:0.6414 AUC_train:0.6815\n",
      "acc_val:0.7303 pre_val:0.7838 recall_val:0.6444 F1_val:0.707317 AUC_val:0.7197\n",
      "Epoch:0029\n",
      "acc_train:0.6200 pre_train:0.6453 recall_train:0.5860 F1_train:0.6142 AUC_train:0.6440\n",
      "acc_val:0.7303 pre_val:0.7838 recall_val:0.6444 F1_val:0.707317 AUC_val:0.7258\n",
      "Epoch:0030\n",
      "acc_train:0.5987 pre_train:0.5935 recall_train:0.7070 F1_train:0.6453 AUC_train:0.6397\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.7520\n",
      "Epoch:0031\n",
      "acc_train:0.6162 pre_train:0.6345 recall_train:0.6053 F1_train:0.6196 AUC_train:0.6180\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.7561\n",
      "Epoch:0032\n",
      "acc_train:0.5888 pre_train:0.5886 recall_train:0.6755 F1_train:0.6291 AUC_train:0.6065\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.7601\n",
      "Epoch:0033\n",
      "acc_train:0.6500 pre_train:0.6736 recall_train:0.6247 F1_train:0.6482 AUC_train:0.6843\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.7646\n",
      "Epoch:0034\n",
      "acc_train:0.6562 pre_train:0.6855 recall_train:0.6174 F1_train:0.6497 AUC_train:0.6891\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.7848\n",
      "Epoch:0035\n",
      "acc_train:0.5987 pre_train:0.6122 recall_train:0.6077 F1_train:0.6100 AUC_train:0.6293\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.7960\n",
      "Epoch:0036\n",
      "acc_train:0.6338 pre_train:0.6554 recall_train:0.6126 F1_train:0.6333 AUC_train:0.6665\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.8172\n",
      "Epoch:0037\n",
      "acc_train:0.6263 pre_train:0.6477 recall_train:0.6053 F1_train:0.6258 AUC_train:0.6710\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.8258\n",
      "Epoch:0038\n",
      "acc_train:0.6375 pre_train:0.6704 recall_train:0.5860 F1_train:0.6253 AUC_train:0.6604\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.8293\n",
      "Epoch:0039\n",
      "acc_train:0.6112 pre_train:0.6238 recall_train:0.6223 F1_train:0.6230 AUC_train:0.6501\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.8298\n",
      "Epoch:0040\n",
      "acc_train:0.6037 pre_train:0.6182 recall_train:0.6077 F1_train:0.6129 AUC_train:0.6321\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.8359\n",
      "Epoch:0041\n",
      "acc_train:0.6513 pre_train:0.6925 recall_train:0.5835 F1_train:0.6334 AUC_train:0.6815\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.8359\n",
      "Epoch:0042\n",
      "acc_train:0.6363 pre_train:0.6525 recall_train:0.6320 F1_train:0.6421 AUC_train:0.6794\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.8369\n",
      "Epoch:0043\n",
      "acc_train:0.6200 pre_train:0.6380 recall_train:0.6102 F1_train:0.6238 AUC_train:0.6780\n",
      "acc_val:0.7640 pre_val:0.8000 recall_val:0.7111 F1_val:0.752941 AUC_val:0.8449\n",
      "Epoch:0044\n",
      "acc_train:0.6275 pre_train:0.6517 recall_train:0.5981 F1_train:0.6237 AUC_train:0.6587\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.8465\n",
      "Epoch:0045\n",
      "acc_train:0.6562 pre_train:0.6816 recall_train:0.6271 F1_train:0.6532 AUC_train:0.6942\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.8490\n",
      "Epoch:0046\n",
      "acc_train:0.6450 pre_train:0.6625 recall_train:0.6368 F1_train:0.6494 AUC_train:0.7032\n",
      "acc_val:0.7528 pre_val:0.8108 recall_val:0.6667 F1_val:0.731707 AUC_val:0.8535\n",
      "Epoch:0047\n",
      "acc_train:0.6513 pre_train:0.6626 recall_train:0.6610 F1_train:0.6618 AUC_train:0.7026\n",
      "acc_val:0.7528 pre_val:0.8108 recall_val:0.6667 F1_val:0.731707 AUC_val:0.8530\n",
      "Epoch:0048\n",
      "acc_train:0.6200 pre_train:0.6203 recall_train:0.6804 F1_train:0.6490 AUC_train:0.6836\n",
      "acc_val:0.7416 pre_val:0.7895 recall_val:0.6667 F1_val:0.722892 AUC_val:0.8571\n",
      "Epoch:0049\n",
      "acc_train:0.6212 pre_train:0.6291 recall_train:0.6489 F1_train:0.6389 AUC_train:0.6799\n",
      "acc_val:0.7191 pre_val:0.7778 recall_val:0.6222 F1_val:0.691358 AUC_val:0.8596\n",
      "Epoch:0050\n",
      "acc_train:0.6250 pre_train:0.6089 recall_train:0.7651 F1_train:0.6781 AUC_train:0.7006\n",
      "acc_val:0.7303 pre_val:0.7442 recall_val:0.7111 F1_val:0.727273 AUC_val:0.8540\n",
      "Epoch:0051\n",
      "acc_train:0.6325 pre_train:0.6319 recall_train:0.6901 F1_train:0.6597 AUC_train:0.6763\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8551\n",
      "Epoch:0052\n",
      "acc_train:0.6712 pre_train:0.7083 recall_train:0.6174 F1_train:0.6598 AUC_train:0.7345\n",
      "acc_val:0.7416 pre_val:0.7500 recall_val:0.7333 F1_val:0.741573 AUC_val:0.8581\n",
      "Epoch:0053\n",
      "acc_train:0.6625 pre_train:0.6857 recall_train:0.6392 F1_train:0.6617 AUC_train:0.7300\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.8641\n",
      "Epoch:0054\n",
      "acc_train:0.6513 pre_train:0.6551 recall_train:0.6852 F1_train:0.6698 AUC_train:0.6970\n",
      "acc_val:0.7416 pre_val:0.7292 recall_val:0.7778 F1_val:0.752688 AUC_val:0.8707\n",
      "Epoch:0055\n",
      "acc_train:0.6575 pre_train:0.6787 recall_train:0.6392 F1_train:0.6584 AUC_train:0.7279\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.8803\n",
      "Epoch:0056\n",
      "acc_train:0.6625 pre_train:0.6682 recall_train:0.6877 F1_train:0.6778 AUC_train:0.7333\n",
      "acc_val:0.7640 pre_val:0.7500 recall_val:0.8000 F1_val:0.774194 AUC_val:0.8838\n",
      "Epoch:0057\n",
      "acc_train:0.6425 pre_train:0.6658 recall_train:0.6174 F1_train:0.6407 AUC_train:0.7108\n",
      "acc_val:0.7640 pre_val:0.7500 recall_val:0.8000 F1_val:0.774194 AUC_val:0.8904\n",
      "Epoch:0058\n",
      "acc_train:0.6762 pre_train:0.6808 recall_train:0.7022 F1_train:0.6913 AUC_train:0.7447\n",
      "acc_val:0.7753 pre_val:0.7551 recall_val:0.8222 F1_val:0.787234 AUC_val:0.8919\n",
      "Epoch:0059\n",
      "acc_train:0.6538 pre_train:0.6910 recall_train:0.5956 F1_train:0.6398 AUC_train:0.7329\n",
      "acc_val:0.7753 pre_val:0.7660 recall_val:0.8000 F1_val:0.782609 AUC_val:0.8955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0060\n",
      "acc_train:0.6562 pre_train:0.7091 recall_train:0.5666 F1_train:0.6299 AUC_train:0.7092\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8965\n",
      "Epoch:0061\n",
      "acc_train:0.6538 pre_train:0.6818 recall_train:0.6174 F1_train:0.6480 AUC_train:0.7459\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8960\n",
      "Epoch:0062\n",
      "acc_train:0.6862 pre_train:0.7189 recall_train:0.6441 F1_train:0.6794 AUC_train:0.7775\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8975\n",
      "Epoch:0063\n",
      "acc_train:0.6825 pre_train:0.7252 recall_train:0.6199 F1_train:0.6684 AUC_train:0.7724\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.9010\n",
      "Epoch:0064\n",
      "acc_train:0.6750 pre_train:0.6917 recall_train:0.6683 F1_train:0.6798 AUC_train:0.7609\n",
      "acc_val:0.7865 pre_val:0.7826 recall_val:0.8000 F1_val:0.791209 AUC_val:0.9045\n",
      "Epoch:0065\n",
      "acc_train:0.7038 pre_train:0.7126 recall_train:0.7143 F1_train:0.7134 AUC_train:0.7896\n",
      "acc_val:0.7978 pre_val:0.8000 recall_val:0.8000 F1_val:0.800000 AUC_val:0.9071\n",
      "Epoch:0066\n",
      "acc_train:0.7038 pre_train:0.7211 recall_train:0.6949 F1_train:0.7078 AUC_train:0.7909\n",
      "acc_val:0.7978 pre_val:0.8000 recall_val:0.8000 F1_val:0.800000 AUC_val:0.9071\n",
      "Epoch:0067\n",
      "acc_train:0.6775 pre_train:0.7112 recall_train:0.6320 F1_train:0.6692 AUC_train:0.7680\n",
      "acc_val:0.7978 pre_val:0.8000 recall_val:0.8000 F1_val:0.800000 AUC_val:0.9086\n",
      "Epoch:0068\n",
      "acc_train:0.6950 pre_train:0.7421 recall_train:0.6271 F1_train:0.6798 AUC_train:0.7795\n",
      "acc_val:0.7978 pre_val:0.8000 recall_val:0.8000 F1_val:0.800000 AUC_val:0.9101\n",
      "Epoch:0069\n",
      "acc_train:0.7150 pre_train:0.7295 recall_train:0.7119 F1_train:0.7206 AUC_train:0.8169\n",
      "acc_val:0.8090 pre_val:0.8182 recall_val:0.8000 F1_val:0.808989 AUC_val:0.9116\n",
      "Epoch:0070\n",
      "acc_train:0.7225 pre_train:0.7312 recall_train:0.7312 F1_train:0.7312 AUC_train:0.8184\n",
      "acc_val:0.7978 pre_val:0.8140 recall_val:0.7778 F1_val:0.795455 AUC_val:0.9126\n",
      "Epoch:0071\n",
      "acc_train:0.7400 pre_train:0.7233 recall_train:0.8039 F1_train:0.7615 AUC_train:0.8115\n",
      "acc_val:0.7865 pre_val:0.7826 recall_val:0.8000 F1_val:0.791209 AUC_val:0.9172\n",
      "Epoch:0072\n",
      "acc_train:0.7312 pre_train:0.7475 recall_train:0.7240 F1_train:0.7355 AUC_train:0.8238\n",
      "acc_val:0.7978 pre_val:0.7872 recall_val:0.8222 F1_val:0.804348 AUC_val:0.9182\n",
      "Epoch:0073\n",
      "acc_train:0.7538 pre_train:0.7488 recall_train:0.7869 F1_train:0.7674 AUC_train:0.8269\n",
      "acc_val:0.7978 pre_val:0.7872 recall_val:0.8222 F1_val:0.804348 AUC_val:0.9192\n",
      "Epoch:0074\n",
      "acc_train:0.7738 pre_train:0.7710 recall_train:0.7990 F1_train:0.7848 AUC_train:0.8501\n",
      "acc_val:0.7978 pre_val:0.7872 recall_val:0.8222 F1_val:0.804348 AUC_val:0.9202\n",
      "Epoch:0075\n",
      "acc_train:0.7800 pre_train:0.7582 recall_train:0.8426 F1_train:0.7982 AUC_train:0.8509\n",
      "acc_val:0.7978 pre_val:0.8293 recall_val:0.7556 F1_val:0.790698 AUC_val:0.9217\n",
      "Epoch:0076\n",
      "acc_train:0.7925 pre_train:0.7738 recall_train:0.8450 F1_train:0.8079 AUC_train:0.8602\n",
      "acc_val:0.7978 pre_val:0.8293 recall_val:0.7556 F1_val:0.790698 AUC_val:0.9217\n",
      "Epoch:0077\n",
      "acc_train:0.7600 pre_train:0.7715 recall_train:0.7603 F1_train:0.7659 AUC_train:0.8449\n",
      "acc_val:0.7978 pre_val:0.8293 recall_val:0.7556 F1_val:0.790698 AUC_val:0.9247\n",
      "Epoch:0078\n",
      "acc_train:0.7550 pre_train:0.7679 recall_train:0.7530 F1_train:0.7604 AUC_train:0.8429\n",
      "acc_val:0.7978 pre_val:0.8293 recall_val:0.7556 F1_val:0.790698 AUC_val:0.9258\n",
      "Epoch:0079\n",
      "acc_train:0.7350 pre_train:0.7815 recall_train:0.6755 F1_train:0.7247 AUC_train:0.8637\n",
      "acc_val:0.7978 pre_val:0.8293 recall_val:0.7556 F1_val:0.790698 AUC_val:0.9268\n",
      "Epoch:0080\n",
      "acc_train:0.7300 pre_train:0.7839 recall_train:0.6586 F1_train:0.7158 AUC_train:0.8642\n",
      "acc_val:0.7978 pre_val:0.8293 recall_val:0.7556 F1_val:0.790698 AUC_val:0.9288\n",
      "Epoch:0081\n",
      "acc_train:0.8012 pre_train:0.7900 recall_train:0.8378 F1_train:0.8132 AUC_train:0.8669\n",
      "acc_val:0.8090 pre_val:0.8182 recall_val:0.8000 F1_val:0.808989 AUC_val:0.9313\n",
      "Epoch:0082\n",
      "acc_train:0.7887 pre_train:0.7919 recall_train:0.8015 F1_train:0.7966 AUC_train:0.8686\n",
      "acc_val:0.8315 pre_val:0.8125 recall_val:0.8667 F1_val:0.838710 AUC_val:0.9303\n",
      "Epoch:0083\n",
      "acc_train:0.8213 pre_train:0.8184 recall_train:0.8402 F1_train:0.8292 AUC_train:0.8872\n",
      "acc_val:0.8427 pre_val:0.8298 recall_val:0.8667 F1_val:0.847826 AUC_val:0.9343\n",
      "Epoch:0084\n",
      "acc_train:0.8525 pre_train:0.8360 recall_train:0.8886 F1_train:0.8615 AUC_train:0.9039\n",
      "acc_val:0.8427 pre_val:0.8039 recall_val:0.9111 F1_val:0.854167 AUC_val:0.9399\n",
      "Epoch:0085\n",
      "acc_train:0.8250 pre_train:0.8289 recall_train:0.8329 F1_train:0.8309 AUC_train:0.8959\n",
      "acc_val:0.8427 pre_val:0.8039 recall_val:0.9111 F1_val:0.854167 AUC_val:0.9429\n",
      "Epoch:0086\n",
      "acc_train:0.8450 pre_train:0.8148 recall_train:0.9056 F1_train:0.8578 AUC_train:0.9072\n",
      "acc_val:0.8427 pre_val:0.7925 recall_val:0.9333 F1_val:0.857143 AUC_val:0.9414\n",
      "Epoch:0087\n",
      "acc_train:0.8450 pre_train:0.8029 recall_train:0.9274 F1_train:0.8607 AUC_train:0.9148\n",
      "acc_val:0.8315 pre_val:0.7778 recall_val:0.9333 F1_val:0.848485 AUC_val:0.9470\n",
      "Epoch:0088\n",
      "acc_train:0.8650 pre_train:0.8266 recall_train:0.9346 F1_train:0.8773 AUC_train:0.9273\n",
      "acc_val:0.8652 pre_val:0.8235 recall_val:0.9333 F1_val:0.875000 AUC_val:0.9399\n",
      "Epoch:0089\n",
      "acc_train:0.8487 pre_train:0.8147 recall_train:0.9153 F1_train:0.8620 AUC_train:0.9008\n",
      "acc_val:0.8652 pre_val:0.8235 recall_val:0.9333 F1_val:0.875000 AUC_val:0.9409\n",
      "Epoch:0090\n",
      "acc_train:0.8675 pre_train:0.8449 recall_train:0.9104 F1_train:0.8765 AUC_train:0.9140\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9434\n",
      "Epoch:0091\n",
      "acc_train:0.8612 pre_train:0.8120 recall_train:0.9516 F1_train:0.8763 AUC_train:0.9092\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9460\n",
      "Epoch:0092\n",
      "acc_train:0.8800 pre_train:0.8546 recall_train:0.9249 F1_train:0.8884 AUC_train:0.9297\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9465\n",
      "Epoch:0093\n",
      "acc_train:0.8737 pre_train:0.8377 recall_train:0.9370 F1_train:0.8846 AUC_train:0.9213\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9500\n",
      "Epoch:0094\n",
      "acc_train:0.8562 pre_train:0.8157 recall_train:0.9322 F1_train:0.8701 AUC_train:0.9153\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9540\n",
      "Epoch:0095\n",
      "acc_train:0.8900 pre_train:0.8465 recall_train:0.9613 F1_train:0.9002 AUC_train:0.9344\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9523\n",
      "Epoch:0096\n",
      "acc_train:0.8963 pre_train:0.8526 recall_train:0.9661 F1_train:0.9058 AUC_train:0.9359\n",
      "acc_val:0.8876 pre_val:0.8302 recall_val:0.9778 F1_val:0.897959 AUC_val:0.9500\n",
      "Epoch:0097\n",
      "acc_train:0.8763 pre_train:0.8285 recall_train:0.9588 F1_train:0.8889 AUC_train:0.9298\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9561\n",
      "Epoch:0098\n",
      "acc_train:0.8988 pre_train:0.8562 recall_train:0.9661 F1_train:0.9078 AUC_train:0.9420\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9566\n",
      "Epoch:0099\n",
      "acc_train:0.8913 pre_train:0.8453 recall_train:0.9661 F1_train:0.9017 AUC_train:0.9468\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9571\n",
      "Epoch:0100\n",
      "acc_train:0.9150 pre_train:0.8791 recall_train:0.9685 F1_train:0.9217 AUC_train:0.9522\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9556\n",
      "Epoch:0101\n",
      "acc_train:0.9112 pre_train:0.8670 recall_train:0.9782 F1_train:0.9192 AUC_train:0.9581\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9596\n",
      "Epoch:0102\n",
      "acc_train:0.9212 pre_train:0.8889 recall_train:0.9685 F1_train:0.9270 AUC_train:0.9536\n",
      "acc_val:0.8876 pre_val:0.8302 recall_val:0.9778 F1_val:0.897959 AUC_val:0.9561\n",
      "Epoch:0103\n",
      "acc_train:0.8975 pre_train:0.8590 recall_train:0.9588 F1_train:0.9062 AUC_train:0.9498\n",
      "acc_val:0.8876 pre_val:0.8302 recall_val:0.9778 F1_val:0.897959 AUC_val:0.9540\n",
      "Epoch:0104\n",
      "acc_train:0.9050 pre_train:0.8770 recall_train:0.9492 F1_train:0.9116 AUC_train:0.9524\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9535\n",
      "Epoch:0105\n",
      "acc_train:0.9087 pre_train:0.8744 recall_train:0.9613 F1_train:0.9158 AUC_train:0.9549\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9581\n",
      "Epoch:0106\n",
      "acc_train:0.9187 pre_train:0.8884 recall_train:0.9637 F1_train:0.9245 AUC_train:0.9564\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0107\n",
      "acc_train:0.9100 pre_train:0.8683 recall_train:0.9734 F1_train:0.9178 AUC_train:0.9484\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9614\n",
      "Epoch:0108\n",
      "acc_train:0.9300 pre_train:0.9029 recall_train:0.9685 F1_train:0.9346 AUC_train:0.9620\n",
      "acc_val:0.9101 pre_val:0.8627 recall_val:0.9778 F1_val:0.916667 AUC_val:0.9606\n",
      "Epoch:0109\n",
      "acc_train:0.9287 pre_train:0.8938 recall_train:0.9782 F1_train:0.9341 AUC_train:0.9581\n",
      "acc_val:0.8876 pre_val:0.8431 recall_val:0.9556 F1_val:0.895833 AUC_val:0.9545\n",
      "Epoch:0110\n",
      "acc_train:0.9175 pre_train:0.8970 recall_train:0.9492 F1_train:0.9224 AUC_train:0.9579\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9520\n",
      "Epoch:0111\n",
      "acc_train:0.8975 pre_train:0.8575 recall_train:0.9613 F1_train:0.9064 AUC_train:0.9474\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9551\n",
      "Epoch:0112\n",
      "acc_train:0.9262 pre_train:0.8933 recall_train:0.9734 F1_train:0.9316 AUC_train:0.9645\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9545\n",
      "Epoch:0113\n",
      "acc_train:0.9400 pre_train:0.9011 recall_train:0.9927 F1_train:0.9447 AUC_train:0.9690\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9573\n",
      "Epoch:0114\n",
      "acc_train:0.9100 pre_train:0.8651 recall_train:0.9782 F1_train:0.9182 AUC_train:0.9683\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9573\n",
      "Epoch:0115\n",
      "acc_train:0.9300 pre_train:0.8906 recall_train:0.9855 F1_train:0.9356 AUC_train:0.9660\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9530\n",
      "Epoch:0116\n",
      "acc_train:0.9287 pre_train:0.9009 recall_train:0.9685 F1_train:0.9335 AUC_train:0.9591\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9455\n",
      "Epoch:0117\n",
      "acc_train:0.9187 pre_train:0.8766 recall_train:0.9806 F1_train:0.9257 AUC_train:0.9694\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9490\n",
      "Epoch:0118\n",
      "acc_train:0.9112 pre_train:0.8800 recall_train:0.9588 F1_train:0.9177 AUC_train:0.9559\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9540\n",
      "Epoch:0119\n",
      "acc_train:0.9262 pre_train:0.8933 recall_train:0.9734 F1_train:0.9316 AUC_train:0.9673\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9508\n",
      "Epoch:0120\n",
      "acc_train:0.9350 pre_train:0.8985 recall_train:0.9855 F1_train:0.9400 AUC_train:0.9729\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9508\n",
      "Epoch:0121\n",
      "acc_train:0.9425 pre_train:0.9142 recall_train:0.9806 F1_train:0.9463 AUC_train:0.9803\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9508\n",
      "Epoch:0122\n",
      "acc_train:0.9337 pre_train:0.9054 recall_train:0.9734 F1_train:0.9382 AUC_train:0.9804\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9508\n",
      "Epoch:0123\n",
      "acc_train:0.9275 pre_train:0.9043 recall_train:0.9613 F1_train:0.9319 AUC_train:0.9716\n",
      "acc_val:0.8202 pre_val:0.7544 recall_val:0.9556 F1_val:0.843137 AUC_val:0.9490\n",
      "Epoch:0124\n",
      "acc_train:0.9350 pre_train:0.9074 recall_train:0.9734 F1_train:0.9393 AUC_train:0.9667\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9472\n",
      "Epoch:0125\n",
      "acc_train:0.9538 pre_train:0.9332 recall_train:0.9806 F1_train:0.9563 AUC_train:0.9777\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9515\n",
      "Epoch:0126\n",
      "acc_train:0.9450 pre_train:0.9184 recall_train:0.9806 F1_train:0.9485 AUC_train:0.9794\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9500\n",
      "Epoch:0127\n",
      "acc_train:0.9287 pre_train:0.8956 recall_train:0.9758 F1_train:0.9340 AUC_train:0.9758\n",
      "acc_val:0.8876 pre_val:0.8302 recall_val:0.9778 F1_val:0.897959 AUC_val:0.9500\n",
      "Epoch:0128\n",
      "acc_train:0.9375 pre_train:0.9172 recall_train:0.9661 F1_train:0.9410 AUC_train:0.9709\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9487\n",
      "Epoch:0129\n",
      "acc_train:0.9212 pre_train:0.8906 recall_train:0.9661 F1_train:0.9268 AUC_train:0.9681\n",
      "acc_val:0.8876 pre_val:0.8302 recall_val:0.9778 F1_val:0.897959 AUC_val:0.9449\n",
      "Epoch:0130\n",
      "acc_train:0.9425 pre_train:0.9124 recall_train:0.9831 F1_train:0.9464 AUC_train:0.9744\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9465\n",
      "Epoch:0131\n",
      "acc_train:0.9350 pre_train:0.8967 recall_train:0.9879 F1_train:0.9401 AUC_train:0.9804\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9475\n",
      "Epoch:0132\n",
      "acc_train:0.9362 pre_train:0.9095 recall_train:0.9734 F1_train:0.9404 AUC_train:0.9760\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9530\n",
      "Epoch:0133\n",
      "acc_train:0.9488 pre_train:0.9227 recall_train:0.9831 F1_train:0.9519 AUC_train:0.9731\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9548\n",
      "Epoch:0134\n",
      "acc_train:0.9563 pre_train:0.9335 recall_train:0.9855 F1_train:0.9588 AUC_train:0.9845\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9593\n",
      "Epoch:0135\n",
      "acc_train:0.9463 pre_train:0.9282 recall_train:0.9709 F1_train:0.9491 AUC_train:0.9750\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9545\n",
      "Epoch:0136\n",
      "acc_train:0.9500 pre_train:0.9191 recall_train:0.9903 F1_train:0.9534 AUC_train:0.9866\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9535\n",
      "Epoch:0137\n",
      "acc_train:0.9500 pre_train:0.9307 recall_train:0.9758 F1_train:0.9527 AUC_train:0.9814\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9561\n",
      "Epoch:0138\n",
      "acc_train:0.9613 pre_train:0.9381 recall_train:0.9903 F1_train:0.9635 AUC_train:0.9822\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9520\n",
      "Epoch:0139\n",
      "acc_train:0.9475 pre_train:0.9226 recall_train:0.9806 F1_train:0.9507 AUC_train:0.9793\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9578\n",
      "Epoch:0140\n",
      "acc_train:0.9538 pre_train:0.9292 recall_train:0.9855 F1_train:0.9565 AUC_train:0.9822\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9598\n",
      "Epoch:0141\n",
      "acc_train:0.9450 pre_train:0.9184 recall_train:0.9806 F1_train:0.9485 AUC_train:0.9813\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9609\n",
      "Epoch:0142\n",
      "acc_train:0.9588 pre_train:0.9338 recall_train:0.9903 F1_train:0.9612 AUC_train:0.9768\n",
      "acc_val:0.7753 pre_val:0.6984 recall_val:0.9778 F1_val:0.814815 AUC_val:0.9621\n",
      "Epoch:0143\n",
      "acc_train:0.9488 pre_train:0.9366 recall_train:0.9661 F1_train:0.9511 AUC_train:0.9742\n",
      "acc_val:0.7753 pre_val:0.6984 recall_val:0.9778 F1_val:0.814815 AUC_val:0.9621\n",
      "Epoch:0144\n",
      "acc_train:0.9600 pre_train:0.9420 recall_train:0.9831 F1_train:0.9621 AUC_train:0.9854\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.9606\n",
      "Epoch:0145\n",
      "acc_train:0.9563 pre_train:0.9395 recall_train:0.9782 F1_train:0.9585 AUC_train:0.9821\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9616\n",
      "Epoch:0146\n",
      "acc_train:0.9600 pre_train:0.9441 recall_train:0.9806 F1_train:0.9620 AUC_train:0.9810\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9664\n",
      "Epoch:0147\n",
      "acc_train:0.9675 pre_train:0.9490 recall_train:0.9903 F1_train:0.9692 AUC_train:0.9896\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9593\n",
      "Early Stopping!!! epoch：146\n",
      " Starting the 2-2 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4288 pre_train:0.4631 recall_train:0.6683 F1_train:0.5471 AUC_train:0.4031\n",
      "acc_val:0.3258 pre_val:0.2414 recall_val:0.1556 F1_val:0.189189 AUC_val:0.2263\n",
      "Epoch:0002\n",
      "acc_train:0.4650 pre_train:0.4863 recall_train:0.6465 F1_train:0.5551 AUC_train:0.4743\n",
      "acc_val:0.4719 pre_val:0.4444 recall_val:0.1778 F1_val:0.253968 AUC_val:0.3328\n",
      "Epoch:0003\n",
      "acc_train:0.4462 pre_train:0.4709 recall_train:0.5884 F1_train:0.5231 AUC_train:0.4473\n",
      "acc_val:0.4607 pre_val:0.3636 recall_val:0.0889 F1_val:0.142857 AUC_val:0.3071\n",
      "Epoch:0004\n",
      "acc_train:0.4575 pre_train:0.4834 recall_train:0.7385 F1_train:0.5843 AUC_train:0.4853\n",
      "acc_val:0.4607 pre_val:0.2857 recall_val:0.0444 F1_val:0.076923 AUC_val:0.2990\n",
      "Epoch:0005\n",
      "acc_train:0.4888 pre_train:0.5036 recall_train:0.6755 F1_train:0.5770 AUC_train:0.5041\n",
      "acc_val:0.3933 pre_val:0.3448 recall_val:0.2222 F1_val:0.270270 AUC_val:0.3323\n",
      "Epoch:0006\n",
      "acc_train:0.4450 pre_train:0.4766 recall_train:0.7627 F1_train:0.5866 AUC_train:0.4440\n",
      "acc_val:0.3034 pre_val:0.3396 recall_val:0.4000 F1_val:0.367347 AUC_val:0.2409\n",
      "Epoch:0007\n",
      "acc_train:0.4575 pre_train:0.4807 recall_train:0.6344 F1_train:0.5470 AUC_train:0.4733\n",
      "acc_val:0.3820 pre_val:0.4194 recall_val:0.5778 F1_val:0.485981 AUC_val:0.2591\n",
      "Epoch:0008\n",
      "acc_train:0.5213 pre_train:0.5371 recall_train:0.5254 F1_train:0.5312 AUC_train:0.5461\n",
      "acc_val:0.3820 pre_val:0.4286 recall_val:0.6667 F1_val:0.521739 AUC_val:0.3242\n",
      "Epoch:0009\n",
      "acc_train:0.5663 pre_train:0.6241 recall_train:0.4019 F1_train:0.4890 AUC_train:0.5504\n",
      "acc_val:0.5169 pre_val:0.5128 recall_val:0.8889 F1_val:0.650407 AUC_val:0.5510\n",
      "Epoch:0010\n",
      "acc_train:0.5537 pre_train:0.6647 recall_train:0.2736 F1_train:0.3877 AUC_train:0.5858\n",
      "acc_val:0.6067 pre_val:0.6087 recall_val:0.6222 F1_val:0.615385 AUC_val:0.6712\n",
      "Epoch:0011\n",
      "acc_train:0.5412 pre_train:0.5612 recall_train:0.5109 F1_train:0.5349 AUC_train:0.5583\n",
      "acc_val:0.6180 pre_val:0.5873 recall_val:0.8222 F1_val:0.685185 AUC_val:0.7126\n",
      "Epoch:0012\n",
      "acc_train:0.5562 pre_train:0.6124 recall_train:0.3826 F1_train:0.4709 AUC_train:0.5588\n",
      "acc_val:0.6742 pre_val:0.6481 recall_val:0.7778 F1_val:0.707071 AUC_val:0.7263\n",
      "Epoch:0013\n",
      "acc_train:0.5987 pre_train:0.6797 recall_train:0.4213 F1_train:0.5202 AUC_train:0.6280\n",
      "acc_val:0.6854 pre_val:0.6545 recall_val:0.8000 F1_val:0.720000 AUC_val:0.7308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0014\n",
      "acc_train:0.5913 pre_train:0.6937 recall_train:0.3729 F1_train:0.4850 AUC_train:0.6178\n",
      "acc_val:0.6966 pre_val:0.7143 recall_val:0.6667 F1_val:0.689655 AUC_val:0.7333\n",
      "Epoch:0015\n",
      "acc_train:0.5813 pre_train:0.6336 recall_train:0.4479 F1_train:0.5248 AUC_train:0.5821\n",
      "acc_val:0.6966 pre_val:0.6667 recall_val:0.8000 F1_val:0.727273 AUC_val:0.7384\n",
      "Epoch:0016\n",
      "acc_train:0.6125 pre_train:0.6678 recall_train:0.4964 F1_train:0.5694 AUC_train:0.6441\n",
      "acc_val:0.7416 pre_val:0.7619 recall_val:0.7111 F1_val:0.735632 AUC_val:0.7439\n",
      "Epoch:0017\n",
      "acc_train:0.5875 pre_train:0.6602 recall_train:0.4140 F1_train:0.5089 AUC_train:0.6170\n",
      "acc_val:0.7303 pre_val:0.7234 recall_val:0.7556 F1_val:0.739130 AUC_val:0.7475\n",
      "Epoch:0018\n",
      "acc_train:0.5650 pre_train:0.5579 recall_train:0.7579 F1_train:0.6427 AUC_train:0.6110\n",
      "acc_val:0.6854 pre_val:0.6441 recall_val:0.8444 F1_val:0.730769 AUC_val:0.7449\n",
      "Epoch:0019\n",
      "acc_train:0.6187 pre_train:0.6222 recall_train:0.6659 F1_train:0.6433 AUC_train:0.6651\n",
      "acc_val:0.6854 pre_val:0.6491 recall_val:0.8222 F1_val:0.725490 AUC_val:0.7465\n",
      "Epoch:0020\n",
      "acc_train:0.5675 pre_train:0.5612 recall_train:0.7433 F1_train:0.6396 AUC_train:0.6183\n",
      "acc_val:0.6180 pre_val:0.5797 recall_val:0.8889 F1_val:0.701754 AUC_val:0.7566\n",
      "Epoch:0021\n",
      "acc_train:0.5888 pre_train:0.5879 recall_train:0.6804 F1_train:0.6308 AUC_train:0.6193\n",
      "acc_val:0.6292 pre_val:0.5882 recall_val:0.8889 F1_val:0.707965 AUC_val:0.7606\n",
      "Epoch:0022\n",
      "acc_train:0.6187 pre_train:0.6330 recall_train:0.6223 F1_train:0.6276 AUC_train:0.6522\n",
      "acc_val:0.6742 pre_val:0.6290 recall_val:0.8667 F1_val:0.728972 AUC_val:0.7798\n",
      "Epoch:0023\n",
      "acc_train:0.6538 pre_train:0.6899 recall_train:0.5981 F1_train:0.6407 AUC_train:0.6760\n",
      "acc_val:0.6966 pre_val:0.6552 recall_val:0.8444 F1_val:0.737864 AUC_val:0.7843\n",
      "Epoch:0024\n",
      "acc_train:0.6338 pre_train:0.6829 recall_train:0.5424 F1_train:0.6046 AUC_train:0.6566\n",
      "acc_val:0.7079 pre_val:0.6667 recall_val:0.8444 F1_val:0.745098 AUC_val:0.7864\n",
      "Epoch:0025\n",
      "acc_train:0.6350 pre_train:0.6486 recall_train:0.6392 F1_train:0.6439 AUC_train:0.6657\n",
      "acc_val:0.7191 pre_val:0.6786 recall_val:0.8444 F1_val:0.752475 AUC_val:0.7848\n",
      "Epoch:0026\n",
      "acc_train:0.6162 pre_train:0.6262 recall_train:0.6368 F1_train:0.6315 AUC_train:0.6479\n",
      "acc_val:0.7528 pre_val:0.7170 recall_val:0.8444 F1_val:0.775510 AUC_val:0.7859\n",
      "Epoch:0027\n",
      "acc_train:0.6050 pre_train:0.6000 recall_train:0.7046 F1_train:0.6481 AUC_train:0.6599\n",
      "acc_val:0.7528 pre_val:0.7255 recall_val:0.8222 F1_val:0.770833 AUC_val:0.7879\n",
      "Epoch:0028\n",
      "acc_train:0.6175 pre_train:0.6375 recall_train:0.6005 F1_train:0.6185 AUC_train:0.6505\n",
      "acc_val:0.7303 pre_val:0.7234 recall_val:0.7556 F1_val:0.739130 AUC_val:0.7904\n",
      "Epoch:0029\n",
      "acc_train:0.6100 pre_train:0.6140 recall_train:0.6586 F1_train:0.6355 AUC_train:0.6470\n",
      "acc_val:0.7528 pre_val:0.7255 recall_val:0.8222 F1_val:0.770833 AUC_val:0.7929\n",
      "Epoch:0030\n",
      "acc_train:0.6012 pre_train:0.6124 recall_train:0.6199 F1_train:0.6161 AUC_train:0.6365\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.7939\n",
      "Epoch:0031\n",
      "acc_train:0.6012 pre_train:0.6049 recall_train:0.6562 F1_train:0.6295 AUC_train:0.6324\n",
      "acc_val:0.7191 pre_val:0.7174 recall_val:0.7333 F1_val:0.725275 AUC_val:0.7965\n",
      "Epoch:0032\n",
      "acc_train:0.6175 pre_train:0.6382 recall_train:0.5981 F1_train:0.6175 AUC_train:0.6486\n",
      "acc_val:0.7079 pre_val:0.7111 recall_val:0.7111 F1_val:0.711111 AUC_val:0.7970\n",
      "Epoch:0033\n",
      "acc_train:0.5738 pre_train:0.5747 recall_train:0.6707 F1_train:0.6190 AUC_train:0.6416\n",
      "acc_val:0.7191 pre_val:0.7273 recall_val:0.7111 F1_val:0.719101 AUC_val:0.7960\n",
      "Epoch:0034\n",
      "acc_train:0.5975 pre_train:0.5887 recall_train:0.7312 F1_train:0.6523 AUC_train:0.6341\n",
      "acc_val:0.7303 pre_val:0.7333 recall_val:0.7333 F1_val:0.733333 AUC_val:0.7985\n",
      "Epoch:0035\n",
      "acc_train:0.6300 pre_train:0.6339 recall_train:0.6707 F1_train:0.6518 AUC_train:0.6650\n",
      "acc_val:0.7303 pre_val:0.7442 recall_val:0.7111 F1_val:0.727273 AUC_val:0.8015\n",
      "Epoch:0036\n",
      "acc_train:0.6237 pre_train:0.6489 recall_train:0.5908 F1_train:0.6185 AUC_train:0.6585\n",
      "acc_val:0.7416 pre_val:0.7619 recall_val:0.7111 F1_val:0.735632 AUC_val:0.8040\n",
      "Epoch:0037\n",
      "acc_train:0.6212 pre_train:0.6698 recall_train:0.5254 F1_train:0.5889 AUC_train:0.6485\n",
      "acc_val:0.7528 pre_val:0.7805 recall_val:0.7111 F1_val:0.744186 AUC_val:0.8025\n",
      "Epoch:0038\n",
      "acc_train:0.6400 pre_train:0.6781 recall_train:0.5763 F1_train:0.6230 AUC_train:0.6711\n",
      "acc_val:0.7416 pre_val:0.7750 recall_val:0.6889 F1_val:0.729412 AUC_val:0.8035\n",
      "Epoch:0039\n",
      "acc_train:0.6275 pre_train:0.6542 recall_train:0.5908 F1_train:0.6209 AUC_train:0.6550\n",
      "acc_val:0.7416 pre_val:0.7750 recall_val:0.6889 F1_val:0.729412 AUC_val:0.8071\n",
      "Epoch:0040\n",
      "acc_train:0.6463 pre_train:0.6958 recall_train:0.5593 F1_train:0.6201 AUC_train:0.7054\n",
      "acc_val:0.7528 pre_val:0.7805 recall_val:0.7111 F1_val:0.744186 AUC_val:0.8061\n",
      "Epoch:0041\n",
      "acc_train:0.6600 pre_train:0.7143 recall_train:0.5690 F1_train:0.6334 AUC_train:0.6926\n",
      "acc_val:0.7416 pre_val:0.7619 recall_val:0.7111 F1_val:0.735632 AUC_val:0.8081\n",
      "Epoch:0042\n",
      "acc_train:0.6375 pre_train:0.6468 recall_train:0.6562 F1_train:0.6514 AUC_train:0.6678\n",
      "acc_val:0.7303 pre_val:0.7442 recall_val:0.7111 F1_val:0.727273 AUC_val:0.8096\n",
      "Epoch:0043\n",
      "acc_train:0.6237 pre_train:0.6564 recall_train:0.5690 F1_train:0.6096 AUC_train:0.6503\n",
      "acc_val:0.7303 pre_val:0.7442 recall_val:0.7111 F1_val:0.727273 AUC_val:0.8106\n",
      "Epoch:0044\n",
      "acc_train:0.6100 pre_train:0.6384 recall_train:0.5642 F1_train:0.5990 AUC_train:0.6708\n",
      "acc_val:0.7416 pre_val:0.7500 recall_val:0.7333 F1_val:0.741573 AUC_val:0.8157\n",
      "Epoch:0045\n",
      "acc_train:0.6313 pre_train:0.6603 recall_train:0.5884 F1_train:0.6223 AUC_train:0.6724\n",
      "acc_val:0.7416 pre_val:0.7500 recall_val:0.7333 F1_val:0.741573 AUC_val:0.8187\n",
      "Epoch:0046\n",
      "acc_train:0.6513 pre_train:0.6754 recall_train:0.6247 F1_train:0.6491 AUC_train:0.6944\n",
      "acc_val:0.7528 pre_val:0.7674 recall_val:0.7333 F1_val:0.750000 AUC_val:0.8202\n",
      "Epoch:0047\n",
      "acc_train:0.6612 pre_train:0.7006 recall_train:0.6005 F1_train:0.6467 AUC_train:0.6848\n",
      "acc_val:0.7528 pre_val:0.7674 recall_val:0.7333 F1_val:0.750000 AUC_val:0.8253\n",
      "Epoch:0048\n",
      "acc_train:0.6538 pre_train:0.6771 recall_train:0.6295 F1_train:0.6524 AUC_train:0.7003\n",
      "acc_val:0.7528 pre_val:0.7674 recall_val:0.7333 F1_val:0.750000 AUC_val:0.8258\n",
      "Epoch:0049\n",
      "acc_train:0.6438 pre_train:0.6608 recall_train:0.6368 F1_train:0.6486 AUC_train:0.7052\n",
      "acc_val:0.7528 pre_val:0.7674 recall_val:0.7333 F1_val:0.750000 AUC_val:0.8283\n",
      "Epoch:0050\n",
      "acc_train:0.6637 pre_train:0.7057 recall_train:0.5981 F1_train:0.6474 AUC_train:0.6805\n",
      "acc_val:0.7528 pre_val:0.7674 recall_val:0.7333 F1_val:0.750000 AUC_val:0.8293\n",
      "Epoch:0051\n",
      "acc_train:0.6400 pre_train:0.6685 recall_train:0.6005 F1_train:0.6327 AUC_train:0.6948\n",
      "acc_val:0.7528 pre_val:0.7674 recall_val:0.7333 F1_val:0.750000 AUC_val:0.8303\n",
      "Epoch:0052\n",
      "acc_train:0.6225 pre_train:0.6188 recall_train:0.6998 F1_train:0.6568 AUC_train:0.6849\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8354\n",
      "Epoch:0053\n",
      "acc_train:0.6338 pre_train:0.6471 recall_train:0.6392 F1_train:0.6431 AUC_train:0.6923\n",
      "acc_val:0.7416 pre_val:0.7391 recall_val:0.7556 F1_val:0.747253 AUC_val:0.8333\n",
      "Epoch:0054\n",
      "acc_train:0.6450 pre_train:0.6369 recall_train:0.7264 F1_train:0.6787 AUC_train:0.6946\n",
      "acc_val:0.7528 pre_val:0.7447 recall_val:0.7778 F1_val:0.760870 AUC_val:0.8399\n",
      "Epoch:0055\n",
      "acc_train:0.6425 pre_train:0.6414 recall_train:0.6973 F1_train:0.6682 AUC_train:0.7109\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8384\n",
      "Epoch:0056\n",
      "acc_train:0.6662 pre_train:0.6931 recall_train:0.6344 F1_train:0.6625 AUC_train:0.7223\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8424\n",
      "Epoch:0057\n",
      "acc_train:0.6637 pre_train:0.7022 recall_train:0.6053 F1_train:0.6502 AUC_train:0.7026\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8657\n",
      "Epoch:0058\n",
      "acc_train:0.6625 pre_train:0.6877 recall_train:0.6344 F1_train:0.6599 AUC_train:0.7229\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8717\n",
      "Epoch:0059\n",
      "acc_train:0.6550 pre_train:0.6846 recall_train:0.6150 F1_train:0.6480 AUC_train:0.7212\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8753\n",
      "Epoch:0060\n",
      "acc_train:0.6650 pre_train:0.6773 recall_train:0.6707 F1_train:0.6740 AUC_train:0.7346\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0061\n",
      "acc_train:0.6600 pre_train:0.6699 recall_train:0.6731 F1_train:0.6715 AUC_train:0.7136\n",
      "acc_val:0.7865 pre_val:0.7826 recall_val:0.8000 F1_val:0.791209 AUC_val:0.8843\n",
      "Epoch:0062\n",
      "acc_train:0.6825 pre_train:0.7166 recall_train:0.6368 F1_train:0.6744 AUC_train:0.7488\n",
      "acc_val:0.7865 pre_val:0.7826 recall_val:0.8000 F1_val:0.791209 AUC_val:0.8894\n",
      "Epoch:0063\n",
      "acc_train:0.6338 pre_train:0.6531 recall_train:0.6199 F1_train:0.6360 AUC_train:0.7146\n",
      "acc_val:0.7865 pre_val:0.7826 recall_val:0.8000 F1_val:0.791209 AUC_val:0.8864\n",
      "Epoch:0064\n",
      "acc_train:0.6625 pre_train:0.7037 recall_train:0.5981 F1_train:0.6466 AUC_train:0.7392\n",
      "acc_val:0.7865 pre_val:0.7826 recall_val:0.8000 F1_val:0.791209 AUC_val:0.8889\n",
      "Epoch:0065\n",
      "acc_train:0.6762 pre_train:0.6878 recall_train:0.6828 F1_train:0.6853 AUC_train:0.7621\n",
      "acc_val:0.7865 pre_val:0.7826 recall_val:0.8000 F1_val:0.791209 AUC_val:0.8960\n",
      "Epoch:0066\n",
      "acc_train:0.6687 pre_train:0.6850 recall_train:0.6634 F1_train:0.6740 AUC_train:0.7527\n",
      "acc_val:0.7978 pre_val:0.7872 recall_val:0.8222 F1_val:0.804348 AUC_val:0.9005\n",
      "Epoch:0067\n",
      "acc_train:0.6963 pre_train:0.7515 recall_train:0.6150 F1_train:0.6764 AUC_train:0.7915\n",
      "acc_val:0.7978 pre_val:0.7872 recall_val:0.8222 F1_val:0.804348 AUC_val:0.9061\n",
      "Epoch:0068\n",
      "acc_train:0.6675 pre_train:0.7036 recall_train:0.6150 F1_train:0.6563 AUC_train:0.7778\n",
      "acc_val:0.8090 pre_val:0.7917 recall_val:0.8444 F1_val:0.817204 AUC_val:0.9101\n",
      "Epoch:0069\n",
      "acc_train:0.6925 pre_train:0.7052 recall_train:0.6949 F1_train:0.7000 AUC_train:0.8029\n",
      "acc_val:0.8202 pre_val:0.7959 recall_val:0.8667 F1_val:0.829787 AUC_val:0.9157\n",
      "Epoch:0070\n",
      "acc_train:0.6988 pre_train:0.7129 recall_train:0.6973 F1_train:0.7050 AUC_train:0.8123\n",
      "acc_val:0.8090 pre_val:0.7800 recall_val:0.8667 F1_val:0.821053 AUC_val:0.9187\n",
      "Epoch:0071\n",
      "acc_train:0.7138 pre_train:0.7447 recall_train:0.6780 F1_train:0.7098 AUC_train:0.8435\n",
      "acc_val:0.8090 pre_val:0.7800 recall_val:0.8667 F1_val:0.821053 AUC_val:0.9202\n",
      "Epoch:0072\n",
      "acc_train:0.7113 pre_train:0.7177 recall_train:0.7264 F1_train:0.7220 AUC_train:0.8249\n",
      "acc_val:0.8202 pre_val:0.7843 recall_val:0.8889 F1_val:0.833333 AUC_val:0.9207\n",
      "Epoch:0073\n",
      "acc_train:0.7425 pre_train:0.7531 recall_train:0.7458 F1_train:0.7494 AUC_train:0.8398\n",
      "acc_val:0.8315 pre_val:0.7778 recall_val:0.9333 F1_val:0.848485 AUC_val:0.9217\n",
      "Epoch:0074\n",
      "acc_train:0.7475 pre_train:0.7530 recall_train:0.7603 F1_train:0.7566 AUC_train:0.8454\n",
      "acc_val:0.8202 pre_val:0.7636 recall_val:0.9333 F1_val:0.840000 AUC_val:0.9227\n",
      "Epoch:0075\n",
      "acc_train:0.7638 pre_train:0.7605 recall_train:0.7918 F1_train:0.7758 AUC_train:0.8606\n",
      "acc_val:0.8202 pre_val:0.7636 recall_val:0.9333 F1_val:0.840000 AUC_val:0.9202\n",
      "Epoch:0076\n",
      "acc_train:0.7900 pre_train:0.7855 recall_train:0.8160 F1_train:0.8005 AUC_train:0.8820\n",
      "acc_val:0.8202 pre_val:0.7636 recall_val:0.9333 F1_val:0.840000 AUC_val:0.9179\n",
      "Epoch:0077\n",
      "acc_train:0.8112 pre_train:0.7695 recall_train:0.9056 F1_train:0.8320 AUC_train:0.8813\n",
      "acc_val:0.8202 pre_val:0.7544 recall_val:0.9556 F1_val:0.843137 AUC_val:0.9220\n",
      "Epoch:0078\n",
      "acc_train:0.8150 pre_train:0.7991 recall_train:0.8571 F1_train:0.8271 AUC_train:0.8897\n",
      "acc_val:0.8315 pre_val:0.7679 recall_val:0.9556 F1_val:0.851485 AUC_val:0.9275\n",
      "Epoch:0079\n",
      "acc_train:0.8475 pre_train:0.8129 recall_train:0.9153 F1_train:0.8610 AUC_train:0.9097\n",
      "acc_val:0.8315 pre_val:0.7778 recall_val:0.9333 F1_val:0.848485 AUC_val:0.9311\n",
      "Epoch:0080\n",
      "acc_train:0.8000 pre_train:0.8155 recall_train:0.7918 F1_train:0.8034 AUC_train:0.8943\n",
      "acc_val:0.8427 pre_val:0.7925 recall_val:0.9333 F1_val:0.857143 AUC_val:0.9328\n",
      "Epoch:0081\n",
      "acc_train:0.8600 pre_train:0.8279 recall_train:0.9201 F1_train:0.8716 AUC_train:0.9152\n",
      "acc_val:0.8427 pre_val:0.7925 recall_val:0.9333 F1_val:0.857143 AUC_val:0.9384\n",
      "Epoch:0082\n",
      "acc_train:0.8687 pre_train:0.8319 recall_train:0.9346 F1_train:0.8803 AUC_train:0.9142\n",
      "acc_val:0.8427 pre_val:0.7925 recall_val:0.9333 F1_val:0.857143 AUC_val:0.9394\n",
      "Epoch:0083\n",
      "acc_train:0.8675 pre_train:0.8191 recall_train:0.9540 F1_train:0.8814 AUC_train:0.9287\n",
      "acc_val:0.8427 pre_val:0.7925 recall_val:0.9333 F1_val:0.857143 AUC_val:0.9348\n",
      "Epoch:0084\n",
      "acc_train:0.8875 pre_train:0.8581 recall_train:0.9370 F1_train:0.8958 AUC_train:0.9312\n",
      "acc_val:0.8539 pre_val:0.8077 recall_val:0.9333 F1_val:0.865979 AUC_val:0.9381\n",
      "Epoch:0085\n",
      "acc_train:0.8888 pre_train:0.8476 recall_train:0.9564 F1_train:0.8987 AUC_train:0.9340\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9409\n",
      "Epoch:0086\n",
      "acc_train:0.9013 pre_train:0.8813 recall_train:0.9346 F1_train:0.9072 AUC_train:0.9385\n",
      "acc_val:0.8539 pre_val:0.7963 recall_val:0.9556 F1_val:0.868687 AUC_val:0.9551\n",
      "Epoch:0087\n",
      "acc_train:0.8950 pre_train:0.8664 recall_train:0.9419 F1_train:0.9026 AUC_train:0.9419\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9563\n",
      "Epoch:0088\n",
      "acc_train:0.9137 pre_train:0.8909 recall_train:0.9492 F1_train:0.9191 AUC_train:0.9612\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9540\n",
      "Epoch:0089\n",
      "acc_train:0.9038 pre_train:0.8767 recall_train:0.9467 F1_train:0.9104 AUC_train:0.9391\n",
      "acc_val:0.8876 pre_val:0.8431 recall_val:0.9556 F1_val:0.895833 AUC_val:0.9520\n",
      "Epoch:0090\n",
      "acc_train:0.9112 pre_train:0.8767 recall_train:0.9637 F1_train:0.9181 AUC_train:0.9422\n",
      "acc_val:0.8539 pre_val:0.7963 recall_val:0.9556 F1_val:0.868687 AUC_val:0.9490\n",
      "Epoch:0091\n",
      "acc_train:0.9000 pre_train:0.8742 recall_train:0.9419 F1_train:0.9068 AUC_train:0.9445\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9460\n",
      "Epoch:0092\n",
      "acc_train:0.9100 pre_train:0.8698 recall_train:0.9709 F1_train:0.9176 AUC_train:0.9609\n",
      "acc_val:0.8876 pre_val:0.8302 recall_val:0.9778 F1_val:0.897959 AUC_val:0.9447\n",
      "Epoch:0093\n",
      "acc_train:0.8988 pre_train:0.8609 recall_train:0.9588 F1_train:0.9072 AUC_train:0.9429\n",
      "acc_val:0.8876 pre_val:0.8302 recall_val:0.9778 F1_val:0.897959 AUC_val:0.9465\n",
      "Epoch:0094\n",
      "acc_train:0.9225 pre_train:0.8874 recall_train:0.9734 F1_train:0.9284 AUC_train:0.9520\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9399\n",
      "Epoch:0095\n",
      "acc_train:0.8975 pre_train:0.8575 recall_train:0.9613 F1_train:0.9064 AUC_train:0.9539\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9341\n",
      "Epoch:0096\n",
      "acc_train:0.9137 pre_train:0.8805 recall_train:0.9637 F1_train:0.9202 AUC_train:0.9546\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9321\n",
      "Epoch:0097\n",
      "acc_train:0.9050 pre_train:0.8655 recall_train:0.9661 F1_train:0.9130 AUC_train:0.9650\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9295\n",
      "Epoch:0098\n",
      "acc_train:0.9137 pre_train:0.8839 recall_train:0.9588 F1_train:0.9199 AUC_train:0.9560\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9285\n",
      "Epoch:0099\n",
      "acc_train:0.9150 pre_train:0.8791 recall_train:0.9685 F1_train:0.9217 AUC_train:0.9617\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.9379\n",
      "Epoch:0100\n",
      "acc_train:0.9225 pre_train:0.8790 recall_train:0.9855 F1_train:0.9292 AUC_train:0.9686\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.9379\n",
      "Epoch:0101\n",
      "acc_train:0.9388 pre_train:0.9081 recall_train:0.9806 F1_train:0.9430 AUC_train:0.9718\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9404\n",
      "Epoch:0102\n",
      "acc_train:0.9275 pre_train:0.8867 recall_train:0.9855 F1_train:0.9335 AUC_train:0.9750\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9477\n",
      "Epoch:0103\n",
      "acc_train:0.9275 pre_train:0.8936 recall_train:0.9758 F1_train:0.9329 AUC_train:0.9676\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9497\n",
      "Epoch:0104\n",
      "acc_train:0.9262 pre_train:0.8986 recall_train:0.9661 F1_train:0.9312 AUC_train:0.9665\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9535\n",
      "Epoch:0105\n",
      "acc_train:0.9362 pre_train:0.9004 recall_train:0.9855 F1_train:0.9410 AUC_train:0.9671\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9515\n",
      "Epoch:0106\n",
      "acc_train:0.9463 pre_train:0.9205 recall_train:0.9806 F1_train:0.9496 AUC_train:0.9679\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9477\n",
      "Epoch:0107\n",
      "acc_train:0.9538 pre_train:0.9273 recall_train:0.9879 F1_train:0.9566 AUC_train:0.9768\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0108\n",
      "acc_train:0.9513 pre_train:0.9269 recall_train:0.9831 F1_train:0.9542 AUC_train:0.9786\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9457\n",
      "Epoch:0109\n",
      "acc_train:0.9463 pre_train:0.9263 recall_train:0.9734 F1_train:0.9492 AUC_train:0.9839\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9447\n",
      "Epoch:0110\n",
      "acc_train:0.9400 pre_train:0.9065 recall_train:0.9855 F1_train:0.9443 AUC_train:0.9725\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9444\n",
      "Epoch:0111\n",
      "acc_train:0.9500 pre_train:0.9307 recall_train:0.9758 F1_train:0.9527 AUC_train:0.9771\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9467\n",
      "Epoch:0112\n",
      "acc_train:0.9500 pre_train:0.9248 recall_train:0.9831 F1_train:0.9531 AUC_train:0.9851\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9515\n",
      "Epoch:0113\n",
      "acc_train:0.9538 pre_train:0.9393 recall_train:0.9734 F1_train:0.9560 AUC_train:0.9821\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9535\n",
      "Epoch:0114\n",
      "acc_train:0.9513 pre_train:0.9269 recall_train:0.9831 F1_train:0.9542 AUC_train:0.9830\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9384\n",
      "Epoch:0115\n",
      "acc_train:0.9413 pre_train:0.9197 recall_train:0.9709 F1_train:0.9446 AUC_train:0.9833\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9429\n",
      "Epoch:0116\n",
      "acc_train:0.9500 pre_train:0.9347 recall_train:0.9709 F1_train:0.9525 AUC_train:0.9822\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.9359\n",
      "Epoch:0117\n",
      "acc_train:0.9500 pre_train:0.9327 recall_train:0.9734 F1_train:0.9526 AUC_train:0.9808\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9434\n",
      "Epoch:0118\n",
      "acc_train:0.9475 pre_train:0.9284 recall_train:0.9734 F1_train:0.9504 AUC_train:0.9807\n",
      "acc_val:0.7753 pre_val:0.6984 recall_val:0.9778 F1_val:0.814815 AUC_val:0.9548\n",
      "Epoch:0119\n",
      "acc_train:0.9625 pre_train:0.9443 recall_train:0.9855 F1_train:0.9645 AUC_train:0.9923\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9576\n",
      "Epoch:0120\n",
      "acc_train:0.9600 pre_train:0.9461 recall_train:0.9782 F1_train:0.9619 AUC_train:0.9877\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9561\n",
      "Epoch:0121\n",
      "acc_train:0.9463 pre_train:0.9282 recall_train:0.9709 F1_train:0.9491 AUC_train:0.9868\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9571\n",
      "Epoch:0122\n",
      "acc_train:0.9563 pre_train:0.9335 recall_train:0.9855 F1_train:0.9588 AUC_train:0.9867\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9545\n",
      "Epoch:0123\n",
      "acc_train:0.9525 pre_train:0.9391 recall_train:0.9709 F1_train:0.9548 AUC_train:0.9816\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9407\n",
      "Epoch:0124\n",
      "acc_train:0.9600 pre_train:0.9568 recall_train:0.9661 F1_train:0.9614 AUC_train:0.9875\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.9341\n",
      "Epoch:0125\n",
      "acc_train:0.9625 pre_train:0.9614 recall_train:0.9661 F1_train:0.9638 AUC_train:0.9859\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.9255\n",
      "Epoch:0126\n",
      "acc_train:0.9563 pre_train:0.9479 recall_train:0.9685 F1_train:0.9581 AUC_train:0.9893\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9336\n",
      "Epoch:0127\n",
      "acc_train:0.9613 pre_train:0.9526 recall_train:0.9734 F1_train:0.9629 AUC_train:0.9875\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9472\n",
      "Epoch:0128\n",
      "acc_train:0.9650 pre_train:0.9487 recall_train:0.9855 F1_train:0.9667 AUC_train:0.9901\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9566\n",
      "Epoch:0129\n",
      "acc_train:0.9600 pre_train:0.9461 recall_train:0.9782 F1_train:0.9619 AUC_train:0.9898\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9601\n",
      "Epoch:0130\n",
      "acc_train:0.9600 pre_train:0.9461 recall_train:0.9782 F1_train:0.9619 AUC_train:0.9856\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9561\n",
      "Epoch:0131\n",
      "acc_train:0.9550 pre_train:0.9394 recall_train:0.9758 F1_train:0.9572 AUC_train:0.9855\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9551\n",
      "Epoch:0132\n",
      "acc_train:0.9588 pre_train:0.9460 recall_train:0.9758 F1_train:0.9607 AUC_train:0.9893\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9402\n",
      "Epoch:0133\n",
      "acc_train:0.9750 pre_train:0.9645 recall_train:0.9879 F1_train:0.9761 AUC_train:0.9938\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9311\n",
      "Epoch:0134\n",
      "acc_train:0.9563 pre_train:0.9458 recall_train:0.9709 F1_train:0.9582 AUC_train:0.9890\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9280\n",
      "Epoch:0135\n",
      "acc_train:0.9650 pre_train:0.9529 recall_train:0.9806 F1_train:0.9666 AUC_train:0.9841\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9336\n",
      "Epoch:0136\n",
      "acc_train:0.9675 pre_train:0.9553 recall_train:0.9831 F1_train:0.9690 AUC_train:0.9927\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9417\n",
      "Epoch:0137\n",
      "acc_train:0.9488 pre_train:0.9429 recall_train:0.9588 F1_train:0.9508 AUC_train:0.9859\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9500\n",
      "Epoch:0138\n",
      "acc_train:0.9712 pre_train:0.9643 recall_train:0.9806 F1_train:0.9724 AUC_train:0.9844\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9561\n",
      "Epoch:0139\n",
      "acc_train:0.9725 pre_train:0.9578 recall_train:0.9903 F1_train:0.9738 AUC_train:0.9932\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9576\n",
      "Epoch:0140\n",
      "acc_train:0.9588 pre_train:0.9439 recall_train:0.9782 F1_train:0.9608 AUC_train:0.9860\n",
      "acc_val:0.8764 pre_val:0.8148 recall_val:0.9778 F1_val:0.888889 AUC_val:0.9561\n",
      "Epoch:0141\n",
      "acc_train:0.9550 pre_train:0.9415 recall_train:0.9734 F1_train:0.9571 AUC_train:0.9905\n",
      "acc_val:0.9101 pre_val:0.8627 recall_val:0.9778 F1_val:0.916667 AUC_val:0.9551\n",
      "Epoch:0142\n",
      "acc_train:0.9725 pre_train:0.9578 recall_train:0.9903 F1_train:0.9738 AUC_train:0.9929\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9561\n",
      "Epoch:0143\n",
      "acc_train:0.9563 pre_train:0.9335 recall_train:0.9855 F1_train:0.9588 AUC_train:0.9910\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9530\n",
      "Epoch:0144\n",
      "acc_train:0.9663 pre_train:0.9509 recall_train:0.9855 F1_train:0.9679 AUC_train:0.9906\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9472\n",
      "Epoch:0145\n",
      "acc_train:0.9787 pre_train:0.9692 recall_train:0.9903 F1_train:0.9796 AUC_train:0.9928\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9487\n",
      "Epoch:0146\n",
      "acc_train:0.9750 pre_train:0.9712 recall_train:0.9806 F1_train:0.9759 AUC_train:0.9966\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9485\n",
      "Epoch:0147\n",
      "acc_train:0.9675 pre_train:0.9663 recall_train:0.9709 F1_train:0.9686 AUC_train:0.9935\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9510\n",
      "Epoch:0148\n",
      "acc_train:0.9663 pre_train:0.9639 recall_train:0.9709 F1_train:0.9674 AUC_train:0.9921\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9513\n",
      "Epoch:0149\n",
      "acc_train:0.9775 pre_train:0.9669 recall_train:0.9903 F1_train:0.9785 AUC_train:0.9938\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9492\n",
      "Epoch:0150\n",
      "acc_train:0.9737 pre_train:0.9601 recall_train:0.9903 F1_train:0.9750 AUC_train:0.9965\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9505\n",
      "Epoch:0151\n",
      "acc_train:0.9712 pre_train:0.9556 recall_train:0.9903 F1_train:0.9727 AUC_train:0.9943\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9490\n",
      "Epoch:0152\n",
      "acc_train:0.9600 pre_train:0.9547 recall_train:0.9685 F1_train:0.9615 AUC_train:0.9913\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9399\n",
      "Epoch:0153\n",
      "acc_train:0.9613 pre_train:0.9548 recall_train:0.9709 F1_train:0.9628 AUC_train:0.9903\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9409\n",
      "Epoch:0154\n",
      "acc_train:0.9750 pre_train:0.9667 recall_train:0.9855 F1_train:0.9760 AUC_train:0.9928\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0155\n",
      "acc_train:0.9675 pre_train:0.9596 recall_train:0.9782 F1_train:0.9688 AUC_train:0.9917\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9374\n",
      "Epoch:0156\n",
      "acc_train:0.9737 pre_train:0.9734 recall_train:0.9758 F1_train:0.9746 AUC_train:0.9925\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9354\n",
      "Epoch:0157\n",
      "acc_train:0.9712 pre_train:0.9665 recall_train:0.9782 F1_train:0.9723 AUC_train:0.9930\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9323\n",
      "Epoch:0158\n",
      "acc_train:0.9750 pre_train:0.9690 recall_train:0.9831 F1_train:0.9760 AUC_train:0.9956\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9260\n",
      "Epoch:0159\n",
      "acc_train:0.9737 pre_train:0.9804 recall_train:0.9685 F1_train:0.9744 AUC_train:0.9960\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9265\n",
      "Epoch:0160\n",
      "acc_train:0.9700 pre_train:0.9598 recall_train:0.9831 F1_train:0.9713 AUC_train:0.9970\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9323\n",
      "Early Stopping!!! epoch：159\n",
      " Starting the 2-3 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4988 pre_train:0.5140 recall_train:0.5351 F1_train:0.5243 AUC_train:0.5029\n",
      "acc_val:0.2584 pre_val:0.2667 recall_val:0.2667 F1_val:0.266667 AUC_val:0.2066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0002\n",
      "acc_train:0.5288 pre_train:0.5385 recall_train:0.6102 F1_train:0.5721 AUC_train:0.5469\n",
      "acc_val:0.2809 pre_val:0.3333 recall_val:0.4222 F1_val:0.372549 AUC_val:0.1995\n",
      "Epoch:0003\n",
      "acc_train:0.5462 pre_train:0.5504 recall_train:0.6610 F1_train:0.6007 AUC_train:0.5814\n",
      "acc_val:0.4607 pre_val:0.4810 recall_val:0.8444 F1_val:0.612903 AUC_val:0.3071\n",
      "Epoch:0004\n",
      "acc_train:0.5275 pre_train:0.5340 recall_train:0.6659 F1_train:0.5927 AUC_train:0.5715\n",
      "acc_val:0.4607 pre_val:0.4810 recall_val:0.8444 F1_val:0.612903 AUC_val:0.6490\n",
      "Epoch:0005\n",
      "acc_train:0.5537 pre_train:0.5593 recall_train:0.6392 F1_train:0.5966 AUC_train:0.6052\n",
      "acc_val:0.6629 pre_val:0.6190 recall_val:0.8667 F1_val:0.722222 AUC_val:0.7152\n",
      "Epoch:0006\n",
      "acc_train:0.5325 pre_train:0.5396 recall_train:0.6441 F1_train:0.5872 AUC_train:0.5598\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.7692\n",
      "Epoch:0007\n",
      "acc_train:0.6200 pre_train:0.6157 recall_train:0.7022 F1_train:0.6561 AUC_train:0.6657\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.7949\n",
      "Epoch:0008\n",
      "acc_train:0.5512 pre_train:0.5556 recall_train:0.6538 F1_train:0.6007 AUC_train:0.5765\n",
      "acc_val:0.7079 pre_val:0.6727 recall_val:0.8222 F1_val:0.740000 AUC_val:0.8106\n",
      "Epoch:0009\n",
      "acc_train:0.6200 pre_train:0.6510 recall_train:0.5690 F1_train:0.6072 AUC_train:0.6446\n",
      "acc_val:0.7753 pre_val:0.7551 recall_val:0.8222 F1_val:0.787234 AUC_val:0.8177\n",
      "Epoch:0010\n",
      "acc_train:0.5713 pre_train:0.5911 recall_train:0.5496 F1_train:0.5696 AUC_train:0.6041\n",
      "acc_val:0.7640 pre_val:0.7400 recall_val:0.8222 F1_val:0.778947 AUC_val:0.8172\n",
      "Epoch:0011\n",
      "acc_train:0.6037 pre_train:0.6111 recall_train:0.6392 F1_train:0.6249 AUC_train:0.6330\n",
      "acc_val:0.7640 pre_val:0.7400 recall_val:0.8222 F1_val:0.778947 AUC_val:0.8192\n",
      "Epoch:0012\n",
      "acc_train:0.5987 pre_train:0.6085 recall_train:0.6247 F1_train:0.6165 AUC_train:0.6220\n",
      "acc_val:0.7640 pre_val:0.7400 recall_val:0.8222 F1_val:0.778947 AUC_val:0.8222\n",
      "Epoch:0013\n",
      "acc_train:0.5888 pre_train:0.5802 recall_train:0.7361 F1_train:0.6489 AUC_train:0.6265\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8207\n",
      "Epoch:0014\n",
      "acc_train:0.6212 pre_train:0.6222 recall_train:0.6780 F1_train:0.6489 AUC_train:0.6506\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8131\n",
      "Epoch:0015\n",
      "acc_train:0.6363 pre_train:0.6406 recall_train:0.6731 F1_train:0.6564 AUC_train:0.6942\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8162\n",
      "Epoch:0016\n",
      "acc_train:0.6263 pre_train:0.6397 recall_train:0.6320 F1_train:0.6358 AUC_train:0.6815\n",
      "acc_val:0.7753 pre_val:0.7451 recall_val:0.8444 F1_val:0.791667 AUC_val:0.8187\n",
      "Epoch:0017\n",
      "acc_train:0.6087 pre_train:0.6131 recall_train:0.6562 F1_train:0.6339 AUC_train:0.6534\n",
      "acc_val:0.7528 pre_val:0.7170 recall_val:0.8444 F1_val:0.775510 AUC_val:0.8192\n",
      "Epoch:0018\n",
      "acc_train:0.6062 pre_train:0.6047 recall_train:0.6852 F1_train:0.6425 AUC_train:0.6435\n",
      "acc_val:0.7528 pre_val:0.7170 recall_val:0.8444 F1_val:0.775510 AUC_val:0.8222\n",
      "Epoch:0019\n",
      "acc_train:0.6363 pre_train:0.6326 recall_train:0.7046 F1_train:0.6667 AUC_train:0.6845\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8237\n",
      "Epoch:0020\n",
      "acc_train:0.6125 pre_train:0.6147 recall_train:0.6683 F1_train:0.6404 AUC_train:0.6618\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8237\n",
      "Epoch:0021\n",
      "acc_train:0.6250 pre_train:0.6242 recall_train:0.6877 F1_train:0.6544 AUC_train:0.6825\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8247\n",
      "Epoch:0022\n",
      "acc_train:0.6375 pre_train:0.6376 recall_train:0.6901 F1_train:0.6628 AUC_train:0.6707\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8258\n",
      "Epoch:0023\n",
      "acc_train:0.6400 pre_train:0.6333 recall_train:0.7191 F1_train:0.6735 AUC_train:0.6822\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8273\n",
      "Epoch:0024\n",
      "acc_train:0.6187 pre_train:0.6239 recall_train:0.6586 F1_train:0.6408 AUC_train:0.6755\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.8283\n",
      "Epoch:0025\n",
      "acc_train:0.6150 pre_train:0.6185 recall_train:0.6634 F1_train:0.6402 AUC_train:0.6597\n",
      "acc_val:0.7528 pre_val:0.7170 recall_val:0.8444 F1_val:0.775510 AUC_val:0.8303\n",
      "Epoch:0026\n",
      "acc_train:0.6587 pre_train:0.6584 recall_train:0.7046 F1_train:0.6807 AUC_train:0.7026\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8328\n",
      "Epoch:0027\n",
      "acc_train:0.6350 pre_train:0.6312 recall_train:0.7046 F1_train:0.6659 AUC_train:0.6896\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8364\n",
      "Epoch:0028\n",
      "acc_train:0.6325 pre_train:0.6455 recall_train:0.6392 F1_train:0.6423 AUC_train:0.6791\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8364\n",
      "Epoch:0029\n",
      "acc_train:0.6662 pre_train:0.6637 recall_train:0.7167 F1_train:0.6892 AUC_train:0.7241\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8389\n",
      "Epoch:0030\n",
      "acc_train:0.6700 pre_train:0.6645 recall_train:0.7288 F1_train:0.6952 AUC_train:0.7235\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8414\n",
      "Epoch:0031\n",
      "acc_train:0.6388 pre_train:0.6276 recall_train:0.7385 F1_train:0.6785 AUC_train:0.7077\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8419\n",
      "Epoch:0032\n",
      "acc_train:0.6587 pre_train:0.6651 recall_train:0.6828 F1_train:0.6738 AUC_train:0.7119\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8419\n",
      "Epoch:0033\n",
      "acc_train:0.6413 pre_train:0.6376 recall_train:0.7070 F1_train:0.6705 AUC_train:0.7136\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8439\n",
      "Epoch:0034\n",
      "acc_train:0.6550 pre_train:0.6519 recall_train:0.7119 F1_train:0.6806 AUC_train:0.6959\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8460\n",
      "Epoch:0035\n",
      "acc_train:0.6800 pre_train:0.6772 recall_train:0.7264 F1_train:0.7009 AUC_train:0.7366\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8495\n",
      "Epoch:0036\n",
      "acc_train:0.6425 pre_train:0.6315 recall_train:0.7385 F1_train:0.6808 AUC_train:0.7093\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.8500\n",
      "Epoch:0037\n",
      "acc_train:0.6450 pre_train:0.6437 recall_train:0.6998 F1_train:0.6705 AUC_train:0.7129\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.8535\n",
      "Epoch:0038\n",
      "acc_train:0.6625 pre_train:0.6571 recall_train:0.7240 F1_train:0.6889 AUC_train:0.7243\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.8561\n",
      "Epoch:0039\n",
      "acc_train:0.6650 pre_train:0.6477 recall_train:0.7700 F1_train:0.7035 AUC_train:0.7439\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.8576\n",
      "Epoch:0040\n",
      "acc_train:0.6500 pre_train:0.6360 recall_train:0.7530 F1_train:0.6896 AUC_train:0.7189\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.8596\n",
      "Epoch:0041\n",
      "acc_train:0.6662 pre_train:0.6527 recall_train:0.7554 F1_train:0.7003 AUC_train:0.7256\n",
      "acc_val:0.7528 pre_val:0.7091 recall_val:0.8667 F1_val:0.780000 AUC_val:0.8626\n",
      "Epoch:0042\n",
      "acc_train:0.6875 pre_train:0.6653 recall_train:0.7942 F1_train:0.7241 AUC_train:0.7358\n",
      "acc_val:0.7528 pre_val:0.7091 recall_val:0.8667 F1_val:0.780000 AUC_val:0.8616\n",
      "Epoch:0043\n",
      "acc_train:0.6687 pre_train:0.6659 recall_train:0.7191 F1_train:0.6915 AUC_train:0.7390\n",
      "acc_val:0.7528 pre_val:0.7091 recall_val:0.8667 F1_val:0.780000 AUC_val:0.8636\n",
      "Epoch:0044\n",
      "acc_train:0.6800 pre_train:0.6612 recall_train:0.7797 F1_train:0.7156 AUC_train:0.7542\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.8662\n",
      "Epoch:0045\n",
      "acc_train:0.6725 pre_train:0.6631 recall_train:0.7433 F1_train:0.7009 AUC_train:0.7338\n",
      "acc_val:0.7528 pre_val:0.7091 recall_val:0.8667 F1_val:0.780000 AUC_val:0.8702\n",
      "Epoch:0046\n",
      "acc_train:0.6950 pre_train:0.6907 recall_train:0.7409 F1_train:0.7150 AUC_train:0.7464\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.8712\n",
      "Epoch:0047\n",
      "acc_train:0.6850 pre_train:0.6633 recall_train:0.7918 F1_train:0.7219 AUC_train:0.7381\n",
      "acc_val:0.7416 pre_val:0.6964 recall_val:0.8667 F1_val:0.772277 AUC_val:0.8773\n",
      "Epoch:0048\n",
      "acc_train:0.6737 pre_train:0.6532 recall_train:0.7845 F1_train:0.7129 AUC_train:0.7292\n",
      "acc_val:0.7753 pre_val:0.7119 recall_val:0.9333 F1_val:0.807692 AUC_val:0.8874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0049\n",
      "acc_train:0.6963 pre_train:0.6864 recall_train:0.7579 F1_train:0.7204 AUC_train:0.7698\n",
      "acc_val:0.7753 pre_val:0.7119 recall_val:0.9333 F1_val:0.807692 AUC_val:0.8975\n",
      "Epoch:0050\n",
      "acc_train:0.6988 pre_train:0.6894 recall_train:0.7579 F1_train:0.7220 AUC_train:0.7662\n",
      "acc_val:0.7753 pre_val:0.7119 recall_val:0.9333 F1_val:0.807692 AUC_val:0.9061\n",
      "Epoch:0051\n",
      "acc_train:0.7138 pre_train:0.7063 recall_train:0.7627 F1_train:0.7334 AUC_train:0.7990\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.9131\n",
      "Epoch:0052\n",
      "acc_train:0.7450 pre_train:0.7257 recall_train:0.8136 F1_train:0.7671 AUC_train:0.8146\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9177\n",
      "Epoch:0053\n",
      "acc_train:0.7400 pre_train:0.7096 recall_train:0.8402 F1_train:0.7694 AUC_train:0.8059\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9227\n",
      "Epoch:0054\n",
      "acc_train:0.7688 pre_train:0.7405 recall_train:0.8499 F1_train:0.7914 AUC_train:0.8198\n",
      "acc_val:0.7528 pre_val:0.6825 recall_val:0.9556 F1_val:0.796296 AUC_val:0.9202\n",
      "Epoch:0055\n",
      "acc_train:0.7588 pre_train:0.7227 recall_train:0.8644 F1_train:0.7872 AUC_train:0.8131\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9333 F1_val:0.777778 AUC_val:0.9217\n",
      "Epoch:0056\n",
      "acc_train:0.8100 pre_train:0.7713 recall_train:0.8983 F1_train:0.8300 AUC_train:0.8720\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.9187\n",
      "Epoch:0057\n",
      "acc_train:0.7850 pre_train:0.7367 recall_train:0.9080 F1_train:0.8134 AUC_train:0.8673\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.9182\n",
      "Epoch:0058\n",
      "acc_train:0.7763 pre_train:0.7250 recall_train:0.9128 F1_train:0.8081 AUC_train:0.8871\n",
      "acc_val:0.7416 pre_val:0.6719 recall_val:0.9556 F1_val:0.788991 AUC_val:0.9192\n",
      "Epoch:0059\n",
      "acc_train:0.8200 pre_train:0.7796 recall_train:0.9080 F1_train:0.8389 AUC_train:0.8818\n",
      "acc_val:0.7416 pre_val:0.6774 recall_val:0.9333 F1_val:0.785047 AUC_val:0.9187\n",
      "Epoch:0060\n",
      "acc_train:0.8138 pre_train:0.7739 recall_train:0.9031 F1_train:0.8335 AUC_train:0.8743\n",
      "acc_val:0.7978 pre_val:0.7368 recall_val:0.9333 F1_val:0.823529 AUC_val:0.9157\n",
      "Epoch:0061\n",
      "acc_train:0.8075 pre_train:0.7515 recall_train:0.9370 F1_train:0.8341 AUC_train:0.8928\n",
      "acc_val:0.7978 pre_val:0.7368 recall_val:0.9333 F1_val:0.823529 AUC_val:0.9162\n",
      "Epoch:0062\n",
      "acc_train:0.7925 pre_train:0.7546 recall_train:0.8862 F1_train:0.8151 AUC_train:0.8715\n",
      "acc_val:0.8202 pre_val:0.7636 recall_val:0.9333 F1_val:0.840000 AUC_val:0.9157\n",
      "Epoch:0063\n",
      "acc_train:0.8213 pre_train:0.7722 recall_train:0.9274 F1_train:0.8427 AUC_train:0.8896\n",
      "acc_val:0.8090 pre_val:0.7593 recall_val:0.9111 F1_val:0.828283 AUC_val:0.9172\n",
      "Epoch:0064\n",
      "acc_train:0.8250 pre_train:0.7803 recall_train:0.9201 F1_train:0.8444 AUC_train:0.8933\n",
      "acc_val:0.7978 pre_val:0.7455 recall_val:0.9111 F1_val:0.820000 AUC_val:0.9187\n",
      "Epoch:0065\n",
      "acc_train:0.8363 pre_train:0.7866 recall_train:0.9370 F1_train:0.8552 AUC_train:0.8994\n",
      "acc_val:0.8090 pre_val:0.7593 recall_val:0.9111 F1_val:0.828283 AUC_val:0.9202\n",
      "Epoch:0066\n",
      "acc_train:0.8612 pre_train:0.8120 recall_train:0.9516 F1_train:0.8763 AUC_train:0.9094\n",
      "acc_val:0.8090 pre_val:0.7593 recall_val:0.9111 F1_val:0.828283 AUC_val:0.9217\n",
      "Epoch:0067\n",
      "acc_train:0.8600 pre_train:0.8090 recall_train:0.9540 F1_train:0.8756 AUC_train:0.9205\n",
      "acc_val:0.8202 pre_val:0.7736 recall_val:0.9111 F1_val:0.836735 AUC_val:0.9212\n",
      "Epoch:0068\n",
      "acc_train:0.8825 pre_train:0.8430 recall_train:0.9492 F1_train:0.8929 AUC_train:0.9275\n",
      "acc_val:0.8090 pre_val:0.7593 recall_val:0.9111 F1_val:0.828283 AUC_val:0.9258\n",
      "Epoch:0069\n",
      "acc_train:0.8763 pre_train:0.8369 recall_train:0.9443 F1_train:0.8874 AUC_train:0.9292\n",
      "acc_val:0.7978 pre_val:0.7455 recall_val:0.9111 F1_val:0.820000 AUC_val:0.9247\n",
      "Epoch:0070\n",
      "acc_train:0.8813 pre_train:0.8442 recall_train:0.9443 F1_train:0.8914 AUC_train:0.9149\n",
      "acc_val:0.7978 pre_val:0.7288 recall_val:0.9556 F1_val:0.826923 AUC_val:0.9253\n",
      "Epoch:0071\n",
      "acc_train:0.8750 pre_train:0.8323 recall_train:0.9492 F1_train:0.8869 AUC_train:0.9279\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9323\n",
      "Epoch:0072\n",
      "acc_train:0.8838 pre_train:0.8433 recall_train:0.9516 F1_train:0.8942 AUC_train:0.9445\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9394\n",
      "Epoch:0073\n",
      "acc_train:0.8800 pre_train:0.8409 recall_train:0.9467 F1_train:0.8907 AUC_train:0.9447\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9429\n",
      "Epoch:0074\n",
      "acc_train:0.8863 pre_train:0.8382 recall_train:0.9661 F1_train:0.8976 AUC_train:0.9458\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9444\n",
      "Epoch:0075\n",
      "acc_train:0.8863 pre_train:0.8368 recall_train:0.9685 F1_train:0.8979 AUC_train:0.9340\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9556\n",
      "Epoch:0076\n",
      "acc_train:0.8863 pre_train:0.8440 recall_train:0.9564 F1_train:0.8967 AUC_train:0.9424\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9566\n",
      "Epoch:0077\n",
      "acc_train:0.8938 pre_train:0.8431 recall_train:0.9758 F1_train:0.9046 AUC_train:0.9470\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9596\n",
      "Epoch:0078\n",
      "acc_train:0.8800 pre_train:0.8282 recall_train:0.9685 F1_train:0.8929 AUC_train:0.9447\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9551\n",
      "Epoch:0079\n",
      "acc_train:0.9050 pre_train:0.8624 recall_train:0.9709 F1_train:0.9134 AUC_train:0.9585\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9510\n",
      "Epoch:0080\n",
      "acc_train:0.9062 pre_train:0.8642 recall_train:0.9709 F1_train:0.9145 AUC_train:0.9620\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9439\n",
      "Epoch:0081\n",
      "acc_train:0.9038 pre_train:0.8590 recall_train:0.9734 F1_train:0.9126 AUC_train:0.9512\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9384\n",
      "Epoch:0082\n",
      "acc_train:0.9100 pre_train:0.8667 recall_train:0.9758 F1_train:0.9180 AUC_train:0.9600\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9346\n",
      "Epoch:0083\n",
      "acc_train:0.9112 pre_train:0.8701 recall_train:0.9734 F1_train:0.9189 AUC_train:0.9641\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.9308\n",
      "Epoch:0084\n",
      "acc_train:0.9150 pre_train:0.8742 recall_train:0.9758 F1_train:0.9222 AUC_train:0.9613\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9278\n",
      "Epoch:0085\n",
      "acc_train:0.9025 pre_train:0.8665 recall_train:0.9588 F1_train:0.9103 AUC_train:0.9485\n",
      "acc_val:0.8315 pre_val:0.7679 recall_val:0.9556 F1_val:0.851485 AUC_val:0.9237\n",
      "Epoch:0086\n",
      "acc_train:0.9237 pre_train:0.8860 recall_train:0.9782 F1_train:0.9298 AUC_train:0.9575\n",
      "acc_val:0.8315 pre_val:0.7679 recall_val:0.9556 F1_val:0.851485 AUC_val:0.9230\n",
      "Epoch:0087\n",
      "acc_train:0.9175 pre_train:0.8847 recall_train:0.9661 F1_train:0.9236 AUC_train:0.9532\n",
      "acc_val:0.8427 pre_val:0.7818 recall_val:0.9556 F1_val:0.860000 AUC_val:0.9255\n",
      "Epoch:0088\n",
      "acc_train:0.9150 pre_train:0.8775 recall_train:0.9709 F1_train:0.9218 AUC_train:0.9578\n",
      "acc_val:0.8090 pre_val:0.7414 recall_val:0.9556 F1_val:0.834951 AUC_val:0.9346\n",
      "Epoch:0089\n",
      "acc_train:0.9350 pre_train:0.9002 recall_train:0.9831 F1_train:0.9398 AUC_train:0.9671\n",
      "acc_val:0.8090 pre_val:0.7414 recall_val:0.9556 F1_val:0.834951 AUC_val:0.9422\n",
      "Epoch:0090\n",
      "acc_train:0.9262 pre_train:0.8899 recall_train:0.9782 F1_train:0.9319 AUC_train:0.9633\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9457\n",
      "Epoch:0091\n",
      "acc_train:0.9312 pre_train:0.9068 recall_train:0.9661 F1_train:0.9355 AUC_train:0.9773\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9500\n",
      "Epoch:0092\n",
      "acc_train:0.9287 pre_train:0.8956 recall_train:0.9758 F1_train:0.9340 AUC_train:0.9758\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9561\n",
      "Epoch:0093\n",
      "acc_train:0.9312 pre_train:0.8943 recall_train:0.9831 F1_train:0.9366 AUC_train:0.9778\n",
      "acc_val:0.8539 pre_val:0.7963 recall_val:0.9556 F1_val:0.868687 AUC_val:0.9591\n",
      "Epoch:0094\n",
      "acc_train:0.9488 pre_train:0.9189 recall_train:0.9879 F1_train:0.9522 AUC_train:0.9689\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9596\n",
      "Epoch:0095\n",
      "acc_train:0.9300 pre_train:0.9048 recall_train:0.9661 F1_train:0.9344 AUC_train:0.9779\n",
      "acc_val:0.8090 pre_val:0.7414 recall_val:0.9556 F1_val:0.834951 AUC_val:0.9571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0096\n",
      "acc_train:0.9325 pre_train:0.8998 recall_train:0.9782 F1_train:0.9374 AUC_train:0.9757\n",
      "acc_val:0.7978 pre_val:0.7288 recall_val:0.9556 F1_val:0.826923 AUC_val:0.9424\n",
      "Epoch:0097\n",
      "acc_train:0.9400 pre_train:0.9047 recall_train:0.9879 F1_train:0.9444 AUC_train:0.9666\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.9298\n",
      "Epoch:0098\n",
      "acc_train:0.9400 pre_train:0.9138 recall_train:0.9758 F1_train:0.9438 AUC_train:0.9719\n",
      "acc_val:0.8202 pre_val:0.7544 recall_val:0.9556 F1_val:0.843137 AUC_val:0.9394\n",
      "Epoch:0099\n",
      "acc_train:0.9275 pre_train:0.8971 recall_train:0.9709 F1_train:0.9326 AUC_train:0.9671\n",
      "acc_val:0.8539 pre_val:0.7963 recall_val:0.9556 F1_val:0.868687 AUC_val:0.9444\n",
      "Epoch:0100\n",
      "acc_train:0.9237 pre_train:0.8946 recall_train:0.9661 F1_train:0.9290 AUC_train:0.9657\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9424\n",
      "Epoch:0101\n",
      "acc_train:0.9450 pre_train:0.9184 recall_train:0.9806 F1_train:0.9485 AUC_train:0.9673\n",
      "acc_val:0.8202 pre_val:0.7544 recall_val:0.9556 F1_val:0.843137 AUC_val:0.9348\n",
      "Epoch:0102\n",
      "acc_train:0.9400 pre_train:0.9138 recall_train:0.9758 F1_train:0.9438 AUC_train:0.9754\n",
      "acc_val:0.7753 pre_val:0.6984 recall_val:0.9778 F1_val:0.814815 AUC_val:0.9293\n",
      "Epoch:0103\n",
      "acc_train:0.9513 pre_train:0.9193 recall_train:0.9927 F1_train:0.9546 AUC_train:0.9843\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.9247\n",
      "Epoch:0104\n",
      "acc_train:0.9625 pre_train:0.9362 recall_train:0.9952 F1_train:0.9648 AUC_train:0.9857\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.9217\n",
      "Epoch:0105\n",
      "acc_train:0.9488 pre_train:0.9266 recall_train:0.9782 F1_train:0.9517 AUC_train:0.9762\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.9167\n",
      "Epoch:0106\n",
      "acc_train:0.9413 pre_train:0.9159 recall_train:0.9758 F1_train:0.9449 AUC_train:0.9689\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.9146\n",
      "Epoch:0107\n",
      "acc_train:0.9538 pre_train:0.9234 recall_train:0.9927 F1_train:0.9568 AUC_train:0.9789\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.9197\n",
      "Epoch:0108\n",
      "acc_train:0.9600 pre_train:0.9359 recall_train:0.9903 F1_train:0.9624 AUC_train:0.9880\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:0.9778 F1_val:0.792793 AUC_val:0.9222\n",
      "Epoch:0109\n",
      "acc_train:0.9463 pre_train:0.9129 recall_train:0.9903 F1_train:0.9501 AUC_train:0.9762\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.9212\n",
      "Epoch:0110\n",
      "acc_train:0.9400 pre_train:0.9176 recall_train:0.9709 F1_train:0.9435 AUC_train:0.9746\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9253\n",
      "Epoch:0111\n",
      "acc_train:0.9438 pre_train:0.9182 recall_train:0.9782 F1_train:0.9472 AUC_train:0.9797\n",
      "acc_val:0.7640 pre_val:0.6935 recall_val:0.9556 F1_val:0.803738 AUC_val:0.9247\n",
      "Epoch:0112\n",
      "acc_train:0.9500 pre_train:0.9268 recall_train:0.9806 F1_train:0.9529 AUC_train:0.9785\n",
      "acc_val:0.7640 pre_val:0.6935 recall_val:0.9556 F1_val:0.803738 AUC_val:0.9270\n",
      "Epoch:0113\n",
      "acc_train:0.9525 pre_train:0.9330 recall_train:0.9782 F1_train:0.9551 AUC_train:0.9787\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.9179\n",
      "Epoch:0114\n",
      "acc_train:0.9650 pre_train:0.9425 recall_train:0.9927 F1_train:0.9670 AUC_train:0.9822\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.9096\n",
      "Epoch:0115\n",
      "acc_train:0.9663 pre_train:0.9468 recall_train:0.9903 F1_train:0.9680 AUC_train:0.9805\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:0.9778 F1_val:0.792793 AUC_val:0.9152\n",
      "Epoch:0116\n",
      "acc_train:0.9575 pre_train:0.9417 recall_train:0.9782 F1_train:0.9596 AUC_train:0.9840\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.9162\n",
      "Epoch:0117\n",
      "acc_train:0.9625 pre_train:0.9402 recall_train:0.9903 F1_train:0.9646 AUC_train:0.9856\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.9250\n",
      "Epoch:0118\n",
      "acc_train:0.9588 pre_train:0.9439 recall_train:0.9782 F1_train:0.9608 AUC_train:0.9859\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9260\n",
      "Epoch:0119\n",
      "acc_train:0.9575 pre_train:0.9317 recall_train:0.9903 F1_train:0.9601 AUC_train:0.9835\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9265\n",
      "Epoch:0120\n",
      "acc_train:0.9513 pre_train:0.9250 recall_train:0.9855 F1_train:0.9543 AUC_train:0.9781\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9295\n",
      "Early Stopping!!! epoch：119\n",
      " Starting the 2-4 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.5225 pre_train:0.5383 recall_train:0.5278 F1_train:0.5330 AUC_train:0.5289\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.7288\n",
      "Epoch:0002\n",
      "acc_train:0.5025 pre_train:0.5151 recall_train:0.6199 F1_train:0.5626 AUC_train:0.5211\n",
      "acc_val:0.5393 pre_val:0.5250 recall_val:0.9333 F1_val:0.672000 AUC_val:0.7394\n",
      "Epoch:0003\n",
      "acc_train:0.5238 pre_train:0.5404 recall_train:0.5182 F1_train:0.5290 AUC_train:0.5205\n",
      "acc_val:0.6292 pre_val:0.5909 recall_val:0.8667 F1_val:0.702703 AUC_val:0.7449\n",
      "Epoch:0004\n",
      "acc_train:0.5475 pre_train:0.5594 recall_train:0.5811 F1_train:0.5701 AUC_train:0.5692\n",
      "acc_val:0.6180 pre_val:0.5821 recall_val:0.8667 F1_val:0.696429 AUC_val:0.7581\n",
      "Epoch:0005\n",
      "acc_train:0.5050 pre_train:0.5139 recall_train:0.7603 F1_train:0.6133 AUC_train:0.5131\n",
      "acc_val:0.6517 pre_val:0.6061 recall_val:0.8889 F1_val:0.720721 AUC_val:0.7758\n",
      "Epoch:0006\n",
      "acc_train:0.5362 pre_train:0.5366 recall_train:0.7458 F1_train:0.6241 AUC_train:0.5530\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.7803\n",
      "Epoch:0007\n",
      "acc_train:0.5100 pre_train:0.5162 recall_train:0.8111 F1_train:0.6309 AUC_train:0.6038\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.7763\n",
      "Epoch:0008\n",
      "acc_train:0.5050 pre_train:0.5131 recall_train:0.8063 F1_train:0.6271 AUC_train:0.5661\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.7778\n",
      "Epoch:0009\n",
      "acc_train:0.5500 pre_train:0.5441 recall_train:0.7918 F1_train:0.6450 AUC_train:0.6126\n",
      "acc_val:0.5730 pre_val:0.5422 recall_val:1.0000 F1_val:0.703125 AUC_val:0.7803\n",
      "Epoch:0010\n",
      "acc_train:0.5450 pre_train:0.5400 recall_train:0.8015 F1_train:0.6452 AUC_train:0.5757\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.7869\n",
      "Epoch:0011\n",
      "acc_train:0.5350 pre_train:0.5365 recall_train:0.7288 F1_train:0.6181 AUC_train:0.5717\n",
      "acc_val:0.6180 pre_val:0.5821 recall_val:0.8667 F1_val:0.696429 AUC_val:0.7869\n",
      "Epoch:0012\n",
      "acc_train:0.5600 pre_train:0.5473 recall_train:0.8547 F1_train:0.6673 AUC_train:0.6366\n",
      "acc_val:0.7079 pre_val:0.6610 recall_val:0.8667 F1_val:0.750000 AUC_val:0.7912\n",
      "Epoch:0013\n",
      "acc_train:0.5813 pre_train:0.5750 recall_train:0.7240 F1_train:0.6409 AUC_train:0.6290\n",
      "acc_val:0.7079 pre_val:0.6727 recall_val:0.8222 F1_val:0.740000 AUC_val:0.7975\n",
      "Epoch:0014\n",
      "acc_train:0.5537 pre_train:0.5424 recall_train:0.8668 F1_train:0.6673 AUC_train:0.6552\n",
      "acc_val:0.7079 pre_val:0.6667 recall_val:0.8444 F1_val:0.745098 AUC_val:0.7838\n",
      "Epoch:0015\n",
      "acc_train:0.5925 pre_train:0.5775 recall_train:0.7845 F1_train:0.6653 AUC_train:0.6505\n",
      "acc_val:0.7528 pre_val:0.7447 recall_val:0.7778 F1_val:0.760870 AUC_val:0.7833\n",
      "Epoch:0016\n",
      "acc_train:0.5950 pre_train:0.5895 recall_train:0.7094 F1_train:0.6440 AUC_train:0.6340\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.7904\n",
      "Epoch:0017\n",
      "acc_train:0.6250 pre_train:0.6782 recall_train:0.5206 F1_train:0.5890 AUC_train:0.6595\n",
      "acc_val:0.7191 pre_val:0.8125 recall_val:0.5778 F1_val:0.675325 AUC_val:0.7919\n",
      "Epoch:0018\n",
      "acc_train:0.6012 pre_train:0.6250 recall_train:0.5690 F1_train:0.5957 AUC_train:0.6202\n",
      "acc_val:0.6854 pre_val:0.7931 recall_val:0.5111 F1_val:0.621622 AUC_val:0.7924\n",
      "Epoch:0019\n",
      "acc_train:0.5975 pre_train:0.6107 recall_train:0.6077 F1_train:0.6092 AUC_train:0.6314\n",
      "acc_val:0.6742 pre_val:0.7857 recall_val:0.4889 F1_val:0.602740 AUC_val:0.7919\n",
      "Epoch:0020\n",
      "acc_train:0.5763 pre_train:0.5693 recall_train:0.7361 F1_train:0.6420 AUC_train:0.6422\n",
      "acc_val:0.6517 pre_val:0.7692 recall_val:0.4444 F1_val:0.563380 AUC_val:0.7914\n",
      "Epoch:0021\n",
      "acc_train:0.6150 pre_train:0.6513 recall_train:0.5472 F1_train:0.5947 AUC_train:0.6334\n",
      "acc_val:0.6742 pre_val:0.7857 recall_val:0.4889 F1_val:0.602740 AUC_val:0.7949\n",
      "Epoch:0022\n",
      "acc_train:0.5575 pre_train:0.5456 recall_train:0.8547 F1_train:0.6660 AUC_train:0.6532\n",
      "acc_val:0.7303 pre_val:0.8182 recall_val:0.6000 F1_val:0.692308 AUC_val:0.7970\n",
      "Epoch:0023\n",
      "acc_train:0.5738 pre_train:0.5687 recall_train:0.7215 F1_train:0.6361 AUC_train:0.6470\n",
      "acc_val:0.7416 pre_val:0.8235 recall_val:0.6222 F1_val:0.708861 AUC_val:0.7971\n",
      "Epoch:0024\n",
      "acc_train:0.6025 pre_train:0.6247 recall_train:0.5763 F1_train:0.5995 AUC_train:0.6116\n",
      "acc_val:0.7528 pre_val:0.8286 recall_val:0.6444 F1_val:0.725000 AUC_val:0.7995\n",
      "Epoch:0025\n",
      "acc_train:0.5600 pre_train:0.5564 recall_train:0.7288 F1_train:0.6310 AUC_train:0.6278\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.7990\n",
      "Epoch:0026\n",
      "acc_train:0.6662 pre_train:0.7500 recall_train:0.5303 F1_train:0.6213 AUC_train:0.6642\n",
      "acc_val:0.7640 pre_val:0.8333 recall_val:0.6667 F1_val:0.740741 AUC_val:0.8000\n",
      "Epoch:0027\n",
      "acc_train:0.5825 pre_train:0.5702 recall_train:0.7772 F1_train:0.6578 AUC_train:0.6454\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.7990\n",
      "Epoch:0028\n",
      "acc_train:0.5475 pre_train:0.5440 recall_train:0.7627 F1_train:0.6351 AUC_train:0.6083\n",
      "acc_val:0.7640 pre_val:0.7609 recall_val:0.7778 F1_val:0.769231 AUC_val:0.7980\n",
      "Epoch:0029\n",
      "acc_train:0.6425 pre_train:0.7068 recall_train:0.5254 F1_train:0.6028 AUC_train:0.6633\n",
      "acc_val:0.7753 pre_val:0.7660 recall_val:0.8000 F1_val:0.782609 AUC_val:0.7894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0030\n",
      "acc_train:0.5312 pre_train:0.5272 recall_train:0.8910 F1_train:0.6625 AUC_train:0.6464\n",
      "acc_val:0.6966 pre_val:0.6452 recall_val:0.8889 F1_val:0.747664 AUC_val:0.7909\n",
      "Epoch:0031\n",
      "acc_train:0.6500 pre_train:0.6832 recall_train:0.6005 F1_train:0.6392 AUC_train:0.6748\n",
      "acc_val:0.7640 pre_val:0.7308 recall_val:0.8444 F1_val:0.783505 AUC_val:0.7889\n",
      "Epoch:0032\n",
      "acc_train:0.5663 pre_train:0.5567 recall_train:0.7845 F1_train:0.6513 AUC_train:0.6468\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.7909\n",
      "Epoch:0033\n",
      "acc_train:0.5375 pre_train:0.5325 recall_train:0.8523 F1_train:0.6555 AUC_train:0.6036\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.7934\n",
      "Epoch:0034\n",
      "acc_train:0.5587 pre_train:0.5475 recall_train:0.8378 F1_train:0.6622 AUC_train:0.6556\n",
      "acc_val:0.5056 pre_val:0.5059 recall_val:0.9556 F1_val:0.661538 AUC_val:0.7955\n",
      "Epoch:0035\n",
      "acc_train:0.5612 pre_train:0.5503 recall_train:0.8208 F1_train:0.6589 AUC_train:0.6328\n",
      "acc_val:0.5730 pre_val:0.5443 recall_val:0.9556 F1_val:0.693548 AUC_val:0.7980\n",
      "Epoch:0036\n",
      "acc_train:0.5763 pre_train:0.5771 recall_train:0.6707 F1_train:0.6204 AUC_train:0.6175\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8066\n",
      "Epoch:0037\n",
      "acc_train:0.6425 pre_train:0.6553 recall_train:0.6489 F1_train:0.6521 AUC_train:0.6754\n",
      "acc_val:0.7528 pre_val:0.8286 recall_val:0.6444 F1_val:0.725000 AUC_val:0.8025\n",
      "Epoch:0038\n",
      "acc_train:0.5800 pre_train:0.5728 recall_train:0.7337 F1_train:0.6433 AUC_train:0.6526\n",
      "acc_val:0.7416 pre_val:0.8235 recall_val:0.6222 F1_val:0.708861 AUC_val:0.8061\n",
      "Epoch:0039\n",
      "acc_train:0.5713 pre_train:0.5603 recall_train:0.7869 F1_train:0.6546 AUC_train:0.6410\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.8086\n",
      "Epoch:0040\n",
      "acc_train:0.6425 pre_train:0.6954 recall_train:0.5472 F1_train:0.6125 AUC_train:0.6754\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.8086\n",
      "Epoch:0041\n",
      "acc_train:0.6538 pre_train:0.7500 recall_train:0.4939 F1_train:0.5956 AUC_train:0.6833\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.8081\n",
      "Epoch:0042\n",
      "acc_train:0.6388 pre_train:0.6623 recall_train:0.6126 F1_train:0.6365 AUC_train:0.6619\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8056\n",
      "Epoch:0043\n",
      "acc_train:0.6500 pre_train:0.6755 recall_train:0.6199 F1_train:0.6465 AUC_train:0.6739\n",
      "acc_val:0.7753 pre_val:0.7660 recall_val:0.8000 F1_val:0.782609 AUC_val:0.8035\n",
      "Epoch:0044\n",
      "acc_train:0.5962 pre_train:0.5760 recall_train:0.8257 F1_train:0.6786 AUC_train:0.6816\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.7995\n",
      "Epoch:0045\n",
      "acc_train:0.6112 pre_train:0.6149 recall_train:0.6610 F1_train:0.6371 AUC_train:0.6637\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.7990\n",
      "Epoch:0046\n",
      "acc_train:0.5738 pre_train:0.5579 recall_train:0.8402 F1_train:0.6705 AUC_train:0.6469\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8030\n",
      "Epoch:0047\n",
      "acc_train:0.6175 pre_train:0.6099 recall_train:0.7191 F1_train:0.6600 AUC_train:0.6799\n",
      "acc_val:0.7191 pre_val:0.6786 recall_val:0.8444 F1_val:0.752475 AUC_val:0.7985\n",
      "Epoch:0048\n",
      "acc_train:0.6488 pre_train:0.7171 recall_train:0.5278 F1_train:0.6081 AUC_train:0.6733\n",
      "acc_val:0.7303 pre_val:0.6981 recall_val:0.8222 F1_val:0.755102 AUC_val:0.7995\n",
      "Epoch:0049\n",
      "acc_train:0.6325 pre_train:0.6355 recall_train:0.6755 F1_train:0.6549 AUC_train:0.6693\n",
      "acc_val:0.7303 pre_val:0.6909 recall_val:0.8444 F1_val:0.760000 AUC_val:0.7980\n",
      "Epoch:0050\n",
      "acc_train:0.6062 pre_train:0.5961 recall_train:0.7361 F1_train:0.6587 AUC_train:0.6424\n",
      "acc_val:0.7303 pre_val:0.6909 recall_val:0.8444 F1_val:0.760000 AUC_val:0.7995\n",
      "Epoch:0051\n",
      "acc_train:0.6075 pre_train:0.6181 recall_train:0.6271 F1_train:0.6226 AUC_train:0.6486\n",
      "acc_val:0.7303 pre_val:0.6909 recall_val:0.8444 F1_val:0.760000 AUC_val:0.8020\n",
      "Epoch:0052\n",
      "acc_train:0.6737 pre_train:0.7099 recall_train:0.6223 F1_train:0.6632 AUC_train:0.6898\n",
      "acc_val:0.7191 pre_val:0.6786 recall_val:0.8444 F1_val:0.752475 AUC_val:0.8035\n",
      "Epoch:0053\n",
      "acc_train:0.6463 pre_train:0.6757 recall_train:0.6053 F1_train:0.6386 AUC_train:0.6843\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8020\n",
      "Epoch:0054\n",
      "acc_train:0.6250 pre_train:0.6160 recall_train:0.7264 F1_train:0.6667 AUC_train:0.6758\n",
      "acc_val:0.7079 pre_val:0.6557 recall_val:0.8889 F1_val:0.754717 AUC_val:0.8020\n",
      "Epoch:0055\n",
      "acc_train:0.6187 pre_train:0.6262 recall_train:0.6489 F1_train:0.6373 AUC_train:0.6575\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8010\n",
      "Epoch:0056\n",
      "acc_train:0.6263 pre_train:0.6203 recall_train:0.7119 F1_train:0.6629 AUC_train:0.6761\n",
      "acc_val:0.6966 pre_val:0.6500 recall_val:0.8667 F1_val:0.742857 AUC_val:0.8030\n",
      "Epoch:0057\n",
      "acc_train:0.6275 pre_train:0.6134 recall_train:0.7530 F1_train:0.6761 AUC_train:0.6809\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8116\n",
      "Epoch:0058\n",
      "acc_train:0.6587 pre_train:0.6813 recall_train:0.6368 F1_train:0.6583 AUC_train:0.6891\n",
      "acc_val:0.6966 pre_val:0.6500 recall_val:0.8667 F1_val:0.742857 AUC_val:0.8162\n",
      "Epoch:0059\n",
      "acc_train:0.6237 pre_train:0.6261 recall_train:0.6731 F1_train:0.6488 AUC_train:0.6571\n",
      "acc_val:0.6966 pre_val:0.6500 recall_val:0.8667 F1_val:0.742857 AUC_val:0.8187\n",
      "Epoch:0060\n",
      "acc_train:0.5938 pre_train:0.5849 recall_train:0.7337 F1_train:0.6509 AUC_train:0.6611\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8217\n",
      "Epoch:0061\n",
      "acc_train:0.6488 pre_train:0.6416 recall_train:0.7240 F1_train:0.6803 AUC_train:0.6796\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8247\n",
      "Epoch:0062\n",
      "acc_train:0.6062 pre_train:0.6084 recall_train:0.6659 F1_train:0.6358 AUC_train:0.6553\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8227\n",
      "Epoch:0063\n",
      "acc_train:0.5962 pre_train:0.5886 recall_train:0.7240 F1_train:0.6493 AUC_train:0.6578\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8237\n",
      "Epoch:0064\n",
      "acc_train:0.6087 pre_train:0.6046 recall_train:0.6998 F1_train:0.6487 AUC_train:0.6526\n",
      "acc_val:0.7191 pre_val:0.6786 recall_val:0.8444 F1_val:0.752475 AUC_val:0.8222\n",
      "Epoch:0065\n",
      "acc_train:0.6125 pre_train:0.6147 recall_train:0.6683 F1_train:0.6404 AUC_train:0.6421\n",
      "acc_val:0.7303 pre_val:0.7059 recall_val:0.8000 F1_val:0.750000 AUC_val:0.8212\n",
      "Epoch:0066\n",
      "acc_train:0.6263 pre_train:0.6319 recall_train:0.6610 F1_train:0.6462 AUC_train:0.6820\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8212\n",
      "Epoch:0067\n",
      "acc_train:0.6175 pre_train:0.6146 recall_train:0.6949 F1_train:0.6523 AUC_train:0.6589\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8222\n",
      "Epoch:0068\n",
      "acc_train:0.6538 pre_train:0.6478 recall_train:0.7215 F1_train:0.6827 AUC_train:0.6917\n",
      "acc_val:0.7528 pre_val:0.7447 recall_val:0.7778 F1_val:0.760870 AUC_val:0.8192\n",
      "Epoch:0069\n",
      "acc_train:0.6388 pre_train:0.6490 recall_train:0.6538 F1_train:0.6514 AUC_train:0.6904\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8197\n",
      "Epoch:0070\n",
      "acc_train:0.6475 pre_train:0.6513 recall_train:0.6828 F1_train:0.6667 AUC_train:0.6914\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8202\n",
      "Epoch:0071\n",
      "acc_train:0.6325 pre_train:0.6368 recall_train:0.6707 F1_train:0.6533 AUC_train:0.6879\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8182\n",
      "Epoch:0072\n",
      "acc_train:0.6288 pre_train:0.6283 recall_train:0.6877 F1_train:0.6566 AUC_train:0.6763\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8207\n",
      "Epoch:0073\n",
      "acc_train:0.6338 pre_train:0.6316 recall_train:0.6973 F1_train:0.6628 AUC_train:0.6892\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8222\n",
      "Epoch:0074\n",
      "acc_train:0.6463 pre_train:0.6432 recall_train:0.7070 F1_train:0.6736 AUC_train:0.6888\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8202\n",
      "Epoch:0075\n",
      "acc_train:0.6525 pre_train:0.6573 recall_train:0.6828 F1_train:0.6698 AUC_train:0.7098\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8207\n",
      "Epoch:0076\n",
      "acc_train:0.6525 pre_train:0.6559 recall_train:0.6877 F1_train:0.6714 AUC_train:0.6924\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0077\n",
      "acc_train:0.6288 pre_train:0.6289 recall_train:0.6852 F1_train:0.6559 AUC_train:0.6828\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8197\n",
      "Epoch:0078\n",
      "acc_train:0.6438 pre_train:0.6481 recall_train:0.6780 F1_train:0.6627 AUC_train:0.7137\n",
      "acc_val:0.7528 pre_val:0.7447 recall_val:0.7778 F1_val:0.760870 AUC_val:0.8177\n",
      "Epoch:0079\n",
      "acc_train:0.6438 pre_train:0.6468 recall_train:0.6828 F1_train:0.6643 AUC_train:0.6997\n",
      "acc_val:0.7528 pre_val:0.7447 recall_val:0.7778 F1_val:0.760870 AUC_val:0.8182\n",
      "Epoch:0080\n",
      "acc_train:0.6475 pre_train:0.6499 recall_train:0.6877 F1_train:0.6682 AUC_train:0.7007\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.8217\n",
      "Epoch:0081\n",
      "acc_train:0.6463 pre_train:0.6444 recall_train:0.7022 F1_train:0.6721 AUC_train:0.7240\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.8222\n",
      "Epoch:0082\n",
      "acc_train:0.6687 pre_train:0.6869 recall_train:0.6586 F1_train:0.6724 AUC_train:0.7072\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.8207\n",
      "Epoch:0083\n",
      "acc_train:0.6612 pre_train:0.6651 recall_train:0.6925 F1_train:0.6785 AUC_train:0.7103\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8197\n",
      "Epoch:0084\n",
      "acc_train:0.6413 pre_train:0.6324 recall_train:0.7288 F1_train:0.6772 AUC_train:0.6998\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8247\n",
      "Epoch:0085\n",
      "acc_train:0.6350 pre_train:0.6353 recall_train:0.6877 F1_train:0.6605 AUC_train:0.6898\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8253\n",
      "Epoch:0086\n",
      "acc_train:0.6675 pre_train:0.6771 recall_train:0.6804 F1_train:0.6787 AUC_train:0.7141\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8253\n",
      "Epoch:0087\n",
      "acc_train:0.6438 pre_train:0.6524 recall_train:0.6634 F1_train:0.6579 AUC_train:0.7007\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8303\n",
      "Epoch:0088\n",
      "acc_train:0.6712 pre_train:0.6752 recall_train:0.6998 F1_train:0.6873 AUC_train:0.7387\n",
      "acc_val:0.7416 pre_val:0.7200 recall_val:0.8000 F1_val:0.757895 AUC_val:0.8338\n",
      "Epoch:0089\n",
      "acc_train:0.6600 pre_train:0.6584 recall_train:0.7094 F1_train:0.6830 AUC_train:0.7276\n",
      "acc_val:0.7191 pre_val:0.7083 recall_val:0.7556 F1_val:0.731183 AUC_val:0.8167\n",
      "Epoch:0090\n",
      "acc_train:0.6475 pre_train:0.6548 recall_train:0.6707 F1_train:0.6627 AUC_train:0.7190\n",
      "acc_val:0.7303 pre_val:0.7234 recall_val:0.7556 F1_val:0.739130 AUC_val:0.8172\n",
      "Epoch:0091\n",
      "acc_train:0.6550 pre_train:0.6667 recall_train:0.6634 F1_train:0.6650 AUC_train:0.7342\n",
      "acc_val:0.7416 pre_val:0.7391 recall_val:0.7556 F1_val:0.747253 AUC_val:0.8182\n",
      "Epoch:0092\n",
      "acc_train:0.6600 pre_train:0.6776 recall_train:0.6513 F1_train:0.6642 AUC_train:0.7386\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8227\n",
      "Epoch:0093\n",
      "acc_train:0.6550 pre_train:0.6691 recall_train:0.6562 F1_train:0.6626 AUC_train:0.7346\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8293\n",
      "Epoch:0094\n",
      "acc_train:0.6587 pre_train:0.6667 recall_train:0.6780 F1_train:0.6723 AUC_train:0.7297\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8359\n",
      "Epoch:0095\n",
      "acc_train:0.6425 pre_train:0.6494 recall_train:0.6683 F1_train:0.6587 AUC_train:0.7261\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8444\n",
      "Epoch:0096\n",
      "acc_train:0.6850 pre_train:0.7007 recall_train:0.6804 F1_train:0.6904 AUC_train:0.7571\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8475\n",
      "Epoch:0097\n",
      "acc_train:0.6850 pre_train:0.7059 recall_train:0.6683 F1_train:0.6866 AUC_train:0.7726\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8576\n",
      "Epoch:0098\n",
      "acc_train:0.6662 pre_train:0.6780 recall_train:0.6731 F1_train:0.6756 AUC_train:0.7489\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8621\n",
      "Epoch:0099\n",
      "acc_train:0.6725 pre_train:0.6883 recall_train:0.6683 F1_train:0.6781 AUC_train:0.7792\n",
      "acc_val:0.7640 pre_val:0.7857 recall_val:0.7333 F1_val:0.758621 AUC_val:0.8626\n",
      "Epoch:0100\n",
      "acc_train:0.6687 pre_train:0.6770 recall_train:0.6852 F1_train:0.6811 AUC_train:0.7733\n",
      "acc_val:0.7640 pre_val:0.7857 recall_val:0.7333 F1_val:0.758621 AUC_val:0.8611\n",
      "Epoch:0101\n",
      "acc_train:0.6850 pre_train:0.6903 recall_train:0.7070 F1_train:0.6986 AUC_train:0.7849\n",
      "acc_val:0.7640 pre_val:0.7857 recall_val:0.7333 F1_val:0.758621 AUC_val:0.8631\n",
      "Epoch:0102\n",
      "acc_train:0.6800 pre_train:0.6796 recall_train:0.7191 F1_train:0.6988 AUC_train:0.7764\n",
      "acc_val:0.7528 pre_val:0.7805 recall_val:0.7111 F1_val:0.744186 AUC_val:0.8652\n",
      "Epoch:0103\n",
      "acc_train:0.6862 pre_train:0.7015 recall_train:0.6828 F1_train:0.6920 AUC_train:0.7830\n",
      "acc_val:0.7640 pre_val:0.8000 recall_val:0.7111 F1_val:0.752941 AUC_val:0.8702\n",
      "Epoch:0104\n",
      "acc_train:0.6913 pre_train:0.6986 recall_train:0.7070 F1_train:0.7028 AUC_train:0.8045\n",
      "acc_val:0.7640 pre_val:0.8000 recall_val:0.7111 F1_val:0.752941 AUC_val:0.8758\n",
      "Epoch:0105\n",
      "acc_train:0.7025 pre_train:0.7002 recall_train:0.7409 F1_train:0.7200 AUC_train:0.8184\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.9000\n",
      "Epoch:0106\n",
      "acc_train:0.7025 pre_train:0.7150 recall_train:0.7046 F1_train:0.7098 AUC_train:0.8137\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.9010\n",
      "Epoch:0107\n",
      "acc_train:0.7000 pre_train:0.7146 recall_train:0.6973 F1_train:0.7059 AUC_train:0.8101\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.9035\n",
      "Epoch:0108\n",
      "acc_train:0.7088 pre_train:0.7206 recall_train:0.7119 F1_train:0.7162 AUC_train:0.8128\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.9096\n",
      "Epoch:0109\n",
      "acc_train:0.7138 pre_train:0.7190 recall_train:0.7312 F1_train:0.7251 AUC_train:0.8293\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.9116\n",
      "Epoch:0110\n",
      "acc_train:0.7038 pre_train:0.7095 recall_train:0.7215 F1_train:0.7155 AUC_train:0.8203\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.9136\n",
      "Epoch:0111\n",
      "acc_train:0.7300 pre_train:0.7469 recall_train:0.7215 F1_train:0.7340 AUC_train:0.8542\n",
      "acc_val:0.7640 pre_val:0.7857 recall_val:0.7333 F1_val:0.758621 AUC_val:0.9167\n",
      "Epoch:0112\n",
      "acc_train:0.7100 pre_train:0.7191 recall_train:0.7191 F1_train:0.7191 AUC_train:0.8392\n",
      "acc_val:0.7753 pre_val:0.7907 recall_val:0.7556 F1_val:0.772727 AUC_val:0.9197\n",
      "Epoch:0113\n",
      "acc_train:0.7350 pre_train:0.7481 recall_train:0.7337 F1_train:0.7408 AUC_train:0.8553\n",
      "acc_val:0.7753 pre_val:0.7907 recall_val:0.7556 F1_val:0.772727 AUC_val:0.9202\n",
      "Epoch:0114\n",
      "acc_train:0.7237 pre_train:0.7319 recall_train:0.7337 F1_train:0.7328 AUC_train:0.8550\n",
      "acc_val:0.8090 pre_val:0.8182 recall_val:0.8000 F1_val:0.808989 AUC_val:0.9247\n",
      "Epoch:0115\n",
      "acc_train:0.7337 pre_train:0.7451 recall_train:0.7361 F1_train:0.7406 AUC_train:0.8594\n",
      "acc_val:0.8090 pre_val:0.8182 recall_val:0.8000 F1_val:0.808989 AUC_val:0.9278\n",
      "Epoch:0116\n",
      "acc_train:0.7362 pre_train:0.7525 recall_train:0.7288 F1_train:0.7405 AUC_train:0.8586\n",
      "acc_val:0.8090 pre_val:0.8182 recall_val:0.8000 F1_val:0.808989 AUC_val:0.9318\n",
      "Epoch:0117\n",
      "acc_train:0.7400 pre_train:0.7482 recall_train:0.7482 F1_train:0.7482 AUC_train:0.8775\n",
      "acc_val:0.8090 pre_val:0.8182 recall_val:0.8000 F1_val:0.808989 AUC_val:0.9359\n",
      "Epoch:0118\n",
      "acc_train:0.7250 pre_train:0.7281 recall_train:0.7458 F1_train:0.7368 AUC_train:0.8614\n",
      "acc_val:0.8090 pre_val:0.8182 recall_val:0.8000 F1_val:0.808989 AUC_val:0.9379\n",
      "Epoch:0119\n",
      "acc_train:0.7525 pre_train:0.7494 recall_train:0.7821 F1_train:0.7654 AUC_train:0.8726\n",
      "acc_val:0.8202 pre_val:0.8222 recall_val:0.8222 F1_val:0.822222 AUC_val:0.9369\n",
      "Epoch:0120\n",
      "acc_train:0.8012 pre_train:0.7668 recall_train:0.8838 F1_train:0.8211 AUC_train:0.8752\n",
      "acc_val:0.8202 pre_val:0.8222 recall_val:0.8222 F1_val:0.822222 AUC_val:0.9359\n",
      "Epoch:0121\n",
      "acc_train:0.8163 pre_train:0.7748 recall_train:0.9080 F1_train:0.8361 AUC_train:0.8976\n",
      "acc_val:0.8202 pre_val:0.8085 recall_val:0.8444 F1_val:0.826087 AUC_val:0.9338\n",
      "Epoch:0122\n",
      "acc_train:0.8388 pre_train:0.8008 recall_train:0.9153 F1_train:0.8542 AUC_train:0.8989\n",
      "acc_val:0.8427 pre_val:0.8163 recall_val:0.8889 F1_val:0.851064 AUC_val:0.9369\n",
      "Epoch:0123\n",
      "acc_train:0.8288 pre_train:0.7863 recall_train:0.9177 F1_train:0.8469 AUC_train:0.8897\n",
      "acc_val:0.8315 pre_val:0.7778 recall_val:0.9333 F1_val:0.848485 AUC_val:0.9288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0124\n",
      "acc_train:0.8575 pre_train:0.8045 recall_train:0.9564 F1_train:0.8739 AUC_train:0.9189\n",
      "acc_val:0.8202 pre_val:0.7544 recall_val:0.9556 F1_val:0.843137 AUC_val:0.9245\n",
      "Epoch:0125\n",
      "acc_train:0.8562 pre_train:0.8041 recall_train:0.9540 F1_train:0.8726 AUC_train:0.9180\n",
      "acc_val:0.8202 pre_val:0.7544 recall_val:0.9556 F1_val:0.843137 AUC_val:0.9285\n",
      "Epoch:0126\n",
      "acc_train:0.8512 pre_train:0.7827 recall_train:0.9855 F1_train:0.8725 AUC_train:0.9450\n",
      "acc_val:0.7978 pre_val:0.7288 recall_val:0.9556 F1_val:0.826923 AUC_val:0.9288\n",
      "Epoch:0127\n",
      "acc_train:0.8350 pre_train:0.7760 recall_train:0.9564 F1_train:0.8568 AUC_train:0.9378\n",
      "acc_val:0.7978 pre_val:0.7368 recall_val:0.9333 F1_val:0.823529 AUC_val:0.9293\n",
      "Epoch:0128\n",
      "acc_train:0.8612 pre_train:0.8057 recall_train:0.9637 F1_train:0.8776 AUC_train:0.9552\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:0.9333 F1_val:0.831683 AUC_val:0.9348\n",
      "Epoch:0129\n",
      "acc_train:0.8587 pre_train:0.8012 recall_train:0.9661 F1_train:0.8760 AUC_train:0.9455\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:0.9333 F1_val:0.831683 AUC_val:0.9379\n",
      "Epoch:0130\n",
      "acc_train:0.8687 pre_train:0.8068 recall_train:0.9806 F1_train:0.8852 AUC_train:0.9562\n",
      "acc_val:0.7978 pre_val:0.7368 recall_val:0.9333 F1_val:0.823529 AUC_val:0.9384\n",
      "Epoch:0131\n",
      "acc_train:0.8612 pre_train:0.8057 recall_train:0.9637 F1_train:0.8776 AUC_train:0.9492\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:0.9333 F1_val:0.831683 AUC_val:0.9414\n",
      "Epoch:0132\n",
      "acc_train:0.8675 pre_train:0.8245 recall_train:0.9443 F1_train:0.8804 AUC_train:0.9447\n",
      "acc_val:0.8315 pre_val:0.7778 recall_val:0.9333 F1_val:0.848485 AUC_val:0.9444\n",
      "Epoch:0133\n",
      "acc_train:0.8838 pre_train:0.8333 recall_train:0.9685 F1_train:0.8959 AUC_train:0.9468\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9482\n",
      "Epoch:0134\n",
      "acc_train:0.8850 pre_train:0.8497 recall_train:0.9443 F1_train:0.8945 AUC_train:0.9498\n",
      "acc_val:0.8427 pre_val:0.7719 recall_val:0.9778 F1_val:0.862745 AUC_val:0.9455\n",
      "Epoch:0135\n",
      "acc_train:0.8975 pre_train:0.8559 recall_train:0.9637 F1_train:0.9066 AUC_train:0.9462\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9465\n",
      "Epoch:0136\n",
      "acc_train:0.8775 pre_train:0.8302 recall_train:0.9588 F1_train:0.8899 AUC_train:0.9580\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9500\n",
      "Epoch:0137\n",
      "acc_train:0.8950 pre_train:0.8615 recall_train:0.9492 F1_train:0.9032 AUC_train:0.9587\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9525\n",
      "Epoch:0138\n",
      "acc_train:0.8950 pre_train:0.8538 recall_train:0.9613 F1_train:0.9043 AUC_train:0.9639\n",
      "acc_val:0.8652 pre_val:0.8000 recall_val:0.9778 F1_val:0.880000 AUC_val:0.9497\n",
      "Epoch:0139\n",
      "acc_train:0.8963 pre_train:0.8556 recall_train:0.9613 F1_train:0.9054 AUC_train:0.9614\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9444\n",
      "Epoch:0140\n",
      "acc_train:0.9000 pre_train:0.8565 recall_train:0.9685 F1_train:0.9091 AUC_train:0.9624\n",
      "acc_val:0.8652 pre_val:0.8235 recall_val:0.9333 F1_val:0.875000 AUC_val:0.9369\n",
      "Epoch:0141\n",
      "acc_train:0.8938 pre_train:0.8534 recall_train:0.9588 F1_train:0.9031 AUC_train:0.9641\n",
      "acc_val:0.8539 pre_val:0.8077 recall_val:0.9333 F1_val:0.865979 AUC_val:0.9303\n",
      "Epoch:0142\n",
      "acc_train:0.8900 pre_train:0.8421 recall_train:0.9685 F1_train:0.9009 AUC_train:0.9595\n",
      "acc_val:0.8427 pre_val:0.7925 recall_val:0.9333 F1_val:0.857143 AUC_val:0.9308\n",
      "Epoch:0143\n",
      "acc_train:0.8925 pre_train:0.8428 recall_train:0.9734 F1_train:0.9034 AUC_train:0.9560\n",
      "acc_val:0.8427 pre_val:0.7925 recall_val:0.9333 F1_val:0.857143 AUC_val:0.9333\n",
      "Epoch:0144\n",
      "acc_train:0.9225 pre_train:0.8874 recall_train:0.9734 F1_train:0.9284 AUC_train:0.9640\n",
      "acc_val:0.8427 pre_val:0.7818 recall_val:0.9556 F1_val:0.860000 AUC_val:0.9313\n",
      "Epoch:0145\n",
      "acc_train:0.9062 pre_train:0.8756 recall_train:0.9540 F1_train:0.9131 AUC_train:0.9623\n",
      "acc_val:0.8315 pre_val:0.7679 recall_val:0.9556 F1_val:0.851485 AUC_val:0.9278\n",
      "Epoch:0146\n",
      "acc_train:0.9150 pre_train:0.8808 recall_train:0.9661 F1_train:0.9215 AUC_train:0.9693\n",
      "acc_val:0.8202 pre_val:0.7736 recall_val:0.9111 F1_val:0.836735 AUC_val:0.9247\n",
      "Epoch:0147\n",
      "acc_train:0.9162 pre_train:0.8879 recall_train:0.9588 F1_train:0.9220 AUC_train:0.9664\n",
      "acc_val:0.8315 pre_val:0.8000 recall_val:0.8889 F1_val:0.842105 AUC_val:0.9258\n",
      "Epoch:0148\n",
      "acc_train:0.9038 pre_train:0.8636 recall_train:0.9661 F1_train:0.9120 AUC_train:0.9721\n",
      "acc_val:0.8764 pre_val:0.8542 recall_val:0.9111 F1_val:0.881720 AUC_val:0.9273\n",
      "Epoch:0149\n",
      "acc_train:0.9087 pre_train:0.8778 recall_train:0.9564 F1_train:0.9154 AUC_train:0.9655\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9303\n",
      "Epoch:0150\n",
      "acc_train:0.9175 pre_train:0.8864 recall_train:0.9637 F1_train:0.9234 AUC_train:0.9745\n",
      "acc_val:0.8876 pre_val:0.8431 recall_val:0.9556 F1_val:0.895833 AUC_val:0.9338\n",
      "Epoch:0151\n",
      "acc_train:0.9100 pre_train:0.8956 recall_train:0.9346 F1_train:0.9147 AUC_train:0.9708\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9364\n",
      "Epoch:0152\n",
      "acc_train:0.9137 pre_train:0.8927 recall_train:0.9467 F1_train:0.9189 AUC_train:0.9672\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9394\n",
      "Epoch:0153\n",
      "acc_train:0.9175 pre_train:0.8864 recall_train:0.9637 F1_train:0.9234 AUC_train:0.9774\n",
      "acc_val:0.8989 pre_val:0.8462 recall_val:0.9778 F1_val:0.907216 AUC_val:0.9389\n",
      "Epoch:0154\n",
      "acc_train:0.9062 pre_train:0.8789 recall_train:0.9492 F1_train:0.9127 AUC_train:0.9668\n",
      "acc_val:0.8876 pre_val:0.8431 recall_val:0.9556 F1_val:0.895833 AUC_val:0.9303\n",
      "Epoch:0155\n",
      "acc_train:0.9175 pre_train:0.8916 recall_train:0.9564 F1_train:0.9229 AUC_train:0.9670\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9227\n",
      "Epoch:0156\n",
      "acc_train:0.9225 pre_train:0.8909 recall_train:0.9685 F1_train:0.9281 AUC_train:0.9743\n",
      "acc_val:0.8652 pre_val:0.8235 recall_val:0.9333 F1_val:0.875000 AUC_val:0.9167\n",
      "Epoch:0157\n",
      "acc_train:0.9187 pre_train:0.8901 recall_train:0.9613 F1_train:0.9243 AUC_train:0.9755\n",
      "acc_val:0.8539 pre_val:0.8077 recall_val:0.9333 F1_val:0.865979 AUC_val:0.9121\n",
      "Epoch:0158\n",
      "acc_train:0.9162 pre_train:0.8844 recall_train:0.9637 F1_train:0.9224 AUC_train:0.9736\n",
      "acc_val:0.8652 pre_val:0.8235 recall_val:0.9333 F1_val:0.875000 AUC_val:0.9106\n",
      "Epoch:0159\n",
      "acc_train:0.9300 pre_train:0.9240 recall_train:0.9419 F1_train:0.9329 AUC_train:0.9795\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9111\n",
      "Epoch:0160\n",
      "acc_train:0.9312 pre_train:0.9163 recall_train:0.9540 F1_train:0.9348 AUC_train:0.9786\n",
      "acc_val:0.8876 pre_val:0.8571 recall_val:0.9333 F1_val:0.893617 AUC_val:0.9136\n",
      "Epoch:0161\n",
      "acc_train:0.9350 pre_train:0.9207 recall_train:0.9564 F1_train:0.9382 AUC_train:0.9740\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9194\n",
      "Epoch:0162\n",
      "acc_train:0.9300 pre_train:0.9142 recall_train:0.9540 F1_train:0.9336 AUC_train:0.9745\n",
      "acc_val:0.8876 pre_val:0.8571 recall_val:0.9333 F1_val:0.893617 AUC_val:0.9280\n",
      "Epoch:0163\n",
      "acc_train:0.9450 pre_train:0.9341 recall_train:0.9613 F1_train:0.9475 AUC_train:0.9719\n",
      "acc_val:0.8876 pre_val:0.8571 recall_val:0.9333 F1_val:0.893617 AUC_val:0.9346\n",
      "Epoch:0164\n",
      "acc_train:0.9162 pre_train:0.9023 recall_train:0.9395 F1_train:0.9205 AUC_train:0.9778\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9376\n",
      "Epoch:0165\n",
      "acc_train:0.9262 pre_train:0.9155 recall_train:0.9443 F1_train:0.9297 AUC_train:0.9660\n",
      "acc_val:0.8989 pre_val:0.8600 recall_val:0.9556 F1_val:0.905263 AUC_val:0.9399\n",
      "Epoch:0166\n",
      "acc_train:0.9325 pre_train:0.9284 recall_train:0.9419 F1_train:0.9351 AUC_train:0.9798\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9399\n",
      "Epoch:0167\n",
      "acc_train:0.9287 pre_train:0.9140 recall_train:0.9516 F1_train:0.9324 AUC_train:0.9769\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9404\n",
      "Epoch:0168\n",
      "acc_train:0.9200 pre_train:0.8939 recall_train:0.9588 F1_train:0.9252 AUC_train:0.9776\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9404\n",
      "Epoch:0169\n",
      "acc_train:0.9225 pre_train:0.8962 recall_train:0.9613 F1_train:0.9276 AUC_train:0.9784\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9399\n",
      "Epoch:0170\n",
      "acc_train:0.9325 pre_train:0.9108 recall_train:0.9637 F1_train:0.9365 AUC_train:0.9761\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0171\n",
      "acc_train:0.9287 pre_train:0.8991 recall_train:0.9709 F1_train:0.9336 AUC_train:0.9754\n",
      "acc_val:0.8989 pre_val:0.8600 recall_val:0.9556 F1_val:0.905263 AUC_val:0.9359\n",
      "Epoch:0172\n",
      "acc_train:0.9312 pre_train:0.9124 recall_train:0.9588 F1_train:0.9351 AUC_train:0.9846\n",
      "acc_val:0.8989 pre_val:0.8600 recall_val:0.9556 F1_val:0.905263 AUC_val:0.9343\n",
      "Epoch:0173\n",
      "acc_train:0.9425 pre_train:0.9297 recall_train:0.9613 F1_train:0.9452 AUC_train:0.9856\n",
      "acc_val:0.8989 pre_val:0.8600 recall_val:0.9556 F1_val:0.905263 AUC_val:0.9303\n",
      "Epoch:0174\n",
      "acc_train:0.9287 pre_train:0.9027 recall_train:0.9661 F1_train:0.9333 AUC_train:0.9774\n",
      "acc_val:0.8989 pre_val:0.8600 recall_val:0.9556 F1_val:0.905263 AUC_val:0.9268\n",
      "Epoch:0175\n",
      "acc_train:0.9300 pre_train:0.9142 recall_train:0.9540 F1_train:0.9336 AUC_train:0.9776\n",
      "acc_val:0.8876 pre_val:0.8431 recall_val:0.9556 F1_val:0.895833 AUC_val:0.9217\n",
      "Epoch:0176\n",
      "acc_train:0.9438 pre_train:0.9259 recall_train:0.9685 F1_train:0.9467 AUC_train:0.9850\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9157\n",
      "Epoch:0177\n",
      "acc_train:0.9325 pre_train:0.9165 recall_train:0.9564 F1_train:0.9360 AUC_train:0.9819\n",
      "acc_val:0.8764 pre_val:0.8400 recall_val:0.9333 F1_val:0.884211 AUC_val:0.9136\n",
      "Epoch:0178\n",
      "acc_train:0.9400 pre_train:0.9274 recall_train:0.9588 F1_train:0.9429 AUC_train:0.9833\n",
      "acc_val:0.8876 pre_val:0.8431 recall_val:0.9556 F1_val:0.895833 AUC_val:0.9146\n",
      "Epoch:0179\n",
      "acc_train:0.9375 pre_train:0.9172 recall_train:0.9661 F1_train:0.9410 AUC_train:0.9830\n",
      "acc_val:0.8876 pre_val:0.8431 recall_val:0.9556 F1_val:0.895833 AUC_val:0.9141\n",
      "Epoch:0180\n",
      "acc_train:0.9500 pre_train:0.9368 recall_train:0.9685 F1_train:0.9524 AUC_train:0.9869\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9116\n",
      "Epoch:0181\n",
      "acc_train:0.9413 pre_train:0.9357 recall_train:0.9516 F1_train:0.9436 AUC_train:0.9798\n",
      "acc_val:0.8539 pre_val:0.7963 recall_val:0.9556 F1_val:0.868687 AUC_val:0.9081\n",
      "Epoch:0182\n",
      "acc_train:0.9375 pre_train:0.9311 recall_train:0.9492 F1_train:0.9400 AUC_train:0.9797\n",
      "acc_val:0.8427 pre_val:0.7818 recall_val:0.9556 F1_val:0.860000 AUC_val:0.8970\n",
      "Epoch:0183\n",
      "acc_train:0.9425 pre_train:0.9465 recall_train:0.9419 F1_train:0.9442 AUC_train:0.9808\n",
      "acc_val:0.8539 pre_val:0.7963 recall_val:0.9556 F1_val:0.868687 AUC_val:0.8975\n",
      "Epoch:0184\n",
      "acc_train:0.9325 pre_train:0.9224 recall_train:0.9492 F1_train:0.9356 AUC_train:0.9844\n",
      "acc_val:0.8764 pre_val:0.8269 recall_val:0.9556 F1_val:0.886598 AUC_val:0.9131\n",
      "Epoch:0185\n",
      "acc_train:0.9463 pre_train:0.9405 recall_train:0.9564 F1_train:0.9484 AUC_train:0.9837\n",
      "acc_val:0.9101 pre_val:0.8776 recall_val:0.9556 F1_val:0.914894 AUC_val:0.9182\n",
      "Epoch:0186\n",
      "acc_train:0.9362 pre_train:0.9209 recall_train:0.9588 F1_train:0.9395 AUC_train:0.9774\n",
      "acc_val:0.9101 pre_val:0.8776 recall_val:0.9556 F1_val:0.914894 AUC_val:0.9232\n",
      "Epoch:0187\n",
      "acc_train:0.9475 pre_train:0.9385 recall_train:0.9613 F1_train:0.9498 AUC_train:0.9844\n",
      "acc_val:0.8876 pre_val:0.8571 recall_val:0.9333 F1_val:0.893617 AUC_val:0.9247\n",
      "Epoch:0188\n",
      "acc_train:0.9413 pre_train:0.9296 recall_train:0.9588 F1_train:0.9440 AUC_train:0.9784\n",
      "acc_val:0.8989 pre_val:0.8750 recall_val:0.9333 F1_val:0.903226 AUC_val:0.9242\n",
      "Epoch:0189\n",
      "acc_train:0.9413 pre_train:0.9598 recall_train:0.9249 F1_train:0.9420 AUC_train:0.9893\n",
      "acc_val:0.9101 pre_val:0.8936 recall_val:0.9333 F1_val:0.913043 AUC_val:0.9227\n",
      "Early Stopping!!! epoch：188\n",
      " Starting the 2-5 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 800\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4863 pre_train:0.5022 recall_train:0.5448 F1_train:0.5226 AUC_train:0.5026\n",
      "acc_val:0.5843 pre_val:0.5541 recall_val:0.9111 F1_val:0.689076 AUC_val:0.6177\n",
      "Epoch:0002\n",
      "acc_train:0.5213 pre_train:0.5354 recall_train:0.5496 F1_train:0.5424 AUC_train:0.5111\n",
      "acc_val:0.5281 pre_val:0.5185 recall_val:0.9333 F1_val:0.666667 AUC_val:0.7182\n",
      "Epoch:0003\n",
      "acc_train:0.4950 pre_train:0.5102 recall_train:0.5448 F1_train:0.5269 AUC_train:0.5211\n",
      "acc_val:0.4944 pre_val:0.5000 recall_val:0.9778 F1_val:0.661654 AUC_val:0.7717\n",
      "Epoch:0004\n",
      "acc_train:0.5487 pre_train:0.5591 recall_train:0.5956 F1_train:0.5768 AUC_train:0.5806\n",
      "acc_val:0.4944 pre_val:0.5000 recall_val:0.9778 F1_val:0.661654 AUC_val:0.7763\n",
      "Epoch:0005\n",
      "acc_train:0.5562 pre_train:0.5587 recall_train:0.6683 F1_train:0.6086 AUC_train:0.5880\n",
      "acc_val:0.4944 pre_val:0.5000 recall_val:0.9556 F1_val:0.656489 AUC_val:0.7919\n",
      "Epoch:0006\n",
      "acc_train:0.5462 pre_train:0.5665 recall_train:0.5157 F1_train:0.5399 AUC_train:0.5674\n",
      "acc_val:0.6180 pre_val:0.5733 recall_val:0.9556 F1_val:0.716667 AUC_val:0.7919\n",
      "Epoch:0007\n",
      "acc_train:0.5650 pre_train:0.5831 recall_train:0.5521 F1_train:0.5672 AUC_train:0.5821\n",
      "acc_val:0.6180 pre_val:0.5733 recall_val:0.9556 F1_val:0.716667 AUC_val:0.7914\n",
      "Epoch:0008\n",
      "acc_train:0.5375 pre_train:0.5392 recall_train:0.7167 F1_train:0.6154 AUC_train:0.6123\n",
      "acc_val:0.6292 pre_val:0.5811 recall_val:0.9556 F1_val:0.722689 AUC_val:0.7995\n",
      "Epoch:0009\n",
      "acc_train:0.5825 pre_train:0.5846 recall_train:0.6610 F1_train:0.6205 AUC_train:0.6268\n",
      "acc_val:0.6629 pre_val:0.6154 recall_val:0.8889 F1_val:0.727273 AUC_val:0.8005\n",
      "Epoch:0010\n",
      "acc_train:0.5813 pre_train:0.6010 recall_train:0.5617 F1_train:0.5807 AUC_train:0.6052\n",
      "acc_val:0.6517 pre_val:0.6000 recall_val:0.9333 F1_val:0.730435 AUC_val:0.8010\n",
      "Epoch:0011\n",
      "acc_train:0.5700 pre_train:0.5613 recall_train:0.7651 F1_train:0.6475 AUC_train:0.6451\n",
      "acc_val:0.5843 pre_val:0.5500 recall_val:0.9778 F1_val:0.704000 AUC_val:0.8106\n",
      "Epoch:0012\n",
      "acc_train:0.6463 pre_train:0.7257 recall_train:0.5061 F1_train:0.5963 AUC_train:0.6652\n",
      "acc_val:0.6517 pre_val:0.5972 recall_val:0.9556 F1_val:0.735043 AUC_val:0.7894\n",
      "Epoch:0013\n",
      "acc_train:0.5050 pre_train:0.5125 recall_train:0.8450 F1_train:0.6380 AUC_train:0.5972\n",
      "acc_val:0.5730 pre_val:0.5443 recall_val:0.9556 F1_val:0.693548 AUC_val:0.7884\n",
      "Epoch:0014\n",
      "acc_train:0.5725 pre_train:0.5744 recall_train:0.6634 F1_train:0.6157 AUC_train:0.6132\n",
      "acc_val:0.6292 pre_val:0.5811 recall_val:0.9556 F1_val:0.722689 AUC_val:0.7823\n",
      "Epoch:0015\n",
      "acc_train:0.6325 pre_train:0.6695 recall_train:0.5690 F1_train:0.6152 AUC_train:0.6360\n",
      "acc_val:0.6742 pre_val:0.6176 recall_val:0.9333 F1_val:0.743363 AUC_val:0.7854\n",
      "Epoch:0016\n",
      "acc_train:0.6187 pre_train:0.6467 recall_train:0.5763 F1_train:0.6095 AUC_train:0.6309\n",
      "acc_val:0.6966 pre_val:0.6500 recall_val:0.8667 F1_val:0.742857 AUC_val:0.7869\n",
      "Epoch:0017\n",
      "acc_train:0.6263 pre_train:0.6377 recall_train:0.6392 F1_train:0.6385 AUC_train:0.6695\n",
      "acc_val:0.7079 pre_val:0.6610 recall_val:0.8667 F1_val:0.750000 AUC_val:0.7848\n",
      "Epoch:0018\n",
      "acc_train:0.5875 pre_train:0.5904 recall_train:0.6562 F1_train:0.6216 AUC_train:0.6330\n",
      "acc_val:0.7303 pre_val:0.6780 recall_val:0.8889 F1_val:0.769231 AUC_val:0.8035\n",
      "Epoch:0019\n",
      "acc_train:0.6325 pre_train:0.6491 recall_train:0.6271 F1_train:0.6379 AUC_train:0.6720\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8035\n",
      "Epoch:0020\n",
      "acc_train:0.6338 pre_train:0.6829 recall_train:0.5424 F1_train:0.6046 AUC_train:0.6708\n",
      "acc_val:0.7303 pre_val:0.6909 recall_val:0.8444 F1_val:0.760000 AUC_val:0.8051\n",
      "Epoch:0021\n",
      "acc_train:0.6050 pre_train:0.6192 recall_train:0.6102 F1_train:0.6146 AUC_train:0.6362\n",
      "acc_val:0.7303 pre_val:0.6909 recall_val:0.8444 F1_val:0.760000 AUC_val:0.8061\n",
      "Epoch:0022\n",
      "acc_train:0.6263 pre_train:0.6208 recall_train:0.7094 F1_train:0.6621 AUC_train:0.6715\n",
      "acc_val:0.7191 pre_val:0.6786 recall_val:0.8444 F1_val:0.752475 AUC_val:0.8086\n",
      "Epoch:0023\n",
      "acc_train:0.6425 pre_train:0.7096 recall_train:0.5206 F1_train:0.6006 AUC_train:0.6648\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8086\n",
      "Epoch:0024\n",
      "acc_train:0.6050 pre_train:0.5992 recall_train:0.7094 F1_train:0.6497 AUC_train:0.6450\n",
      "acc_val:0.7191 pre_val:0.6724 recall_val:0.8667 F1_val:0.757282 AUC_val:0.8096\n",
      "Epoch:0025\n",
      "acc_train:0.6075 pre_train:0.6199 recall_train:0.6199 F1_train:0.6199 AUC_train:0.6469\n",
      "acc_val:0.7303 pre_val:0.6780 recall_val:0.8889 F1_val:0.769231 AUC_val:0.8106\n",
      "Epoch:0026\n",
      "acc_train:0.6388 pre_train:0.6360 recall_train:0.7022 F1_train:0.6674 AUC_train:0.6715\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8131\n",
      "Epoch:0027\n",
      "acc_train:0.6263 pre_train:0.6439 recall_train:0.6174 F1_train:0.6304 AUC_train:0.6560\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8157\n",
      "Epoch:0028\n",
      "acc_train:0.6200 pre_train:0.6157 recall_train:0.7022 F1_train:0.6561 AUC_train:0.6624\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8167\n",
      "Epoch:0029\n",
      "acc_train:0.6062 pre_train:0.5988 recall_train:0.7191 F1_train:0.6535 AUC_train:0.6766\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8207\n",
      "Epoch:0030\n",
      "acc_train:0.6363 pre_train:0.6160 recall_train:0.7845 F1_train:0.6901 AUC_train:0.6900\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8207\n",
      "Epoch:0031\n",
      "acc_train:0.6150 pre_train:0.6023 recall_train:0.7482 F1_train:0.6674 AUC_train:0.6830\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8232\n",
      "Epoch:0032\n",
      "acc_train:0.5850 pre_train:0.5717 recall_train:0.7821 F1_train:0.6605 AUC_train:0.6349\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8268\n",
      "Epoch:0033\n",
      "acc_train:0.6425 pre_train:0.6348 recall_train:0.7240 F1_train:0.6765 AUC_train:0.7030\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8273\n",
      "Epoch:0034\n",
      "acc_train:0.6313 pre_train:0.6239 recall_train:0.7191 F1_train:0.6682 AUC_train:0.6777\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8278\n",
      "Epoch:0035\n",
      "acc_train:0.6275 pre_train:0.6171 recall_train:0.7337 F1_train:0.6704 AUC_train:0.6766\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0036\n",
      "acc_train:0.6112 pre_train:0.6024 recall_train:0.7264 F1_train:0.6586 AUC_train:0.6555\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8318\n",
      "Epoch:0037\n",
      "acc_train:0.6263 pre_train:0.6319 recall_train:0.6610 F1_train:0.6462 AUC_train:0.6736\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8288\n",
      "Epoch:0038\n",
      "acc_train:0.6300 pre_train:0.6232 recall_train:0.7167 F1_train:0.6667 AUC_train:0.6789\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8192\n",
      "Epoch:0039\n",
      "acc_train:0.6662 pre_train:0.6921 recall_train:0.6368 F1_train:0.6633 AUC_train:0.6925\n",
      "acc_val:0.7079 pre_val:0.6610 recall_val:0.8667 F1_val:0.750000 AUC_val:0.8177\n",
      "Epoch:0040\n",
      "acc_train:0.6363 pre_train:0.6164 recall_train:0.7821 F1_train:0.6894 AUC_train:0.6956\n",
      "acc_val:0.6966 pre_val:0.6552 recall_val:0.8444 F1_val:0.737864 AUC_val:0.7919\n",
      "Epoch:0041\n",
      "acc_train:0.6325 pre_train:0.6285 recall_train:0.7046 F1_train:0.6644 AUC_train:0.6812\n",
      "acc_val:0.6966 pre_val:0.6552 recall_val:0.8444 F1_val:0.737864 AUC_val:0.7894\n",
      "Epoch:0042\n",
      "acc_train:0.6125 pre_train:0.5966 recall_train:0.7700 F1_train:0.6723 AUC_train:0.6463\n",
      "acc_val:0.6966 pre_val:0.6552 recall_val:0.8444 F1_val:0.737864 AUC_val:0.7970\n",
      "Epoch:0043\n",
      "acc_train:0.6100 pre_train:0.5992 recall_train:0.7385 F1_train:0.6616 AUC_train:0.6696\n",
      "acc_val:0.6966 pre_val:0.6552 recall_val:0.8444 F1_val:0.737864 AUC_val:0.8015\n",
      "Epoch:0044\n",
      "acc_train:0.6513 pre_train:0.6414 recall_train:0.7361 F1_train:0.6855 AUC_train:0.7238\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8303\n",
      "Epoch:0045\n",
      "acc_train:0.5913 pre_train:0.5821 recall_train:0.7385 F1_train:0.6510 AUC_train:0.6611\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8313\n",
      "Epoch:0046\n",
      "acc_train:0.6413 pre_train:0.6370 recall_train:0.7094 F1_train:0.6712 AUC_train:0.7000\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8303\n",
      "Epoch:0047\n",
      "acc_train:0.6288 pre_train:0.6133 recall_train:0.7603 F1_train:0.6789 AUC_train:0.7015\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8278\n",
      "Epoch:0048\n",
      "acc_train:0.6400 pre_train:0.6437 recall_train:0.6780 F1_train:0.6604 AUC_train:0.6945\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8273\n",
      "Epoch:0049\n",
      "acc_train:0.6388 pre_train:0.6260 recall_train:0.7458 F1_train:0.6807 AUC_train:0.6968\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8253\n",
      "Epoch:0050\n",
      "acc_train:0.6450 pre_train:0.6287 recall_train:0.7627 F1_train:0.6893 AUC_train:0.7166\n",
      "acc_val:0.7191 pre_val:0.6667 recall_val:0.8889 F1_val:0.761905 AUC_val:0.8268\n",
      "Epoch:0051\n",
      "acc_train:0.6425 pre_train:0.6383 recall_train:0.7094 F1_train:0.6720 AUC_train:0.7184\n",
      "acc_val:0.7303 pre_val:0.6780 recall_val:0.8889 F1_val:0.769231 AUC_val:0.8268\n",
      "Epoch:0052\n",
      "acc_train:0.6300 pre_train:0.6269 recall_train:0.6998 F1_train:0.6613 AUC_train:0.6938\n",
      "acc_val:0.7303 pre_val:0.6780 recall_val:0.8889 F1_val:0.769231 AUC_val:0.8278\n",
      "Epoch:0053\n",
      "acc_train:0.6787 pre_train:0.6653 recall_train:0.7603 F1_train:0.7096 AUC_train:0.7214\n",
      "acc_val:0.7416 pre_val:0.6897 recall_val:0.8889 F1_val:0.776699 AUC_val:0.8268\n",
      "Epoch:0054\n",
      "acc_train:0.6500 pre_train:0.6360 recall_train:0.7530 F1_train:0.6896 AUC_train:0.7066\n",
      "acc_val:0.7416 pre_val:0.6897 recall_val:0.8889 F1_val:0.776699 AUC_val:0.8247\n",
      "Epoch:0055\n",
      "acc_train:0.6675 pre_train:0.6509 recall_train:0.7676 F1_train:0.7044 AUC_train:0.7333\n",
      "acc_val:0.7528 pre_val:0.7018 recall_val:0.8889 F1_val:0.784314 AUC_val:0.8278\n",
      "Epoch:0056\n",
      "acc_train:0.6662 pre_train:0.6521 recall_train:0.7579 F1_train:0.7010 AUC_train:0.7325\n",
      "acc_val:0.7753 pre_val:0.7193 recall_val:0.9111 F1_val:0.803922 AUC_val:0.8338\n",
      "Epoch:0057\n",
      "acc_train:0.6750 pre_train:0.6527 recall_train:0.7918 F1_train:0.7155 AUC_train:0.7295\n",
      "acc_val:0.7865 pre_val:0.7321 recall_val:0.9111 F1_val:0.811881 AUC_val:0.8384\n",
      "Epoch:0058\n",
      "acc_train:0.6938 pre_train:0.6780 recall_train:0.7748 F1_train:0.7232 AUC_train:0.7473\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8384\n",
      "Epoch:0059\n",
      "acc_train:0.6950 pre_train:0.6874 recall_train:0.7506 F1_train:0.7176 AUC_train:0.7546\n",
      "acc_val:0.7528 pre_val:0.7170 recall_val:0.8444 F1_val:0.775510 AUC_val:0.8409\n",
      "Epoch:0060\n",
      "acc_train:0.6700 pre_train:0.6652 recall_train:0.7264 F1_train:0.6944 AUC_train:0.7523\n",
      "acc_val:0.7528 pre_val:0.7170 recall_val:0.8444 F1_val:0.775510 AUC_val:0.8434\n",
      "Epoch:0061\n",
      "acc_train:0.7000 pre_train:0.6784 recall_train:0.7966 F1_train:0.7327 AUC_train:0.7734\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.8485\n",
      "Epoch:0062\n",
      "acc_train:0.6975 pre_train:0.6966 recall_train:0.7337 F1_train:0.7146 AUC_train:0.7566\n",
      "acc_val:0.7528 pre_val:0.7347 recall_val:0.8000 F1_val:0.765957 AUC_val:0.8520\n",
      "Epoch:0063\n",
      "acc_train:0.6888 pre_train:0.7081 recall_train:0.6755 F1_train:0.6914 AUC_train:0.7549\n",
      "acc_val:0.7528 pre_val:0.7255 recall_val:0.8222 F1_val:0.770833 AUC_val:0.8535\n",
      "Epoch:0064\n",
      "acc_train:0.7050 pre_train:0.7053 recall_train:0.7361 F1_train:0.7204 AUC_train:0.7834\n",
      "acc_val:0.7528 pre_val:0.7170 recall_val:0.8444 F1_val:0.775510 AUC_val:0.8540\n",
      "Epoch:0065\n",
      "acc_train:0.7063 pre_train:0.6943 recall_train:0.7700 F1_train:0.7302 AUC_train:0.7818\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8561\n",
      "Epoch:0066\n",
      "acc_train:0.7250 pre_train:0.7169 recall_train:0.7724 F1_train:0.7436 AUC_train:0.7804\n",
      "acc_val:0.7640 pre_val:0.7222 recall_val:0.8667 F1_val:0.787879 AUC_val:0.8545\n",
      "Epoch:0067\n",
      "acc_train:0.7650 pre_train:0.7462 recall_train:0.8257 F1_train:0.7839 AUC_train:0.8065\n",
      "acc_val:0.7528 pre_val:0.7018 recall_val:0.8889 F1_val:0.784314 AUC_val:0.8480\n",
      "Epoch:0068\n",
      "acc_train:0.7450 pre_train:0.7348 recall_train:0.7918 F1_train:0.7622 AUC_train:0.7877\n",
      "acc_val:0.7303 pre_val:0.6842 recall_val:0.8667 F1_val:0.764706 AUC_val:0.8354\n",
      "Epoch:0069\n",
      "acc_train:0.7487 pre_train:0.7294 recall_train:0.8160 F1_train:0.7703 AUC_train:0.8019\n",
      "acc_val:0.7303 pre_val:0.6842 recall_val:0.8667 F1_val:0.764706 AUC_val:0.8364\n",
      "Epoch:0070\n",
      "acc_train:0.7650 pre_train:0.7339 recall_train:0.8547 F1_train:0.7897 AUC_train:0.8204\n",
      "acc_val:0.7640 pre_val:0.7069 recall_val:0.9111 F1_val:0.796117 AUC_val:0.8631\n",
      "Epoch:0071\n",
      "acc_train:0.7613 pre_train:0.7220 recall_train:0.8741 F1_train:0.7908 AUC_train:0.8144\n",
      "acc_val:0.7416 pre_val:0.6897 recall_val:0.8889 F1_val:0.776699 AUC_val:0.8465\n",
      "Epoch:0072\n",
      "acc_train:0.7925 pre_train:0.7526 recall_train:0.8910 F1_train:0.8160 AUC_train:0.8301\n",
      "acc_val:0.7528 pre_val:0.7018 recall_val:0.8889 F1_val:0.784314 AUC_val:0.8505\n",
      "Epoch:0073\n",
      "acc_train:0.7987 pre_train:0.7561 recall_train:0.9007 F1_train:0.8221 AUC_train:0.8302\n",
      "acc_val:0.7640 pre_val:0.7069 recall_val:0.9111 F1_val:0.796117 AUC_val:0.8717\n",
      "Epoch:0074\n",
      "acc_train:0.8087 pre_train:0.7610 recall_train:0.9177 F1_train:0.8321 AUC_train:0.8580\n",
      "acc_val:0.7978 pre_val:0.7368 recall_val:0.9333 F1_val:0.823529 AUC_val:0.8753\n",
      "Epoch:0075\n",
      "acc_train:0.7962 pre_train:0.7480 recall_train:0.9128 F1_train:0.8222 AUC_train:0.8530\n",
      "acc_val:0.7865 pre_val:0.7321 recall_val:0.9111 F1_val:0.811881 AUC_val:0.8823\n",
      "Epoch:0076\n",
      "acc_train:0.8087 pre_train:0.7653 recall_train:0.9080 F1_train:0.8306 AUC_train:0.8566\n",
      "acc_val:0.7865 pre_val:0.7407 recall_val:0.8889 F1_val:0.808081 AUC_val:0.8859\n",
      "Epoch:0077\n",
      "acc_train:0.8338 pre_train:0.7917 recall_train:0.9201 F1_train:0.8511 AUC_train:0.8715\n",
      "acc_val:0.7865 pre_val:0.7407 recall_val:0.8889 F1_val:0.808081 AUC_val:0.8884\n",
      "Epoch:0078\n",
      "acc_train:0.8537 pre_train:0.7996 recall_train:0.9564 F1_train:0.8710 AUC_train:0.8868\n",
      "acc_val:0.7978 pre_val:0.7547 recall_val:0.8889 F1_val:0.816327 AUC_val:0.8722\n",
      "Epoch:0079\n",
      "acc_train:0.8263 pre_train:0.7718 recall_train:0.9419 F1_train:0.8484 AUC_train:0.8722\n",
      "acc_val:0.8090 pre_val:0.7692 recall_val:0.8889 F1_val:0.824742 AUC_val:0.8742\n",
      "Epoch:0080\n",
      "acc_train:0.8587 pre_train:0.8061 recall_train:0.9564 F1_train:0.8749 AUC_train:0.9000\n",
      "acc_val:0.8202 pre_val:0.7843 recall_val:0.8889 F1_val:0.833333 AUC_val:0.8768\n",
      "Epoch:0081\n",
      "acc_train:0.8475 pre_train:0.7975 recall_train:0.9443 F1_train:0.8647 AUC_train:0.8883\n",
      "acc_val:0.8090 pre_val:0.7692 recall_val:0.8889 F1_val:0.824742 AUC_val:0.8828\n",
      "Epoch:0082\n",
      "acc_train:0.8525 pre_train:0.7992 recall_train:0.9540 F1_train:0.8698 AUC_train:0.9056\n",
      "acc_val:0.7978 pre_val:0.7547 recall_val:0.8889 F1_val:0.816327 AUC_val:0.8859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0083\n",
      "acc_train:0.8662 pre_train:0.8122 recall_train:0.9637 F1_train:0.8815 AUC_train:0.9189\n",
      "acc_val:0.7978 pre_val:0.7455 recall_val:0.9111 F1_val:0.820000 AUC_val:0.8874\n",
      "Epoch:0084\n",
      "acc_train:0.8800 pre_train:0.8309 recall_train:0.9637 F1_train:0.8924 AUC_train:0.9285\n",
      "acc_val:0.7865 pre_val:0.7321 recall_val:0.9111 F1_val:0.811881 AUC_val:0.8904\n",
      "Epoch:0085\n",
      "acc_train:0.8650 pre_train:0.8184 recall_train:0.9492 F1_train:0.8789 AUC_train:0.9269\n",
      "acc_val:0.7865 pre_val:0.7241 recall_val:0.9333 F1_val:0.815534 AUC_val:0.8929\n",
      "Epoch:0086\n",
      "acc_train:0.8712 pre_train:0.8163 recall_train:0.9685 F1_train:0.8859 AUC_train:0.9349\n",
      "acc_val:0.7865 pre_val:0.7241 recall_val:0.9333 F1_val:0.815534 AUC_val:0.8919\n",
      "Epoch:0087\n",
      "acc_train:0.8788 pre_train:0.8251 recall_train:0.9709 F1_train:0.8921 AUC_train:0.9372\n",
      "acc_val:0.7753 pre_val:0.7193 recall_val:0.9111 F1_val:0.803922 AUC_val:0.8934\n",
      "Epoch:0088\n",
      "acc_train:0.8838 pre_train:0.8320 recall_train:0.9709 F1_train:0.8961 AUC_train:0.9339\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.8955\n",
      "Epoch:0089\n",
      "acc_train:0.8900 pre_train:0.8378 recall_train:0.9758 F1_train:0.9016 AUC_train:0.9307\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.8967\n",
      "Epoch:0090\n",
      "acc_train:0.9000 pre_train:0.8627 recall_train:0.9588 F1_train:0.9083 AUC_train:0.9506\n",
      "acc_val:0.7640 pre_val:0.6935 recall_val:0.9556 F1_val:0.803738 AUC_val:0.9008\n",
      "Epoch:0091\n",
      "acc_train:0.9125 pre_train:0.8720 recall_train:0.9734 F1_train:0.9199 AUC_train:0.9507\n",
      "acc_val:0.7528 pre_val:0.6885 recall_val:0.9333 F1_val:0.792453 AUC_val:0.9056\n",
      "Epoch:0092\n",
      "acc_train:0.8975 pre_train:0.8544 recall_train:0.9661 F1_train:0.9068 AUC_train:0.9396\n",
      "acc_val:0.7640 pre_val:0.7000 recall_val:0.9333 F1_val:0.800000 AUC_val:0.9056\n",
      "Epoch:0093\n",
      "acc_train:0.8963 pre_train:0.8511 recall_train:0.9685 F1_train:0.9060 AUC_train:0.9460\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9159\n",
      "Epoch:0094\n",
      "acc_train:0.9087 pre_train:0.8648 recall_train:0.9758 F1_train:0.9170 AUC_train:0.9419\n",
      "acc_val:0.7640 pre_val:0.7000 recall_val:0.9333 F1_val:0.800000 AUC_val:0.9121\n",
      "Epoch:0095\n",
      "acc_train:0.9050 pre_train:0.8608 recall_train:0.9734 F1_train:0.9136 AUC_train:0.9491\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9091\n",
      "Epoch:0096\n",
      "acc_train:0.9275 pre_train:0.8953 recall_train:0.9734 F1_train:0.9327 AUC_train:0.9556\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.9247\n",
      "Epoch:0097\n",
      "acc_train:0.9237 pre_train:0.8843 recall_train:0.9806 F1_train:0.9300 AUC_train:0.9616\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9354\n",
      "Epoch:0098\n",
      "acc_train:0.9262 pre_train:0.8899 recall_train:0.9782 F1_train:0.9319 AUC_train:0.9638\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9434\n",
      "Epoch:0099\n",
      "acc_train:0.9212 pre_train:0.8855 recall_train:0.9734 F1_train:0.9273 AUC_train:0.9641\n",
      "acc_val:0.8202 pre_val:0.7458 recall_val:0.9778 F1_val:0.846154 AUC_val:0.9419\n",
      "Epoch:0100\n",
      "acc_train:0.9275 pre_train:0.8850 recall_train:0.9879 F1_train:0.9336 AUC_train:0.9536\n",
      "acc_val:0.8539 pre_val:0.7857 recall_val:0.9778 F1_val:0.871287 AUC_val:0.9404\n",
      "Epoch:0101\n",
      "acc_train:0.9187 pre_train:0.8799 recall_train:0.9758 F1_train:0.9254 AUC_train:0.9704\n",
      "acc_val:0.8652 pre_val:0.8113 recall_val:0.9556 F1_val:0.877551 AUC_val:0.9404\n",
      "Epoch:0102\n",
      "acc_train:0.9225 pre_train:0.8857 recall_train:0.9758 F1_train:0.9286 AUC_train:0.9577\n",
      "acc_val:0.8427 pre_val:0.7818 recall_val:0.9556 F1_val:0.860000 AUC_val:0.9394\n",
      "Epoch:0103\n",
      "acc_train:0.9312 pre_train:0.9013 recall_train:0.9734 F1_train:0.9360 AUC_train:0.9551\n",
      "acc_val:0.8315 pre_val:0.7679 recall_val:0.9556 F1_val:0.851485 AUC_val:0.9379\n",
      "Epoch:0104\n",
      "acc_train:0.9413 pre_train:0.9067 recall_train:0.9879 F1_train:0.9455 AUC_train:0.9765\n",
      "acc_val:0.8315 pre_val:0.7586 recall_val:0.9778 F1_val:0.854369 AUC_val:0.9364\n",
      "Epoch:0105\n",
      "acc_train:0.9362 pre_train:0.9022 recall_train:0.9831 F1_train:0.9409 AUC_train:0.9617\n",
      "acc_val:0.8090 pre_val:0.7333 recall_val:0.9778 F1_val:0.838095 AUC_val:0.9434\n",
      "Epoch:0106\n",
      "acc_train:0.9400 pre_train:0.9065 recall_train:0.9855 F1_train:0.9443 AUC_train:0.9733\n",
      "acc_val:0.7978 pre_val:0.7213 recall_val:0.9778 F1_val:0.830189 AUC_val:0.9455\n",
      "Epoch:0107\n",
      "acc_train:0.9350 pre_train:0.9002 recall_train:0.9831 F1_train:0.9398 AUC_train:0.9683\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.9449\n",
      "Epoch:0108\n",
      "acc_train:0.9400 pre_train:0.9029 recall_train:0.9903 F1_train:0.9446 AUC_train:0.9814\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9422\n",
      "Epoch:0109\n",
      "acc_train:0.9525 pre_train:0.9291 recall_train:0.9831 F1_train:0.9553 AUC_train:0.9870\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9331\n",
      "Epoch:0110\n",
      "acc_train:0.9413 pre_train:0.9122 recall_train:0.9806 F1_train:0.9452 AUC_train:0.9767\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.9290\n",
      "Epoch:0111\n",
      "acc_train:0.9337 pre_train:0.8930 recall_train:0.9903 F1_train:0.9392 AUC_train:0.9694\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9260\n",
      "Epoch:0112\n",
      "acc_train:0.9362 pre_train:0.9095 recall_train:0.9734 F1_train:0.9404 AUC_train:0.9760\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9250\n",
      "Epoch:0113\n",
      "acc_train:0.9475 pre_train:0.9169 recall_train:0.9879 F1_train:0.9510 AUC_train:0.9789\n",
      "acc_val:0.7528 pre_val:0.6825 recall_val:0.9556 F1_val:0.796296 AUC_val:0.9336\n",
      "Epoch:0114\n",
      "acc_train:0.9538 pre_train:0.9273 recall_train:0.9879 F1_train:0.9566 AUC_train:0.9801\n",
      "acc_val:0.7640 pre_val:0.6935 recall_val:0.9556 F1_val:0.803738 AUC_val:0.9366\n",
      "Epoch:0115\n",
      "acc_train:0.9488 pre_train:0.9227 recall_train:0.9831 F1_train:0.9519 AUC_train:0.9800\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9348\n",
      "Epoch:0116\n",
      "acc_train:0.9463 pre_train:0.9282 recall_train:0.9709 F1_train:0.9491 AUC_train:0.9813\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.9374\n",
      "Epoch:0117\n",
      "acc_train:0.9375 pre_train:0.9192 recall_train:0.9637 F1_train:0.9409 AUC_train:0.9793\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.9366\n",
      "Epoch:0118\n",
      "acc_train:0.9513 pre_train:0.9212 recall_train:0.9903 F1_train:0.9545 AUC_train:0.9855\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.9366\n",
      "Epoch:0119\n",
      "acc_train:0.9463 pre_train:0.9224 recall_train:0.9782 F1_train:0.9495 AUC_train:0.9845\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.9394\n",
      "Epoch:0120\n",
      "acc_train:0.9438 pre_train:0.9163 recall_train:0.9806 F1_train:0.9474 AUC_train:0.9814\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.9434\n",
      "Epoch:0121\n",
      "acc_train:0.9488 pre_train:0.9170 recall_train:0.9903 F1_train:0.9523 AUC_train:0.9920\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:0.9778 F1_val:0.792793 AUC_val:0.9472\n",
      "Early Stopping!!! epoch：120\n",
      "Loading the Model for the 2-th Fold:... ... Size of samples in the test set:223\n",
      "Fold 2 Results: test acc:0.6413 test_pre:0.6129 test_recall:0.8261 test_F1:0.7037 test_AUC:0.6769 time:490.102s\n",
      "Size of the 3-fold Training, Validation, and Test Sets:801,89,222\n",
      " Starting the 3-1 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.3858 pre_train:0.3833 recall_train:0.3382 F1_train:0.3594 AUC_train:0.3459\n",
      "acc_val:0.5618 pre_val:0.5682 recall_val:0.9804 F1_val:0.719424 AUC_val:0.5351\n",
      "Epoch:0002\n",
      "acc_train:0.4644 pre_train:0.4717 recall_train:0.4289 F1_train:0.4493 AUC_train:0.4258\n",
      "acc_val:0.5618 pre_val:0.5682 recall_val:0.9804 F1_val:0.719424 AUC_val:0.6089\n",
      "Epoch:0003\n",
      "acc_train:0.4282 pre_train:0.4238 recall_train:0.3407 F1_train:0.3777 AUC_train:0.4086\n",
      "acc_val:0.5843 pre_val:0.5833 recall_val:0.9608 F1_val:0.725926 AUC_val:0.6285\n",
      "Epoch:0004\n",
      "acc_train:0.4919 pre_train:0.5014 recall_train:0.4314 F1_train:0.4638 AUC_train:0.4833\n",
      "acc_val:0.6180 pre_val:0.6349 recall_val:0.7843 F1_val:0.701754 AUC_val:0.7059\n",
      "Epoch:0005\n",
      "acc_train:0.5481 pre_train:0.5569 recall_train:0.5515 F1_train:0.5542 AUC_train:0.5727\n",
      "acc_val:0.6742 pre_val:0.8438 recall_val:0.5294 F1_val:0.650602 AUC_val:0.7312\n",
      "Epoch:0006\n",
      "acc_train:0.5643 pre_train:0.6139 recall_train:0.3897 F1_train:0.4768 AUC_train:0.5560\n",
      "acc_val:0.6854 pre_val:0.9259 recall_val:0.4902 F1_val:0.641026 AUC_val:0.7441\n",
      "Epoch:0007\n",
      "acc_train:0.5318 pre_train:0.5587 recall_train:0.3848 F1_train:0.4557 AUC_train:0.5334\n",
      "acc_val:0.6854 pre_val:0.8966 recall_val:0.5098 F1_val:0.650000 AUC_val:0.7621\n",
      "Epoch:0008\n",
      "acc_train:0.5730 pre_train:0.6473 recall_train:0.3554 F1_train:0.4589 AUC_train:0.5802\n",
      "acc_val:0.6854 pre_val:0.8966 recall_val:0.5098 F1_val:0.650000 AUC_val:0.7647\n",
      "Epoch:0009\n",
      "acc_train:0.5918 pre_train:0.7238 recall_train:0.3211 F1_train:0.4448 AUC_train:0.6001\n",
      "acc_val:0.6966 pre_val:0.9286 recall_val:0.5098 F1_val:0.658228 AUC_val:0.7580\n",
      "Epoch:0010\n",
      "acc_train:0.5793 pre_train:0.6766 recall_train:0.3333 F1_train:0.4466 AUC_train:0.5939\n",
      "acc_val:0.6854 pre_val:0.8966 recall_val:0.5098 F1_val:0.650000 AUC_val:0.7539\n",
      "Epoch:0011\n",
      "acc_train:0.5668 pre_train:0.6063 recall_train:0.4265 F1_train:0.5007 AUC_train:0.5964\n",
      "acc_val:0.6854 pre_val:0.8966 recall_val:0.5098 F1_val:0.650000 AUC_val:0.7162\n",
      "Epoch:0012\n",
      "acc_train:0.6030 pre_train:0.7045 recall_train:0.3799 F1_train:0.4936 AUC_train:0.6223\n",
      "acc_val:0.6854 pre_val:0.8966 recall_val:0.5098 F1_val:0.650000 AUC_val:0.7208\n",
      "Epoch:0013\n",
      "acc_train:0.6017 pre_train:0.7032 recall_train:0.3775 F1_train:0.4912 AUC_train:0.6686\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.7206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0014\n",
      "acc_train:0.5943 pre_train:0.6084 recall_train:0.5711 F1_train:0.5891 AUC_train:0.6042\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.7379\n",
      "Epoch:0015\n",
      "acc_train:0.5718 pre_train:0.6526 recall_train:0.3407 F1_train:0.4477 AUC_train:0.5849\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.7451\n",
      "Epoch:0016\n",
      "acc_train:0.5968 pre_train:0.7136 recall_train:0.3480 F1_train:0.4679 AUC_train:0.6181\n",
      "acc_val:0.6966 pre_val:0.9286 recall_val:0.5098 F1_val:0.658228 AUC_val:0.6904\n",
      "Epoch:0017\n",
      "acc_train:0.5918 pre_train:0.7189 recall_train:0.3260 F1_train:0.4486 AUC_train:0.6174\n",
      "acc_val:0.6629 pre_val:0.9565 recall_val:0.4314 F1_val:0.594595 AUC_val:0.6930\n",
      "Epoch:0018\n",
      "acc_train:0.5768 pre_train:0.6520 recall_train:0.3627 F1_train:0.4661 AUC_train:0.6383\n",
      "acc_val:0.6742 pre_val:0.9583 recall_val:0.4510 F1_val:0.613333 AUC_val:0.6966\n",
      "Epoch:0019\n",
      "acc_train:0.5918 pre_train:0.6640 recall_train:0.4020 F1_train:0.5008 AUC_train:0.6210\n",
      "acc_val:0.6742 pre_val:0.9583 recall_val:0.4510 F1_val:0.613333 AUC_val:0.7002\n",
      "Epoch:0020\n",
      "acc_train:0.5830 pre_train:0.6542 recall_train:0.3848 F1_train:0.4846 AUC_train:0.6239\n",
      "acc_val:0.6742 pre_val:0.9583 recall_val:0.4510 F1_val:0.613333 AUC_val:0.6992\n",
      "Epoch:0021\n",
      "acc_train:0.6255 pre_train:0.7571 recall_train:0.3897 F1_train:0.5146 AUC_train:0.6461\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7012\n",
      "Epoch:0022\n",
      "acc_train:0.6005 pre_train:0.6654 recall_train:0.4338 F1_train:0.5252 AUC_train:0.6514\n",
      "acc_val:0.6966 pre_val:0.9615 recall_val:0.4902 F1_val:0.649351 AUC_val:0.7033\n",
      "Epoch:0023\n",
      "acc_train:0.5930 pre_train:0.6015 recall_train:0.5956 F1_train:0.5985 AUC_train:0.6432\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.6961\n",
      "Epoch:0024\n",
      "acc_train:0.6155 pre_train:0.6761 recall_train:0.4706 F1_train:0.5549 AUC_train:0.6233\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.7105\n",
      "Epoch:0025\n",
      "acc_train:0.6429 pre_train:0.7480 recall_train:0.4510 F1_train:0.5627 AUC_train:0.6858\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.7136\n",
      "Epoch:0026\n",
      "acc_train:0.6492 pre_train:0.7167 recall_train:0.5147 F1_train:0.5991 AUC_train:0.6821\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.7141\n",
      "Epoch:0027\n",
      "acc_train:0.5843 pre_train:0.6206 recall_train:0.4730 F1_train:0.5369 AUC_train:0.6231\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.7131\n",
      "Epoch:0028\n",
      "acc_train:0.6255 pre_train:0.7109 recall_train:0.4461 F1_train:0.5482 AUC_train:0.6607\n",
      "acc_val:0.7079 pre_val:0.9630 recall_val:0.5098 F1_val:0.666667 AUC_val:0.7276\n",
      "Epoch:0029\n",
      "acc_train:0.6317 pre_train:0.7678 recall_train:0.3971 F1_train:0.5234 AUC_train:0.6631\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7322\n",
      "Epoch:0030\n",
      "acc_train:0.6342 pre_train:0.7578 recall_train:0.4142 F1_train:0.5357 AUC_train:0.6695\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7270\n",
      "Epoch:0031\n",
      "acc_train:0.6542 pre_train:0.7610 recall_train:0.4681 F1_train:0.5797 AUC_train:0.6749\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7575\n",
      "Epoch:0032\n",
      "acc_train:0.6317 pre_train:0.7251 recall_train:0.4461 F1_train:0.5524 AUC_train:0.6701\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7673\n",
      "Epoch:0033\n",
      "acc_train:0.6142 pre_train:0.7106 recall_train:0.4093 F1_train:0.5194 AUC_train:0.6534\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7678\n",
      "Epoch:0034\n",
      "acc_train:0.6355 pre_train:0.6401 recall_train:0.6495 F1_train:0.6448 AUC_train:0.6877\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7724\n",
      "Epoch:0035\n",
      "acc_train:0.6230 pre_train:0.7650 recall_train:0.3750 F1_train:0.5033 AUC_train:0.6883\n",
      "acc_val:0.6742 pre_val:0.9583 recall_val:0.4510 F1_val:0.613333 AUC_val:0.7750\n",
      "Epoch:0036\n",
      "acc_train:0.6330 pre_train:0.7336 recall_train:0.4387 F1_train:0.5491 AUC_train:0.6877\n",
      "acc_val:0.6742 pre_val:0.9583 recall_val:0.4510 F1_val:0.613333 AUC_val:0.7724\n",
      "Epoch:0037\n",
      "acc_train:0.6404 pre_train:0.7521 recall_train:0.4387 F1_train:0.5542 AUC_train:0.6767\n",
      "acc_val:0.6742 pre_val:0.9583 recall_val:0.4510 F1_val:0.613333 AUC_val:0.7740\n",
      "Epoch:0038\n",
      "acc_train:0.6492 pre_train:0.7530 recall_train:0.4632 F1_train:0.5736 AUC_train:0.6890\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7745\n",
      "Epoch:0039\n",
      "acc_train:0.6492 pre_train:0.7679 recall_train:0.4461 F1_train:0.5643 AUC_train:0.6822\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.7781\n",
      "Epoch:0040\n",
      "acc_train:0.6467 pre_train:0.7880 recall_train:0.4191 F1_train:0.5472 AUC_train:0.7161\n",
      "acc_val:0.6966 pre_val:0.9615 recall_val:0.4902 F1_val:0.649351 AUC_val:0.7786\n",
      "Epoch:0041\n",
      "acc_train:0.6654 pre_train:0.6977 recall_train:0.6054 F1_train:0.6483 AUC_train:0.6919\n",
      "acc_val:0.6966 pre_val:0.9615 recall_val:0.4902 F1_val:0.649351 AUC_val:0.7792\n",
      "Epoch:0042\n",
      "acc_train:0.6492 pre_train:0.7900 recall_train:0.4240 F1_train:0.5518 AUC_train:0.6781\n",
      "acc_val:0.6966 pre_val:0.9615 recall_val:0.4902 F1_val:0.649351 AUC_val:0.7802\n",
      "Epoch:0043\n",
      "acc_train:0.5643 pre_train:0.5518 recall_train:0.7696 F1_train:0.6428 AUC_train:0.6465\n",
      "acc_val:0.6966 pre_val:0.9286 recall_val:0.5098 F1_val:0.658228 AUC_val:0.7828\n",
      "Epoch:0044\n",
      "acc_train:0.6280 pre_train:0.6950 recall_train:0.4804 F1_train:0.5681 AUC_train:0.6655\n",
      "acc_val:0.6966 pre_val:0.9286 recall_val:0.5098 F1_val:0.658228 AUC_val:0.7864\n",
      "Epoch:0045\n",
      "acc_train:0.6642 pre_train:0.7003 recall_train:0.5956 F1_train:0.6437 AUC_train:0.6785\n",
      "acc_val:0.6966 pre_val:0.9286 recall_val:0.5098 F1_val:0.658228 AUC_val:0.7864\n",
      "Epoch:0046\n",
      "acc_train:0.6717 pre_train:0.7066 recall_train:0.6078 F1_train:0.6535 AUC_train:0.7030\n",
      "acc_val:0.6966 pre_val:0.9000 recall_val:0.5294 F1_val:0.666667 AUC_val:0.7879\n",
      "Epoch:0047\n",
      "acc_train:0.6604 pre_train:0.7615 recall_train:0.4853 F1_train:0.5928 AUC_train:0.6865\n",
      "acc_val:0.6966 pre_val:0.9000 recall_val:0.5294 F1_val:0.666667 AUC_val:0.7900\n",
      "Epoch:0048\n",
      "acc_train:0.6330 pre_train:0.8065 recall_train:0.3676 F1_train:0.5051 AUC_train:0.7090\n",
      "acc_val:0.7079 pre_val:0.9310 recall_val:0.5294 F1_val:0.675000 AUC_val:0.7895\n",
      "Epoch:0049\n",
      "acc_train:0.6529 pre_train:0.7241 recall_train:0.5147 F1_train:0.6017 AUC_train:0.6956\n",
      "acc_val:0.6966 pre_val:0.9000 recall_val:0.5294 F1_val:0.666667 AUC_val:0.7921\n",
      "Epoch:0050\n",
      "acc_train:0.6679 pre_train:0.7367 recall_train:0.5417 F1_train:0.6243 AUC_train:0.7043\n",
      "acc_val:0.7191 pre_val:0.9062 recall_val:0.5686 F1_val:0.698795 AUC_val:0.7931\n",
      "Epoch:0051\n",
      "acc_train:0.6417 pre_train:0.7093 recall_train:0.5025 F1_train:0.5882 AUC_train:0.6672\n",
      "acc_val:0.7191 pre_val:0.9062 recall_val:0.5686 F1_val:0.698795 AUC_val:0.7941\n",
      "Epoch:0052\n",
      "acc_train:0.6467 pre_train:0.8049 recall_train:0.4044 F1_train:0.5383 AUC_train:0.6997\n",
      "acc_val:0.7191 pre_val:0.9062 recall_val:0.5686 F1_val:0.698795 AUC_val:0.7967\n",
      "Epoch:0053\n",
      "acc_train:0.6667 pre_train:0.7143 recall_train:0.5760 F1_train:0.6377 AUC_train:0.6881\n",
      "acc_val:0.7191 pre_val:0.9062 recall_val:0.5686 F1_val:0.698795 AUC_val:0.7982\n",
      "Epoch:0054\n",
      "acc_train:0.6654 pre_train:0.7756 recall_train:0.4828 F1_train:0.5952 AUC_train:0.7142\n",
      "acc_val:0.7191 pre_val:0.9062 recall_val:0.5686 F1_val:0.698795 AUC_val:0.7962\n",
      "Epoch:0055\n",
      "acc_train:0.6592 pre_train:0.7848 recall_train:0.4559 F1_train:0.5767 AUC_train:0.6913\n",
      "acc_val:0.7191 pre_val:0.9062 recall_val:0.5686 F1_val:0.698795 AUC_val:0.7957\n",
      "Epoch:0056\n",
      "acc_train:0.6704 pre_train:0.7647 recall_train:0.5098 F1_train:0.6118 AUC_train:0.7097\n",
      "acc_val:0.7191 pre_val:0.9062 recall_val:0.5686 F1_val:0.698795 AUC_val:0.7988\n",
      "Epoch:0057\n",
      "acc_train:0.6617 pre_train:0.7566 recall_train:0.4951 F1_train:0.5985 AUC_train:0.6858\n",
      "acc_val:0.7303 pre_val:0.9091 recall_val:0.5882 F1_val:0.714286 AUC_val:0.8003\n",
      "Epoch:0058\n",
      "acc_train:0.6392 pre_train:0.6434 recall_train:0.6544 F1_train:0.6488 AUC_train:0.6955\n",
      "acc_val:0.7416 pre_val:0.9118 recall_val:0.6078 F1_val:0.729412 AUC_val:0.8019\n",
      "Epoch:0059\n",
      "acc_train:0.6854 pre_train:0.7500 recall_train:0.5735 F1_train:0.6500 AUC_train:0.7214\n",
      "acc_val:0.7416 pre_val:0.9118 recall_val:0.6078 F1_val:0.729412 AUC_val:0.8034\n",
      "Epoch:0060\n",
      "acc_train:0.6479 pre_train:0.6388 recall_train:0.7108 F1_train:0.6729 AUC_train:0.7105\n",
      "acc_val:0.6966 pre_val:0.8158 recall_val:0.6078 F1_val:0.696629 AUC_val:0.8008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0061\n",
      "acc_train:0.6367 pre_train:0.6612 recall_train:0.5882 F1_train:0.6226 AUC_train:0.6934\n",
      "acc_val:0.7079 pre_val:0.8378 recall_val:0.6078 F1_val:0.704545 AUC_val:0.8019\n",
      "Epoch:0062\n",
      "acc_train:0.6841 pre_train:0.7541 recall_train:0.5637 F1_train:0.6452 AUC_train:0.7091\n",
      "acc_val:0.7416 pre_val:0.9118 recall_val:0.6078 F1_val:0.729412 AUC_val:0.8019\n",
      "Epoch:0063\n",
      "acc_train:0.6367 pre_train:0.6452 recall_train:0.6373 F1_train:0.6412 AUC_train:0.6952\n",
      "acc_val:0.7079 pre_val:0.8378 recall_val:0.6078 F1_val:0.704545 AUC_val:0.7998\n",
      "Epoch:0064\n",
      "acc_train:0.6429 pre_train:0.6622 recall_train:0.6103 F1_train:0.6352 AUC_train:0.6994\n",
      "acc_val:0.6966 pre_val:0.8158 recall_val:0.6078 F1_val:0.696629 AUC_val:0.8013\n",
      "Epoch:0065\n",
      "acc_train:0.6479 pre_train:0.6458 recall_train:0.6838 F1_train:0.6643 AUC_train:0.7267\n",
      "acc_val:0.7079 pre_val:0.8205 recall_val:0.6275 F1_val:0.711111 AUC_val:0.8024\n",
      "Epoch:0066\n",
      "acc_train:0.6205 pre_train:0.6711 recall_train:0.5000 F1_train:0.5730 AUC_train:0.6649\n",
      "acc_val:0.7303 pre_val:0.9091 recall_val:0.5882 F1_val:0.714286 AUC_val:0.7977\n",
      "Epoch:0067\n",
      "acc_train:0.6804 pre_train:0.7375 recall_train:0.5784 F1_train:0.6484 AUC_train:0.7343\n",
      "acc_val:0.7303 pre_val:0.9091 recall_val:0.5882 F1_val:0.714286 AUC_val:0.7982\n",
      "Epoch:0068\n",
      "acc_train:0.6317 pre_train:0.6323 recall_train:0.6618 F1_train:0.6467 AUC_train:0.7012\n",
      "acc_val:0.7079 pre_val:0.8378 recall_val:0.6078 F1_val:0.704545 AUC_val:0.7977\n",
      "Epoch:0069\n",
      "acc_train:0.6692 pre_train:0.7440 recall_train:0.5343 F1_train:0.6220 AUC_train:0.7049\n",
      "acc_val:0.7303 pre_val:0.8857 recall_val:0.6078 F1_val:0.720930 AUC_val:0.7982\n",
      "Epoch:0070\n",
      "acc_train:0.6866 pre_train:0.7698 recall_train:0.5490 F1_train:0.6409 AUC_train:0.7178\n",
      "acc_val:0.7303 pre_val:0.9091 recall_val:0.5882 F1_val:0.714286 AUC_val:0.7988\n",
      "Epoch:0071\n",
      "acc_train:0.6642 pre_train:0.6777 recall_train:0.6495 F1_train:0.6633 AUC_train:0.7218\n",
      "acc_val:0.7303 pre_val:0.9091 recall_val:0.5882 F1_val:0.714286 AUC_val:0.8013\n",
      "Epoch:0072\n",
      "acc_train:0.6529 pre_train:0.6720 recall_train:0.6225 F1_train:0.6463 AUC_train:0.7076\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8029\n",
      "Epoch:0073\n",
      "acc_train:0.6792 pre_train:0.7726 recall_train:0.5245 F1_train:0.6248 AUC_train:0.7171\n",
      "acc_val:0.7191 pre_val:0.8611 recall_val:0.6078 F1_val:0.712644 AUC_val:0.8055\n",
      "Epoch:0074\n",
      "acc_train:0.6404 pre_train:0.6562 recall_train:0.6176 F1_train:0.6364 AUC_train:0.7038\n",
      "acc_val:0.7079 pre_val:0.8378 recall_val:0.6078 F1_val:0.704545 AUC_val:0.8070\n",
      "Epoch:0075\n",
      "acc_train:0.6542 pre_train:0.6433 recall_train:0.7206 F1_train:0.6798 AUC_train:0.7406\n",
      "acc_val:0.7303 pre_val:0.8293 recall_val:0.6667 F1_val:0.739130 AUC_val:0.8106\n",
      "Epoch:0076\n",
      "acc_train:0.6754 pre_train:0.7033 recall_train:0.6275 F1_train:0.6632 AUC_train:0.7156\n",
      "acc_val:0.7079 pre_val:0.8205 recall_val:0.6275 F1_val:0.711111 AUC_val:0.8127\n",
      "Epoch:0077\n",
      "acc_train:0.6317 pre_train:0.6247 recall_train:0.6936 F1_train:0.6574 AUC_train:0.6988\n",
      "acc_val:0.7303 pre_val:0.8293 recall_val:0.6667 F1_val:0.739130 AUC_val:0.8127\n",
      "Epoch:0078\n",
      "acc_train:0.6704 pre_train:0.7628 recall_train:0.5123 F1_train:0.6129 AUC_train:0.7226\n",
      "acc_val:0.7191 pre_val:0.8250 recall_val:0.6471 F1_val:0.725275 AUC_val:0.8153\n",
      "Epoch:0079\n",
      "acc_train:0.6442 pre_train:0.6667 recall_train:0.6029 F1_train:0.6332 AUC_train:0.7078\n",
      "acc_val:0.7303 pre_val:0.8293 recall_val:0.6667 F1_val:0.739130 AUC_val:0.8168\n",
      "Epoch:0080\n",
      "acc_train:0.6542 pre_train:0.6520 recall_train:0.6887 F1_train:0.6698 AUC_train:0.7379\n",
      "acc_val:0.7303 pre_val:0.8293 recall_val:0.6667 F1_val:0.739130 AUC_val:0.8189\n",
      "Epoch:0081\n",
      "acc_train:0.6679 pre_train:0.6564 recall_train:0.7304 F1_train:0.6914 AUC_train:0.7434\n",
      "acc_val:0.7416 pre_val:0.8333 recall_val:0.6863 F1_val:0.752688 AUC_val:0.8235\n",
      "Epoch:0082\n",
      "acc_train:0.6879 pre_train:0.7394 recall_train:0.5980 F1_train:0.6612 AUC_train:0.7508\n",
      "acc_val:0.7416 pre_val:0.8333 recall_val:0.6863 F1_val:0.752688 AUC_val:0.8266\n",
      "Epoch:0083\n",
      "acc_train:0.6704 pre_train:0.6800 recall_train:0.6667 F1_train:0.6733 AUC_train:0.7372\n",
      "acc_val:0.7416 pre_val:0.8333 recall_val:0.6863 F1_val:0.752688 AUC_val:0.8318\n",
      "Epoch:0084\n",
      "acc_train:0.6592 pre_train:0.6559 recall_train:0.6961 F1_train:0.6754 AUC_train:0.7458\n",
      "acc_val:0.7528 pre_val:0.8372 recall_val:0.7059 F1_val:0.765957 AUC_val:0.8364\n",
      "Epoch:0085\n",
      "acc_train:0.6617 pre_train:0.6752 recall_train:0.6471 F1_train:0.6608 AUC_train:0.7380\n",
      "acc_val:0.7528 pre_val:0.8372 recall_val:0.7059 F1_val:0.765957 AUC_val:0.8400\n",
      "Epoch:0086\n",
      "acc_train:0.6792 pre_train:0.7139 recall_train:0.6176 F1_train:0.6623 AUC_train:0.7558\n",
      "acc_val:0.7528 pre_val:0.8372 recall_val:0.7059 F1_val:0.765957 AUC_val:0.8411\n",
      "Epoch:0087\n",
      "acc_train:0.6654 pre_train:0.6699 recall_train:0.6765 F1_train:0.6732 AUC_train:0.7517\n",
      "acc_val:0.7416 pre_val:0.8333 recall_val:0.6863 F1_val:0.752688 AUC_val:0.8447\n",
      "Epoch:0088\n",
      "acc_train:0.6717 pre_train:0.6622 recall_train:0.7255 F1_train:0.6924 AUC_train:0.7455\n",
      "acc_val:0.7528 pre_val:0.8222 recall_val:0.7255 F1_val:0.770833 AUC_val:0.8514\n",
      "Epoch:0089\n",
      "acc_train:0.6891 pre_train:0.7331 recall_train:0.6127 F1_train:0.6676 AUC_train:0.7596\n",
      "acc_val:0.7528 pre_val:0.8222 recall_val:0.7255 F1_val:0.770833 AUC_val:0.8545\n",
      "Epoch:0090\n",
      "acc_train:0.6754 pre_train:0.6729 recall_train:0.7059 F1_train:0.6890 AUC_train:0.7701\n",
      "acc_val:0.7640 pre_val:0.8125 recall_val:0.7647 F1_val:0.787879 AUC_val:0.8591\n",
      "Epoch:0091\n",
      "acc_train:0.6841 pre_train:0.6618 recall_train:0.7770 F1_train:0.7148 AUC_train:0.7659\n",
      "acc_val:0.7640 pre_val:0.8000 recall_val:0.7843 F1_val:0.792079 AUC_val:0.8633\n",
      "Epoch:0092\n",
      "acc_train:0.6929 pre_train:0.6929 recall_train:0.7132 F1_train:0.7029 AUC_train:0.7877\n",
      "acc_val:0.7753 pre_val:0.8039 recall_val:0.8039 F1_val:0.803922 AUC_val:0.8658\n",
      "Epoch:0093\n",
      "acc_train:0.6866 pre_train:0.7302 recall_train:0.6103 F1_train:0.6649 AUC_train:0.7880\n",
      "acc_val:0.7865 pre_val:0.8077 recall_val:0.8235 F1_val:0.815534 AUC_val:0.8710\n",
      "Epoch:0094\n",
      "acc_train:0.7054 pre_train:0.7429 recall_train:0.6446 F1_train:0.6903 AUC_train:0.8184\n",
      "acc_val:0.7865 pre_val:0.7963 recall_val:0.8431 F1_val:0.819048 AUC_val:0.8787\n",
      "Epoch:0095\n",
      "acc_train:0.7079 pre_train:0.7091 recall_train:0.7230 F1_train:0.7160 AUC_train:0.8052\n",
      "acc_val:0.7753 pre_val:0.7818 recall_val:0.8431 F1_val:0.811321 AUC_val:0.8865\n",
      "Epoch:0096\n",
      "acc_train:0.7116 pre_train:0.7611 recall_train:0.6324 F1_train:0.6908 AUC_train:0.8338\n",
      "acc_val:0.7528 pre_val:0.7544 recall_val:0.8431 F1_val:0.796296 AUC_val:0.8932\n",
      "Epoch:0097\n",
      "acc_train:0.7353 pre_train:0.7279 recall_train:0.7672 F1_train:0.7470 AUC_train:0.8226\n",
      "acc_val:0.7640 pre_val:0.7586 recall_val:0.8627 F1_val:0.807339 AUC_val:0.9004\n",
      "Epoch:0098\n",
      "acc_train:0.7391 pre_train:0.7696 recall_train:0.6961 F1_train:0.7310 AUC_train:0.8491\n",
      "acc_val:0.7640 pre_val:0.7586 recall_val:0.8627 F1_val:0.807339 AUC_val:0.9025\n",
      "Epoch:0099\n",
      "acc_train:0.7715 pre_train:0.7586 recall_train:0.8088 F1_train:0.7829 AUC_train:0.8478\n",
      "acc_val:0.7865 pre_val:0.7667 recall_val:0.9020 F1_val:0.828829 AUC_val:0.9056\n",
      "Epoch:0100\n",
      "acc_train:0.7928 pre_train:0.7531 recall_train:0.8824 F1_train:0.8126 AUC_train:0.8652\n",
      "acc_val:0.7865 pre_val:0.7667 recall_val:0.9020 F1_val:0.828829 AUC_val:0.9087\n",
      "Epoch:0101\n",
      "acc_train:0.7890 pre_train:0.7424 recall_train:0.8971 F1_train:0.8124 AUC_train:0.8627\n",
      "acc_val:0.7753 pre_val:0.7627 recall_val:0.8824 F1_val:0.818182 AUC_val:0.9107\n",
      "Epoch:0102\n",
      "acc_train:0.7965 pre_train:0.7445 recall_train:0.9142 F1_train:0.8207 AUC_train:0.8807\n",
      "acc_val:0.7753 pre_val:0.7627 recall_val:0.8824 F1_val:0.818182 AUC_val:0.9087\n",
      "Epoch:0103\n",
      "acc_train:0.8090 pre_train:0.7662 recall_train:0.8995 F1_train:0.8275 AUC_train:0.8752\n",
      "acc_val:0.7865 pre_val:0.7759 recall_val:0.8824 F1_val:0.825688 AUC_val:0.9107\n",
      "Epoch:0104\n",
      "acc_train:0.8290 pre_train:0.8101 recall_train:0.8676 F1_train:0.8379 AUC_train:0.8982\n",
      "acc_val:0.8202 pre_val:0.8182 recall_val:0.8824 F1_val:0.849057 AUC_val:0.9154\n",
      "Epoch:0105\n",
      "acc_train:0.8177 pre_train:0.7937 recall_train:0.8676 F1_train:0.8290 AUC_train:0.8882\n",
      "acc_val:0.8315 pre_val:0.8462 recall_val:0.8627 F1_val:0.854369 AUC_val:0.9180\n",
      "Epoch:0106\n",
      "acc_train:0.8240 pre_train:0.7834 recall_train:0.9044 F1_train:0.8396 AUC_train:0.9019\n",
      "acc_val:0.8315 pre_val:0.8462 recall_val:0.8627 F1_val:0.854369 AUC_val:0.9205\n",
      "Epoch:0107\n",
      "acc_train:0.8252 pre_train:0.7888 recall_train:0.8971 F1_train:0.8394 AUC_train:0.8896\n",
      "acc_val:0.8202 pre_val:0.8302 recall_val:0.8627 F1_val:0.846154 AUC_val:0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0108\n",
      "acc_train:0.8377 pre_train:0.8218 recall_train:0.8701 F1_train:0.8452 AUC_train:0.8974\n",
      "acc_val:0.8315 pre_val:0.8214 recall_val:0.9020 F1_val:0.859813 AUC_val:0.9334\n",
      "Epoch:0109\n",
      "acc_train:0.8414 pre_train:0.7885 recall_train:0.9412 F1_train:0.8581 AUC_train:0.9189\n",
      "acc_val:0.8315 pre_val:0.8214 recall_val:0.9020 F1_val:0.859813 AUC_val:0.9391\n",
      "Epoch:0110\n",
      "acc_train:0.8739 pre_train:0.8191 recall_train:0.9657 F1_train:0.8864 AUC_train:0.9311\n",
      "acc_val:0.8315 pre_val:0.8103 recall_val:0.9216 F1_val:0.862385 AUC_val:0.9407\n",
      "Epoch:0111\n",
      "acc_train:0.8614 pre_train:0.8113 recall_train:0.9485 F1_train:0.8746 AUC_train:0.9149\n",
      "acc_val:0.8202 pre_val:0.7966 recall_val:0.9216 F1_val:0.854545 AUC_val:0.9458\n",
      "Epoch:0112\n",
      "acc_train:0.8777 pre_train:0.8298 recall_train:0.9559 F1_train:0.8884 AUC_train:0.9451\n",
      "acc_val:0.8315 pre_val:0.8103 recall_val:0.9216 F1_val:0.862385 AUC_val:0.9484\n",
      "Epoch:0113\n",
      "acc_train:0.8702 pre_train:0.8248 recall_train:0.9461 F1_train:0.8813 AUC_train:0.9393\n",
      "acc_val:0.8315 pre_val:0.8103 recall_val:0.9216 F1_val:0.862385 AUC_val:0.9484\n",
      "Epoch:0114\n",
      "acc_train:0.8814 pre_train:0.8395 recall_train:0.9485 F1_train:0.8907 AUC_train:0.9379\n",
      "acc_val:0.8202 pre_val:0.7966 recall_val:0.9216 F1_val:0.854545 AUC_val:0.9505\n",
      "Epoch:0115\n",
      "acc_train:0.8876 pre_train:0.8354 recall_train:0.9706 F1_train:0.8980 AUC_train:0.9472\n",
      "acc_val:0.8315 pre_val:0.7903 recall_val:0.9608 F1_val:0.867257 AUC_val:0.9510\n",
      "Epoch:0116\n",
      "acc_train:0.8951 pre_train:0.8375 recall_train:0.9853 F1_train:0.9054 AUC_train:0.9564\n",
      "acc_val:0.8202 pre_val:0.7778 recall_val:0.9608 F1_val:0.859649 AUC_val:0.9536\n",
      "Epoch:0117\n",
      "acc_train:0.8901 pre_train:0.8390 recall_train:0.9706 F1_train:0.9000 AUC_train:0.9523\n",
      "acc_val:0.8202 pre_val:0.7966 recall_val:0.9216 F1_val:0.854545 AUC_val:0.9541\n",
      "Epoch:0118\n",
      "acc_train:0.9039 pre_train:0.8653 recall_train:0.9608 F1_train:0.9106 AUC_train:0.9564\n",
      "acc_val:0.8315 pre_val:0.8103 recall_val:0.9216 F1_val:0.862385 AUC_val:0.9525\n",
      "Epoch:0119\n",
      "acc_train:0.8889 pre_train:0.8401 recall_train:0.9657 F1_train:0.8985 AUC_train:0.9496\n",
      "acc_val:0.8652 pre_val:0.8545 recall_val:0.9216 F1_val:0.886792 AUC_val:0.9515\n",
      "Epoch:0120\n",
      "acc_train:0.8951 pre_train:0.8403 recall_train:0.9804 F1_train:0.9050 AUC_train:0.9484\n",
      "acc_val:0.8764 pre_val:0.8704 recall_val:0.9216 F1_val:0.895238 AUC_val:0.9525\n",
      "Epoch:0121\n",
      "acc_train:0.9126 pre_train:0.8824 recall_train:0.9559 F1_train:0.9176 AUC_train:0.9613\n",
      "acc_val:0.8539 pre_val:0.8276 recall_val:0.9412 F1_val:0.880734 AUC_val:0.9546\n",
      "Epoch:0122\n",
      "acc_train:0.9139 pre_train:0.8709 recall_train:0.9755 F1_train:0.9202 AUC_train:0.9576\n",
      "acc_val:0.8427 pre_val:0.8033 recall_val:0.9608 F1_val:0.875000 AUC_val:0.9572\n",
      "Epoch:0123\n",
      "acc_train:0.9114 pre_train:0.8736 recall_train:0.9657 F1_train:0.9173 AUC_train:0.9633\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9592\n",
      "Epoch:0124\n",
      "acc_train:0.9101 pre_train:0.8605 recall_train:0.9828 F1_train:0.9176 AUC_train:0.9687\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9608\n",
      "Epoch:0125\n",
      "acc_train:0.9126 pre_train:0.8706 recall_train:0.9730 F1_train:0.9190 AUC_train:0.9749\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9628\n",
      "Epoch:0126\n",
      "acc_train:0.9189 pre_train:0.8753 recall_train:0.9804 F1_train:0.9249 AUC_train:0.9720\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9644\n",
      "Epoch:0127\n",
      "acc_train:0.9213 pre_train:0.8742 recall_train:0.9877 F1_train:0.9275 AUC_train:0.9797\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9665\n",
      "Epoch:0128\n",
      "acc_train:0.9238 pre_train:0.8847 recall_train:0.9779 F1_train:0.9290 AUC_train:0.9784\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9659\n",
      "Epoch:0129\n",
      "acc_train:0.9338 pre_train:0.8971 recall_train:0.9828 F1_train:0.9380 AUC_train:0.9724\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9644\n",
      "Epoch:0130\n",
      "acc_train:0.9338 pre_train:0.8989 recall_train:0.9804 F1_train:0.9379 AUC_train:0.9748\n",
      "acc_val:0.8764 pre_val:0.8333 recall_val:0.9804 F1_val:0.900901 AUC_val:0.9634\n",
      "Epoch:0131\n",
      "acc_train:0.9351 pre_train:0.9120 recall_train:0.9657 F1_train:0.9381 AUC_train:0.9757\n",
      "acc_val:0.8764 pre_val:0.8333 recall_val:0.9804 F1_val:0.900901 AUC_val:0.9649\n",
      "Epoch:0132\n",
      "acc_train:0.9276 pre_train:0.8906 recall_train:0.9779 F1_train:0.9322 AUC_train:0.9731\n",
      "acc_val:0.8652 pre_val:0.8095 recall_val:1.0000 F1_val:0.894737 AUC_val:0.9659\n",
      "Epoch:0133\n",
      "acc_train:0.9413 pre_train:0.9038 recall_train:0.9902 F1_train:0.9450 AUC_train:0.9765\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9670\n",
      "Epoch:0134\n",
      "acc_train:0.9426 pre_train:0.9114 recall_train:0.9828 F1_train:0.9458 AUC_train:0.9759\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9670\n",
      "Epoch:0135\n",
      "acc_train:0.9476 pre_train:0.9178 recall_train:0.9853 F1_train:0.9504 AUC_train:0.9762\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9665\n",
      "Epoch:0136\n",
      "acc_train:0.9438 pre_train:0.9116 recall_train:0.9853 F1_train:0.9470 AUC_train:0.9837\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9670\n",
      "Epoch:0137\n",
      "acc_train:0.9388 pre_train:0.9108 recall_train:0.9755 F1_train:0.9420 AUC_train:0.9810\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9654\n",
      "Epoch:0138\n",
      "acc_train:0.9338 pre_train:0.9062 recall_train:0.9706 F1_train:0.9373 AUC_train:0.9765\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9690\n",
      "Epoch:0139\n",
      "acc_train:0.9538 pre_train:0.9304 recall_train:0.9828 F1_train:0.9559 AUC_train:0.9789\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9706\n",
      "Epoch:0140\n",
      "acc_train:0.9526 pre_train:0.9243 recall_train:0.9877 F1_train:0.9550 AUC_train:0.9802\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9706\n",
      "Epoch:0141\n",
      "acc_train:0.9526 pre_train:0.9302 recall_train:0.9804 F1_train:0.9547 AUC_train:0.9789\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9696\n",
      "Epoch:0142\n",
      "acc_train:0.9551 pre_train:0.9366 recall_train:0.9779 F1_train:0.9568 AUC_train:0.9773\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9675\n",
      "Epoch:0143\n",
      "acc_train:0.9600 pre_train:0.9393 recall_train:0.9853 F1_train:0.9617 AUC_train:0.9845\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9685\n",
      "Epoch:0144\n",
      "acc_train:0.9613 pre_train:0.9394 recall_train:0.9877 F1_train:0.9630 AUC_train:0.9862\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9675\n",
      "Epoch:0145\n",
      "acc_train:0.9600 pre_train:0.9455 recall_train:0.9779 F1_train:0.9614 AUC_train:0.9825\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9665\n",
      "Epoch:0146\n",
      "acc_train:0.9576 pre_train:0.9369 recall_train:0.9828 F1_train:0.9593 AUC_train:0.9856\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9696\n",
      "Epoch:0147\n",
      "acc_train:0.9613 pre_train:0.9394 recall_train:0.9877 F1_train:0.9630 AUC_train:0.9810\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9701\n",
      "Epoch:0148\n",
      "acc_train:0.9625 pre_train:0.9395 recall_train:0.9902 F1_train:0.9642 AUC_train:0.9868\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9696\n",
      "Epoch:0149\n",
      "acc_train:0.9688 pre_train:0.9506 recall_train:0.9902 F1_train:0.9700 AUC_train:0.9856\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9711\n",
      "Epoch:0150\n",
      "acc_train:0.9551 pre_train:0.9286 recall_train:0.9877 F1_train:0.9572 AUC_train:0.9845\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9737\n",
      "Epoch:0151\n",
      "acc_train:0.9688 pre_train:0.9527 recall_train:0.9877 F1_train:0.9699 AUC_train:0.9902\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9763\n",
      "Epoch:0152\n",
      "acc_train:0.9625 pre_train:0.9395 recall_train:0.9902 F1_train:0.9642 AUC_train:0.9843\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9721\n",
      "Epoch:0153\n",
      "acc_train:0.9750 pre_train:0.9597 recall_train:0.9926 F1_train:0.9759 AUC_train:0.9872\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9752\n",
      "Epoch:0154\n",
      "acc_train:0.9700 pre_train:0.9571 recall_train:0.9853 F1_train:0.9710 AUC_train:0.9887\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0155\n",
      "acc_train:0.9650 pre_train:0.9460 recall_train:0.9877 F1_train:0.9664 AUC_train:0.9897\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9732\n",
      "Epoch:0156\n",
      "acc_train:0.9738 pre_train:0.9618 recall_train:0.9877 F1_train:0.9746 AUC_train:0.9878\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9727\n",
      "Epoch:0157\n",
      "acc_train:0.9713 pre_train:0.9551 recall_train:0.9902 F1_train:0.9723 AUC_train:0.9855\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9716\n",
      "Epoch:0158\n",
      "acc_train:0.9650 pre_train:0.9398 recall_train:0.9951 F1_train:0.9667 AUC_train:0.9849\n",
      "acc_val:0.8764 pre_val:0.8333 recall_val:0.9804 F1_val:0.900901 AUC_val:0.9701\n",
      "Epoch:0159\n",
      "acc_train:0.9663 pre_train:0.9482 recall_train:0.9877 F1_train:0.9676 AUC_train:0.9823\n",
      "acc_val:0.8876 pre_val:0.8475 recall_val:0.9804 F1_val:0.909091 AUC_val:0.9685\n",
      "Epoch:0160\n",
      "acc_train:0.9650 pre_train:0.9398 recall_train:0.9951 F1_train:0.9667 AUC_train:0.9808\n",
      "acc_val:0.8652 pre_val:0.8197 recall_val:0.9804 F1_val:0.892857 AUC_val:0.9685\n",
      "Epoch:0161\n",
      "acc_train:0.9613 pre_train:0.9394 recall_train:0.9877 F1_train:0.9630 AUC_train:0.9858\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9711\n",
      "Epoch:0162\n",
      "acc_train:0.9700 pre_train:0.9571 recall_train:0.9853 F1_train:0.9710 AUC_train:0.9880\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9727\n",
      "Epoch:0163\n",
      "acc_train:0.9713 pre_train:0.9529 recall_train:0.9926 F1_train:0.9724 AUC_train:0.9878\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9737\n",
      "Epoch:0164\n",
      "acc_train:0.9813 pre_train:0.9758 recall_train:0.9877 F1_train:0.9817 AUC_train:0.9906\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9690\n",
      "Epoch:0165\n",
      "acc_train:0.9763 pre_train:0.9576 recall_train:0.9975 F1_train:0.9772 AUC_train:0.9925\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9641\n",
      "Epoch:0166\n",
      "acc_train:0.9725 pre_train:0.9531 recall_train:0.9951 F1_train:0.9736 AUC_train:0.9909\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9706\n",
      "Epoch:0167\n",
      "acc_train:0.9688 pre_train:0.9527 recall_train:0.9877 F1_train:0.9699 AUC_train:0.9910\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9727\n",
      "Epoch:0168\n",
      "acc_train:0.9738 pre_train:0.9574 recall_train:0.9926 F1_train:0.9747 AUC_train:0.9871\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9732\n",
      "Epoch:0169\n",
      "acc_train:0.9700 pre_train:0.9486 recall_train:0.9951 F1_train:0.9713 AUC_train:0.9975\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9716\n",
      "Epoch:0170\n",
      "acc_train:0.9738 pre_train:0.9618 recall_train:0.9877 F1_train:0.9746 AUC_train:0.9876\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9747\n",
      "Epoch:0171\n",
      "acc_train:0.9813 pre_train:0.9690 recall_train:0.9951 F1_train:0.9819 AUC_train:0.9904\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9763\n",
      "Epoch:0172\n",
      "acc_train:0.9775 pre_train:0.9621 recall_train:0.9951 F1_train:0.9783 AUC_train:0.9896\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9763\n",
      "Epoch:0173\n",
      "acc_train:0.9838 pre_train:0.9714 recall_train:0.9975 F1_train:0.9843 AUC_train:0.9955\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9747\n",
      "Epoch:0174\n",
      "acc_train:0.9750 pre_train:0.9619 recall_train:0.9902 F1_train:0.9758 AUC_train:0.9891\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9742\n",
      "Epoch:0175\n",
      "acc_train:0.9663 pre_train:0.9461 recall_train:0.9902 F1_train:0.9677 AUC_train:0.9901\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9732\n",
      "Epoch:0176\n",
      "acc_train:0.9763 pre_train:0.9598 recall_train:0.9951 F1_train:0.9771 AUC_train:0.9869\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9737\n",
      "Epoch:0177\n",
      "acc_train:0.9738 pre_train:0.9596 recall_train:0.9902 F1_train:0.9747 AUC_train:0.9959\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9742\n",
      "Epoch:0178\n",
      "acc_train:0.9638 pre_train:0.9459 recall_train:0.9853 F1_train:0.9652 AUC_train:0.9879\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9737\n",
      "Epoch:0179\n",
      "acc_train:0.9775 pre_train:0.9643 recall_train:0.9926 F1_train:0.9783 AUC_train:0.9855\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9742\n",
      "Early Stopping!!! epoch：178\n",
      " Starting the 3-2 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.5281 pre_train:0.5323 recall_train:0.6054 F1_train:0.5665 AUC_train:0.5622\n",
      "acc_val:0.4944 pre_val:0.6875 recall_val:0.2157 F1_val:0.328358 AUC_val:0.5686\n",
      "Epoch:0002\n",
      "acc_train:0.5743 pre_train:0.5743 recall_train:0.6348 F1_train:0.6030 AUC_train:0.6326\n",
      "acc_val:0.6629 pre_val:0.7692 recall_val:0.5882 F1_val:0.666667 AUC_val:0.6796\n",
      "Epoch:0003\n",
      "acc_train:0.5568 pre_train:0.5533 recall_train:0.6740 F1_train:0.6077 AUC_train:0.6229\n",
      "acc_val:0.7303 pre_val:0.7872 recall_val:0.7255 F1_val:0.755102 AUC_val:0.7786\n",
      "Epoch:0004\n",
      "acc_train:0.5843 pre_train:0.5835 recall_train:0.6422 F1_train:0.6114 AUC_train:0.6449\n",
      "acc_val:0.7079 pre_val:0.7451 recall_val:0.7451 F1_val:0.745098 AUC_val:0.7673\n",
      "Epoch:0005\n",
      "acc_train:0.6167 pre_train:0.6077 recall_train:0.6985 F1_train:0.6499 AUC_train:0.6725\n",
      "acc_val:0.7303 pre_val:0.8000 recall_val:0.7059 F1_val:0.750000 AUC_val:0.7792\n",
      "Epoch:0006\n",
      "acc_train:0.6092 pre_train:0.6082 recall_train:0.6544 F1_train:0.6305 AUC_train:0.6787\n",
      "acc_val:0.7079 pre_val:0.7907 recall_val:0.6667 F1_val:0.723404 AUC_val:0.7807\n",
      "Epoch:0007\n",
      "acc_train:0.6205 pre_train:0.6187 recall_train:0.6642 F1_train:0.6407 AUC_train:0.6829\n",
      "acc_val:0.7191 pre_val:0.8095 recall_val:0.6667 F1_val:0.731183 AUC_val:0.7828\n",
      "Epoch:0008\n",
      "acc_train:0.6629 pre_train:0.6716 recall_train:0.6618 F1_train:0.6667 AUC_train:0.7251\n",
      "acc_val:0.7079 pre_val:0.8049 recall_val:0.6471 F1_val:0.717391 AUC_val:0.7869\n",
      "Epoch:0009\n",
      "acc_train:0.6442 pre_train:0.6461 recall_train:0.6667 F1_train:0.6562 AUC_train:0.7075\n",
      "acc_val:0.7079 pre_val:0.8049 recall_val:0.6471 F1_val:0.717391 AUC_val:0.7859\n",
      "Epoch:0010\n",
      "acc_train:0.6504 pre_train:0.6702 recall_train:0.6176 F1_train:0.6429 AUC_train:0.7082\n",
      "acc_val:0.7079 pre_val:0.8378 recall_val:0.6078 F1_val:0.704545 AUC_val:0.7884\n",
      "Epoch:0011\n",
      "acc_train:0.6604 pre_train:0.7061 recall_train:0.5711 F1_train:0.6314 AUC_train:0.7069\n",
      "acc_val:0.7079 pre_val:0.8378 recall_val:0.6078 F1_val:0.704545 AUC_val:0.7931\n",
      "Epoch:0012\n",
      "acc_train:0.6742 pre_train:0.6992 recall_train:0.6324 F1_train:0.6641 AUC_train:0.7324\n",
      "acc_val:0.7079 pre_val:0.8378 recall_val:0.6078 F1_val:0.704545 AUC_val:0.8008\n",
      "Epoch:0013\n",
      "acc_train:0.6654 pre_train:0.6923 recall_train:0.6176 F1_train:0.6528 AUC_train:0.7342\n",
      "acc_val:0.7191 pre_val:0.8611 recall_val:0.6078 F1_val:0.712644 AUC_val:0.8060\n",
      "Epoch:0014\n",
      "acc_train:0.6429 pre_train:0.6510 recall_train:0.6446 F1_train:0.6478 AUC_train:0.7239\n",
      "acc_val:0.7191 pre_val:0.8611 recall_val:0.6078 F1_val:0.712644 AUC_val:0.8158\n",
      "Epoch:0015\n",
      "acc_train:0.6679 pre_train:0.6951 recall_train:0.6201 F1_train:0.6554 AUC_train:0.7406\n",
      "acc_val:0.7191 pre_val:0.8611 recall_val:0.6078 F1_val:0.712644 AUC_val:0.8246\n",
      "Epoch:0016\n",
      "acc_train:0.6642 pre_train:0.6853 recall_train:0.6299 F1_train:0.6564 AUC_train:0.7339\n",
      "acc_val:0.7303 pre_val:0.8857 recall_val:0.6078 F1_val:0.720930 AUC_val:0.8333\n",
      "Epoch:0017\n",
      "acc_train:0.6829 pre_train:0.7048 recall_train:0.6495 F1_train:0.6760 AUC_train:0.7646\n",
      "acc_val:0.7303 pre_val:0.8857 recall_val:0.6078 F1_val:0.720930 AUC_val:0.8431\n",
      "Epoch:0018\n",
      "acc_train:0.6754 pre_train:0.7256 recall_train:0.5833 F1_train:0.6467 AUC_train:0.7733\n",
      "acc_val:0.7303 pre_val:0.8857 recall_val:0.6078 F1_val:0.720930 AUC_val:0.8581\n",
      "Epoch:0019\n",
      "acc_train:0.6991 pre_train:0.7288 recall_train:0.6520 F1_train:0.6882 AUC_train:0.7708\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8638\n",
      "Epoch:0020\n",
      "acc_train:0.7016 pre_train:0.7683 recall_train:0.5931 F1_train:0.6694 AUC_train:0.8054\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8762\n",
      "Epoch:0021\n",
      "acc_train:0.6941 pre_train:0.7270 recall_train:0.6397 F1_train:0.6806 AUC_train:0.8071\n",
      "acc_val:0.7303 pre_val:0.8857 recall_val:0.6078 F1_val:0.720930 AUC_val:0.8803\n",
      "Epoch:0022\n",
      "acc_train:0.7353 pre_train:0.7475 recall_train:0.7255 F1_train:0.7363 AUC_train:0.8171\n",
      "acc_val:0.7303 pre_val:0.8857 recall_val:0.6078 F1_val:0.720930 AUC_val:0.8808\n",
      "Epoch:0023\n",
      "acc_train:0.7615 pre_train:0.7460 recall_train:0.8064 F1_train:0.7750 AUC_train:0.8392\n",
      "acc_val:0.7753 pre_val:0.8974 recall_val:0.6863 F1_val:0.777778 AUC_val:0.8824\n",
      "Epoch:0024\n",
      "acc_train:0.7141 pre_train:0.7479 recall_train:0.6618 F1_train:0.7022 AUC_train:0.8270\n",
      "acc_val:0.7528 pre_val:0.8537 recall_val:0.6863 F1_val:0.760870 AUC_val:0.8829\n",
      "Epoch:0025\n",
      "acc_train:0.7416 pre_train:0.7332 recall_train:0.7745 F1_train:0.7533 AUC_train:0.8306\n",
      "acc_val:0.7416 pre_val:0.8333 recall_val:0.6863 F1_val:0.752688 AUC_val:0.8818\n",
      "Epoch:0026\n",
      "acc_train:0.7391 pre_train:0.7481 recall_train:0.7353 F1_train:0.7417 AUC_train:0.8435\n",
      "acc_val:0.7640 pre_val:0.8409 recall_val:0.7255 F1_val:0.778947 AUC_val:0.8834\n",
      "Epoch:0027\n",
      "acc_train:0.7316 pre_train:0.7615 recall_train:0.6887 F1_train:0.7233 AUC_train:0.8538\n",
      "acc_val:0.7640 pre_val:0.8409 recall_val:0.7255 F1_val:0.778947 AUC_val:0.8860\n",
      "Epoch:0028\n",
      "acc_train:0.7928 pre_train:0.7701 recall_train:0.8456 F1_train:0.8061 AUC_train:0.8663\n",
      "acc_val:0.7753 pre_val:0.8298 recall_val:0.7647 F1_val:0.795918 AUC_val:0.8870\n",
      "Epoch:0029\n",
      "acc_train:0.7865 pre_train:0.8000 recall_train:0.7745 F1_train:0.7870 AUC_train:0.8752\n",
      "acc_val:0.7640 pre_val:0.8125 recall_val:0.7647 F1_val:0.787879 AUC_val:0.8891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0030\n",
      "acc_train:0.8240 pre_train:0.8097 recall_train:0.8554 F1_train:0.8319 AUC_train:0.8985\n",
      "acc_val:0.7865 pre_val:0.8200 recall_val:0.8039 F1_val:0.811881 AUC_val:0.8927\n",
      "Epoch:0031\n",
      "acc_train:0.8439 pre_train:0.8030 recall_train:0.9191 F1_train:0.8571 AUC_train:0.9059\n",
      "acc_val:0.7978 pre_val:0.8113 recall_val:0.8431 F1_val:0.826923 AUC_val:0.8947\n",
      "Epoch:0032\n",
      "acc_train:0.8340 pre_train:0.7847 recall_train:0.9289 F1_train:0.8507 AUC_train:0.9094\n",
      "acc_val:0.8202 pre_val:0.8302 recall_val:0.8627 F1_val:0.846154 AUC_val:0.8968\n",
      "Epoch:0033\n",
      "acc_train:0.8477 pre_train:0.7979 recall_train:0.9387 F1_train:0.8626 AUC_train:0.9163\n",
      "acc_val:0.8315 pre_val:0.8333 recall_val:0.8824 F1_val:0.857143 AUC_val:0.8958\n",
      "Epoch:0034\n",
      "acc_train:0.8527 pre_train:0.8125 recall_train:0.9240 F1_train:0.8647 AUC_train:0.9119\n",
      "acc_val:0.8315 pre_val:0.8462 recall_val:0.8627 F1_val:0.854369 AUC_val:0.8947\n",
      "Epoch:0035\n",
      "acc_train:0.8652 pre_train:0.8472 recall_train:0.8971 F1_train:0.8714 AUC_train:0.9145\n",
      "acc_val:0.8202 pre_val:0.8431 recall_val:0.8431 F1_val:0.843137 AUC_val:0.8978\n",
      "Epoch:0036\n",
      "acc_train:0.8365 pre_train:0.8524 recall_train:0.8211 F1_train:0.8365 AUC_train:0.9109\n",
      "acc_val:0.8202 pre_val:0.8302 recall_val:0.8627 F1_val:0.846154 AUC_val:0.8983\n",
      "Epoch:0037\n",
      "acc_train:0.8527 pre_train:0.8662 recall_train:0.8407 F1_train:0.8532 AUC_train:0.9148\n",
      "acc_val:0.8202 pre_val:0.8302 recall_val:0.8627 F1_val:0.846154 AUC_val:0.9004\n",
      "Epoch:0038\n",
      "acc_train:0.8777 pre_train:0.8555 recall_train:0.9142 F1_train:0.8839 AUC_train:0.9283\n",
      "acc_val:0.8427 pre_val:0.8364 recall_val:0.9020 F1_val:0.867925 AUC_val:0.9097\n",
      "Epoch:0039\n",
      "acc_train:0.8739 pre_train:0.8315 recall_train:0.9436 F1_train:0.8840 AUC_train:0.9342\n",
      "acc_val:0.8315 pre_val:0.8214 recall_val:0.9020 F1_val:0.859813 AUC_val:0.9200\n",
      "Epoch:0040\n",
      "acc_train:0.8839 pre_train:0.8637 recall_train:0.9167 F1_train:0.8894 AUC_train:0.9417\n",
      "acc_val:0.8202 pre_val:0.7966 recall_val:0.9216 F1_val:0.854545 AUC_val:0.9247\n",
      "Epoch:0041\n",
      "acc_train:0.8876 pre_train:0.8472 recall_train:0.9510 F1_train:0.8961 AUC_train:0.9546\n",
      "acc_val:0.7978 pre_val:0.7705 recall_val:0.9216 F1_val:0.839286 AUC_val:0.9288\n",
      "Epoch:0042\n",
      "acc_train:0.9001 pre_train:0.8644 recall_train:0.9534 F1_train:0.9068 AUC_train:0.9509\n",
      "acc_val:0.7978 pre_val:0.7619 recall_val:0.9412 F1_val:0.842105 AUC_val:0.9262\n",
      "Epoch:0043\n",
      "acc_train:0.8951 pre_train:0.8553 recall_train:0.9559 F1_train:0.9028 AUC_train:0.9527\n",
      "acc_val:0.8427 pre_val:0.8033 recall_val:0.9608 F1_val:0.875000 AUC_val:0.9303\n",
      "Epoch:0044\n",
      "acc_train:0.9001 pre_train:0.8550 recall_train:0.9681 F1_train:0.9080 AUC_train:0.9566\n",
      "acc_val:0.8427 pre_val:0.8033 recall_val:0.9608 F1_val:0.875000 AUC_val:0.9283\n",
      "Epoch:0045\n",
      "acc_train:0.9101 pre_train:0.8750 recall_train:0.9608 F1_train:0.9159 AUC_train:0.9643\n",
      "acc_val:0.8315 pre_val:0.8000 recall_val:0.9412 F1_val:0.864865 AUC_val:0.9314\n",
      "Epoch:0046\n",
      "acc_train:0.9089 pre_train:0.8681 recall_train:0.9681 F1_train:0.9154 AUC_train:0.9583\n",
      "acc_val:0.8202 pre_val:0.8070 recall_val:0.9020 F1_val:0.851852 AUC_val:0.9345\n",
      "Epoch:0047\n",
      "acc_train:0.8914 pre_train:0.8408 recall_train:0.9706 F1_train:0.9010 AUC_train:0.9614\n",
      "acc_val:0.8315 pre_val:0.8103 recall_val:0.9216 F1_val:0.862385 AUC_val:0.9381\n",
      "Epoch:0048\n",
      "acc_train:0.9089 pre_train:0.8747 recall_train:0.9583 F1_train:0.9146 AUC_train:0.9543\n",
      "acc_val:0.8539 pre_val:0.8393 recall_val:0.9216 F1_val:0.878505 AUC_val:0.9422\n",
      "Epoch:0049\n",
      "acc_train:0.9064 pre_train:0.8776 recall_train:0.9485 F1_train:0.9117 AUC_train:0.9612\n",
      "acc_val:0.8764 pre_val:0.8571 recall_val:0.9412 F1_val:0.897196 AUC_val:0.9469\n",
      "Epoch:0050\n",
      "acc_train:0.9001 pre_train:0.8727 recall_train:0.9412 F1_train:0.9057 AUC_train:0.9561\n",
      "acc_val:0.8427 pre_val:0.7937 recall_val:0.9804 F1_val:0.877193 AUC_val:0.9525\n",
      "Epoch:0051\n",
      "acc_train:0.9101 pre_train:0.8700 recall_train:0.9681 F1_train:0.9165 AUC_train:0.9671\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9536\n",
      "Epoch:0052\n",
      "acc_train:0.9251 pre_train:0.9009 recall_train:0.9583 F1_train:0.9287 AUC_train:0.9646\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9567\n",
      "Epoch:0053\n",
      "acc_train:0.9326 pre_train:0.8986 recall_train:0.9779 F1_train:0.9366 AUC_train:0.9737\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9572\n",
      "Epoch:0054\n",
      "acc_train:0.9189 pre_train:0.8837 recall_train:0.9681 F1_train:0.9240 AUC_train:0.9669\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9520\n",
      "Epoch:0055\n",
      "acc_train:0.9326 pre_train:0.9041 recall_train:0.9706 F1_train:0.9362 AUC_train:0.9728\n",
      "acc_val:0.8764 pre_val:0.8333 recall_val:0.9804 F1_val:0.900901 AUC_val:0.9510\n",
      "Epoch:0056\n",
      "acc_train:0.9313 pre_train:0.9039 recall_train:0.9681 F1_train:0.9349 AUC_train:0.9781\n",
      "acc_val:0.8876 pre_val:0.8475 recall_val:0.9804 F1_val:0.909091 AUC_val:0.9489\n",
      "Epoch:0057\n",
      "acc_train:0.9301 pre_train:0.8877 recall_train:0.9877 F1_train:0.9350 AUC_train:0.9782\n",
      "acc_val:0.8876 pre_val:0.8475 recall_val:0.9804 F1_val:0.909091 AUC_val:0.9479\n",
      "Epoch:0058\n",
      "acc_train:0.9288 pre_train:0.9034 recall_train:0.9632 F1_train:0.9324 AUC_train:0.9765\n",
      "acc_val:0.8764 pre_val:0.8333 recall_val:0.9804 F1_val:0.900901 AUC_val:0.9479\n",
      "Epoch:0059\n",
      "acc_train:0.9526 pre_train:0.9263 recall_train:0.9853 F1_train:0.9549 AUC_train:0.9780\n",
      "acc_val:0.8652 pre_val:0.8197 recall_val:0.9804 F1_val:0.892857 AUC_val:0.9474\n",
      "Epoch:0060\n",
      "acc_train:0.9413 pre_train:0.9112 recall_train:0.9804 F1_train:0.9445 AUC_train:0.9775\n",
      "acc_val:0.8652 pre_val:0.8095 recall_val:1.0000 F1_val:0.894737 AUC_val:0.9530\n",
      "Epoch:0061\n",
      "acc_train:0.9576 pre_train:0.9309 recall_train:0.9902 F1_train:0.9596 AUC_train:0.9827\n",
      "acc_val:0.8652 pre_val:0.8095 recall_val:1.0000 F1_val:0.894737 AUC_val:0.9572\n",
      "Epoch:0062\n",
      "acc_train:0.9401 pre_train:0.9091 recall_train:0.9804 F1_train:0.9434 AUC_train:0.9812\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9572\n",
      "Epoch:0063\n",
      "acc_train:0.9488 pre_train:0.9318 recall_train:0.9706 F1_train:0.9508 AUC_train:0.9849\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9556\n",
      "Epoch:0064\n",
      "acc_train:0.9401 pre_train:0.9167 recall_train:0.9706 F1_train:0.9429 AUC_train:0.9805\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9541\n",
      "Epoch:0065\n",
      "acc_train:0.9313 pre_train:0.9021 recall_train:0.9706 F1_train:0.9351 AUC_train:0.9752\n",
      "acc_val:0.8539 pre_val:0.8167 recall_val:0.9608 F1_val:0.882883 AUC_val:0.9551\n",
      "Epoch:0066\n",
      "acc_train:0.9351 pre_train:0.9120 recall_train:0.9657 F1_train:0.9381 AUC_train:0.9779\n",
      "acc_val:0.8764 pre_val:0.8448 recall_val:0.9608 F1_val:0.899083 AUC_val:0.9598\n",
      "Epoch:0067\n",
      "acc_train:0.9438 pre_train:0.9231 recall_train:0.9706 F1_train:0.9462 AUC_train:0.9806\n",
      "acc_val:0.8989 pre_val:0.8500 recall_val:1.0000 F1_val:0.918919 AUC_val:0.9608\n",
      "Epoch:0068\n",
      "acc_train:0.9401 pre_train:0.9110 recall_train:0.9779 F1_train:0.9433 AUC_train:0.9654\n",
      "acc_val:0.8652 pre_val:0.8095 recall_val:1.0000 F1_val:0.894737 AUC_val:0.9634\n",
      "Epoch:0069\n",
      "acc_train:0.9551 pre_train:0.9387 recall_train:0.9755 F1_train:0.9567 AUC_train:0.9800\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9639\n",
      "Epoch:0070\n",
      "acc_train:0.9538 pre_train:0.9304 recall_train:0.9828 F1_train:0.9559 AUC_train:0.9790\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9608\n",
      "Epoch:0071\n",
      "acc_train:0.9513 pre_train:0.9341 recall_train:0.9730 F1_train:0.9532 AUC_train:0.9890\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9587\n",
      "Epoch:0072\n",
      "acc_train:0.9588 pre_train:0.9291 recall_train:0.9951 F1_train:0.9609 AUC_train:0.9861\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9577\n",
      "Epoch:0073\n",
      "acc_train:0.9538 pre_train:0.9324 recall_train:0.9804 F1_train:0.9558 AUC_train:0.9829\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9598\n",
      "Epoch:0074\n",
      "acc_train:0.9563 pre_train:0.9307 recall_train:0.9877 F1_train:0.9584 AUC_train:0.9814\n",
      "acc_val:0.8652 pre_val:0.8197 recall_val:0.9804 F1_val:0.892857 AUC_val:0.9567\n",
      "Epoch:0075\n",
      "acc_train:0.9463 pre_train:0.9274 recall_train:0.9706 F1_train:0.9485 AUC_train:0.9801\n",
      "acc_val:0.8539 pre_val:0.8065 recall_val:0.9804 F1_val:0.884956 AUC_val:0.9608\n",
      "Epoch:0076\n",
      "acc_train:0.9488 pre_train:0.9238 recall_train:0.9804 F1_train:0.9512 AUC_train:0.9818\n",
      "acc_val:0.8539 pre_val:0.8065 recall_val:0.9804 F1_val:0.884956 AUC_val:0.9659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0077\n",
      "acc_train:0.9600 pre_train:0.9372 recall_train:0.9877 F1_train:0.9618 AUC_train:0.9852\n",
      "acc_val:0.8427 pre_val:0.7937 recall_val:0.9804 F1_val:0.877193 AUC_val:0.9659\n",
      "Epoch:0078\n",
      "acc_train:0.9563 pre_train:0.9287 recall_train:0.9902 F1_train:0.9585 AUC_train:0.9876\n",
      "acc_val:0.8202 pre_val:0.7692 recall_val:0.9804 F1_val:0.862069 AUC_val:0.9696\n",
      "Epoch:0079\n",
      "acc_train:0.9675 pre_train:0.9548 recall_train:0.9828 F1_train:0.9686 AUC_train:0.9859\n",
      "acc_val:0.8090 pre_val:0.7576 recall_val:0.9804 F1_val:0.854701 AUC_val:0.9727\n",
      "Epoch:0080\n",
      "acc_train:0.9588 pre_train:0.9371 recall_train:0.9853 F1_train:0.9606 AUC_train:0.9856\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9742\n",
      "Epoch:0081\n",
      "acc_train:0.9613 pre_train:0.9415 recall_train:0.9853 F1_train:0.9629 AUC_train:0.9821\n",
      "acc_val:0.8202 pre_val:0.7692 recall_val:0.9804 F1_val:0.862069 AUC_val:0.9747\n",
      "Epoch:0082\n",
      "acc_train:0.9588 pre_train:0.9371 recall_train:0.9853 F1_train:0.9606 AUC_train:0.9861\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9763\n",
      "Epoch:0083\n",
      "acc_train:0.9576 pre_train:0.9329 recall_train:0.9877 F1_train:0.9595 AUC_train:0.9870\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9757\n",
      "Epoch:0084\n",
      "acc_train:0.9700 pre_train:0.9593 recall_train:0.9828 F1_train:0.9709 AUC_train:0.9885\n",
      "acc_val:0.8652 pre_val:0.8095 recall_val:1.0000 F1_val:0.894737 AUC_val:0.9763\n",
      "Epoch:0085\n",
      "acc_train:0.9650 pre_train:0.9502 recall_train:0.9828 F1_train:0.9663 AUC_train:0.9853\n",
      "acc_val:0.8989 pre_val:0.8500 recall_val:1.0000 F1_val:0.918919 AUC_val:0.9701\n",
      "Epoch:0086\n",
      "acc_train:0.9625 pre_train:0.9458 recall_train:0.9828 F1_train:0.9639 AUC_train:0.9846\n",
      "acc_val:0.8876 pre_val:0.8596 recall_val:0.9608 F1_val:0.907407 AUC_val:0.9670\n",
      "Epoch:0087\n",
      "acc_train:0.9563 pre_train:0.9327 recall_train:0.9853 F1_train:0.9583 AUC_train:0.9841\n",
      "acc_val:0.9101 pre_val:0.8644 recall_val:1.0000 F1_val:0.927273 AUC_val:0.9685\n",
      "Epoch:0088\n",
      "acc_train:0.9625 pre_train:0.9565 recall_train:0.9706 F1_train:0.9635 AUC_train:0.9815\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9701\n",
      "Epoch:0089\n",
      "acc_train:0.9688 pre_train:0.9637 recall_train:0.9755 F1_train:0.9695 AUC_train:0.9901\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9711\n",
      "Epoch:0090\n",
      "acc_train:0.9775 pre_train:0.9643 recall_train:0.9926 F1_train:0.9783 AUC_train:0.9911\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9721\n",
      "Epoch:0091\n",
      "acc_train:0.9750 pre_train:0.9619 recall_train:0.9902 F1_train:0.9758 AUC_train:0.9895\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9706\n",
      "Epoch:0092\n",
      "acc_train:0.9775 pre_train:0.9688 recall_train:0.9877 F1_train:0.9782 AUC_train:0.9917\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9721\n",
      "Epoch:0093\n",
      "acc_train:0.9738 pre_train:0.9596 recall_train:0.9902 F1_train:0.9747 AUC_train:0.9928\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9711\n",
      "Epoch:0094\n",
      "acc_train:0.9725 pre_train:0.9617 recall_train:0.9853 F1_train:0.9734 AUC_train:0.9919\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9696\n",
      "Epoch:0095\n",
      "acc_train:0.9688 pre_train:0.9570 recall_train:0.9828 F1_train:0.9698 AUC_train:0.9900\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9701\n",
      "Epoch:0096\n",
      "acc_train:0.9576 pre_train:0.9410 recall_train:0.9779 F1_train:0.9591 AUC_train:0.9854\n",
      "acc_val:0.8539 pre_val:0.8065 recall_val:0.9804 F1_val:0.884956 AUC_val:0.9716\n",
      "Epoch:0097\n",
      "acc_train:0.9688 pre_train:0.9570 recall_train:0.9828 F1_train:0.9698 AUC_train:0.9874\n",
      "acc_val:0.8539 pre_val:0.8065 recall_val:0.9804 F1_val:0.884956 AUC_val:0.9727\n",
      "Epoch:0098\n",
      "acc_train:0.9775 pre_train:0.9643 recall_train:0.9926 F1_train:0.9783 AUC_train:0.9848\n",
      "acc_val:0.8652 pre_val:0.8095 recall_val:1.0000 F1_val:0.894737 AUC_val:0.9737\n",
      "Epoch:0099\n",
      "acc_train:0.9725 pre_train:0.9595 recall_train:0.9877 F1_train:0.9734 AUC_train:0.9891\n",
      "acc_val:0.8652 pre_val:0.8095 recall_val:1.0000 F1_val:0.894737 AUC_val:0.9763\n",
      "Epoch:0100\n",
      "acc_train:0.9750 pre_train:0.9641 recall_train:0.9877 F1_train:0.9758 AUC_train:0.9912\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9773\n",
      "Epoch:0101\n",
      "acc_train:0.9725 pre_train:0.9595 recall_train:0.9877 F1_train:0.9734 AUC_train:0.9937\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9773\n",
      "Epoch:0102\n",
      "acc_train:0.9613 pre_train:0.9415 recall_train:0.9853 F1_train:0.9629 AUC_train:0.9914\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9794\n",
      "Epoch:0103\n",
      "acc_train:0.9700 pre_train:0.9528 recall_train:0.9902 F1_train:0.9712 AUC_train:0.9924\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9835\n",
      "Epoch:0104\n",
      "acc_train:0.9700 pre_train:0.9660 recall_train:0.9755 F1_train:0.9707 AUC_train:0.9903\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9850\n",
      "Epoch:0105\n",
      "acc_train:0.9775 pre_train:0.9665 recall_train:0.9902 F1_train:0.9782 AUC_train:0.9898\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9840\n",
      "Epoch:0106\n",
      "acc_train:0.9763 pre_train:0.9642 recall_train:0.9902 F1_train:0.9770 AUC_train:0.9923\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9835\n",
      "Epoch:0107\n",
      "acc_train:0.9763 pre_train:0.9687 recall_train:0.9853 F1_train:0.9769 AUC_train:0.9920\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9825\n",
      "Epoch:0108\n",
      "acc_train:0.9675 pre_train:0.9505 recall_train:0.9877 F1_train:0.9688 AUC_train:0.9889\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9799\n",
      "Epoch:0109\n",
      "acc_train:0.9825 pre_train:0.9713 recall_train:0.9951 F1_train:0.9831 AUC_train:0.9914\n",
      "acc_val:0.8989 pre_val:0.8621 recall_val:0.9804 F1_val:0.917431 AUC_val:0.9732\n",
      "Epoch:0110\n",
      "acc_train:0.9775 pre_train:0.9643 recall_train:0.9926 F1_train:0.9783 AUC_train:0.9968\n",
      "acc_val:0.8989 pre_val:0.8750 recall_val:0.9608 F1_val:0.915888 AUC_val:0.9706\n",
      "Epoch:0111\n",
      "acc_train:0.9838 pre_train:0.9805 recall_train:0.9877 F1_train:0.9841 AUC_train:0.9917\n",
      "acc_val:0.8989 pre_val:0.8750 recall_val:0.9608 F1_val:0.915888 AUC_val:0.9701\n",
      "Epoch:0112\n",
      "acc_train:0.9675 pre_train:0.9526 recall_train:0.9853 F1_train:0.9687 AUC_train:0.9911\n",
      "acc_val:0.8989 pre_val:0.8750 recall_val:0.9608 F1_val:0.915888 AUC_val:0.9685\n",
      "Epoch:0113\n",
      "acc_train:0.9663 pre_train:0.9568 recall_train:0.9779 F1_train:0.9673 AUC_train:0.9924\n",
      "acc_val:0.8876 pre_val:0.8475 recall_val:0.9804 F1_val:0.909091 AUC_val:0.9706\n",
      "Epoch:0114\n",
      "acc_train:0.9688 pre_train:0.9592 recall_train:0.9804 F1_train:0.9697 AUC_train:0.9907\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9737\n",
      "Epoch:0115\n",
      "acc_train:0.9663 pre_train:0.9568 recall_train:0.9779 F1_train:0.9673 AUC_train:0.9889\n",
      "acc_val:0.8652 pre_val:0.8095 recall_val:1.0000 F1_val:0.894737 AUC_val:0.9778\n",
      "Epoch:0116\n",
      "acc_train:0.9788 pre_train:0.9644 recall_train:0.9951 F1_train:0.9795 AUC_train:0.9960\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9752\n",
      "Epoch:0117\n",
      "acc_train:0.9788 pre_train:0.9666 recall_train:0.9926 F1_train:0.9794 AUC_train:0.9935\n",
      "acc_val:0.7865 pre_val:0.7286 recall_val:1.0000 F1_val:0.842975 AUC_val:0.9732\n",
      "Epoch:0118\n",
      "acc_train:0.9800 pre_train:0.9734 recall_train:0.9877 F1_train:0.9805 AUC_train:0.9923\n",
      "acc_val:0.7865 pre_val:0.7286 recall_val:1.0000 F1_val:0.842975 AUC_val:0.9696\n",
      "Epoch:0119\n",
      "acc_train:0.9775 pre_train:0.9688 recall_train:0.9877 F1_train:0.9782 AUC_train:0.9951\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9649\n",
      "Epoch:0120\n",
      "acc_train:0.9813 pre_train:0.9712 recall_train:0.9926 F1_train:0.9818 AUC_train:0.9962\n",
      "acc_val:0.7978 pre_val:0.7463 recall_val:0.9804 F1_val:0.847458 AUC_val:0.9623\n",
      "Epoch:0121\n",
      "acc_train:0.9763 pre_train:0.9642 recall_train:0.9902 F1_train:0.9770 AUC_train:0.9957\n",
      "acc_val:0.8202 pre_val:0.7692 recall_val:0.9804 F1_val:0.862069 AUC_val:0.9592\n",
      "Epoch:0122\n",
      "acc_train:0.9750 pre_train:0.9641 recall_train:0.9877 F1_train:0.9758 AUC_train:0.9965\n",
      "acc_val:0.8539 pre_val:0.8065 recall_val:0.9804 F1_val:0.884956 AUC_val:0.9567\n",
      "Epoch:0123\n",
      "acc_train:0.9788 pre_train:0.9622 recall_train:0.9975 F1_train:0.9795 AUC_train:0.9937\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0124\n",
      "acc_train:0.9800 pre_train:0.9757 recall_train:0.9853 F1_train:0.9805 AUC_train:0.9919\n",
      "acc_val:0.8989 pre_val:0.8500 recall_val:1.0000 F1_val:0.918919 AUC_val:0.9561\n",
      "Epoch:0125\n",
      "acc_train:0.9738 pre_train:0.9685 recall_train:0.9804 F1_train:0.9744 AUC_train:0.9959\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9582\n",
      "Epoch:0126\n",
      "acc_train:0.9813 pre_train:0.9735 recall_train:0.9902 F1_train:0.9818 AUC_train:0.9943\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9598\n",
      "Epoch:0127\n",
      "acc_train:0.9775 pre_train:0.9643 recall_train:0.9926 F1_train:0.9783 AUC_train:0.9915\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9613\n",
      "Epoch:0128\n",
      "acc_train:0.9850 pre_train:0.9737 recall_train:0.9975 F1_train:0.9855 AUC_train:0.9934\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9654\n",
      "Epoch:0129\n",
      "acc_train:0.9788 pre_train:0.9734 recall_train:0.9853 F1_train:0.9793 AUC_train:0.9972\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9670\n",
      "Epoch:0130\n",
      "acc_train:0.9850 pre_train:0.9760 recall_train:0.9951 F1_train:0.9854 AUC_train:0.9946\n",
      "acc_val:0.8764 pre_val:0.8226 recall_val:1.0000 F1_val:0.902655 AUC_val:0.9680\n",
      "Epoch:0131\n",
      "acc_train:0.9813 pre_train:0.9758 recall_train:0.9877 F1_train:0.9817 AUC_train:0.9945\n",
      "acc_val:0.8876 pre_val:0.8361 recall_val:1.0000 F1_val:0.910714 AUC_val:0.9716\n",
      "Early Stopping!!! epoch：130\n",
      " Starting the 3-3 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4494 pre_train:0.4622 recall_train:0.4951 F1_train:0.4781 AUC_train:0.4317\n",
      "acc_val:0.4045 pre_val:0.2500 recall_val:0.0196 F1_val:0.036364 AUC_val:0.2967\n",
      "Epoch:0002\n",
      "acc_train:0.4919 pre_train:0.5011 recall_train:0.5662 F1_train:0.5316 AUC_train:0.4997\n",
      "acc_val:0.4607 pre_val:0.7143 recall_val:0.0980 F1_val:0.172414 AUC_val:0.3870\n",
      "Epoch:0003\n",
      "acc_train:0.5094 pre_train:0.5176 recall_train:0.5392 F1_train:0.5282 AUC_train:0.5142\n",
      "acc_val:0.4382 pre_val:0.5455 recall_val:0.1176 F1_val:0.193548 AUC_val:0.4360\n",
      "Epoch:0004\n",
      "acc_train:0.5169 pre_train:0.5220 recall_train:0.6103 F1_train:0.5627 AUC_train:0.5172\n",
      "acc_val:0.5506 pre_val:0.6667 recall_val:0.4314 F1_val:0.523810 AUC_val:0.6269\n",
      "Epoch:0005\n",
      "acc_train:0.5481 pre_train:0.5525 recall_train:0.5931 F1_train:0.5721 AUC_train:0.5542\n",
      "acc_val:0.6404 pre_val:0.7317 recall_val:0.5882 F1_val:0.652174 AUC_val:0.6940\n",
      "Epoch:0006\n",
      "acc_train:0.5581 pre_train:0.5563 recall_train:0.6544 F1_train:0.6014 AUC_train:0.5846\n",
      "acc_val:0.6292 pre_val:0.7250 recall_val:0.5686 F1_val:0.637363 AUC_val:0.7276\n",
      "Epoch:0007\n",
      "acc_train:0.5618 pre_train:0.5687 recall_train:0.5784 F1_train:0.5735 AUC_train:0.5737\n",
      "acc_val:0.6517 pre_val:0.7273 recall_val:0.6275 F1_val:0.673684 AUC_val:0.7368\n",
      "Epoch:0008\n",
      "acc_train:0.5643 pre_train:0.5632 recall_train:0.6446 F1_train:0.6011 AUC_train:0.5828\n",
      "acc_val:0.6629 pre_val:0.7333 recall_val:0.6471 F1_val:0.687500 AUC_val:0.7425\n",
      "Epoch:0009\n",
      "acc_train:0.6005 pre_train:0.6023 recall_train:0.6348 F1_train:0.6181 AUC_train:0.6305\n",
      "acc_val:0.6742 pre_val:0.7391 recall_val:0.6667 F1_val:0.701031 AUC_val:0.7497\n",
      "Epoch:0010\n",
      "acc_train:0.5680 pre_train:0.5708 recall_train:0.6127 F1_train:0.5910 AUC_train:0.6258\n",
      "acc_val:0.6629 pre_val:0.7143 recall_val:0.6863 F1_val:0.700000 AUC_val:0.7394\n",
      "Epoch:0011\n",
      "acc_train:0.6067 pre_train:0.6059 recall_train:0.6520 F1_train:0.6281 AUC_train:0.6561\n",
      "acc_val:0.6966 pre_val:0.7308 recall_val:0.7451 F1_val:0.737864 AUC_val:0.7477\n",
      "Epoch:0012\n",
      "acc_train:0.5905 pre_train:0.5966 recall_train:0.6054 F1_train:0.6010 AUC_train:0.6133\n",
      "acc_val:0.7079 pre_val:0.7358 recall_val:0.7647 F1_val:0.750000 AUC_val:0.7590\n",
      "Epoch:0013\n",
      "acc_train:0.6380 pre_train:0.6513 recall_train:0.6225 F1_train:0.6366 AUC_train:0.6830\n",
      "acc_val:0.7079 pre_val:0.7358 recall_val:0.7647 F1_val:0.750000 AUC_val:0.7683\n",
      "Epoch:0014\n",
      "acc_train:0.5818 pre_train:0.5806 recall_train:0.6446 F1_train:0.6109 AUC_train:0.6157\n",
      "acc_val:0.7079 pre_val:0.7358 recall_val:0.7647 F1_val:0.750000 AUC_val:0.7776\n",
      "Epoch:0015\n",
      "acc_train:0.6242 pre_train:0.6247 recall_train:0.6569 F1_train:0.6404 AUC_train:0.6683\n",
      "acc_val:0.7079 pre_val:0.7358 recall_val:0.7647 F1_val:0.750000 AUC_val:0.7797\n",
      "Epoch:0016\n",
      "acc_train:0.6117 pre_train:0.6163 recall_train:0.6299 F1_train:0.6230 AUC_train:0.6658\n",
      "acc_val:0.7079 pre_val:0.7358 recall_val:0.7647 F1_val:0.750000 AUC_val:0.7807\n",
      "Epoch:0017\n",
      "acc_train:0.6629 pre_train:0.7018 recall_train:0.5882 F1_train:0.6400 AUC_train:0.7030\n",
      "acc_val:0.6966 pre_val:0.7308 recall_val:0.7451 F1_val:0.737864 AUC_val:0.7848\n",
      "Epoch:0018\n",
      "acc_train:0.6155 pre_train:0.6042 recall_train:0.7108 F1_train:0.6532 AUC_train:0.6884\n",
      "acc_val:0.6966 pre_val:0.7143 recall_val:0.7843 F1_val:0.747664 AUC_val:0.7936\n",
      "Epoch:0019\n",
      "acc_train:0.6342 pre_train:0.6509 recall_train:0.6078 F1_train:0.6286 AUC_train:0.6938\n",
      "acc_val:0.6966 pre_val:0.7143 recall_val:0.7843 F1_val:0.747664 AUC_val:0.7957\n",
      "Epoch:0020\n",
      "acc_train:0.6292 pre_train:0.6276 recall_train:0.6691 F1_train:0.6477 AUC_train:0.6966\n",
      "acc_val:0.6966 pre_val:0.7143 recall_val:0.7843 F1_val:0.747664 AUC_val:0.7967\n",
      "Epoch:0021\n",
      "acc_train:0.6704 pre_train:0.7182 recall_train:0.5809 F1_train:0.6423 AUC_train:0.7111\n",
      "acc_val:0.7191 pre_val:0.7407 recall_val:0.7843 F1_val:0.761905 AUC_val:0.7967\n",
      "Epoch:0022\n",
      "acc_train:0.5968 pre_train:0.6081 recall_train:0.5858 F1_train:0.5968 AUC_train:0.6630\n",
      "acc_val:0.6854 pre_val:0.7255 recall_val:0.7255 F1_val:0.725490 AUC_val:0.7905\n",
      "Epoch:0023\n",
      "acc_train:0.6330 pre_train:0.6566 recall_train:0.5858 F1_train:0.6192 AUC_train:0.6706\n",
      "acc_val:0.7303 pre_val:0.7872 recall_val:0.7255 F1_val:0.755102 AUC_val:0.7936\n",
      "Epoch:0024\n",
      "acc_train:0.6592 pre_train:0.6675 recall_train:0.6593 F1_train:0.6634 AUC_train:0.7070\n",
      "acc_val:0.7079 pre_val:0.7451 recall_val:0.7451 F1_val:0.745098 AUC_val:0.7972\n",
      "Epoch:0025\n",
      "acc_train:0.6767 pre_train:0.7427 recall_train:0.5588 F1_train:0.6378 AUC_train:0.7211\n",
      "acc_val:0.7303 pre_val:0.7872 recall_val:0.7255 F1_val:0.755102 AUC_val:0.7972\n",
      "Epoch:0026\n",
      "acc_train:0.6792 pre_train:0.7295 recall_train:0.5882 F1_train:0.6513 AUC_train:0.7287\n",
      "acc_val:0.7079 pre_val:0.8205 recall_val:0.6275 F1_val:0.711111 AUC_val:0.7988\n",
      "Epoch:0027\n",
      "acc_train:0.6792 pre_train:0.7035 recall_train:0.6397 F1_train:0.6701 AUC_train:0.7356\n",
      "acc_val:0.7191 pre_val:0.8611 recall_val:0.6078 F1_val:0.712644 AUC_val:0.8019\n",
      "Epoch:0028\n",
      "acc_train:0.6804 pre_train:0.7676 recall_train:0.5343 F1_train:0.6301 AUC_train:0.7359\n",
      "acc_val:0.7303 pre_val:0.8857 recall_val:0.6078 F1_val:0.720930 AUC_val:0.8039\n",
      "Epoch:0029\n",
      "acc_train:0.6517 pre_train:0.6748 recall_train:0.6103 F1_train:0.6409 AUC_train:0.7155\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8008\n",
      "Epoch:0030\n",
      "acc_train:0.6679 pre_train:0.6940 recall_train:0.6225 F1_train:0.6563 AUC_train:0.7383\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8034\n",
      "Epoch:0031\n",
      "acc_train:0.6816 pre_train:0.7243 recall_train:0.6054 F1_train:0.6595 AUC_train:0.7601\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8075\n",
      "Epoch:0032\n",
      "acc_train:0.7079 pre_train:0.7175 recall_train:0.7034 F1_train:0.7104 AUC_train:0.7748\n",
      "acc_val:0.7303 pre_val:0.9091 recall_val:0.5882 F1_val:0.714286 AUC_val:0.8122\n",
      "Epoch:0033\n",
      "acc_train:0.6929 pre_train:0.7812 recall_train:0.5515 F1_train:0.6466 AUC_train:0.7567\n",
      "acc_val:0.7416 pre_val:0.9375 recall_val:0.5882 F1_val:0.722892 AUC_val:0.8148\n",
      "Epoch:0034\n",
      "acc_train:0.6854 pre_train:0.7267 recall_train:0.6127 F1_train:0.6649 AUC_train:0.7689\n",
      "acc_val:0.7416 pre_val:0.9375 recall_val:0.5882 F1_val:0.722892 AUC_val:0.8173\n",
      "Epoch:0035\n",
      "acc_train:0.6979 pre_train:0.7150 recall_train:0.6765 F1_train:0.6952 AUC_train:0.7803\n",
      "acc_val:0.7416 pre_val:0.9375 recall_val:0.5882 F1_val:0.722892 AUC_val:0.8199\n",
      "Epoch:0036\n",
      "acc_train:0.7016 pre_train:0.7649 recall_train:0.5980 F1_train:0.6713 AUC_train:0.7747\n",
      "acc_val:0.7416 pre_val:0.9375 recall_val:0.5882 F1_val:0.722892 AUC_val:0.8173\n",
      "Epoch:0037\n",
      "acc_train:0.6916 pre_train:0.7477 recall_train:0.5956 F1_train:0.6630 AUC_train:0.7567\n",
      "acc_val:0.7303 pre_val:0.9091 recall_val:0.5882 F1_val:0.714286 AUC_val:0.8184\n",
      "Epoch:0038\n",
      "acc_train:0.7016 pre_train:0.7616 recall_train:0.6029 F1_train:0.6731 AUC_train:0.7863\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8189\n",
      "Epoch:0039\n",
      "acc_train:0.7091 pre_train:0.7726 recall_train:0.6078 F1_train:0.6804 AUC_train:0.7922\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8251\n",
      "Epoch:0040\n",
      "acc_train:0.7166 pre_train:0.8131 recall_train:0.5760 F1_train:0.6743 AUC_train:0.7941\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8266\n",
      "Epoch:0041\n",
      "acc_train:0.7191 pre_train:0.7133 recall_train:0.7500 F1_train:0.7312 AUC_train:0.8190\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8277\n",
      "Epoch:0042\n",
      "acc_train:0.7253 pre_train:0.7582 recall_train:0.6765 F1_train:0.7150 AUC_train:0.8249\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8297\n",
      "Epoch:0043\n",
      "acc_train:0.7403 pre_train:0.8311 recall_train:0.6152 F1_train:0.7070 AUC_train:0.8628\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8349\n",
      "Epoch:0044\n",
      "acc_train:0.7453 pre_train:0.8592 recall_train:0.5980 F1_train:0.7052 AUC_train:0.8339\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8375\n",
      "Epoch:0045\n",
      "acc_train:0.7503 pre_train:0.8467 recall_train:0.6225 F1_train:0.7175 AUC_train:0.8515\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8426\n",
      "Epoch:0046\n",
      "acc_train:0.7154 pre_train:0.8333 recall_train:0.5515 F1_train:0.6637 AUC_train:0.8558\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0047\n",
      "acc_train:0.7328 pre_train:0.8212 recall_train:0.6078 F1_train:0.6986 AUC_train:0.8478\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8462\n",
      "Epoch:0048\n",
      "acc_train:0.7341 pre_train:0.7573 recall_train:0.7034 F1_train:0.7294 AUC_train:0.8549\n",
      "acc_val:0.7528 pre_val:0.8919 recall_val:0.6471 F1_val:0.750000 AUC_val:0.8509\n",
      "Epoch:0049\n",
      "acc_train:0.7915 pre_train:0.7932 recall_train:0.7990 F1_train:0.7961 AUC_train:0.8788\n",
      "acc_val:0.7528 pre_val:0.8919 recall_val:0.6471 F1_val:0.750000 AUC_val:0.8566\n",
      "Epoch:0050\n",
      "acc_train:0.7940 pre_train:0.7985 recall_train:0.7966 F1_train:0.7975 AUC_train:0.8744\n",
      "acc_val:0.7528 pre_val:0.8718 recall_val:0.6667 F1_val:0.755556 AUC_val:0.8607\n",
      "Epoch:0051\n",
      "acc_train:0.8127 pre_train:0.8014 recall_train:0.8407 F1_train:0.8206 AUC_train:0.8823\n",
      "acc_val:0.7528 pre_val:0.8718 recall_val:0.6667 F1_val:0.755556 AUC_val:0.8689\n",
      "Epoch:0052\n",
      "acc_train:0.7478 pre_train:0.7696 recall_train:0.7206 F1_train:0.7443 AUC_train:0.8674\n",
      "acc_val:0.7640 pre_val:0.8947 recall_val:0.6667 F1_val:0.764045 AUC_val:0.8725\n",
      "Epoch:0053\n",
      "acc_train:0.7640 pre_train:0.8033 recall_train:0.7108 F1_train:0.7542 AUC_train:0.8768\n",
      "acc_val:0.7753 pre_val:0.8974 recall_val:0.6863 F1_val:0.777778 AUC_val:0.8798\n",
      "Epoch:0054\n",
      "acc_train:0.7578 pre_train:0.8057 recall_train:0.6912 F1_train:0.7441 AUC_train:0.8847\n",
      "acc_val:0.7865 pre_val:0.9211 recall_val:0.6863 F1_val:0.786517 AUC_val:0.8860\n",
      "Epoch:0055\n",
      "acc_train:0.8315 pre_train:0.8182 recall_train:0.8603 F1_train:0.8387 AUC_train:0.8972\n",
      "acc_val:0.7978 pre_val:0.9231 recall_val:0.7059 F1_val:0.800000 AUC_val:0.8958\n",
      "Epoch:0056\n",
      "acc_train:0.7428 pre_train:0.8507 recall_train:0.6005 F1_train:0.7040 AUC_train:0.8674\n",
      "acc_val:0.7865 pre_val:0.9444 recall_val:0.6667 F1_val:0.781609 AUC_val:0.9051\n",
      "Epoch:0057\n",
      "acc_train:0.8502 pre_train:0.8600 recall_train:0.8431 F1_train:0.8515 AUC_train:0.9218\n",
      "acc_val:0.8202 pre_val:0.9487 recall_val:0.7255 F1_val:0.822222 AUC_val:0.9102\n",
      "Epoch:0058\n",
      "acc_train:0.8689 pre_train:0.8565 recall_train:0.8922 F1_train:0.8739 AUC_train:0.9262\n",
      "acc_val:0.8315 pre_val:0.9500 recall_val:0.7451 F1_val:0.835165 AUC_val:0.9143\n",
      "Epoch:0059\n",
      "acc_train:0.8414 pre_train:0.8009 recall_train:0.9167 F1_train:0.8549 AUC_train:0.9181\n",
      "acc_val:0.8652 pre_val:0.9535 recall_val:0.8039 F1_val:0.872340 AUC_val:0.9205\n",
      "Epoch:0060\n",
      "acc_train:0.8727 pre_train:0.8509 recall_train:0.9093 F1_train:0.8791 AUC_train:0.9220\n",
      "acc_val:0.8652 pre_val:0.9333 recall_val:0.8235 F1_val:0.875000 AUC_val:0.9293\n",
      "Epoch:0061\n",
      "acc_train:0.8614 pre_train:0.8249 recall_train:0.9240 F1_train:0.8717 AUC_train:0.9291\n",
      "acc_val:0.8764 pre_val:0.9348 recall_val:0.8431 F1_val:0.886598 AUC_val:0.9360\n",
      "Epoch:0062\n",
      "acc_train:0.8752 pre_train:0.8532 recall_train:0.9118 F1_train:0.8815 AUC_train:0.9370\n",
      "acc_val:0.8989 pre_val:0.9375 recall_val:0.8824 F1_val:0.909091 AUC_val:0.9391\n",
      "Epoch:0063\n",
      "acc_train:0.8777 pre_train:0.8399 recall_train:0.9387 F1_train:0.8866 AUC_train:0.9420\n",
      "acc_val:0.8876 pre_val:0.9184 recall_val:0.8824 F1_val:0.900000 AUC_val:0.9401\n",
      "Epoch:0064\n",
      "acc_train:0.8714 pre_train:0.8412 recall_train:0.9216 F1_train:0.8795 AUC_train:0.9405\n",
      "acc_val:0.8764 pre_val:0.9167 recall_val:0.8627 F1_val:0.888889 AUC_val:0.9417\n",
      "Epoch:0065\n",
      "acc_train:0.8951 pre_train:0.8665 recall_train:0.9387 F1_train:0.9012 AUC_train:0.9429\n",
      "acc_val:0.8876 pre_val:0.9362 recall_val:0.8627 F1_val:0.897959 AUC_val:0.9396\n",
      "Epoch:0066\n",
      "acc_train:0.9014 pre_train:0.8782 recall_train:0.9363 F1_train:0.9063 AUC_train:0.9467\n",
      "acc_val:0.8876 pre_val:0.9362 recall_val:0.8627 F1_val:0.897959 AUC_val:0.9407\n",
      "Epoch:0067\n",
      "acc_train:0.8851 pre_train:0.8607 recall_train:0.9240 F1_train:0.8913 AUC_train:0.9465\n",
      "acc_val:0.8876 pre_val:0.9362 recall_val:0.8627 F1_val:0.897959 AUC_val:0.9422\n",
      "Epoch:0068\n",
      "acc_train:0.8939 pre_train:0.8730 recall_train:0.9265 F1_train:0.8989 AUC_train:0.9477\n",
      "acc_val:0.8876 pre_val:0.9362 recall_val:0.8627 F1_val:0.897959 AUC_val:0.9489\n",
      "Epoch:0069\n",
      "acc_train:0.9064 pre_train:0.8863 recall_train:0.9363 F1_train:0.9106 AUC_train:0.9544\n",
      "acc_val:0.8876 pre_val:0.9362 recall_val:0.8627 F1_val:0.897959 AUC_val:0.9546\n",
      "Epoch:0070\n",
      "acc_train:0.9126 pre_train:0.8894 recall_train:0.9461 F1_train:0.9169 AUC_train:0.9560\n",
      "acc_val:0.8989 pre_val:0.9200 recall_val:0.9020 F1_val:0.910891 AUC_val:0.9582\n",
      "Epoch:0071\n",
      "acc_train:0.9176 pre_train:0.8958 recall_train:0.9485 F1_train:0.9214 AUC_train:0.9556\n",
      "acc_val:0.8876 pre_val:0.9020 recall_val:0.9020 F1_val:0.901961 AUC_val:0.9592\n",
      "Epoch:0072\n",
      "acc_train:0.9051 pre_train:0.8722 recall_train:0.9534 F1_train:0.9110 AUC_train:0.9610\n",
      "acc_val:0.8764 pre_val:0.8846 recall_val:0.9020 F1_val:0.893204 AUC_val:0.9603\n",
      "Epoch:0073\n",
      "acc_train:0.8964 pre_train:0.8685 recall_train:0.9387 F1_train:0.9022 AUC_train:0.9567\n",
      "acc_val:0.8652 pre_val:0.8421 recall_val:0.9412 F1_val:0.888889 AUC_val:0.9603\n",
      "Epoch:0074\n",
      "acc_train:0.8976 pre_train:0.8622 recall_train:0.9510 F1_train:0.9044 AUC_train:0.9629\n",
      "acc_val:0.8202 pre_val:0.8070 recall_val:0.9020 F1_val:0.851852 AUC_val:0.9577\n",
      "Epoch:0075\n",
      "acc_train:0.9176 pre_train:0.8958 recall_train:0.9485 F1_train:0.9214 AUC_train:0.9656\n",
      "acc_val:0.8427 pre_val:0.8364 recall_val:0.9020 F1_val:0.867925 AUC_val:0.9582\n",
      "Epoch:0076\n",
      "acc_train:0.9089 pre_train:0.8665 recall_train:0.9706 F1_train:0.9156 AUC_train:0.9666\n",
      "acc_val:0.8764 pre_val:0.8846 recall_val:0.9020 F1_val:0.893204 AUC_val:0.9572\n",
      "Epoch:0077\n",
      "acc_train:0.9076 pre_train:0.8795 recall_train:0.9485 F1_train:0.9127 AUC_train:0.9698\n",
      "acc_val:0.8764 pre_val:0.8846 recall_val:0.9020 F1_val:0.893204 AUC_val:0.9561\n",
      "Epoch:0078\n",
      "acc_train:0.9326 pre_train:0.9175 recall_train:0.9534 F1_train:0.9351 AUC_train:0.9652\n",
      "acc_val:0.8764 pre_val:0.8846 recall_val:0.9020 F1_val:0.893204 AUC_val:0.9577\n",
      "Epoch:0079\n",
      "acc_train:0.9139 pre_train:0.8844 recall_train:0.9559 F1_train:0.9187 AUC_train:0.9675\n",
      "acc_val:0.8764 pre_val:0.8846 recall_val:0.9020 F1_val:0.893204 AUC_val:0.9572\n",
      "Epoch:0080\n",
      "acc_train:0.9301 pre_train:0.9000 recall_train:0.9706 F1_train:0.9340 AUC_train:0.9774\n",
      "acc_val:0.8427 pre_val:0.8136 recall_val:0.9412 F1_val:0.872727 AUC_val:0.9598\n",
      "Epoch:0081\n",
      "acc_train:0.9251 pre_train:0.8919 recall_train:0.9706 F1_train:0.9296 AUC_train:0.9750\n",
      "acc_val:0.8427 pre_val:0.8033 recall_val:0.9608 F1_val:0.875000 AUC_val:0.9613\n",
      "Epoch:0082\n",
      "acc_train:0.9263 pre_train:0.8993 recall_train:0.9632 F1_train:0.9302 AUC_train:0.9721\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9649\n",
      "Epoch:0083\n",
      "acc_train:0.9238 pre_train:0.8899 recall_train:0.9706 F1_train:0.9285 AUC_train:0.9743\n",
      "acc_val:0.8202 pre_val:0.7692 recall_val:0.9804 F1_val:0.862069 AUC_val:0.9670\n",
      "Epoch:0084\n",
      "acc_train:0.9201 pre_train:0.8927 recall_train:0.9583 F1_train:0.9243 AUC_train:0.9687\n",
      "acc_val:0.8427 pre_val:0.7937 recall_val:0.9804 F1_val:0.877193 AUC_val:0.9649\n",
      "Epoch:0085\n",
      "acc_train:0.9438 pre_train:0.9192 recall_train:0.9755 F1_train:0.9465 AUC_train:0.9807\n",
      "acc_val:0.8539 pre_val:0.8167 recall_val:0.9608 F1_val:0.882883 AUC_val:0.9613\n",
      "Epoch:0086\n",
      "acc_train:0.9338 pre_train:0.9118 recall_train:0.9632 F1_train:0.9368 AUC_train:0.9796\n",
      "acc_val:0.8539 pre_val:0.8393 recall_val:0.9216 F1_val:0.878505 AUC_val:0.9582\n",
      "Epoch:0087\n",
      "acc_train:0.9263 pre_train:0.9030 recall_train:0.9583 F1_train:0.9298 AUC_train:0.9748\n",
      "acc_val:0.8652 pre_val:0.8545 recall_val:0.9216 F1_val:0.886792 AUC_val:0.9556\n",
      "Epoch:0088\n",
      "acc_train:0.9463 pre_train:0.9234 recall_train:0.9755 F1_train:0.9487 AUC_train:0.9827\n",
      "acc_val:0.8427 pre_val:0.8246 recall_val:0.9216 F1_val:0.870370 AUC_val:0.9551\n",
      "Epoch:0089\n",
      "acc_train:0.9313 pre_train:0.8966 recall_train:0.9779 F1_train:0.9355 AUC_train:0.9786\n",
      "acc_val:0.8315 pre_val:0.7903 recall_val:0.9608 F1_val:0.867257 AUC_val:0.9582\n",
      "Epoch:0090\n",
      "acc_train:0.9451 pre_train:0.9213 recall_train:0.9755 F1_train:0.9476 AUC_train:0.9787\n",
      "acc_val:0.7978 pre_val:0.7538 recall_val:0.9608 F1_val:0.844828 AUC_val:0.9592\n",
      "Epoch:0091\n",
      "acc_train:0.9488 pre_train:0.9258 recall_train:0.9779 F1_train:0.9511 AUC_train:0.9820\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9608\n",
      "Epoch:0092\n",
      "acc_train:0.9451 pre_train:0.9313 recall_train:0.9632 F1_train:0.9470 AUC_train:0.9817\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9608\n",
      "Epoch:0093\n",
      "acc_train:0.9438 pre_train:0.9251 recall_train:0.9681 F1_train:0.9461 AUC_train:0.9824\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0094\n",
      "acc_train:0.9326 pre_train:0.9136 recall_train:0.9583 F1_train:0.9354 AUC_train:0.9797\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9644\n",
      "Epoch:0095\n",
      "acc_train:0.9513 pre_train:0.9341 recall_train:0.9730 F1_train:0.9532 AUC_train:0.9841\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9628\n",
      "Epoch:0096\n",
      "acc_train:0.9538 pre_train:0.9344 recall_train:0.9779 F1_train:0.9557 AUC_train:0.9759\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9618\n",
      "Epoch:0097\n",
      "acc_train:0.9638 pre_train:0.9459 recall_train:0.9853 F1_train:0.9652 AUC_train:0.9880\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9649\n",
      "Epoch:0098\n",
      "acc_train:0.9501 pre_train:0.9279 recall_train:0.9779 F1_train:0.9523 AUC_train:0.9843\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9654\n",
      "Epoch:0099\n",
      "acc_train:0.9488 pre_train:0.9297 recall_train:0.9730 F1_train:0.9509 AUC_train:0.9794\n",
      "acc_val:0.8652 pre_val:0.8197 recall_val:0.9804 F1_val:0.892857 AUC_val:0.9628\n",
      "Epoch:0100\n",
      "acc_train:0.9563 pre_train:0.9388 recall_train:0.9779 F1_train:0.9580 AUC_train:0.9825\n",
      "acc_val:0.8652 pre_val:0.8197 recall_val:0.9804 F1_val:0.892857 AUC_val:0.9623\n",
      "Epoch:0101\n",
      "acc_train:0.9538 pre_train:0.9365 recall_train:0.9755 F1_train:0.9556 AUC_train:0.9807\n",
      "acc_val:0.8539 pre_val:0.8065 recall_val:0.9804 F1_val:0.884956 AUC_val:0.9639\n",
      "Epoch:0102\n",
      "acc_train:0.9513 pre_train:0.9321 recall_train:0.9755 F1_train:0.9533 AUC_train:0.9832\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9706\n",
      "Epoch:0103\n",
      "acc_train:0.9638 pre_train:0.9523 recall_train:0.9779 F1_train:0.9649 AUC_train:0.9807\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9742\n",
      "Epoch:0104\n",
      "acc_train:0.9625 pre_train:0.9437 recall_train:0.9853 F1_train:0.9640 AUC_train:0.9816\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9747\n",
      "Epoch:0105\n",
      "acc_train:0.9576 pre_train:0.9410 recall_train:0.9779 F1_train:0.9591 AUC_train:0.9871\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9727\n",
      "Epoch:0106\n",
      "acc_train:0.9675 pre_train:0.9569 recall_train:0.9804 F1_train:0.9685 AUC_train:0.9867\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9711\n",
      "Epoch:0107\n",
      "acc_train:0.9700 pre_train:0.9638 recall_train:0.9779 F1_train:0.9708 AUC_train:0.9887\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9685\n",
      "Epoch:0108\n",
      "acc_train:0.9700 pre_train:0.9660 recall_train:0.9755 F1_train:0.9707 AUC_train:0.9918\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9696\n",
      "Epoch:0109\n",
      "acc_train:0.9563 pre_train:0.9472 recall_train:0.9681 F1_train:0.9576 AUC_train:0.9889\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9654\n",
      "Epoch:0110\n",
      "acc_train:0.9763 pre_train:0.9709 recall_train:0.9828 F1_train:0.9769 AUC_train:0.9913\n",
      "acc_val:0.8090 pre_val:0.7576 recall_val:0.9804 F1_val:0.854701 AUC_val:0.9587\n",
      "Epoch:0111\n",
      "acc_train:0.9688 pre_train:0.9570 recall_train:0.9828 F1_train:0.9698 AUC_train:0.9894\n",
      "acc_val:0.8539 pre_val:0.8276 recall_val:0.9412 F1_val:0.880734 AUC_val:0.9546\n",
      "Epoch:0112\n",
      "acc_train:0.9551 pre_train:0.9515 recall_train:0.9608 F1_train:0.9561 AUC_train:0.9879\n",
      "acc_val:0.8539 pre_val:0.8276 recall_val:0.9412 F1_val:0.880734 AUC_val:0.9551\n",
      "Epoch:0113\n",
      "acc_train:0.9600 pre_train:0.9455 recall_train:0.9779 F1_train:0.9614 AUC_train:0.9892\n",
      "acc_val:0.8202 pre_val:0.7869 recall_val:0.9412 F1_val:0.857143 AUC_val:0.9546\n",
      "Epoch:0114\n",
      "acc_train:0.9600 pre_train:0.9476 recall_train:0.9755 F1_train:0.9614 AUC_train:0.9920\n",
      "acc_val:0.8315 pre_val:0.7812 recall_val:0.9804 F1_val:0.869565 AUC_val:0.9577\n",
      "Epoch:0115\n",
      "acc_train:0.9713 pre_train:0.9572 recall_train:0.9877 F1_train:0.9723 AUC_train:0.9960\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9603\n",
      "Epoch:0116\n",
      "acc_train:0.9713 pre_train:0.9594 recall_train:0.9853 F1_train:0.9722 AUC_train:0.9907\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9649\n",
      "Epoch:0117\n",
      "acc_train:0.9725 pre_train:0.9639 recall_train:0.9828 F1_train:0.9733 AUC_train:0.9919\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9665\n",
      "Epoch:0118\n",
      "acc_train:0.9675 pre_train:0.9463 recall_train:0.9926 F1_train:0.9689 AUC_train:0.9948\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9670\n",
      "Epoch:0119\n",
      "acc_train:0.9738 pre_train:0.9596 recall_train:0.9902 F1_train:0.9747 AUC_train:0.9962\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9639\n",
      "Epoch:0120\n",
      "acc_train:0.9663 pre_train:0.9525 recall_train:0.9828 F1_train:0.9674 AUC_train:0.9908\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9665\n",
      "Early Stopping!!! epoch：119\n",
      " Starting the 3-4 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001\n",
      "acc_train:0.4831 pre_train:0.4949 recall_train:0.7206 F1_train:0.5868 AUC_train:0.4873\n",
      "acc_val:0.4270 pre_val:0.0000 recall_val:0.0000 F1_val:0.000000 AUC_val:0.5124\n",
      "Epoch:0002\n",
      "acc_train:0.4919 pre_train:0.5009 recall_train:0.6691 F1_train:0.5729 AUC_train:0.4981\n",
      "acc_val:0.4607 pre_val:1.0000 recall_val:0.0588 F1_val:0.111111 AUC_val:0.6109\n",
      "Epoch:0003\n",
      "acc_train:0.5318 pre_train:0.5306 recall_train:0.7010 F1_train:0.6040 AUC_train:0.5406\n",
      "acc_val:0.5506 pre_val:0.8667 recall_val:0.2549 F1_val:0.393939 AUC_val:0.7147\n",
      "Epoch:0004\n",
      "acc_train:0.5755 pre_train:0.5700 recall_train:0.6789 F1_train:0.6197 AUC_train:0.6061\n",
      "acc_val:0.5281 pre_val:0.8462 recall_val:0.2157 F1_val:0.343750 AUC_val:0.7528\n",
      "Epoch:0005\n",
      "acc_train:0.5293 pre_train:0.5336 recall_train:0.6029 F1_train:0.5662 AUC_train:0.5555\n",
      "acc_val:0.5506 pre_val:0.8667 recall_val:0.2549 F1_val:0.393939 AUC_val:0.7358\n",
      "Epoch:0006\n",
      "acc_train:0.5705 pre_train:0.5727 recall_train:0.6176 F1_train:0.5943 AUC_train:0.5848\n",
      "acc_val:0.5506 pre_val:0.7895 recall_val:0.2941 F1_val:0.428571 AUC_val:0.7255\n",
      "Epoch:0007\n",
      "acc_train:0.5868 pre_train:0.5850 recall_train:0.6495 F1_train:0.6156 AUC_train:0.5950\n",
      "acc_val:0.5618 pre_val:0.8000 recall_val:0.3137 F1_val:0.450704 AUC_val:0.7735\n",
      "Epoch:0008\n",
      "acc_train:0.5855 pre_train:0.5872 recall_train:0.6275 F1_train:0.6066 AUC_train:0.6127\n",
      "acc_val:0.6180 pre_val:0.8400 recall_val:0.4118 F1_val:0.552632 AUC_val:0.7776\n",
      "Epoch:0009\n",
      "acc_train:0.6067 pre_train:0.6094 recall_train:0.6348 F1_train:0.6218 AUC_train:0.6474\n",
      "acc_val:0.6854 pre_val:0.8710 recall_val:0.5294 F1_val:0.658537 AUC_val:0.7910\n",
      "Epoch:0010\n",
      "acc_train:0.6042 pre_train:0.6076 recall_train:0.6299 F1_train:0.6185 AUC_train:0.6402\n",
      "acc_val:0.7079 pre_val:0.8788 recall_val:0.5686 F1_val:0.690476 AUC_val:0.8008\n",
      "Epoch:0011\n",
      "acc_train:0.6117 pre_train:0.6169 recall_train:0.6275 F1_train:0.6221 AUC_train:0.6634\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8024\n",
      "Epoch:0012\n",
      "acc_train:0.6242 pre_train:0.6295 recall_train:0.6373 F1_train:0.6334 AUC_train:0.6720\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8104\n",
      "Epoch:0013\n",
      "acc_train:0.6504 pre_train:0.6658 recall_train:0.6299 F1_train:0.6474 AUC_train:0.6986\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8240\n",
      "Epoch:0014\n",
      "acc_train:0.6292 pre_train:0.6457 recall_train:0.6029 F1_train:0.6236 AUC_train:0.6937\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8230\n",
      "Epoch:0015\n",
      "acc_train:0.6592 pre_train:0.6700 recall_train:0.6520 F1_train:0.6609 AUC_train:0.7192\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8308\n",
      "Epoch:0016\n",
      "acc_train:0.6654 pre_train:0.6750 recall_train:0.6618 F1_train:0.6683 AUC_train:0.7355\n",
      "acc_val:0.7191 pre_val:0.8824 recall_val:0.5882 F1_val:0.705882 AUC_val:0.8483\n",
      "Epoch:0017\n",
      "acc_train:0.7041 pre_train:0.7268 recall_train:0.6716 F1_train:0.6981 AUC_train:0.7756\n",
      "acc_val:0.7416 pre_val:0.9118 recall_val:0.6078 F1_val:0.729412 AUC_val:0.8643\n",
      "Epoch:0018\n",
      "acc_train:0.6904 pre_train:0.7041 recall_train:0.6765 F1_train:0.6900 AUC_train:0.7503\n",
      "acc_val:0.7528 pre_val:0.9143 recall_val:0.6275 F1_val:0.744186 AUC_val:0.8762\n",
      "Epoch:0019\n",
      "acc_train:0.7066 pre_train:0.7136 recall_train:0.7083 F1_train:0.7109 AUC_train:0.7686\n",
      "acc_val:0.7640 pre_val:0.9167 recall_val:0.6471 F1_val:0.758621 AUC_val:0.8885\n",
      "Epoch:0020\n",
      "acc_train:0.7378 pre_train:0.7302 recall_train:0.7696 F1_train:0.7494 AUC_train:0.8030\n",
      "acc_val:0.8090 pre_val:0.9250 recall_val:0.7255 F1_val:0.813187 AUC_val:0.8968\n",
      "Epoch:0021\n",
      "acc_train:0.7416 pre_train:0.7584 recall_train:0.7230 F1_train:0.7403 AUC_train:0.8149\n",
      "acc_val:0.7978 pre_val:0.8837 recall_val:0.7451 F1_val:0.808511 AUC_val:0.9051\n",
      "Epoch:0022\n",
      "acc_train:0.7241 pre_train:0.7507 recall_train:0.6863 F1_train:0.7170 AUC_train:0.7992\n",
      "acc_val:0.8202 pre_val:0.8889 recall_val:0.7843 F1_val:0.833333 AUC_val:0.9143\n",
      "Epoch:0023\n",
      "acc_train:0.7553 pre_train:0.7598 recall_train:0.7598 F1_train:0.7598 AUC_train:0.8278\n",
      "acc_val:0.8202 pre_val:0.8723 recall_val:0.8039 F1_val:0.836735 AUC_val:0.9180\n",
      "Epoch:0024\n",
      "acc_train:0.7640 pre_train:0.7506 recall_train:0.8039 F1_train:0.7763 AUC_train:0.8287\n",
      "acc_val:0.8315 pre_val:0.8913 recall_val:0.8039 F1_val:0.845361 AUC_val:0.9174\n",
      "Epoch:0025\n",
      "acc_train:0.7878 pre_train:0.7621 recall_train:0.8480 F1_train:0.8028 AUC_train:0.8483\n",
      "acc_val:0.8315 pre_val:0.8750 recall_val:0.8235 F1_val:0.848485 AUC_val:0.9118\n",
      "Epoch:0026\n",
      "acc_train:0.7928 pre_train:0.7881 recall_train:0.8113 F1_train:0.7995 AUC_train:0.8550\n",
      "acc_val:0.8315 pre_val:0.8750 recall_val:0.8235 F1_val:0.848485 AUC_val:0.9123\n",
      "Epoch:0027\n",
      "acc_train:0.8177 pre_train:0.7977 recall_train:0.8603 F1_train:0.8278 AUC_train:0.8661\n",
      "acc_val:0.8427 pre_val:0.8776 recall_val:0.8431 F1_val:0.860000 AUC_val:0.9118\n",
      "Epoch:0028\n",
      "acc_train:0.8090 pre_train:0.7904 recall_train:0.8505 F1_train:0.8194 AUC_train:0.8716\n",
      "acc_val:0.8427 pre_val:0.8776 recall_val:0.8431 F1_val:0.860000 AUC_val:0.9138\n",
      "Epoch:0029\n",
      "acc_train:0.8390 pre_train:0.8107 recall_train:0.8922 F1_train:0.8495 AUC_train:0.9025\n",
      "acc_val:0.8427 pre_val:0.8776 recall_val:0.8431 F1_val:0.860000 AUC_val:0.9174\n",
      "Epoch:0030\n",
      "acc_train:0.8327 pre_train:0.7915 recall_train:0.9118 F1_train:0.8474 AUC_train:0.8839\n",
      "acc_val:0.8539 pre_val:0.8958 recall_val:0.8431 F1_val:0.868687 AUC_val:0.9211\n",
      "Epoch:0031\n",
      "acc_train:0.8127 pre_train:0.7676 recall_train:0.9069 F1_train:0.8315 AUC_train:0.8677\n",
      "acc_val:0.8539 pre_val:0.8958 recall_val:0.8431 F1_val:0.868687 AUC_val:0.9247\n",
      "Epoch:0032\n",
      "acc_train:0.8427 pre_train:0.8052 recall_train:0.9118 F1_train:0.8552 AUC_train:0.8914\n",
      "acc_val:0.8315 pre_val:0.8600 recall_val:0.8431 F1_val:0.851485 AUC_val:0.9257\n",
      "Epoch:0033\n",
      "acc_train:0.8277 pre_train:0.7836 recall_train:0.9142 F1_train:0.8439 AUC_train:0.8887\n",
      "acc_val:0.8315 pre_val:0.8600 recall_val:0.8431 F1_val:0.851485 AUC_val:0.9288\n",
      "Epoch:0034\n",
      "acc_train:0.8627 pre_train:0.8130 recall_train:0.9485 F1_train:0.8756 AUC_train:0.9124\n",
      "acc_val:0.8539 pre_val:0.8519 recall_val:0.9020 F1_val:0.876190 AUC_val:0.9334\n",
      "Epoch:0035\n",
      "acc_train:0.8502 pre_train:0.7975 recall_train:0.9461 F1_train:0.8655 AUC_train:0.9069\n",
      "acc_val:0.8090 pre_val:0.7833 recall_val:0.9216 F1_val:0.846847 AUC_val:0.9401\n",
      "Epoch:0036\n",
      "acc_train:0.8539 pre_train:0.7963 recall_train:0.9583 F1_train:0.8699 AUC_train:0.9238\n",
      "acc_val:0.7865 pre_val:0.7424 recall_val:0.9608 F1_val:0.837607 AUC_val:0.9463\n",
      "Epoch:0037\n",
      "acc_train:0.8539 pre_train:0.7951 recall_train:0.9608 F1_train:0.8701 AUC_train:0.9376\n",
      "acc_val:0.7753 pre_val:0.7183 recall_val:1.0000 F1_val:0.836066 AUC_val:0.9530\n",
      "Epoch:0038\n",
      "acc_train:0.8801 pre_train:0.8319 recall_train:0.9583 F1_train:0.8907 AUC_train:0.9413\n",
      "acc_val:0.7753 pre_val:0.7183 recall_val:1.0000 F1_val:0.836066 AUC_val:0.9546\n",
      "Epoch:0039\n",
      "acc_train:0.8764 pre_train:0.8253 recall_train:0.9608 F1_train:0.8879 AUC_train:0.9410\n",
      "acc_val:0.7753 pre_val:0.7183 recall_val:1.0000 F1_val:0.836066 AUC_val:0.9556\n",
      "Epoch:0040\n",
      "acc_train:0.8964 pre_train:0.8480 recall_train:0.9706 F1_train:0.9051 AUC_train:0.9469\n",
      "acc_val:0.7865 pre_val:0.7353 recall_val:0.9804 F1_val:0.840336 AUC_val:0.9541\n",
      "Epoch:0041\n",
      "acc_train:0.8964 pre_train:0.8465 recall_train:0.9730 F1_train:0.9054 AUC_train:0.9522\n",
      "acc_val:0.8202 pre_val:0.7778 recall_val:0.9608 F1_val:0.859649 AUC_val:0.9510\n",
      "Epoch:0042\n",
      "acc_train:0.8864 pre_train:0.8337 recall_train:0.9706 F1_train:0.8969 AUC_train:0.9477\n",
      "acc_val:0.8427 pre_val:0.8136 recall_val:0.9412 F1_val:0.872727 AUC_val:0.9479\n",
      "Epoch:0043\n",
      "acc_train:0.8864 pre_train:0.8365 recall_train:0.9657 F1_train:0.8965 AUC_train:0.9418\n",
      "acc_val:0.8539 pre_val:0.8393 recall_val:0.9216 F1_val:0.878505 AUC_val:0.9458\n",
      "Epoch:0044\n",
      "acc_train:0.9051 pre_train:0.8532 recall_train:0.9828 F1_train:0.9134 AUC_train:0.9414\n",
      "acc_val:0.8539 pre_val:0.8393 recall_val:0.9216 F1_val:0.878505 AUC_val:0.9474\n",
      "Epoch:0045\n",
      "acc_train:0.8901 pre_train:0.8347 recall_train:0.9779 F1_train:0.9007 AUC_train:0.9438\n",
      "acc_val:0.8427 pre_val:0.8364 recall_val:0.9020 F1_val:0.867925 AUC_val:0.9474\n",
      "Epoch:0046\n",
      "acc_train:0.9201 pre_train:0.8772 recall_train:0.9804 F1_train:0.9259 AUC_train:0.9554\n",
      "acc_val:0.8427 pre_val:0.8364 recall_val:0.9020 F1_val:0.867925 AUC_val:0.9494\n",
      "Epoch:0047\n",
      "acc_train:0.9151 pre_train:0.8680 recall_train:0.9828 F1_train:0.9218 AUC_train:0.9492\n",
      "acc_val:0.8652 pre_val:0.8421 recall_val:0.9412 F1_val:0.888889 AUC_val:0.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0048\n",
      "acc_train:0.9039 pre_train:0.8559 recall_train:0.9755 F1_train:0.9118 AUC_train:0.9515\n",
      "acc_val:0.8202 pre_val:0.7869 recall_val:0.9412 F1_val:0.857143 AUC_val:0.9530\n",
      "Epoch:0049\n",
      "acc_train:0.9226 pre_train:0.8827 recall_train:0.9779 F1_train:0.9279 AUC_train:0.9659\n",
      "acc_val:0.8090 pre_val:0.7656 recall_val:0.9608 F1_val:0.852174 AUC_val:0.9525\n",
      "Epoch:0050\n",
      "acc_train:0.9176 pre_train:0.8701 recall_train:0.9853 F1_train:0.9241 AUC_train:0.9708\n",
      "acc_val:0.7865 pre_val:0.7424 recall_val:0.9608 F1_val:0.837607 AUC_val:0.9541\n",
      "Epoch:0051\n",
      "acc_train:0.8951 pre_train:0.8447 recall_train:0.9730 F1_train:0.9043 AUC_train:0.9677\n",
      "acc_val:0.7978 pre_val:0.7463 recall_val:0.9804 F1_val:0.847458 AUC_val:0.9546\n",
      "Epoch:0052\n",
      "acc_train:0.9201 pre_train:0.8772 recall_train:0.9804 F1_train:0.9259 AUC_train:0.9731\n",
      "acc_val:0.7978 pre_val:0.7463 recall_val:0.9804 F1_val:0.847458 AUC_val:0.9592\n",
      "Epoch:0053\n",
      "acc_train:0.9089 pre_train:0.8602 recall_train:0.9804 F1_train:0.9164 AUC_train:0.9674\n",
      "acc_val:0.7978 pre_val:0.7463 recall_val:0.9804 F1_val:0.847458 AUC_val:0.9587\n",
      "Epoch:0054\n",
      "acc_train:0.9151 pre_train:0.8881 recall_train:0.9534 F1_train:0.9196 AUC_train:0.9679\n",
      "acc_val:0.8090 pre_val:0.7576 recall_val:0.9804 F1_val:0.854701 AUC_val:0.9598\n",
      "Epoch:0055\n",
      "acc_train:0.9413 pre_train:0.9130 recall_train:0.9779 F1_train:0.9444 AUC_train:0.9690\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9618\n",
      "Epoch:0056\n",
      "acc_train:0.9338 pre_train:0.9025 recall_train:0.9755 F1_train:0.9376 AUC_train:0.9724\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9628\n",
      "Epoch:0057\n",
      "acc_train:0.9226 pre_train:0.8844 recall_train:0.9755 F1_train:0.9277 AUC_train:0.9628\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9644\n",
      "Epoch:0058\n",
      "acc_train:0.9326 pre_train:0.8951 recall_train:0.9828 F1_train:0.9369 AUC_train:0.9711\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9659\n",
      "Epoch:0059\n",
      "acc_train:0.9351 pre_train:0.9140 recall_train:0.9632 F1_train:0.9379 AUC_train:0.9555\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9680\n",
      "Epoch:0060\n",
      "acc_train:0.9363 pre_train:0.9048 recall_train:0.9779 F1_train:0.9399 AUC_train:0.9742\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9690\n",
      "Epoch:0061\n",
      "acc_train:0.9363 pre_train:0.9066 recall_train:0.9755 F1_train:0.9398 AUC_train:0.9664\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9701\n",
      "Epoch:0062\n",
      "acc_train:0.9338 pre_train:0.9007 recall_train:0.9779 F1_train:0.9377 AUC_train:0.9765\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9732\n",
      "Epoch:0063\n",
      "acc_train:0.9426 pre_train:0.9132 recall_train:0.9804 F1_train:0.9456 AUC_train:0.9785\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9711\n",
      "Epoch:0064\n",
      "acc_train:0.9488 pre_train:0.9277 recall_train:0.9755 F1_train:0.9510 AUC_train:0.9756\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9706\n",
      "Epoch:0065\n",
      "acc_train:0.9376 pre_train:0.9106 recall_train:0.9730 F1_train:0.9408 AUC_train:0.9769\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9685\n",
      "Epoch:0066\n",
      "acc_train:0.9376 pre_train:0.9050 recall_train:0.9804 F1_train:0.9412 AUC_train:0.9781\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9685\n",
      "Epoch:0067\n",
      "acc_train:0.9513 pre_train:0.9241 recall_train:0.9853 F1_train:0.9537 AUC_train:0.9745\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9680\n",
      "Epoch:0068\n",
      "acc_train:0.9476 pre_train:0.9197 recall_train:0.9828 F1_train:0.9502 AUC_train:0.9787\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9685\n",
      "Epoch:0069\n",
      "acc_train:0.9563 pre_train:0.9327 recall_train:0.9853 F1_train:0.9583 AUC_train:0.9804\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9685\n",
      "Epoch:0070\n",
      "acc_train:0.9476 pre_train:0.9197 recall_train:0.9828 F1_train:0.9502 AUC_train:0.9789\n",
      "acc_val:0.8202 pre_val:0.7692 recall_val:0.9804 F1_val:0.862069 AUC_val:0.9680\n",
      "Epoch:0071\n",
      "acc_train:0.9576 pre_train:0.9329 recall_train:0.9877 F1_train:0.9595 AUC_train:0.9896\n",
      "acc_val:0.8202 pre_val:0.7692 recall_val:0.9804 F1_val:0.862069 AUC_val:0.9711\n",
      "Epoch:0072\n",
      "acc_train:0.9588 pre_train:0.9350 recall_train:0.9877 F1_train:0.9607 AUC_train:0.9821\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9711\n",
      "Epoch:0073\n",
      "acc_train:0.9538 pre_train:0.9284 recall_train:0.9853 F1_train:0.9560 AUC_train:0.9827\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9742\n",
      "Epoch:0074\n",
      "acc_train:0.9538 pre_train:0.9324 recall_train:0.9804 F1_train:0.9558 AUC_train:0.9857\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9752\n",
      "Epoch:0075\n",
      "acc_train:0.9438 pre_train:0.9079 recall_train:0.9902 F1_train:0.9472 AUC_train:0.9799\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9763\n",
      "Epoch:0076\n",
      "acc_train:0.9551 pre_train:0.9326 recall_train:0.9828 F1_train:0.9570 AUC_train:0.9853\n",
      "acc_val:0.7753 pre_val:0.7183 recall_val:1.0000 F1_val:0.836066 AUC_val:0.9757\n",
      "Epoch:0077\n",
      "acc_train:0.9513 pre_train:0.9241 recall_train:0.9853 F1_train:0.9537 AUC_train:0.9864\n",
      "acc_val:0.7865 pre_val:0.7286 recall_val:1.0000 F1_val:0.842975 AUC_val:0.9763\n",
      "Epoch:0078\n",
      "acc_train:0.9526 pre_train:0.9363 recall_train:0.9730 F1_train:0.9543 AUC_train:0.9812\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9768\n",
      "Epoch:0079\n",
      "acc_train:0.9625 pre_train:0.9437 recall_train:0.9853 F1_train:0.9640 AUC_train:0.9795\n",
      "acc_val:0.8427 pre_val:0.7846 recall_val:1.0000 F1_val:0.879310 AUC_val:0.9768\n",
      "Epoch:0080\n",
      "acc_train:0.9663 pre_train:0.9461 recall_train:0.9902 F1_train:0.9677 AUC_train:0.9817\n",
      "acc_val:0.8539 pre_val:0.7969 recall_val:1.0000 F1_val:0.886957 AUC_val:0.9742\n",
      "Epoch:0081\n",
      "acc_train:0.9663 pre_train:0.9441 recall_train:0.9926 F1_train:0.9677 AUC_train:0.9854\n",
      "acc_val:0.8539 pre_val:0.8065 recall_val:0.9804 F1_val:0.884956 AUC_val:0.9706\n",
      "Epoch:0082\n",
      "acc_train:0.9588 pre_train:0.9330 recall_train:0.9902 F1_train:0.9608 AUC_train:0.9774\n",
      "acc_val:0.8315 pre_val:0.7903 recall_val:0.9608 F1_val:0.867257 AUC_val:0.9685\n",
      "Epoch:0083\n",
      "acc_train:0.9563 pre_train:0.9327 recall_train:0.9853 F1_train:0.9583 AUC_train:0.9758\n",
      "acc_val:0.8427 pre_val:0.7937 recall_val:0.9804 F1_val:0.877193 AUC_val:0.9716\n",
      "Epoch:0084\n",
      "acc_train:0.9663 pre_train:0.9441 recall_train:0.9926 F1_train:0.9677 AUC_train:0.9714\n",
      "acc_val:0.8090 pre_val:0.7576 recall_val:0.9804 F1_val:0.854701 AUC_val:0.9701\n",
      "Epoch:0085\n",
      "acc_train:0.9625 pre_train:0.9458 recall_train:0.9828 F1_train:0.9639 AUC_train:0.9869\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9716\n",
      "Epoch:0086\n",
      "acc_train:0.9613 pre_train:0.9374 recall_train:0.9902 F1_train:0.9631 AUC_train:0.9840\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9721\n",
      "Epoch:0087\n",
      "acc_train:0.9675 pre_train:0.9614 recall_train:0.9755 F1_train:0.9684 AUC_train:0.9883\n",
      "acc_val:0.7865 pre_val:0.7286 recall_val:1.0000 F1_val:0.842975 AUC_val:0.9680\n",
      "Epoch:0088\n",
      "acc_train:0.9600 pre_train:0.9332 recall_train:0.9926 F1_train:0.9620 AUC_train:0.9822\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9551\n",
      "Epoch:0089\n",
      "acc_train:0.9650 pre_train:0.9481 recall_train:0.9853 F1_train:0.9663 AUC_train:0.9830\n",
      "acc_val:0.7865 pre_val:0.7286 recall_val:1.0000 F1_val:0.842975 AUC_val:0.9561\n",
      "Epoch:0090\n",
      "acc_train:0.9738 pre_train:0.9574 recall_train:0.9926 F1_train:0.9747 AUC_train:0.9879\n",
      "acc_val:0.7978 pre_val:0.7391 recall_val:1.0000 F1_val:0.850000 AUC_val:0.9546\n",
      "Epoch:0091\n",
      "acc_train:0.9700 pre_train:0.9528 recall_train:0.9902 F1_train:0.9712 AUC_train:0.9885\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9541\n",
      "Epoch:0092\n",
      "acc_train:0.9675 pre_train:0.9484 recall_train:0.9902 F1_train:0.9688 AUC_train:0.9851\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9675\n",
      "Epoch:0093\n",
      "acc_train:0.9538 pre_train:0.9324 recall_train:0.9804 F1_train:0.9558 AUC_train:0.9859\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9701\n",
      "Epoch:0094\n",
      "acc_train:0.9750 pre_train:0.9575 recall_train:0.9951 F1_train:0.9760 AUC_train:0.9863\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0095\n",
      "acc_train:0.9713 pre_train:0.9508 recall_train:0.9951 F1_train:0.9725 AUC_train:0.9897\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9732\n",
      "Epoch:0096\n",
      "acc_train:0.9688 pre_train:0.9443 recall_train:0.9975 F1_train:0.9702 AUC_train:0.9908\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9757\n",
      "Epoch:0097\n",
      "acc_train:0.9763 pre_train:0.9598 recall_train:0.9951 F1_train:0.9771 AUC_train:0.9877\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9799\n",
      "Epoch:0098\n",
      "acc_train:0.9688 pre_train:0.9485 recall_train:0.9926 F1_train:0.9701 AUC_train:0.9831\n",
      "acc_val:0.8315 pre_val:0.7727 recall_val:1.0000 F1_val:0.871795 AUC_val:0.9757\n",
      "Epoch:0099\n",
      "acc_train:0.9788 pre_train:0.9666 recall_train:0.9926 F1_train:0.9794 AUC_train:0.9882\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9680\n",
      "Epoch:0100\n",
      "acc_train:0.9738 pre_train:0.9553 recall_train:0.9951 F1_train:0.9748 AUC_train:0.9852\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9644\n",
      "Epoch:0101\n",
      "acc_train:0.9713 pre_train:0.9616 recall_train:0.9828 F1_train:0.9721 AUC_train:0.9903\n",
      "acc_val:0.8202 pre_val:0.7612 recall_val:1.0000 F1_val:0.864407 AUC_val:0.9649\n",
      "Epoch:0102\n",
      "acc_train:0.9725 pre_train:0.9531 recall_train:0.9951 F1_train:0.9736 AUC_train:0.9894\n",
      "acc_val:0.8090 pre_val:0.7500 recall_val:1.0000 F1_val:0.857143 AUC_val:0.9628\n",
      "Early Stopping!!! epoch：101\n",
      " Starting the 3-5 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.5243 pre_train:0.5622 recall_train:0.2990 F1_train:0.3904 AUC_train:0.5496\n",
      "acc_val:0.5730 pre_val:0.5730 recall_val:1.0000 F1_val:0.728571 AUC_val:0.7038\n",
      "Epoch:0002\n",
      "acc_train:0.5406 pre_train:0.5990 recall_train:0.2966 F1_train:0.3967 AUC_train:0.5609\n",
      "acc_val:0.6180 pre_val:0.6133 recall_val:0.9020 F1_val:0.730159 AUC_val:0.7312\n",
      "Epoch:0003\n",
      "acc_train:0.5343 pre_train:0.5907 recall_train:0.2794 F1_train:0.3794 AUC_train:0.5569\n",
      "acc_val:0.7079 pre_val:0.7273 recall_val:0.7843 F1_val:0.754717 AUC_val:0.7575\n",
      "Epoch:0004\n",
      "acc_train:0.5893 pre_train:0.7068 recall_train:0.3309 F1_train:0.4508 AUC_train:0.6442\n",
      "acc_val:0.6854 pre_val:0.7674 recall_val:0.6471 F1_val:0.702128 AUC_val:0.7879\n",
      "Epoch:0005\n",
      "acc_train:0.5693 pre_train:0.6235 recall_train:0.3897 F1_train:0.4796 AUC_train:0.5732\n",
      "acc_val:0.7191 pre_val:0.8095 recall_val:0.6667 F1_val:0.731183 AUC_val:0.8101\n",
      "Epoch:0006\n",
      "acc_train:0.5531 pre_train:0.6116 recall_train:0.3358 F1_train:0.4335 AUC_train:0.6109\n",
      "acc_val:0.7079 pre_val:0.8049 recall_val:0.6471 F1_val:0.717391 AUC_val:0.8106\n",
      "Epoch:0007\n",
      "acc_train:0.6117 pre_train:0.7650 recall_train:0.3431 F1_train:0.4738 AUC_train:0.6533\n",
      "acc_val:0.7191 pre_val:0.8250 recall_val:0.6471 F1_val:0.725275 AUC_val:0.8091\n",
      "Epoch:0008\n",
      "acc_train:0.5930 pre_train:0.6708 recall_train:0.3946 F1_train:0.4969 AUC_train:0.6335\n",
      "acc_val:0.7079 pre_val:0.8049 recall_val:0.6471 F1_val:0.717391 AUC_val:0.8065\n",
      "Epoch:0009\n",
      "acc_train:0.6117 pre_train:0.6777 recall_train:0.4534 F1_train:0.5433 AUC_train:0.6395\n",
      "acc_val:0.7079 pre_val:0.8049 recall_val:0.6471 F1_val:0.717391 AUC_val:0.8080\n",
      "Epoch:0010\n",
      "acc_train:0.6180 pre_train:0.6962 recall_train:0.4436 F1_train:0.5419 AUC_train:0.6445\n",
      "acc_val:0.6966 pre_val:0.8000 recall_val:0.6275 F1_val:0.703297 AUC_val:0.8096\n",
      "Epoch:0011\n",
      "acc_train:0.6230 pre_train:0.7208 recall_train:0.4240 F1_train:0.5340 AUC_train:0.6599\n",
      "acc_val:0.6966 pre_val:0.8333 recall_val:0.5882 F1_val:0.689655 AUC_val:0.8117\n",
      "Epoch:0012\n",
      "acc_train:0.6067 pre_train:0.6979 recall_train:0.4020 F1_train:0.5101 AUC_train:0.6379\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8096\n",
      "Epoch:0013\n",
      "acc_train:0.6230 pre_train:0.7023 recall_train:0.4510 F1_train:0.5493 AUC_train:0.6606\n",
      "acc_val:0.6854 pre_val:0.8485 recall_val:0.5490 F1_val:0.666667 AUC_val:0.8080\n",
      "Epoch:0014\n",
      "acc_train:0.6267 pre_train:0.7154 recall_train:0.4436 F1_train:0.5477 AUC_train:0.6366\n",
      "acc_val:0.6854 pre_val:0.8485 recall_val:0.5490 F1_val:0.666667 AUC_val:0.8070\n",
      "Epoch:0015\n",
      "acc_train:0.6554 pre_train:0.7340 recall_train:0.5074 F1_train:0.6000 AUC_train:0.6780\n",
      "acc_val:0.6966 pre_val:0.8529 recall_val:0.5686 F1_val:0.682353 AUC_val:0.8086\n",
      "Epoch:0016\n",
      "acc_train:0.6642 pre_train:0.7603 recall_train:0.4975 F1_train:0.6015 AUC_train:0.6823\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8070\n",
      "Epoch:0017\n",
      "acc_train:0.6492 pre_train:0.7110 recall_train:0.5245 F1_train:0.6037 AUC_train:0.6703\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8055\n",
      "Epoch:0018\n",
      "acc_train:0.6492 pre_train:0.7326 recall_train:0.4902 F1_train:0.5874 AUC_train:0.6829\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8080\n",
      "Epoch:0019\n",
      "acc_train:0.6604 pre_train:0.7656 recall_train:0.4804 F1_train:0.5904 AUC_train:0.6859\n",
      "acc_val:0.6966 pre_val:0.8333 recall_val:0.5882 F1_val:0.689655 AUC_val:0.8060\n",
      "Epoch:0020\n",
      "acc_train:0.6642 pre_train:0.7860 recall_train:0.4681 F1_train:0.5868 AUC_train:0.6917\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8065\n",
      "Epoch:0021\n",
      "acc_train:0.6642 pre_train:0.7860 recall_train:0.4681 F1_train:0.5868 AUC_train:0.7064\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8101\n",
      "Epoch:0022\n",
      "acc_train:0.6305 pre_train:0.6958 recall_train:0.4877 F1_train:0.5735 AUC_train:0.6664\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8096\n",
      "Epoch:0023\n",
      "acc_train:0.6442 pre_train:0.7071 recall_train:0.5147 F1_train:0.5957 AUC_train:0.6913\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8091\n",
      "Epoch:0024\n",
      "acc_train:0.6579 pre_train:0.7463 recall_train:0.4975 F1_train:0.5971 AUC_train:0.6918\n",
      "acc_val:0.6966 pre_val:0.8529 recall_val:0.5686 F1_val:0.682353 AUC_val:0.8086\n",
      "Epoch:0025\n",
      "acc_train:0.6767 pre_train:0.7427 recall_train:0.5588 F1_train:0.6378 AUC_train:0.7085\n",
      "acc_val:0.6966 pre_val:0.8529 recall_val:0.5686 F1_val:0.682353 AUC_val:0.8111\n",
      "Epoch:0026\n",
      "acc_train:0.6592 pre_train:0.7419 recall_train:0.5074 F1_train:0.6026 AUC_train:0.7008\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8111\n",
      "Epoch:0027\n",
      "acc_train:0.6704 pre_train:0.7517 recall_train:0.5270 F1_train:0.6196 AUC_train:0.6959\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8132\n",
      "Epoch:0028\n",
      "acc_train:0.6779 pre_train:0.7660 recall_train:0.5294 F1_train:0.6261 AUC_train:0.6951\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8132\n",
      "Epoch:0029\n",
      "acc_train:0.6829 pre_train:0.7619 recall_train:0.5490 F1_train:0.6382 AUC_train:0.7226\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8127\n",
      "Epoch:0030\n",
      "acc_train:0.6866 pre_train:0.7591 recall_train:0.5637 F1_train:0.6470 AUC_train:0.7166\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8111\n",
      "Epoch:0031\n",
      "acc_train:0.6804 pre_train:0.7484 recall_train:0.5613 F1_train:0.6415 AUC_train:0.7133\n",
      "acc_val:0.6854 pre_val:0.8286 recall_val:0.5686 F1_val:0.674419 AUC_val:0.8106\n",
      "Epoch:0032\n",
      "acc_train:0.7004 pre_train:0.8043 recall_train:0.5441 F1_train:0.6491 AUC_train:0.7172\n",
      "acc_val:0.6966 pre_val:0.8529 recall_val:0.5686 F1_val:0.682353 AUC_val:0.8086\n",
      "Epoch:0033\n",
      "acc_train:0.6829 pre_train:0.7362 recall_train:0.5882 F1_train:0.6540 AUC_train:0.7227\n",
      "acc_val:0.7079 pre_val:0.8571 recall_val:0.5882 F1_val:0.697674 AUC_val:0.8106\n",
      "Epoch:0034\n",
      "acc_train:0.6554 pre_train:0.6953 recall_train:0.5760 F1_train:0.6300 AUC_train:0.7042\n",
      "acc_val:0.7079 pre_val:0.8571 recall_val:0.5882 F1_val:0.697674 AUC_val:0.8132\n",
      "Epoch:0035\n",
      "acc_train:0.6966 pre_train:0.7477 recall_train:0.6103 F1_train:0.6721 AUC_train:0.7345\n",
      "acc_val:0.7303 pre_val:0.8649 recall_val:0.6275 F1_val:0.727273 AUC_val:0.8173\n",
      "Epoch:0036\n",
      "acc_train:0.6804 pre_train:0.7331 recall_train:0.5858 F1_train:0.6512 AUC_train:0.7215\n",
      "acc_val:0.7191 pre_val:0.8611 recall_val:0.6078 F1_val:0.712644 AUC_val:0.8179\n",
      "Epoch:0037\n",
      "acc_train:0.6729 pre_train:0.7160 recall_train:0.5931 F1_train:0.6488 AUC_train:0.7157\n",
      "acc_val:0.7303 pre_val:0.8649 recall_val:0.6275 F1_val:0.727273 AUC_val:0.8168\n",
      "Epoch:0038\n",
      "acc_train:0.6979 pre_train:0.7695 recall_train:0.5809 F1_train:0.6620 AUC_train:0.7084\n",
      "acc_val:0.7303 pre_val:0.8649 recall_val:0.6275 F1_val:0.727273 AUC_val:0.8153\n",
      "Epoch:0039\n",
      "acc_train:0.6966 pre_train:0.7636 recall_train:0.5858 F1_train:0.6630 AUC_train:0.7165\n",
      "acc_val:0.7303 pre_val:0.8649 recall_val:0.6275 F1_val:0.727273 AUC_val:0.8194\n",
      "Epoch:0040\n",
      "acc_train:0.6904 pre_train:0.7667 recall_train:0.5637 F1_train:0.6497 AUC_train:0.7280\n",
      "acc_val:0.7416 pre_val:0.8889 recall_val:0.6275 F1_val:0.735632 AUC_val:0.8204\n",
      "Epoch:0041\n",
      "acc_train:0.6841 pre_train:0.7414 recall_train:0.5833 F1_train:0.6529 AUC_train:0.7098\n",
      "acc_val:0.7303 pre_val:0.8857 recall_val:0.6078 F1_val:0.720930 AUC_val:0.8240\n",
      "Epoch:0042\n",
      "acc_train:0.7166 pre_train:0.8027 recall_train:0.5882 F1_train:0.6789 AUC_train:0.7285\n",
      "acc_val:0.7303 pre_val:0.9091 recall_val:0.5882 F1_val:0.714286 AUC_val:0.8271\n",
      "Epoch:0043\n",
      "acc_train:0.7129 pre_train:0.8397 recall_train:0.5392 F1_train:0.6567 AUC_train:0.7395\n",
      "acc_val:0.7303 pre_val:0.9355 recall_val:0.5686 F1_val:0.707317 AUC_val:0.8333\n",
      "Epoch:0044\n",
      "acc_train:0.7316 pre_train:0.8697 recall_train:0.5564 F1_train:0.6786 AUC_train:0.7557\n",
      "acc_val:0.7416 pre_val:0.9667 recall_val:0.5686 F1_val:0.716049 AUC_val:0.8364\n",
      "Epoch:0045\n",
      "acc_train:0.6991 pre_train:0.7811 recall_train:0.5686 F1_train:0.6582 AUC_train:0.7473\n",
      "acc_val:0.7416 pre_val:0.9667 recall_val:0.5686 F1_val:0.716049 AUC_val:0.8406\n",
      "Epoch:0046\n",
      "acc_train:0.7129 pre_train:0.8112 recall_train:0.5686 F1_train:0.6686 AUC_train:0.7517\n",
      "acc_val:0.7416 pre_val:1.0000 recall_val:0.5490 F1_val:0.708861 AUC_val:0.8416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0047\n",
      "acc_train:0.7366 pre_train:0.8481 recall_train:0.5882 F1_train:0.6946 AUC_train:0.7669\n",
      "acc_val:0.7416 pre_val:1.0000 recall_val:0.5490 F1_val:0.708861 AUC_val:0.8426\n",
      "Epoch:0048\n",
      "acc_train:0.7291 pre_train:0.8631 recall_train:0.5564 F1_train:0.6766 AUC_train:0.7668\n",
      "acc_val:0.7303 pre_val:1.0000 recall_val:0.5294 F1_val:0.692308 AUC_val:0.8431\n",
      "Epoch:0049\n",
      "acc_train:0.7303 pre_train:0.8810 recall_train:0.5441 F1_train:0.6727 AUC_train:0.7641\n",
      "acc_val:0.7303 pre_val:1.0000 recall_val:0.5294 F1_val:0.692308 AUC_val:0.8447\n",
      "Epoch:0050\n",
      "acc_train:0.7278 pre_train:0.8626 recall_train:0.5539 F1_train:0.6746 AUC_train:0.7559\n",
      "acc_val:0.7303 pre_val:1.0000 recall_val:0.5294 F1_val:0.692308 AUC_val:0.8478\n",
      "Epoch:0051\n",
      "acc_train:0.7553 pre_train:0.8897 recall_train:0.5931 F1_train:0.7118 AUC_train:0.8064\n",
      "acc_val:0.7079 pre_val:1.0000 recall_val:0.4902 F1_val:0.657895 AUC_val:0.8540\n",
      "Epoch:0052\n",
      "acc_train:0.7428 pre_train:0.8976 recall_train:0.5588 F1_train:0.6888 AUC_train:0.7924\n",
      "acc_val:0.7079 pre_val:1.0000 recall_val:0.4902 F1_val:0.657895 AUC_val:0.8545\n",
      "Epoch:0053\n",
      "acc_train:0.7353 pre_train:0.8657 recall_train:0.5686 F1_train:0.6864 AUC_train:0.7818\n",
      "acc_val:0.7079 pre_val:1.0000 recall_val:0.4902 F1_val:0.657895 AUC_val:0.8638\n",
      "Epoch:0054\n",
      "acc_train:0.7353 pre_train:0.8403 recall_train:0.5931 F1_train:0.6954 AUC_train:0.7685\n",
      "acc_val:0.7079 pre_val:1.0000 recall_val:0.4902 F1_val:0.657895 AUC_val:0.8669\n",
      "Epoch:0055\n",
      "acc_train:0.7453 pre_train:0.8592 recall_train:0.5980 F1_train:0.7052 AUC_train:0.8097\n",
      "acc_val:0.7079 pre_val:1.0000 recall_val:0.4902 F1_val:0.657895 AUC_val:0.8710\n",
      "Epoch:0056\n",
      "acc_train:0.7503 pre_train:0.8910 recall_train:0.5809 F1_train:0.7033 AUC_train:0.7902\n",
      "acc_val:0.6966 pre_val:0.9615 recall_val:0.4902 F1_val:0.649351 AUC_val:0.8772\n",
      "Epoch:0057\n",
      "acc_train:0.7491 pre_train:0.8606 recall_train:0.6054 F1_train:0.7108 AUC_train:0.8158\n",
      "acc_val:0.6966 pre_val:0.9615 recall_val:0.4902 F1_val:0.649351 AUC_val:0.8798\n",
      "Epoch:0058\n",
      "acc_train:0.7690 pre_train:0.8912 recall_train:0.6225 F1_train:0.7330 AUC_train:0.8370\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.8818\n",
      "Epoch:0059\n",
      "acc_train:0.7628 pre_train:0.8385 recall_train:0.6618 F1_train:0.7397 AUC_train:0.8456\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.8885\n",
      "Epoch:0060\n",
      "acc_train:0.7803 pre_train:0.8718 recall_train:0.6667 F1_train:0.7556 AUC_train:0.8576\n",
      "acc_val:0.6854 pre_val:0.9600 recall_val:0.4706 F1_val:0.631579 AUC_val:0.9035\n",
      "Epoch:0061\n",
      "acc_train:0.7665 pre_train:0.8623 recall_train:0.6446 F1_train:0.7377 AUC_train:0.8526\n",
      "acc_val:0.6966 pre_val:0.9615 recall_val:0.4902 F1_val:0.649351 AUC_val:0.9154\n",
      "Epoch:0062\n",
      "acc_train:0.7853 pre_train:0.9041 recall_train:0.6471 F1_train:0.7543 AUC_train:0.8799\n",
      "acc_val:0.7191 pre_val:0.9643 recall_val:0.5294 F1_val:0.683544 AUC_val:0.9231\n",
      "Epoch:0063\n",
      "acc_train:0.8090 pre_train:0.8875 recall_train:0.7157 F1_train:0.7924 AUC_train:0.9111\n",
      "acc_val:0.7640 pre_val:0.9688 recall_val:0.6078 F1_val:0.746988 AUC_val:0.9329\n",
      "Epoch:0064\n",
      "acc_train:0.7990 pre_train:0.8871 recall_train:0.6936 F1_train:0.7785 AUC_train:0.8913\n",
      "acc_val:0.8090 pre_val:0.9722 recall_val:0.6863 F1_val:0.804598 AUC_val:0.9427\n",
      "Epoch:0065\n",
      "acc_train:0.8240 pre_train:0.9108 recall_train:0.7255 F1_train:0.8076 AUC_train:0.9182\n",
      "acc_val:0.8090 pre_val:1.0000 recall_val:0.6667 F1_val:0.800000 AUC_val:0.9448\n",
      "Epoch:0066\n",
      "acc_train:0.8340 pre_train:0.9283 recall_train:0.7304 F1_train:0.8176 AUC_train:0.9237\n",
      "acc_val:0.8090 pre_val:1.0000 recall_val:0.6667 F1_val:0.800000 AUC_val:0.9474\n",
      "Epoch:0067\n",
      "acc_train:0.8452 pre_train:0.9128 recall_train:0.7696 F1_train:0.8351 AUC_train:0.9381\n",
      "acc_val:0.7978 pre_val:1.0000 recall_val:0.6471 F1_val:0.785714 AUC_val:0.9489\n",
      "Epoch:0068\n",
      "acc_train:0.8514 pre_train:0.9366 recall_train:0.7598 F1_train:0.8390 AUC_train:0.9532\n",
      "acc_val:0.8090 pre_val:1.0000 recall_val:0.6667 F1_val:0.800000 AUC_val:0.9525\n",
      "Epoch:0069\n",
      "acc_train:0.8539 pre_train:0.9369 recall_train:0.7647 F1_train:0.8421 AUC_train:0.9502\n",
      "acc_val:0.8090 pre_val:0.9722 recall_val:0.6863 F1_val:0.804598 AUC_val:0.9536\n",
      "Epoch:0070\n",
      "acc_train:0.8489 pre_train:0.9388 recall_train:0.7525 F1_train:0.8354 AUC_train:0.9481\n",
      "acc_val:0.8315 pre_val:0.9737 recall_val:0.7255 F1_val:0.831461 AUC_val:0.9499\n",
      "Epoch:0071\n",
      "acc_train:0.8889 pre_train:0.9518 recall_train:0.8235 F1_train:0.8830 AUC_train:0.9632\n",
      "acc_val:0.8427 pre_val:0.9744 recall_val:0.7451 F1_val:0.844444 AUC_val:0.9432\n",
      "Epoch:0072\n",
      "acc_train:0.8964 pre_train:0.9452 recall_train:0.8456 F1_train:0.8926 AUC_train:0.9730\n",
      "acc_val:0.8427 pre_val:0.9744 recall_val:0.7451 F1_val:0.844444 AUC_val:0.9376\n",
      "Epoch:0073\n",
      "acc_train:0.8926 pre_train:0.9626 recall_train:0.8211 F1_train:0.8862 AUC_train:0.9728\n",
      "acc_val:0.8427 pre_val:0.9744 recall_val:0.7451 F1_val:0.844444 AUC_val:0.9324\n",
      "Epoch:0074\n",
      "acc_train:0.8939 pre_train:0.9549 recall_train:0.8309 F1_train:0.8886 AUC_train:0.9725\n",
      "acc_val:0.8652 pre_val:0.9756 recall_val:0.7843 F1_val:0.869565 AUC_val:0.9309\n",
      "Epoch:0075\n",
      "acc_train:0.8976 pre_train:0.9454 recall_train:0.8480 F1_train:0.8941 AUC_train:0.9684\n",
      "acc_val:0.8652 pre_val:0.9756 recall_val:0.7843 F1_val:0.869565 AUC_val:0.9272\n",
      "Epoch:0076\n",
      "acc_train:0.9151 pre_train:0.9696 recall_train:0.8603 F1_train:0.9117 AUC_train:0.9825\n",
      "acc_val:0.8652 pre_val:0.9756 recall_val:0.7843 F1_val:0.869565 AUC_val:0.9345\n",
      "Epoch:0077\n",
      "acc_train:0.9101 pre_train:0.9615 recall_train:0.8578 F1_train:0.9067 AUC_train:0.9804\n",
      "acc_val:0.8764 pre_val:0.9762 recall_val:0.8039 F1_val:0.881720 AUC_val:0.9412\n",
      "Epoch:0078\n",
      "acc_train:0.9213 pre_train:0.9675 recall_train:0.8750 F1_train:0.9189 AUC_train:0.9816\n",
      "acc_val:0.8764 pre_val:0.9348 recall_val:0.8431 F1_val:0.886598 AUC_val:0.9494\n",
      "Epoch:0079\n",
      "acc_train:0.9201 pre_train:0.9699 recall_train:0.8701 F1_train:0.9173 AUC_train:0.9788\n",
      "acc_val:0.8652 pre_val:0.9149 recall_val:0.8431 F1_val:0.877551 AUC_val:0.9489\n",
      "Epoch:0080\n",
      "acc_train:0.9213 pre_train:0.9859 recall_train:0.8578 F1_train:0.9174 AUC_train:0.9847\n",
      "acc_val:0.8764 pre_val:0.9167 recall_val:0.8627 F1_val:0.888889 AUC_val:0.9479\n",
      "Epoch:0081\n",
      "acc_train:0.9189 pre_train:0.9777 recall_train:0.8603 F1_train:0.9153 AUC_train:0.9829\n",
      "acc_val:0.8315 pre_val:0.8913 recall_val:0.8039 F1_val:0.845361 AUC_val:0.9453\n",
      "Epoch:0082\n",
      "acc_train:0.9201 pre_train:0.9725 recall_train:0.8676 F1_train:0.9171 AUC_train:0.9865\n",
      "acc_val:0.8427 pre_val:0.9111 recall_val:0.8039 F1_val:0.854167 AUC_val:0.9448\n",
      "Epoch:0083\n",
      "acc_train:0.9151 pre_train:0.9570 recall_train:0.8725 F1_train:0.9128 AUC_train:0.9832\n",
      "acc_val:0.8427 pre_val:0.9111 recall_val:0.8039 F1_val:0.854167 AUC_val:0.9510\n",
      "Epoch:0084\n",
      "acc_train:0.9401 pre_train:0.9839 recall_train:0.8971 F1_train:0.9385 AUC_train:0.9906\n",
      "acc_val:0.8652 pre_val:0.9149 recall_val:0.8431 F1_val:0.877551 AUC_val:0.9541\n",
      "Epoch:0085\n",
      "acc_train:0.9388 pre_train:0.9761 recall_train:0.9020 F1_train:0.9376 AUC_train:0.9898\n",
      "acc_val:0.8427 pre_val:0.9302 recall_val:0.7843 F1_val:0.851064 AUC_val:0.9551\n",
      "Epoch:0086\n",
      "acc_train:0.9488 pre_train:0.9816 recall_train:0.9167 F1_train:0.9480 AUC_train:0.9923\n",
      "acc_val:0.8315 pre_val:0.9286 recall_val:0.7647 F1_val:0.838710 AUC_val:0.9587\n",
      "Epoch:0087\n",
      "acc_train:0.9413 pre_train:0.9839 recall_train:0.8995 F1_train:0.9398 AUC_train:0.9936\n",
      "acc_val:0.8652 pre_val:0.9756 recall_val:0.7843 F1_val:0.869565 AUC_val:0.9541\n",
      "Epoch:0088\n",
      "acc_train:0.9451 pre_train:0.9815 recall_train:0.9093 F1_train:0.9440 AUC_train:0.9904\n",
      "acc_val:0.8876 pre_val:0.9767 recall_val:0.8235 F1_val:0.893617 AUC_val:0.9505\n",
      "Epoch:0089\n",
      "acc_train:0.9438 pre_train:0.9866 recall_train:0.9020 F1_train:0.9424 AUC_train:0.9934\n",
      "acc_val:0.8764 pre_val:0.9762 recall_val:0.8039 F1_val:0.881720 AUC_val:0.9515\n",
      "Epoch:0090\n",
      "acc_train:0.9488 pre_train:0.9842 recall_train:0.9142 F1_train:0.9479 AUC_train:0.9955\n",
      "acc_val:0.8876 pre_val:0.9767 recall_val:0.8235 F1_val:0.893617 AUC_val:0.9536\n",
      "Epoch:0091\n",
      "acc_train:0.9501 pre_train:0.9842 recall_train:0.9167 F1_train:0.9492 AUC_train:0.9940\n",
      "acc_val:0.8876 pre_val:0.9767 recall_val:0.8235 F1_val:0.893617 AUC_val:0.9577\n",
      "Epoch:0092\n",
      "acc_train:0.9413 pre_train:0.9813 recall_train:0.9020 F1_train:0.9400 AUC_train:0.9913\n",
      "acc_val:0.8652 pre_val:0.9756 recall_val:0.7843 F1_val:0.869565 AUC_val:0.9572\n",
      "Epoch:0093\n",
      "acc_train:0.9650 pre_train:0.9822 recall_train:0.9485 F1_train:0.9651 AUC_train:0.9967\n",
      "acc_val:0.8315 pre_val:0.9737 recall_val:0.7255 F1_val:0.831461 AUC_val:0.9628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0094\n",
      "acc_train:0.9738 pre_train:0.9850 recall_train:0.9632 F1_train:0.9740 AUC_train:0.9948\n",
      "acc_val:0.8315 pre_val:0.9737 recall_val:0.7255 F1_val:0.831461 AUC_val:0.9623\n",
      "Epoch:0095\n",
      "acc_train:0.9501 pre_train:0.9868 recall_train:0.9142 F1_train:0.9491 AUC_train:0.9946\n",
      "acc_val:0.8315 pre_val:0.9500 recall_val:0.7451 F1_val:0.835165 AUC_val:0.9587\n",
      "Epoch:0096\n",
      "acc_train:0.9663 pre_train:0.9847 recall_train:0.9485 F1_train:0.9663 AUC_train:0.9946\n",
      "acc_val:0.8315 pre_val:0.9500 recall_val:0.7451 F1_val:0.835165 AUC_val:0.9582\n",
      "Epoch:0097\n",
      "acc_train:0.9625 pre_train:0.9773 recall_train:0.9485 F1_train:0.9627 AUC_train:0.9952\n",
      "acc_val:0.8202 pre_val:0.9487 recall_val:0.7255 F1_val:0.822222 AUC_val:0.9530\n",
      "Epoch:0098\n",
      "acc_train:0.9750 pre_train:0.9850 recall_train:0.9657 F1_train:0.9752 AUC_train:0.9969\n",
      "acc_val:0.7978 pre_val:0.9231 recall_val:0.7059 F1_val:0.800000 AUC_val:0.9520\n",
      "Epoch:0099\n",
      "acc_train:0.9638 pre_train:0.9797 recall_train:0.9485 F1_train:0.9639 AUC_train:0.9959\n",
      "acc_val:0.8090 pre_val:0.9250 recall_val:0.7255 F1_val:0.813187 AUC_val:0.9515\n",
      "Epoch:0100\n",
      "acc_train:0.9663 pre_train:0.9798 recall_train:0.9534 F1_train:0.9665 AUC_train:0.9938\n",
      "acc_val:0.8090 pre_val:0.9250 recall_val:0.7255 F1_val:0.813187 AUC_val:0.9525\n",
      "Epoch:0101\n",
      "acc_train:0.9638 pre_train:0.9749 recall_train:0.9534 F1_train:0.9641 AUC_train:0.9945\n",
      "acc_val:0.8090 pre_val:0.9250 recall_val:0.7255 F1_val:0.813187 AUC_val:0.9505\n",
      "Epoch:0102\n",
      "acc_train:0.9688 pre_train:0.9923 recall_train:0.9461 F1_train:0.9686 AUC_train:0.9968\n",
      "acc_val:0.8315 pre_val:0.9286 recall_val:0.7647 F1_val:0.838710 AUC_val:0.9499\n",
      "Epoch:0103\n",
      "acc_train:0.9650 pre_train:0.9750 recall_train:0.9559 F1_train:0.9653 AUC_train:0.9970\n",
      "acc_val:0.8539 pre_val:0.9318 recall_val:0.8039 F1_val:0.863158 AUC_val:0.9474\n",
      "Epoch:0104\n",
      "acc_train:0.9700 pre_train:0.9898 recall_train:0.9510 F1_train:0.9700 AUC_train:0.9972\n",
      "acc_val:0.8090 pre_val:0.9048 recall_val:0.7451 F1_val:0.817204 AUC_val:0.9458\n",
      "Epoch:0105\n",
      "acc_train:0.9675 pre_train:0.9728 recall_train:0.9632 F1_train:0.9680 AUC_train:0.9950\n",
      "acc_val:0.8090 pre_val:0.9250 recall_val:0.7255 F1_val:0.813187 AUC_val:0.9458\n",
      "Epoch:0106\n",
      "acc_train:0.9725 pre_train:0.9707 recall_train:0.9755 F1_train:0.9731 AUC_train:0.9956\n",
      "acc_val:0.8202 pre_val:0.9268 recall_val:0.7451 F1_val:0.826087 AUC_val:0.9469\n",
      "Epoch:0107\n",
      "acc_train:0.9750 pre_train:0.9850 recall_train:0.9657 F1_train:0.9752 AUC_train:0.9953\n",
      "acc_val:0.8315 pre_val:0.9500 recall_val:0.7451 F1_val:0.835165 AUC_val:0.9427\n",
      "Epoch:0108\n",
      "acc_train:0.9663 pre_train:0.9823 recall_train:0.9510 F1_train:0.9664 AUC_train:0.9959\n",
      "acc_val:0.8202 pre_val:0.9487 recall_val:0.7255 F1_val:0.822222 AUC_val:0.9427\n",
      "Epoch:0109\n",
      "acc_train:0.9725 pre_train:0.9898 recall_train:0.9559 F1_train:0.9726 AUC_train:0.9983\n",
      "acc_val:0.8202 pre_val:0.9487 recall_val:0.7255 F1_val:0.822222 AUC_val:0.9422\n",
      "Epoch:0110\n",
      "acc_train:0.9738 pre_train:0.9899 recall_train:0.9583 F1_train:0.9738 AUC_train:0.9982\n",
      "acc_val:0.8202 pre_val:0.9487 recall_val:0.7255 F1_val:0.822222 AUC_val:0.9417\n",
      "Epoch:0111\n",
      "acc_train:0.9713 pre_train:0.9898 recall_train:0.9534 F1_train:0.9713 AUC_train:0.9974\n",
      "acc_val:0.8202 pre_val:0.9268 recall_val:0.7451 F1_val:0.826087 AUC_val:0.9427\n",
      "Epoch:0112\n",
      "acc_train:0.9725 pre_train:0.9923 recall_train:0.9534 F1_train:0.9725 AUC_train:0.9982\n",
      "acc_val:0.8202 pre_val:0.9268 recall_val:0.7451 F1_val:0.826087 AUC_val:0.9469\n",
      "Epoch:0113\n",
      "acc_train:0.9688 pre_train:0.9948 recall_train:0.9436 F1_train:0.9686 AUC_train:0.9968\n",
      "acc_val:0.8090 pre_val:0.9250 recall_val:0.7255 F1_val:0.813187 AUC_val:0.9489\n",
      "Epoch:0114\n",
      "acc_train:0.9625 pre_train:0.9749 recall_train:0.9510 F1_train:0.9628 AUC_train:0.9955\n",
      "acc_val:0.8202 pre_val:0.9268 recall_val:0.7451 F1_val:0.826087 AUC_val:0.9541\n",
      "Epoch:0115\n",
      "acc_train:0.9763 pre_train:0.9875 recall_train:0.9657 F1_train:0.9765 AUC_train:0.9991\n",
      "acc_val:0.8315 pre_val:0.9500 recall_val:0.7451 F1_val:0.835165 AUC_val:0.9551\n",
      "Epoch:0116\n",
      "acc_train:0.9725 pre_train:0.9825 recall_train:0.9632 F1_train:0.9728 AUC_train:0.9967\n",
      "acc_val:0.8315 pre_val:0.9500 recall_val:0.7451 F1_val:0.835165 AUC_val:0.9561\n",
      "Epoch:0117\n",
      "acc_train:0.9788 pre_train:0.9900 recall_train:0.9681 F1_train:0.9789 AUC_train:0.9986\n",
      "acc_val:0.8427 pre_val:0.9744 recall_val:0.7451 F1_val:0.844444 AUC_val:0.9525\n",
      "Epoch:0118\n",
      "acc_train:0.9825 pre_train:0.9852 recall_train:0.9804 F1_train:0.9828 AUC_train:0.9979\n",
      "acc_val:0.8427 pre_val:0.9744 recall_val:0.7451 F1_val:0.844444 AUC_val:0.9510\n",
      "Epoch:0119\n",
      "acc_train:0.9763 pre_train:0.9899 recall_train:0.9632 F1_train:0.9764 AUC_train:0.9942\n",
      "acc_val:0.8427 pre_val:0.9744 recall_val:0.7451 F1_val:0.844444 AUC_val:0.9494\n",
      "Epoch:0120\n",
      "acc_train:0.9850 pre_train:0.9975 recall_train:0.9730 F1_train:0.9851 AUC_train:0.9978\n",
      "acc_val:0.8427 pre_val:0.9744 recall_val:0.7451 F1_val:0.844444 AUC_val:0.9458\n",
      "Epoch:0121\n",
      "acc_train:0.9788 pre_train:0.9827 recall_train:0.9755 F1_train:0.9791 AUC_train:0.9965\n",
      "acc_val:0.8202 pre_val:0.9487 recall_val:0.7255 F1_val:0.822222 AUC_val:0.9407\n",
      "Epoch:0122\n",
      "acc_train:0.9800 pre_train:0.9876 recall_train:0.9730 F1_train:0.9802 AUC_train:0.9957\n",
      "acc_val:0.8315 pre_val:0.9500 recall_val:0.7451 F1_val:0.835165 AUC_val:0.9350\n",
      "Epoch:0123\n",
      "acc_train:0.9725 pre_train:0.9923 recall_train:0.9534 F1_train:0.9725 AUC_train:0.9944\n",
      "acc_val:0.8202 pre_val:0.9268 recall_val:0.7451 F1_val:0.826087 AUC_val:0.9334\n",
      "Early Stopping!!! epoch：122\n",
      "Loading the Model for the 3-th Fold:... ... Size of samples in the test set:222\n",
      "Fold 3 Results: test acc:0.5631 test_pre:0.8400 test_recall:0.1842 test_F1:0.3022 test_AUC:0.7310 time:477.259s\n",
      "Size of the 4-fold Training, Validation, and Test Sets:801,89,222\n",
      " Starting the 4-1 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4944 pre_train:0.5181 recall_train:0.3116 F1_train:0.3891 AUC_train:0.4954\n",
      "acc_val:0.4607 pre_val:0.4545 recall_val:0.3333 F1_val:0.384615 AUC_val:0.4152\n",
      "Epoch:0002\n",
      "acc_train:0.5156 pre_train:0.5504 recall_train:0.3430 F1_train:0.4226 AUC_train:0.5061\n",
      "acc_val:0.4270 pre_val:0.3846 recall_val:0.2222 F1_val:0.281690 AUC_val:0.3934\n",
      "Epoch:0003\n",
      "acc_train:0.5368 pre_train:0.5900 recall_train:0.3406 F1_train:0.4319 AUC_train:0.5014\n",
      "acc_val:0.4382 pre_val:0.4324 recall_val:0.3556 F1_val:0.390244 AUC_val:0.3626\n",
      "Epoch:0004\n",
      "acc_train:0.5056 pre_train:0.5385 recall_train:0.3043 F1_train:0.3889 AUC_train:0.5104\n",
      "acc_val:0.4382 pre_val:0.4490 recall_val:0.4889 F1_val:0.468085 AUC_val:0.4227\n",
      "Epoch:0005\n",
      "acc_train:0.4707 pre_train:0.4900 recall_train:0.5894 F1_train:0.5351 AUC_train:0.4719\n",
      "acc_val:0.4157 pre_val:0.4364 recall_val:0.5333 F1_val:0.480000 AUC_val:0.4343\n",
      "Epoch:0006\n",
      "acc_train:0.4956 pre_train:0.5130 recall_train:0.4758 F1_train:0.4937 AUC_train:0.5021\n",
      "acc_val:0.4382 pre_val:0.4603 recall_val:0.6444 F1_val:0.537037 AUC_val:0.4318\n",
      "Epoch:0007\n",
      "acc_train:0.5044 pre_train:0.5353 recall_train:0.3116 F1_train:0.3939 AUC_train:0.4952\n",
      "acc_val:0.4382 pre_val:0.4603 recall_val:0.6444 F1_val:0.537037 AUC_val:0.4157\n",
      "Epoch:0008\n",
      "acc_train:0.5119 pre_train:0.5205 recall_train:0.7053 F1_train:0.5990 AUC_train:0.5030\n",
      "acc_val:0.4157 pre_val:0.4462 recall_val:0.6444 F1_val:0.527273 AUC_val:0.4066\n",
      "Epoch:0009\n",
      "acc_train:0.5406 pre_train:0.5983 recall_train:0.3382 F1_train:0.4321 AUC_train:0.5404\n",
      "acc_val:0.4719 pre_val:0.4865 recall_val:0.8000 F1_val:0.605042 AUC_val:0.3616\n",
      "Epoch:0010\n",
      "acc_train:0.5206 pre_train:0.5586 recall_train:0.3454 F1_train:0.4269 AUC_train:0.4965\n",
      "acc_val:0.5281 pre_val:0.5181 recall_val:0.9556 F1_val:0.671875 AUC_val:0.3556\n",
      "Epoch:0011\n",
      "acc_train:0.4557 pre_train:0.4835 recall_train:0.7778 F1_train:0.5963 AUC_train:0.4778\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.3308\n",
      "Epoch:0012\n",
      "acc_train:0.5006 pre_train:0.5122 recall_train:0.7126 F1_train:0.5960 AUC_train:0.5262\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.3394\n",
      "Epoch:0013\n",
      "acc_train:0.5293 pre_train:0.5321 recall_train:0.7415 F1_train:0.6196 AUC_train:0.5514\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5551\n",
      "Epoch:0014\n",
      "acc_train:0.5605 pre_train:0.6348 recall_train:0.3527 F1_train:0.4534 AUC_train:0.5363\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5737\n",
      "Epoch:0015\n",
      "acc_train:0.5218 pre_train:0.5313 recall_train:0.6353 F1_train:0.5787 AUC_train:0.5222\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5753\n",
      "Epoch:0016\n",
      "acc_train:0.5106 pre_train:0.5183 recall_train:0.7536 F1_train:0.6142 AUC_train:0.5542\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5672\n",
      "Epoch:0017\n",
      "acc_train:0.4906 pre_train:0.5041 recall_train:0.9010 F1_train:0.6464 AUC_train:0.5142\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5682\n",
      "Epoch:0018\n",
      "acc_train:0.5218 pre_train:0.5250 recall_train:0.7874 F1_train:0.6300 AUC_train:0.5294\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5490\n",
      "Epoch:0019\n",
      "acc_train:0.4894 pre_train:0.5039 recall_train:0.7826 F1_train:0.6131 AUC_train:0.5114\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.4394\n",
      "Epoch:0020\n",
      "acc_train:0.5181 pre_train:0.5276 recall_train:0.6473 F1_train:0.5813 AUC_train:0.5481\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.4525\n",
      "Epoch:0021\n",
      "acc_train:0.5194 pre_train:0.5210 recall_train:0.8671 F1_train:0.6510 AUC_train:0.5581\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5071\n",
      "Epoch:0022\n",
      "acc_train:0.5281 pre_train:0.5469 recall_train:0.5072 F1_train:0.5263 AUC_train:0.5418\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0023\n",
      "acc_train:0.5268 pre_train:0.5269 recall_train:0.8285 F1_train:0.6441 AUC_train:0.5588\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5263\n",
      "Epoch:0024\n",
      "acc_train:0.5381 pre_train:0.5466 recall_train:0.6232 F1_train:0.5824 AUC_train:0.5514\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5343\n",
      "Epoch:0025\n",
      "acc_train:0.5106 pre_train:0.5166 recall_train:0.8285 F1_train:0.6364 AUC_train:0.5204\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5960\n",
      "Epoch:0026\n",
      "acc_train:0.5069 pre_train:0.5135 recall_train:0.8720 F1_train:0.6464 AUC_train:0.5284\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5985\n",
      "Epoch:0027\n",
      "acc_train:0.5718 pre_train:0.6360 recall_train:0.4010 F1_train:0.4919 AUC_train:0.5853\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5980\n",
      "Epoch:0028\n",
      "acc_train:0.5169 pre_train:0.5480 recall_train:0.3720 F1_train:0.4432 AUC_train:0.5161\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5955\n",
      "Epoch:0029\n",
      "acc_train:0.5318 pre_train:0.5438 recall_train:0.5845 F1_train:0.5634 AUC_train:0.5710\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5894\n",
      "Epoch:0030\n",
      "acc_train:0.5406 pre_train:0.5364 recall_train:0.8188 F1_train:0.6482 AUC_train:0.5735\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5884\n",
      "Epoch:0031\n",
      "acc_train:0.5331 pre_train:0.5294 recall_train:0.8696 F1_train:0.6581 AUC_train:0.5470\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5894\n",
      "Epoch:0032\n",
      "acc_train:0.4919 pre_train:0.5072 recall_train:0.5966 F1_train:0.5483 AUC_train:0.5071\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5894\n",
      "Epoch:0033\n",
      "acc_train:0.5406 pre_train:0.5852 recall_train:0.3816 F1_train:0.4620 AUC_train:0.5301\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5828\n",
      "Epoch:0034\n",
      "acc_train:0.5293 pre_train:0.5457 recall_train:0.5338 F1_train:0.5397 AUC_train:0.5588\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5778\n",
      "Epoch:0035\n",
      "acc_train:0.5006 pre_train:0.5135 recall_train:0.6449 F1_train:0.5717 AUC_train:0.5088\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.5818\n",
      "Epoch:0036\n",
      "acc_train:0.5281 pre_train:0.5407 recall_train:0.5773 F1_train:0.5584 AUC_train:0.5502\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.5783\n",
      "Epoch:0037\n",
      "acc_train:0.5231 pre_train:0.5290 recall_train:0.7053 F1_train:0.6046 AUC_train:0.5287\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5833\n",
      "Epoch:0038\n",
      "acc_train:0.5468 pre_train:0.5757 recall_train:0.4686 F1_train:0.5166 AUC_train:0.5639\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.5838\n",
      "Epoch:0039\n",
      "acc_train:0.5443 pre_train:0.5451 recall_train:0.7150 F1_train:0.6186 AUC_train:0.5566\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5879\n",
      "Epoch:0040\n",
      "acc_train:0.5069 pre_train:0.5153 recall_train:0.7729 F1_train:0.6184 AUC_train:0.5059\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5874\n",
      "Epoch:0041\n",
      "acc_train:0.5543 pre_train:0.5624 recall_train:0.6208 F1_train:0.5901 AUC_train:0.5923\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5874\n",
      "Epoch:0042\n",
      "acc_train:0.5531 pre_train:0.5633 recall_train:0.6014 F1_train:0.5818 AUC_train:0.5854\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5864\n",
      "Epoch:0043\n",
      "acc_train:0.5268 pre_train:0.5499 recall_train:0.4662 F1_train:0.5046 AUC_train:0.5405\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5838\n",
      "Epoch:0044\n",
      "acc_train:0.5431 pre_train:0.5759 recall_train:0.4396 F1_train:0.4986 AUC_train:0.5668\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5854\n",
      "Epoch:0045\n",
      "acc_train:0.5306 pre_train:0.5594 recall_train:0.4324 F1_train:0.4877 AUC_train:0.5554\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5859\n",
      "Epoch:0046\n",
      "acc_train:0.5381 pre_train:0.5374 recall_train:0.7633 F1_train:0.6307 AUC_train:0.5737\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5894\n",
      "Epoch:0047\n",
      "acc_train:0.5281 pre_train:0.5278 recall_train:0.8261 F1_train:0.6441 AUC_train:0.5479\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.5889\n",
      "Epoch:0048\n",
      "acc_train:0.5268 pre_train:0.5246 recall_train:0.9010 F1_train:0.6631 AUC_train:0.5590\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5884\n",
      "Epoch:0049\n",
      "acc_train:0.5393 pre_train:0.5363 recall_train:0.8019 F1_train:0.6428 AUC_train:0.5680\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5813\n",
      "Epoch:0050\n",
      "acc_train:0.5431 pre_train:0.5400 recall_train:0.7826 F1_train:0.6391 AUC_train:0.5667\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5641\n",
      "Epoch:0051\n",
      "acc_train:0.5331 pre_train:0.5370 recall_train:0.7005 F1_train:0.6080 AUC_train:0.5598\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.5682\n",
      "Epoch:0052\n",
      "acc_train:0.5655 pre_train:0.5527 recall_train:0.8357 F1_train:0.6654 AUC_train:0.5904\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.5697\n",
      "Epoch:0053\n",
      "acc_train:0.5481 pre_train:0.5526 recall_train:0.6594 F1_train:0.6013 AUC_train:0.5756\n",
      "acc_val:0.5169 pre_val:0.5116 recall_val:0.9778 F1_val:0.671756 AUC_val:0.5722\n",
      "Epoch:0054\n",
      "acc_train:0.5381 pre_train:0.5491 recall_train:0.5942 F1_train:0.5708 AUC_train:0.5721\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.5783\n",
      "Epoch:0055\n",
      "acc_train:0.5406 pre_train:0.5411 recall_train:0.7319 F1_train:0.6222 AUC_train:0.5717\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.5823\n",
      "Epoch:0056\n",
      "acc_train:0.5568 pre_train:0.5637 recall_train:0.6304 F1_train:0.5952 AUC_train:0.5949\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.5924\n",
      "Epoch:0057\n",
      "acc_train:0.5331 pre_train:0.5300 recall_train:0.8527 F1_train:0.6537 AUC_train:0.5688\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.5899\n",
      "Epoch:0058\n",
      "acc_train:0.5630 pre_train:0.5724 recall_train:0.6111 F1_train:0.5911 AUC_train:0.5978\n",
      "acc_val:0.5730 pre_val:0.5467 recall_val:0.9111 F1_val:0.683333 AUC_val:0.5980\n",
      "Epoch:0059\n",
      "acc_train:0.6017 pre_train:0.6049 recall_train:0.6618 F1_train:0.6321 AUC_train:0.6378\n",
      "acc_val:0.5843 pre_val:0.5541 recall_val:0.9111 F1_val:0.689076 AUC_val:0.6005\n",
      "Epoch:0060\n",
      "acc_train:0.5456 pre_train:0.5443 recall_train:0.7415 F1_train:0.6278 AUC_train:0.5578\n",
      "acc_val:0.5169 pre_val:0.5119 recall_val:0.9556 F1_val:0.666667 AUC_val:0.6111\n",
      "Epoch:0061\n",
      "acc_train:0.5543 pre_train:0.5539 recall_train:0.7077 F1_train:0.6214 AUC_train:0.5986\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.6051\n",
      "Epoch:0062\n",
      "acc_train:0.5793 pre_train:0.5885 recall_train:0.6184 F1_train:0.6031 AUC_train:0.6247\n",
      "acc_val:0.5730 pre_val:0.5479 recall_val:0.8889 F1_val:0.677966 AUC_val:0.6071\n",
      "Epoch:0063\n",
      "acc_train:0.5943 pre_train:0.5914 recall_train:0.6957 F1_train:0.6393 AUC_train:0.6307\n",
      "acc_val:0.5730 pre_val:0.5467 recall_val:0.9111 F1_val:0.683333 AUC_val:0.6136\n",
      "Epoch:0064\n",
      "acc_train:0.5805 pre_train:0.5844 recall_train:0.6522 F1_train:0.6164 AUC_train:0.6186\n",
      "acc_val:0.5730 pre_val:0.5455 recall_val:0.9333 F1_val:0.688525 AUC_val:0.6187\n",
      "Epoch:0065\n",
      "acc_train:0.5805 pre_train:0.5789 recall_train:0.6908 F1_train:0.6300 AUC_train:0.6131\n",
      "acc_val:0.5506 pre_val:0.5316 recall_val:0.9333 F1_val:0.677419 AUC_val:0.6242\n",
      "Epoch:0066\n",
      "acc_train:0.6017 pre_train:0.5922 recall_train:0.7367 F1_train:0.6566 AUC_train:0.6432\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.6303\n",
      "Epoch:0067\n",
      "acc_train:0.6217 pre_train:0.6041 recall_train:0.7778 F1_train:0.6800 AUC_train:0.6465\n",
      "acc_val:0.5506 pre_val:0.5301 recall_val:0.9778 F1_val:0.687500 AUC_val:0.6424\n",
      "Epoch:0068\n",
      "acc_train:0.6092 pre_train:0.5795 recall_train:0.8889 F1_train:0.7016 AUC_train:0.6636\n",
      "acc_val:0.5393 pre_val:0.5238 recall_val:0.9778 F1_val:0.682171 AUC_val:0.6520\n",
      "Epoch:0069\n",
      "acc_train:0.6429 pre_train:0.6280 recall_train:0.7585 F1_train:0.6871 AUC_train:0.7033\n",
      "acc_val:0.5506 pre_val:0.5301 recall_val:0.9778 F1_val:0.687500 AUC_val:0.6576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0070\n",
      "acc_train:0.6429 pre_train:0.6221 recall_train:0.7874 F1_train:0.6951 AUC_train:0.6788\n",
      "acc_val:0.5730 pre_val:0.5432 recall_val:0.9778 F1_val:0.698413 AUC_val:0.6717\n",
      "Epoch:0071\n",
      "acc_train:0.6517 pre_train:0.6306 recall_train:0.7874 F1_train:0.7003 AUC_train:0.6919\n",
      "acc_val:0.5730 pre_val:0.5432 recall_val:0.9778 F1_val:0.698413 AUC_val:0.6828\n",
      "Epoch:0072\n",
      "acc_train:0.6729 pre_train:0.6392 recall_train:0.8430 F1_train:0.7271 AUC_train:0.7298\n",
      "acc_val:0.5843 pre_val:0.5500 recall_val:0.9778 F1_val:0.704000 AUC_val:0.6909\n",
      "Epoch:0073\n",
      "acc_train:0.7029 pre_train:0.6630 recall_train:0.8647 F1_train:0.7505 AUC_train:0.7435\n",
      "acc_val:0.5955 pre_val:0.5570 recall_val:0.9778 F1_val:0.709677 AUC_val:0.6995\n",
      "Epoch:0074\n",
      "acc_train:0.7278 pre_train:0.7000 recall_train:0.8285 F1_train:0.7588 AUC_train:0.7642\n",
      "acc_val:0.5955 pre_val:0.5570 recall_val:0.9778 F1_val:0.709677 AUC_val:0.7101\n",
      "Epoch:0075\n",
      "acc_train:0.7428 pre_train:0.7008 recall_train:0.8768 F1_train:0.7790 AUC_train:0.7834\n",
      "acc_val:0.5955 pre_val:0.5556 recall_val:1.0000 F1_val:0.714286 AUC_val:0.7210\n",
      "Epoch:0076\n",
      "acc_train:0.7466 pre_train:0.6957 recall_train:0.9058 F1_train:0.7870 AUC_train:0.8088\n",
      "acc_val:0.6067 pre_val:0.5625 recall_val:1.0000 F1_val:0.720000 AUC_val:0.7417\n",
      "Epoch:0077\n",
      "acc_train:0.7541 pre_train:0.7075 recall_train:0.8937 F1_train:0.7898 AUC_train:0.8026\n",
      "acc_val:0.5955 pre_val:0.5556 recall_val:1.0000 F1_val:0.714286 AUC_val:0.7455\n",
      "Epoch:0078\n",
      "acc_train:0.7678 pre_train:0.7167 recall_train:0.9106 F1_train:0.8021 AUC_train:0.8420\n",
      "acc_val:0.5955 pre_val:0.5556 recall_val:1.0000 F1_val:0.714286 AUC_val:0.7449\n",
      "Epoch:0079\n",
      "acc_train:0.7615 pre_train:0.7031 recall_train:0.9324 F1_train:0.8017 AUC_train:0.8721\n",
      "acc_val:0.5730 pre_val:0.5422 recall_val:1.0000 F1_val:0.703125 AUC_val:0.7313\n",
      "Epoch:0080\n",
      "acc_train:0.7778 pre_train:0.7169 recall_train:0.9420 F1_train:0.8142 AUC_train:0.8533\n",
      "acc_val:0.5730 pre_val:0.5432 recall_val:0.9778 F1_val:0.698413 AUC_val:0.7192\n",
      "Epoch:0081\n",
      "acc_train:0.7528 pre_train:0.6957 recall_train:0.9275 F1_train:0.7950 AUC_train:0.8308\n",
      "acc_val:0.5730 pre_val:0.5432 recall_val:0.9778 F1_val:0.698413 AUC_val:0.7227\n",
      "Epoch:0082\n",
      "acc_train:0.7703 pre_train:0.7091 recall_train:0.9420 F1_train:0.8091 AUC_train:0.8564\n",
      "acc_val:0.5730 pre_val:0.5432 recall_val:0.9778 F1_val:0.698413 AUC_val:0.7545\n",
      "Epoch:0083\n",
      "acc_train:0.7790 pre_train:0.7257 recall_train:0.9203 F1_train:0.8115 AUC_train:0.8651\n",
      "acc_val:0.6067 pre_val:0.5641 recall_val:0.9778 F1_val:0.715447 AUC_val:0.7730\n",
      "Epoch:0084\n",
      "acc_train:0.7928 pre_train:0.7313 recall_train:0.9469 F1_train:0.8253 AUC_train:0.8923\n",
      "acc_val:0.6292 pre_val:0.5769 recall_val:1.0000 F1_val:0.731707 AUC_val:0.7869\n",
      "Epoch:0085\n",
      "acc_train:0.7978 pre_train:0.7368 recall_train:0.9469 F1_train:0.8288 AUC_train:0.8772\n",
      "acc_val:0.6292 pre_val:0.5769 recall_val:1.0000 F1_val:0.731707 AUC_val:0.7927\n",
      "Epoch:0086\n",
      "acc_train:0.8277 pre_train:0.7685 recall_train:0.9541 F1_train:0.8513 AUC_train:0.9125\n",
      "acc_val:0.6067 pre_val:0.5625 recall_val:1.0000 F1_val:0.720000 AUC_val:0.8013\n",
      "Epoch:0087\n",
      "acc_train:0.8252 pre_train:0.7740 recall_train:0.9348 F1_train:0.8468 AUC_train:0.9021\n",
      "acc_val:0.6067 pre_val:0.5625 recall_val:1.0000 F1_val:0.720000 AUC_val:0.8182\n",
      "Epoch:0088\n",
      "acc_train:0.8327 pre_train:0.7672 recall_train:0.9710 F1_train:0.8571 AUC_train:0.9254\n",
      "acc_val:0.6292 pre_val:0.5769 recall_val:1.0000 F1_val:0.731707 AUC_val:0.8500\n",
      "Epoch:0089\n",
      "acc_train:0.8539 pre_train:0.8049 recall_train:0.9469 F1_train:0.8701 AUC_train:0.9449\n",
      "acc_val:0.6517 pre_val:0.5921 recall_val:1.0000 F1_val:0.743802 AUC_val:0.8487\n",
      "Epoch:0090\n",
      "acc_train:0.8552 pre_train:0.8041 recall_train:0.9517 F1_train:0.8717 AUC_train:0.9318\n",
      "acc_val:0.6629 pre_val:0.6000 recall_val:1.0000 F1_val:0.750000 AUC_val:0.8505\n",
      "Epoch:0091\n",
      "acc_train:0.8664 pre_train:0.8178 recall_train:0.9541 F1_train:0.8807 AUC_train:0.9200\n",
      "acc_val:0.6629 pre_val:0.6000 recall_val:1.0000 F1_val:0.750000 AUC_val:0.8576\n",
      "Epoch:0092\n",
      "acc_train:0.8764 pre_train:0.8247 recall_train:0.9662 F1_train:0.8899 AUC_train:0.9335\n",
      "acc_val:0.6854 pre_val:0.6164 recall_val:1.0000 F1_val:0.762712 AUC_val:0.8652\n",
      "Epoch:0093\n",
      "acc_train:0.8714 pre_train:0.8180 recall_train:0.9662 F1_train:0.8859 AUC_train:0.9522\n",
      "acc_val:0.7079 pre_val:0.6338 recall_val:1.0000 F1_val:0.775862 AUC_val:0.8838\n",
      "Epoch:0094\n",
      "acc_train:0.8876 pre_train:0.8447 recall_train:0.9589 F1_train:0.8982 AUC_train:0.9365\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.8886\n",
      "Epoch:0095\n",
      "acc_train:0.8889 pre_train:0.8465 recall_train:0.9589 F1_train:0.8992 AUC_train:0.9473\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.8924\n",
      "Epoch:0096\n",
      "acc_train:0.9051 pre_train:0.8690 recall_train:0.9614 F1_train:0.9128 AUC_train:0.9560\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.8952\n",
      "Epoch:0097\n",
      "acc_train:0.8964 pre_train:0.8499 recall_train:0.9710 F1_train:0.9064 AUC_train:0.9526\n",
      "acc_val:0.6966 pre_val:0.6286 recall_val:0.9778 F1_val:0.765217 AUC_val:0.8942\n",
      "Epoch:0098\n",
      "acc_train:0.8864 pre_train:0.8386 recall_train:0.9662 F1_train:0.8979 AUC_train:0.9577\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.9126\n",
      "Epoch:0099\n",
      "acc_train:0.9089 pre_train:0.8667 recall_train:0.9734 F1_train:0.9170 AUC_train:0.9577\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:0.9778 F1_val:0.792793 AUC_val:0.9081\n",
      "Epoch:0100\n",
      "acc_train:0.8951 pre_train:0.8452 recall_train:0.9758 F1_train:0.9058 AUC_train:0.9588\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:0.9778 F1_val:0.792793 AUC_val:0.9045\n",
      "Epoch:0101\n",
      "acc_train:0.8989 pre_train:0.8535 recall_train:0.9710 F1_train:0.9085 AUC_train:0.9579\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.9005\n",
      "Epoch:0102\n",
      "acc_train:0.9176 pre_train:0.8750 recall_train:0.9807 F1_train:0.9248 AUC_train:0.9714\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.8904\n",
      "Epoch:0103\n",
      "acc_train:0.9076 pre_train:0.8696 recall_train:0.9662 F1_train:0.9153 AUC_train:0.9736\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.8859\n",
      "Epoch:0104\n",
      "acc_train:0.9151 pre_train:0.8777 recall_train:0.9710 F1_train:0.9220 AUC_train:0.9703\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.8828\n",
      "Epoch:0105\n",
      "acc_train:0.9089 pre_train:0.8698 recall_train:0.9686 F1_train:0.9166 AUC_train:0.9697\n",
      "acc_val:0.7528 pre_val:0.6825 recall_val:0.9556 F1_val:0.796296 AUC_val:0.8793\n",
      "Epoch:0106\n",
      "acc_train:0.9226 pre_train:0.8826 recall_train:0.9807 F1_train:0.9291 AUC_train:0.9732\n",
      "acc_val:0.7640 pre_val:0.6935 recall_val:0.9556 F1_val:0.803738 AUC_val:0.8793\n",
      "Epoch:0107\n",
      "acc_train:0.9176 pre_train:0.8783 recall_train:0.9758 F1_train:0.9245 AUC_train:0.9700\n",
      "acc_val:0.7640 pre_val:0.6935 recall_val:0.9556 F1_val:0.803738 AUC_val:0.8740\n",
      "Epoch:0108\n",
      "acc_train:0.9151 pre_train:0.8697 recall_train:0.9831 F1_train:0.9229 AUC_train:0.9645\n",
      "acc_val:0.7528 pre_val:0.6825 recall_val:0.9556 F1_val:0.796296 AUC_val:0.8753\n",
      "Epoch:0109\n",
      "acc_train:0.9313 pre_train:0.8928 recall_train:0.9855 F1_train:0.9369 AUC_train:0.9758\n",
      "acc_val:0.7416 pre_val:0.6719 recall_val:0.9556 F1_val:0.788991 AUC_val:0.8788\n",
      "Epoch:0110\n",
      "acc_train:0.9151 pre_train:0.8794 recall_train:0.9686 F1_train:0.9218 AUC_train:0.9733\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.8894\n",
      "Epoch:0111\n",
      "acc_train:0.9201 pre_train:0.8821 recall_train:0.9758 F1_train:0.9266 AUC_train:0.9740\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.8894\n",
      "Epoch:0112\n",
      "acc_train:0.9338 pre_train:0.8985 recall_train:0.9831 F1_train:0.9389 AUC_train:0.9736\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.8924\n",
      "Epoch:0113\n",
      "acc_train:0.9363 pre_train:0.9079 recall_train:0.9758 F1_train:0.9406 AUC_train:0.9703\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.8909\n",
      "Epoch:0114\n",
      "acc_train:0.9388 pre_train:0.9138 recall_train:0.9734 F1_train:0.9427 AUC_train:0.9730\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.8753\n",
      "Epoch:0115\n",
      "acc_train:0.9313 pre_train:0.8962 recall_train:0.9807 F1_train:0.9366 AUC_train:0.9763\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.8682\n",
      "Epoch:0116\n",
      "acc_train:0.9426 pre_train:0.9163 recall_train:0.9783 F1_train:0.9463 AUC_train:0.9772\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.8692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0117\n",
      "acc_train:0.9363 pre_train:0.8972 recall_train:0.9903 F1_train:0.9414 AUC_train:0.9784\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.8687\n",
      "Epoch:0118\n",
      "acc_train:0.9401 pre_train:0.9067 recall_train:0.9855 F1_train:0.9444 AUC_train:0.9788\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.8684\n",
      "Epoch:0119\n",
      "acc_train:0.9363 pre_train:0.9079 recall_train:0.9758 F1_train:0.9406 AUC_train:0.9804\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.8684\n",
      "Epoch:0120\n",
      "acc_train:0.9313 pre_train:0.8998 recall_train:0.9758 F1_train:0.9363 AUC_train:0.9787\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.8707\n",
      "Epoch:0121\n",
      "acc_train:0.9513 pre_train:0.9252 recall_train:0.9855 F1_train:0.9544 AUC_train:0.9828\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:0.9778 F1_val:0.792793 AUC_val:0.8737\n",
      "Epoch:0122\n",
      "acc_train:0.9438 pre_train:0.9222 recall_train:0.9734 F1_train:0.9471 AUC_train:0.9853\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:0.9778 F1_val:0.792793 AUC_val:0.8765\n",
      "Epoch:0123\n",
      "acc_train:0.9538 pre_train:0.9236 recall_train:0.9928 F1_train:0.9569 AUC_train:0.9816\n",
      "acc_val:0.7303 pre_val:0.6567 recall_val:0.9778 F1_val:0.785714 AUC_val:0.8770\n",
      "Epoch:0124\n",
      "acc_train:0.9526 pre_train:0.9253 recall_train:0.9879 F1_train:0.9556 AUC_train:0.9831\n",
      "acc_val:0.7079 pre_val:0.6377 recall_val:0.9778 F1_val:0.771930 AUC_val:0.8798\n",
      "Epoch:0125\n",
      "acc_train:0.9551 pre_train:0.9257 recall_train:0.9928 F1_train:0.9580 AUC_train:0.9875\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.8803\n",
      "Epoch:0126\n",
      "acc_train:0.9438 pre_train:0.9222 recall_train:0.9734 F1_train:0.9471 AUC_train:0.9847\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.8813\n",
      "Epoch:0127\n",
      "acc_train:0.9463 pre_train:0.9206 recall_train:0.9807 F1_train:0.9497 AUC_train:0.9803\n",
      "acc_val:0.7191 pre_val:0.6471 recall_val:0.9778 F1_val:0.778761 AUC_val:0.8874\n",
      "Early Stopping!!! epoch：126\n",
      " Starting the 4-2 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4794 pre_train:0.4972 recall_train:0.6522 F1_train:0.5643 AUC_train:0.4739\n",
      "acc_val:0.4494 pre_val:0.4231 recall_val:0.2444 F1_val:0.309859 AUC_val:0.4172\n",
      "Epoch:0002\n",
      "acc_train:0.4582 pre_train:0.4823 recall_train:0.6594 F1_train:0.5571 AUC_train:0.4575\n",
      "acc_val:0.4607 pre_val:0.4444 recall_val:0.2667 F1_val:0.333333 AUC_val:0.4232\n",
      "Epoch:0003\n",
      "acc_train:0.4794 pre_train:0.4969 recall_train:0.5773 F1_train:0.5341 AUC_train:0.4793\n",
      "acc_val:0.4270 pre_val:0.4000 recall_val:0.2667 F1_val:0.320000 AUC_val:0.4071\n",
      "Epoch:0004\n",
      "acc_train:0.4844 pre_train:0.5011 recall_train:0.5435 F1_train:0.5214 AUC_train:0.4605\n",
      "acc_val:0.4157 pre_val:0.4000 recall_val:0.3111 F1_val:0.350000 AUC_val:0.3884\n",
      "Epoch:0005\n",
      "acc_train:0.4819 pre_train:0.4983 recall_train:0.3551 F1_train:0.4147 AUC_train:0.4596\n",
      "acc_val:0.4157 pre_val:0.4054 recall_val:0.3333 F1_val:0.365854 AUC_val:0.3955\n",
      "Epoch:0006\n",
      "acc_train:0.4569 pre_train:0.4745 recall_train:0.4710 F1_train:0.4727 AUC_train:0.4302\n",
      "acc_val:0.3933 pre_val:0.3846 recall_val:0.3333 F1_val:0.357143 AUC_val:0.3652\n",
      "Epoch:0007\n",
      "acc_train:0.5031 pre_train:0.5166 recall_train:0.6014 F1_train:0.5558 AUC_train:0.5029\n",
      "acc_val:0.3708 pre_val:0.3778 recall_val:0.3778 F1_val:0.377778 AUC_val:0.3343\n",
      "Epoch:0008\n",
      "acc_train:0.4569 pre_train:0.4727 recall_train:0.4396 F1_train:0.4556 AUC_train:0.4514\n",
      "acc_val:0.4157 pre_val:0.4286 recall_val:0.4667 F1_val:0.446809 AUC_val:0.3308\n",
      "Epoch:0009\n",
      "acc_train:0.4806 pre_train:0.4979 recall_train:0.5628 F1_train:0.5283 AUC_train:0.4645\n",
      "acc_val:0.4382 pre_val:0.4510 recall_val:0.5111 F1_val:0.479167 AUC_val:0.3495\n",
      "Epoch:0010\n",
      "acc_train:0.5031 pre_train:0.5237 recall_train:0.4275 F1_train:0.4707 AUC_train:0.5068\n",
      "acc_val:0.3820 pre_val:0.4194 recall_val:0.5778 F1_val:0.485981 AUC_val:0.3551\n",
      "Epoch:0011\n",
      "acc_train:0.5256 pre_train:0.5415 recall_train:0.5362 F1_train:0.5388 AUC_train:0.5343\n",
      "acc_val:0.3820 pre_val:0.4194 recall_val:0.5778 F1_val:0.485981 AUC_val:0.3535\n",
      "Epoch:0012\n",
      "acc_train:0.4869 pre_train:0.5028 recall_train:0.6570 F1_train:0.5696 AUC_train:0.4900\n",
      "acc_val:0.3820 pre_val:0.4194 recall_val:0.5778 F1_val:0.485981 AUC_val:0.3530\n",
      "Epoch:0013\n",
      "acc_train:0.5056 pre_train:0.5260 recall_train:0.4396 F1_train:0.4789 AUC_train:0.5126\n",
      "acc_val:0.3820 pre_val:0.4194 recall_val:0.5778 F1_val:0.485981 AUC_val:0.3566\n",
      "Epoch:0014\n",
      "acc_train:0.4981 pre_train:0.5120 recall_train:0.6159 F1_train:0.5592 AUC_train:0.5144\n",
      "acc_val:0.3933 pre_val:0.4286 recall_val:0.6000 F1_val:0.500000 AUC_val:0.3540\n",
      "Epoch:0015\n",
      "acc_train:0.5406 pre_train:0.5799 recall_train:0.4034 F1_train:0.4758 AUC_train:0.5148\n",
      "acc_val:0.3933 pre_val:0.4286 recall_val:0.6000 F1_val:0.500000 AUC_val:0.3556\n",
      "Epoch:0016\n",
      "acc_train:0.5056 pre_train:0.5162 recall_train:0.6908 F1_train:0.5909 AUC_train:0.5106\n",
      "acc_val:0.4045 pre_val:0.4394 recall_val:0.6444 F1_val:0.522523 AUC_val:0.3530\n",
      "Epoch:0017\n",
      "acc_train:0.5481 pre_train:0.6092 recall_train:0.3502 F1_train:0.4448 AUC_train:0.5506\n",
      "acc_val:0.4157 pre_val:0.4462 recall_val:0.6444 F1_val:0.527273 AUC_val:0.3591\n",
      "Epoch:0018\n",
      "acc_train:0.4906 pre_train:0.5056 recall_train:0.6522 F1_train:0.5696 AUC_train:0.4975\n",
      "acc_val:0.4157 pre_val:0.4462 recall_val:0.6444 F1_val:0.527273 AUC_val:0.3571\n",
      "Epoch:0019\n",
      "acc_train:0.5006 pre_train:0.5104 recall_train:0.8333 F1_train:0.6330 AUC_train:0.5260\n",
      "acc_val:0.4270 pre_val:0.4595 recall_val:0.7556 F1_val:0.571429 AUC_val:0.3838\n",
      "Epoch:0020\n",
      "acc_train:0.5206 pre_train:0.5234 recall_train:0.8092 F1_train:0.6357 AUC_train:0.5433\n",
      "acc_val:0.4382 pre_val:0.4667 recall_val:0.7778 F1_val:0.583333 AUC_val:0.3843\n",
      "Epoch:0021\n",
      "acc_train:0.5318 pre_train:0.5481 recall_train:0.5362 F1_train:0.5421 AUC_train:0.5461\n",
      "acc_val:0.4494 pre_val:0.4750 recall_val:0.8444 F1_val:0.608000 AUC_val:0.3838\n",
      "Epoch:0022\n",
      "acc_train:0.5131 pre_train:0.5287 recall_train:0.5338 F1_train:0.5312 AUC_train:0.5159\n",
      "acc_val:0.4607 pre_val:0.4815 recall_val:0.8667 F1_val:0.619048 AUC_val:0.3606\n",
      "Epoch:0023\n",
      "acc_train:0.5318 pre_train:0.5586 recall_train:0.4493 F1_train:0.4980 AUC_train:0.5274\n",
      "acc_val:0.4494 pre_val:0.4750 recall_val:0.8444 F1_val:0.608000 AUC_val:0.3606\n",
      "Epoch:0024\n",
      "acc_train:0.5006 pre_train:0.5174 recall_train:0.5024 F1_train:0.5098 AUC_train:0.5124\n",
      "acc_val:0.4270 pre_val:0.4605 recall_val:0.7778 F1_val:0.578512 AUC_val:0.3495\n",
      "Epoch:0025\n",
      "acc_train:0.5318 pre_train:0.5549 recall_train:0.4758 F1_train:0.5124 AUC_train:0.5604\n",
      "acc_val:0.4607 pre_val:0.4810 recall_val:0.8444 F1_val:0.612903 AUC_val:0.3540\n",
      "Epoch:0026\n",
      "acc_train:0.5431 pre_train:0.5870 recall_train:0.3913 F1_train:0.4696 AUC_train:0.5584\n",
      "acc_val:0.4270 pre_val:0.4605 recall_val:0.7778 F1_val:0.578512 AUC_val:0.3571\n",
      "Epoch:0027\n",
      "acc_train:0.5306 pre_train:0.5704 recall_train:0.3720 F1_train:0.4503 AUC_train:0.5375\n",
      "acc_val:0.4270 pre_val:0.4605 recall_val:0.7778 F1_val:0.578512 AUC_val:0.3545\n",
      "Epoch:0028\n",
      "acc_train:0.5331 pre_train:0.5532 recall_train:0.5024 F1_train:0.5266 AUC_train:0.5239\n",
      "acc_val:0.4157 pre_val:0.4533 recall_val:0.7556 F1_val:0.566667 AUC_val:0.3702\n",
      "Epoch:0029\n",
      "acc_train:0.5331 pre_train:0.5442 recall_train:0.5942 F1_train:0.5681 AUC_train:0.5242\n",
      "acc_val:0.4719 pre_val:0.4872 recall_val:0.8444 F1_val:0.617886 AUC_val:0.4217\n",
      "Epoch:0030\n",
      "acc_train:0.5243 pre_train:0.5407 recall_train:0.5290 F1_train:0.5348 AUC_train:0.5214\n",
      "acc_val:0.4831 pre_val:0.4935 recall_val:0.8444 F1_val:0.622951 AUC_val:0.4505\n",
      "Epoch:0031\n",
      "acc_train:0.5581 pre_train:0.6014 recall_train:0.4300 F1_train:0.5014 AUC_train:0.5591\n",
      "acc_val:0.5056 pre_val:0.5065 recall_val:0.8667 F1_val:0.639344 AUC_val:0.4556\n",
      "Epoch:0032\n",
      "acc_train:0.5006 pre_train:0.5132 recall_train:0.6570 F1_train:0.5763 AUC_train:0.5188\n",
      "acc_val:0.4719 pre_val:0.4868 recall_val:0.8222 F1_val:0.611570 AUC_val:0.4374\n",
      "Epoch:0033\n",
      "acc_train:0.5543 pre_train:0.6029 recall_train:0.4034 F1_train:0.4834 AUC_train:0.5567\n",
      "acc_val:0.4607 pre_val:0.4795 recall_val:0.7778 F1_val:0.593220 AUC_val:0.4384\n",
      "Epoch:0034\n",
      "acc_train:0.5056 pre_train:0.5251 recall_train:0.4541 F1_train:0.4870 AUC_train:0.4748\n",
      "acc_val:0.4607 pre_val:0.4795 recall_val:0.7778 F1_val:0.593220 AUC_val:0.4419\n",
      "Epoch:0035\n",
      "acc_train:0.5368 pre_train:0.5771 recall_train:0.3889 F1_train:0.4646 AUC_train:0.5340\n",
      "acc_val:0.4719 pre_val:0.4865 recall_val:0.8000 F1_val:0.605042 AUC_val:0.4505\n",
      "Epoch:0036\n",
      "acc_train:0.5181 pre_train:0.5287 recall_train:0.6232 F1_train:0.5721 AUC_train:0.5382\n",
      "acc_val:0.5393 pre_val:0.5323 recall_val:0.7333 F1_val:0.616822 AUC_val:0.4914\n",
      "Epoch:0037\n",
      "acc_train:0.5231 pre_train:0.5684 recall_train:0.3213 F1_train:0.4105 AUC_train:0.5392\n",
      "acc_val:0.5506 pre_val:0.5410 recall_val:0.7333 F1_val:0.622642 AUC_val:0.4980\n",
      "Epoch:0038\n",
      "acc_train:0.5144 pre_train:0.5321 recall_train:0.5000 F1_train:0.5156 AUC_train:0.5302\n",
      "acc_val:0.5169 pre_val:0.5147 recall_val:0.7778 F1_val:0.619469 AUC_val:0.5288\n",
      "Epoch:0039\n",
      "acc_train:0.5306 pre_train:0.5629 recall_train:0.4106 F1_train:0.4749 AUC_train:0.5410\n",
      "acc_val:0.5393 pre_val:0.5270 recall_val:0.8667 F1_val:0.655462 AUC_val:0.5212\n",
      "Epoch:0040\n",
      "acc_train:0.5181 pre_train:0.5443 recall_train:0.4155 F1_train:0.4712 AUC_train:0.5196\n",
      "acc_val:0.5281 pre_val:0.5185 recall_val:0.9333 F1_val:0.666667 AUC_val:0.4894\n",
      "Epoch:0041\n",
      "acc_train:0.4757 pre_train:0.4954 recall_train:0.7802 F1_train:0.6060 AUC_train:0.4955\n",
      "acc_val:0.5393 pre_val:0.5233 recall_val:1.0000 F1_val:0.687023 AUC_val:0.4934\n",
      "Epoch:0042\n",
      "acc_train:0.4969 pre_train:0.5090 recall_train:0.7512 F1_train:0.6068 AUC_train:0.4930\n",
      "acc_val:0.5393 pre_val:0.5250 recall_val:0.9333 F1_val:0.672000 AUC_val:0.4990\n",
      "Epoch:0043\n",
      "acc_train:0.5181 pre_train:0.5352 recall_train:0.5145 F1_train:0.5246 AUC_train:0.5198\n",
      "acc_val:0.5618 pre_val:0.5395 recall_val:0.9111 F1_val:0.677686 AUC_val:0.5187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0044\n",
      "acc_train:0.4919 pre_train:0.5053 recall_train:0.8068 F1_train:0.6214 AUC_train:0.5056\n",
      "acc_val:0.5169 pre_val:0.5125 recall_val:0.9111 F1_val:0.656000 AUC_val:0.5253\n",
      "Epoch:0045\n",
      "acc_train:0.5156 pre_train:0.5551 recall_train:0.3164 F1_train:0.4031 AUC_train:0.5240\n",
      "acc_val:0.5056 pre_val:0.5060 recall_val:0.9333 F1_val:0.656250 AUC_val:0.5323\n",
      "Epoch:0046\n",
      "acc_train:0.5306 pre_train:0.5397 recall_train:0.6232 F1_train:0.5785 AUC_train:0.5532\n",
      "acc_val:0.5056 pre_val:0.5062 recall_val:0.9111 F1_val:0.650794 AUC_val:0.5404\n",
      "Epoch:0047\n",
      "acc_train:0.5343 pre_train:0.5810 recall_train:0.3551 F1_train:0.4408 AUC_train:0.5260\n",
      "acc_val:0.5169 pre_val:0.5128 recall_val:0.8889 F1_val:0.650407 AUC_val:0.5298\n",
      "Epoch:0048\n",
      "acc_train:0.5218 pre_train:0.5633 recall_train:0.3333 F1_train:0.4188 AUC_train:0.5379\n",
      "acc_val:0.5056 pre_val:0.5057 recall_val:0.9778 F1_val:0.666667 AUC_val:0.5258\n",
      "Epoch:0049\n",
      "acc_train:0.5056 pre_train:0.5395 recall_train:0.2971 F1_train:0.3832 AUC_train:0.4816\n",
      "acc_val:0.5056 pre_val:0.5057 recall_val:0.9778 F1_val:0.666667 AUC_val:0.5035\n",
      "Epoch:0050\n",
      "acc_train:0.5531 pre_train:0.5993 recall_train:0.4082 F1_train:0.4856 AUC_train:0.5782\n",
      "acc_val:0.5618 pre_val:0.5385 recall_val:0.9333 F1_val:0.682927 AUC_val:0.5434\n",
      "Epoch:0051\n",
      "acc_train:0.5356 pre_train:0.5833 recall_train:0.3551 F1_train:0.4414 AUC_train:0.5525\n",
      "acc_val:0.5618 pre_val:0.5366 recall_val:0.9778 F1_val:0.692913 AUC_val:0.5460\n",
      "Epoch:0052\n",
      "acc_train:0.5668 pre_train:0.6012 recall_train:0.4807 F1_train:0.5342 AUC_train:0.5549\n",
      "acc_val:0.5506 pre_val:0.5301 recall_val:0.9778 F1_val:0.687500 AUC_val:0.5384\n",
      "Epoch:0053\n",
      "acc_train:0.4994 pre_train:0.5110 recall_train:0.7271 F1_train:0.6002 AUC_train:0.5230\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5475\n",
      "Epoch:0054\n",
      "acc_train:0.5680 pre_train:0.6269 recall_train:0.4058 F1_train:0.4927 AUC_train:0.5754\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5535\n",
      "Epoch:0055\n",
      "acc_train:0.5743 pre_train:0.6347 recall_train:0.4155 F1_train:0.5022 AUC_train:0.5823\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5652\n",
      "Epoch:0056\n",
      "acc_train:0.5268 pre_train:0.5681 recall_train:0.3527 F1_train:0.4352 AUC_train:0.5346\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5742\n",
      "Epoch:0057\n",
      "acc_train:0.5431 pre_train:0.5612 recall_train:0.5314 F1_train:0.5459 AUC_train:0.5304\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5773\n",
      "Epoch:0058\n",
      "acc_train:0.5194 pre_train:0.5543 recall_train:0.3575 F1_train:0.4347 AUC_train:0.5439\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5970\n",
      "Epoch:0059\n",
      "acc_train:0.5855 pre_train:0.6289 recall_train:0.4831 F1_train:0.5464 AUC_train:0.5994\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6040\n",
      "Epoch:0060\n",
      "acc_train:0.5406 pre_train:0.5816 recall_train:0.3961 F1_train:0.4713 AUC_train:0.5410\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5985\n",
      "Epoch:0061\n",
      "acc_train:0.5218 pre_train:0.5246 recall_train:0.7971 F1_train:0.6328 AUC_train:0.5606\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6141\n",
      "Epoch:0062\n",
      "acc_train:0.5206 pre_train:0.5236 recall_train:0.8043 F1_train:0.6343 AUC_train:0.5516\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6116\n",
      "Epoch:0063\n",
      "acc_train:0.5206 pre_train:0.5260 recall_train:0.7343 F1_train:0.6129 AUC_train:0.5225\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6076\n",
      "Epoch:0064\n",
      "acc_train:0.5031 pre_train:0.5122 recall_train:0.8092 F1_train:0.6273 AUC_train:0.5350\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6131\n",
      "Epoch:0065\n",
      "acc_train:0.5531 pre_train:0.5773 recall_train:0.5048 F1_train:0.5387 AUC_train:0.5685\n",
      "acc_val:0.5618 pre_val:0.5469 recall_val:0.7778 F1_val:0.642202 AUC_val:0.6157\n",
      "Epoch:0066\n",
      "acc_train:0.5605 pre_train:0.5917 recall_train:0.4831 F1_train:0.5319 AUC_train:0.5552\n",
      "acc_val:0.5955 pre_val:0.5672 recall_val:0.8444 F1_val:0.678571 AUC_val:0.6126\n",
      "Epoch:0067\n",
      "acc_train:0.5331 pre_train:0.5877 recall_train:0.3237 F1_train:0.4174 AUC_train:0.5456\n",
      "acc_val:0.5955 pre_val:0.5882 recall_val:0.6667 F1_val:0.625000 AUC_val:0.6116\n",
      "Epoch:0068\n",
      "acc_train:0.5306 pre_train:0.5714 recall_train:0.3671 F1_train:0.4471 AUC_train:0.5303\n",
      "acc_val:0.5730 pre_val:0.5854 recall_val:0.5333 F1_val:0.558140 AUC_val:0.6030\n",
      "Epoch:0069\n",
      "acc_train:0.5218 pre_train:0.5548 recall_train:0.3792 F1_train:0.4505 AUC_train:0.5379\n",
      "acc_val:0.5730 pre_val:0.6296 recall_val:0.3778 F1_val:0.472222 AUC_val:0.6010\n",
      "Epoch:0070\n",
      "acc_train:0.5556 pre_train:0.6343 recall_train:0.3309 F1_train:0.4349 AUC_train:0.5854\n",
      "acc_val:0.5618 pre_val:0.6250 recall_val:0.3333 F1_val:0.434783 AUC_val:0.6071\n",
      "Epoch:0071\n",
      "acc_train:0.4769 pre_train:0.4964 recall_train:0.8406 F1_train:0.6242 AUC_train:0.5038\n",
      "acc_val:0.5730 pre_val:0.5614 recall_val:0.7111 F1_val:0.627451 AUC_val:0.6096\n",
      "Epoch:0072\n",
      "acc_train:0.5780 pre_train:0.6473 recall_train:0.4034 F1_train:0.4970 AUC_train:0.5777\n",
      "acc_val:0.5618 pre_val:0.5682 recall_val:0.5556 F1_val:0.561798 AUC_val:0.6071\n",
      "Epoch:0073\n",
      "acc_train:0.5493 pre_train:0.5472 recall_train:0.7415 F1_train:0.6297 AUC_train:0.5822\n",
      "acc_val:0.5843 pre_val:0.5800 recall_val:0.6444 F1_val:0.610526 AUC_val:0.6061\n",
      "Epoch:0074\n",
      "acc_train:0.5443 pre_train:0.5465 recall_train:0.6957 F1_train:0.6121 AUC_train:0.5683\n",
      "acc_val:0.5843 pre_val:0.5741 recall_val:0.6889 F1_val:0.626263 AUC_val:0.6030\n",
      "Epoch:0075\n",
      "acc_train:0.5630 pre_train:0.6053 recall_train:0.4444 F1_train:0.5125 AUC_train:0.5624\n",
      "acc_val:0.5618 pre_val:0.5429 recall_val:0.8444 F1_val:0.660870 AUC_val:0.5970\n",
      "Epoch:0076\n",
      "acc_train:0.5506 pre_train:0.6107 recall_train:0.3599 F1_train:0.4529 AUC_train:0.5596\n",
      "acc_val:0.5843 pre_val:0.5541 recall_val:0.9111 F1_val:0.689076 AUC_val:0.6126\n",
      "Epoch:0077\n",
      "acc_train:0.5655 pre_train:0.6065 recall_train:0.4541 F1_train:0.5193 AUC_train:0.5483\n",
      "acc_val:0.5730 pre_val:0.5479 recall_val:0.8889 F1_val:0.677966 AUC_val:0.6212\n",
      "Epoch:0078\n",
      "acc_train:0.4981 pre_train:0.5117 recall_train:0.6353 F1_train:0.5668 AUC_train:0.5241\n",
      "acc_val:0.5393 pre_val:0.5233 recall_val:1.0000 F1_val:0.687023 AUC_val:0.6197\n",
      "Epoch:0079\n",
      "acc_train:0.5443 pre_train:0.5630 recall_train:0.5290 F1_train:0.5455 AUC_train:0.5376\n",
      "acc_val:0.5393 pre_val:0.5233 recall_val:1.0000 F1_val:0.687023 AUC_val:0.6182\n",
      "Epoch:0080\n",
      "acc_train:0.5730 pre_train:0.6047 recall_train:0.5024 F1_train:0.5488 AUC_train:0.5987\n",
      "acc_val:0.5506 pre_val:0.5309 recall_val:0.9556 F1_val:0.682540 AUC_val:0.6141\n",
      "Epoch:0081\n",
      "acc_train:0.5443 pre_train:0.5854 recall_train:0.4058 F1_train:0.4793 AUC_train:0.5831\n",
      "acc_val:0.5506 pre_val:0.5309 recall_val:0.9556 F1_val:0.682540 AUC_val:0.6167\n",
      "Epoch:0082\n",
      "acc_train:0.5743 pre_train:0.6144 recall_train:0.4734 F1_train:0.5348 AUC_train:0.5877\n",
      "acc_val:0.5618 pre_val:0.5417 recall_val:0.8667 F1_val:0.666667 AUC_val:0.6146\n",
      "Epoch:0083\n",
      "acc_train:0.6067 pre_train:0.6505 recall_train:0.5169 F1_train:0.5760 AUC_train:0.6135\n",
      "acc_val:0.5730 pre_val:0.5507 recall_val:0.8444 F1_val:0.666667 AUC_val:0.6192\n",
      "Early Stopping!!! epoch：82\n",
      " Starting the 4-3 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4432 pre_train:0.4574 recall_train:0.4155 F1_train:0.4354 AUC_train:0.4306\n",
      "acc_val:0.5281 pre_val:0.5172 recall_val:1.0000 F1_val:0.681818 AUC_val:0.5596\n",
      "Epoch:0002\n",
      "acc_train:0.5293 pre_train:0.5358 recall_train:0.6691 F1_train:0.5951 AUC_train:0.5470\n",
      "acc_val:0.5169 pre_val:0.5143 recall_val:0.8000 F1_val:0.626087 AUC_val:0.4960\n",
      "Epoch:0003\n",
      "acc_train:0.4969 pre_train:0.5132 recall_train:0.5169 F1_train:0.5150 AUC_train:0.5152\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.4934\n",
      "Epoch:0004\n",
      "acc_train:0.5106 pre_train:0.5247 recall_train:0.5652 F1_train:0.5442 AUC_train:0.5421\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.4874\n",
      "Epoch:0005\n",
      "acc_train:0.4994 pre_train:0.5169 recall_train:0.4807 F1_train:0.4981 AUC_train:0.5195\n",
      "acc_val:0.5281 pre_val:0.5172 recall_val:1.0000 F1_val:0.681818 AUC_val:0.5045\n",
      "Epoch:0006\n",
      "acc_train:0.4944 pre_train:0.5082 recall_train:0.6739 F1_train:0.5794 AUC_train:0.5081\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5449\n",
      "Epoch:0007\n",
      "acc_train:0.5106 pre_train:0.5248 recall_train:0.5628 F1_train:0.5431 AUC_train:0.5124\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5672\n",
      "Epoch:0008\n",
      "acc_train:0.5281 pre_train:0.5404 recall_train:0.5821 F1_train:0.5605 AUC_train:0.5470\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5702\n",
      "Epoch:0009\n",
      "acc_train:0.5356 pre_train:0.5498 recall_train:0.5604 F1_train:0.5550 AUC_train:0.5360\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5727\n",
      "Epoch:0010\n",
      "acc_train:0.5044 pre_train:0.5136 recall_train:0.7754 F1_train:0.6179 AUC_train:0.5252\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5854\n",
      "Epoch:0011\n",
      "acc_train:0.5568 pre_train:0.5870 recall_train:0.4807 F1_train:0.5286 AUC_train:0.5699\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5753\n",
      "Epoch:0012\n",
      "acc_train:0.5268 pre_train:0.5439 recall_train:0.5242 F1_train:0.5338 AUC_train:0.5357\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5692\n",
      "Epoch:0013\n",
      "acc_train:0.5044 pre_train:0.5166 recall_train:0.6377 F1_train:0.5708 AUC_train:0.5166\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5788\n",
      "Epoch:0014\n",
      "acc_train:0.5169 pre_train:0.5364 recall_train:0.4807 F1_train:0.5070 AUC_train:0.5293\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0015\n",
      "acc_train:0.5144 pre_train:0.5201 recall_train:0.7802 F1_train:0.6242 AUC_train:0.5324\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5833\n",
      "Epoch:0016\n",
      "acc_train:0.5418 pre_train:0.5791 recall_train:0.4155 F1_train:0.4838 AUC_train:0.5377\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5783\n",
      "Epoch:0017\n",
      "acc_train:0.5630 pre_train:0.5804 recall_train:0.5580 F1_train:0.5690 AUC_train:0.5710\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5763\n",
      "Epoch:0018\n",
      "acc_train:0.5393 pre_train:0.5451 recall_train:0.6570 F1_train:0.5958 AUC_train:0.5578\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5697\n",
      "Epoch:0019\n",
      "acc_train:0.5268 pre_train:0.5262 recall_train:0.8502 F1_train:0.6500 AUC_train:0.5700\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5646\n",
      "Epoch:0020\n",
      "acc_train:0.4981 pre_train:0.5103 recall_train:0.7174 F1_train:0.5964 AUC_train:0.5381\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5515\n",
      "Epoch:0021\n",
      "acc_train:0.5393 pre_train:0.5637 recall_train:0.4807 F1_train:0.5189 AUC_train:0.5529\n",
      "acc_val:0.5618 pre_val:0.5375 recall_val:0.9556 F1_val:0.688000 AUC_val:0.5460\n",
      "Epoch:0022\n",
      "acc_train:0.5268 pre_train:0.5338 recall_train:0.6667 F1_train:0.5929 AUC_train:0.5488\n",
      "acc_val:0.5730 pre_val:0.5443 recall_val:0.9556 F1_val:0.693548 AUC_val:0.5439\n",
      "Epoch:0023\n",
      "acc_train:0.4994 pre_train:0.5107 recall_train:0.7512 F1_train:0.6080 AUC_train:0.5254\n",
      "acc_val:0.5618 pre_val:0.5385 recall_val:0.9333 F1_val:0.682927 AUC_val:0.5626\n",
      "Epoch:0024\n",
      "acc_train:0.5069 pre_train:0.5145 recall_train:0.8116 F1_train:0.6298 AUC_train:0.5226\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5833\n",
      "Epoch:0025\n",
      "acc_train:0.5156 pre_train:0.5220 recall_train:0.7464 F1_train:0.6143 AUC_train:0.5635\n",
      "acc_val:0.5730 pre_val:0.5443 recall_val:0.9556 F1_val:0.693548 AUC_val:0.5889\n",
      "Epoch:0026\n",
      "acc_train:0.5218 pre_train:0.5246 recall_train:0.7971 F1_train:0.6328 AUC_train:0.5607\n",
      "acc_val:0.6067 pre_val:0.5676 recall_val:0.9333 F1_val:0.705882 AUC_val:0.5939\n",
      "Epoch:0027\n",
      "acc_train:0.5493 pre_train:0.6199 recall_train:0.3309 F1_train:0.4315 AUC_train:0.5629\n",
      "acc_val:0.5506 pre_val:0.5581 recall_val:0.5333 F1_val:0.545455 AUC_val:0.6035\n",
      "Epoch:0028\n",
      "acc_train:0.5094 pre_train:0.5165 recall_train:0.7947 F1_train:0.6261 AUC_train:0.5299\n",
      "acc_val:0.5955 pre_val:0.5570 recall_val:0.9778 F1_val:0.709677 AUC_val:0.6066\n",
      "Epoch:0029\n",
      "acc_train:0.5643 pre_train:0.6148 recall_train:0.4203 F1_train:0.4993 AUC_train:0.6015\n",
      "acc_val:0.6067 pre_val:0.5806 recall_val:0.8000 F1_val:0.672897 AUC_val:0.6101\n",
      "Epoch:0030\n",
      "acc_train:0.5568 pre_train:0.6065 recall_train:0.4058 F1_train:0.4863 AUC_train:0.5943\n",
      "acc_val:0.6067 pre_val:0.5806 recall_val:0.8000 F1_val:0.672897 AUC_val:0.6192\n",
      "Epoch:0031\n",
      "acc_train:0.5206 pre_train:0.5466 recall_train:0.4251 F1_train:0.4783 AUC_train:0.5243\n",
      "acc_val:0.6292 pre_val:0.5968 recall_val:0.8222 F1_val:0.691589 AUC_val:0.6253\n",
      "Epoch:0032\n",
      "acc_train:0.5855 pre_train:0.6464 recall_train:0.4372 F1_train:0.5216 AUC_train:0.5998\n",
      "acc_val:0.6067 pre_val:0.5781 recall_val:0.8222 F1_val:0.678899 AUC_val:0.6308\n",
      "Epoch:0033\n",
      "acc_train:0.5568 pre_train:0.6439 recall_train:0.3188 F1_train:0.4265 AUC_train:0.6041\n",
      "acc_val:0.6180 pre_val:0.5821 recall_val:0.8667 F1_val:0.696429 AUC_val:0.6389\n",
      "Epoch:0034\n",
      "acc_train:0.5605 pre_train:0.6449 recall_train:0.3333 F1_train:0.4395 AUC_train:0.5947\n",
      "acc_val:0.6180 pre_val:0.5797 recall_val:0.8889 F1_val:0.701754 AUC_val:0.6414\n",
      "Epoch:0035\n",
      "acc_train:0.5506 pre_train:0.5616 recall_train:0.5942 F1_train:0.5775 AUC_train:0.5740\n",
      "acc_val:0.6067 pre_val:0.5658 recall_val:0.9556 F1_val:0.710744 AUC_val:0.6374\n",
      "Epoch:0036\n",
      "acc_train:0.6005 pre_train:0.5887 recall_train:0.7536 F1_train:0.6610 AUC_train:0.6234\n",
      "acc_val:0.5955 pre_val:0.5556 recall_val:1.0000 F1_val:0.714286 AUC_val:0.6364\n",
      "Epoch:0037\n",
      "acc_train:0.5705 pre_train:0.6174 recall_train:0.4444 F1_train:0.5169 AUC_train:0.5856\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6354\n",
      "Epoch:0038\n",
      "acc_train:0.5855 pre_train:0.6358 recall_train:0.4638 F1_train:0.5363 AUC_train:0.5971\n",
      "acc_val:0.5618 pre_val:0.5357 recall_val:1.0000 F1_val:0.697674 AUC_val:0.6338\n",
      "Epoch:0039\n",
      "acc_train:0.5468 pre_train:0.5501 recall_train:0.6763 F1_train:0.6067 AUC_train:0.5534\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6369\n",
      "Epoch:0040\n",
      "acc_train:0.5381 pre_train:0.5370 recall_train:0.7705 F1_train:0.6329 AUC_train:0.5693\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6379\n",
      "Epoch:0041\n",
      "acc_train:0.5993 pre_train:0.6545 recall_train:0.4758 F1_train:0.5510 AUC_train:0.6367\n",
      "acc_val:0.5281 pre_val:0.5172 recall_val:1.0000 F1_val:0.681818 AUC_val:0.6384\n",
      "Epoch:0042\n",
      "acc_train:0.6005 pre_train:0.6469 recall_train:0.5000 F1_train:0.5640 AUC_train:0.6408\n",
      "acc_val:0.5506 pre_val:0.5294 recall_val:1.0000 F1_val:0.692308 AUC_val:0.6354\n",
      "Epoch:0043\n",
      "acc_train:0.6055 pre_train:0.6581 recall_train:0.4928 F1_train:0.5635 AUC_train:0.6415\n",
      "acc_val:0.5506 pre_val:0.5294 recall_val:1.0000 F1_val:0.692308 AUC_val:0.6389\n",
      "Epoch:0044\n",
      "acc_train:0.5843 pre_train:0.6167 recall_train:0.5169 F1_train:0.5624 AUC_train:0.6198\n",
      "acc_val:0.5618 pre_val:0.5357 recall_val:1.0000 F1_val:0.697674 AUC_val:0.6424\n",
      "Epoch:0045\n",
      "acc_train:0.6105 pre_train:0.5992 recall_train:0.7440 F1_train:0.6638 AUC_train:0.6514\n",
      "acc_val:0.5506 pre_val:0.5294 recall_val:1.0000 F1_val:0.692308 AUC_val:0.6566\n",
      "Epoch:0046\n",
      "acc_train:0.5581 pre_train:0.5448 recall_train:0.8816 F1_train:0.6734 AUC_train:0.6175\n",
      "acc_val:0.5506 pre_val:0.5294 recall_val:1.0000 F1_val:0.692308 AUC_val:0.6611\n",
      "Epoch:0047\n",
      "acc_train:0.6380 pre_train:0.6270 recall_train:0.7391 F1_train:0.6785 AUC_train:0.6630\n",
      "acc_val:0.5730 pre_val:0.5422 recall_val:1.0000 F1_val:0.703125 AUC_val:0.6747\n",
      "Epoch:0048\n",
      "acc_train:0.6180 pre_train:0.6788 recall_train:0.4952 F1_train:0.5726 AUC_train:0.6984\n",
      "acc_val:0.6517 pre_val:0.5921 recall_val:1.0000 F1_val:0.743802 AUC_val:0.6955\n",
      "Epoch:0049\n",
      "acc_train:0.6330 pre_train:0.6103 recall_train:0.8019 F1_train:0.6931 AUC_train:0.6884\n",
      "acc_val:0.6966 pre_val:0.6286 recall_val:0.9778 F1_val:0.765217 AUC_val:0.7177\n",
      "Epoch:0050\n",
      "acc_train:0.6242 pre_train:0.6160 recall_train:0.7246 F1_train:0.6659 AUC_train:0.6834\n",
      "acc_val:0.6742 pre_val:0.6176 recall_val:0.9333 F1_val:0.743363 AUC_val:0.7288\n",
      "Epoch:0051\n",
      "acc_train:0.6604 pre_train:0.6315 recall_train:0.8237 F1_train:0.7149 AUC_train:0.6913\n",
      "acc_val:0.6629 pre_val:0.6190 recall_val:0.8667 F1_val:0.722222 AUC_val:0.7313\n",
      "Epoch:0052\n",
      "acc_train:0.6704 pre_train:0.6354 recall_train:0.8502 F1_train:0.7273 AUC_train:0.7147\n",
      "acc_val:0.6404 pre_val:0.6066 recall_val:0.8222 F1_val:0.698113 AUC_val:0.7394\n",
      "Epoch:0053\n",
      "acc_train:0.6492 pre_train:0.6234 recall_train:0.8116 F1_train:0.7051 AUC_train:0.6819\n",
      "acc_val:0.6292 pre_val:0.6000 recall_val:0.8000 F1_val:0.685714 AUC_val:0.7414\n",
      "Epoch:0054\n",
      "acc_train:0.6517 pre_train:0.6364 recall_train:0.7609 F1_train:0.6931 AUC_train:0.7042\n",
      "acc_val:0.6517 pre_val:0.6522 recall_val:0.6667 F1_val:0.659341 AUC_val:0.7475\n",
      "Epoch:0055\n",
      "acc_train:0.6492 pre_train:0.6388 recall_train:0.7391 F1_train:0.6853 AUC_train:0.7024\n",
      "acc_val:0.6966 pre_val:0.7143 recall_val:0.6667 F1_val:0.689655 AUC_val:0.7561\n",
      "Epoch:0056\n",
      "acc_train:0.6754 pre_train:0.6464 recall_train:0.8213 F1_train:0.7234 AUC_train:0.7494\n",
      "acc_val:0.6854 pre_val:0.7297 recall_val:0.6000 F1_val:0.658537 AUC_val:0.7707\n",
      "Epoch:0057\n",
      "acc_train:0.6717 pre_train:0.6380 recall_train:0.8430 F1_train:0.7263 AUC_train:0.7266\n",
      "acc_val:0.7191 pre_val:0.7778 recall_val:0.6222 F1_val:0.691358 AUC_val:0.7864\n",
      "Epoch:0058\n",
      "acc_train:0.6904 pre_train:0.6515 recall_train:0.8623 F1_train:0.7422 AUC_train:0.7475\n",
      "acc_val:0.6629 pre_val:0.7586 recall_val:0.4889 F1_val:0.594595 AUC_val:0.7884\n",
      "Epoch:0059\n",
      "acc_train:0.6991 pre_train:0.7235 recall_train:0.6763 F1_train:0.6991 AUC_train:0.7738\n",
      "acc_val:0.6067 pre_val:0.6923 recall_val:0.4000 F1_val:0.507042 AUC_val:0.7348\n",
      "Epoch:0060\n",
      "acc_train:0.7241 pre_train:0.7546 recall_train:0.6908 F1_train:0.7213 AUC_train:0.7978\n",
      "acc_val:0.5955 pre_val:0.6957 recall_val:0.3556 F1_val:0.470588 AUC_val:0.7354\n",
      "Epoch:0061\n",
      "acc_train:0.6816 pre_train:0.6544 recall_train:0.8140 F1_train:0.7255 AUC_train:0.7824\n",
      "acc_val:0.6067 pre_val:0.7273 recall_val:0.3556 F1_val:0.477612 AUC_val:0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0062\n",
      "acc_train:0.7041 pre_train:0.6624 recall_train:0.8720 F1_train:0.7529 AUC_train:0.8025\n",
      "acc_val:0.6292 pre_val:0.7727 recall_val:0.3778 F1_val:0.507463 AUC_val:0.8189\n",
      "Epoch:0063\n",
      "acc_train:0.7216 pre_train:0.6994 recall_train:0.8092 F1_train:0.7503 AUC_train:0.8170\n",
      "acc_val:0.6854 pre_val:0.8696 recall_val:0.4444 F1_val:0.588235 AUC_val:0.8566\n",
      "Epoch:0064\n",
      "acc_train:0.7266 pre_train:0.7893 recall_train:0.6425 F1_train:0.7084 AUC_train:0.8247\n",
      "acc_val:0.7191 pre_val:0.8846 recall_val:0.5111 F1_val:0.647887 AUC_val:0.8641\n",
      "Epoch:0065\n",
      "acc_train:0.7466 pre_train:0.7859 recall_train:0.7005 F1_train:0.7407 AUC_train:0.8373\n",
      "acc_val:0.7528 pre_val:0.8966 recall_val:0.5778 F1_val:0.702703 AUC_val:0.8576\n",
      "Epoch:0066\n",
      "acc_train:0.7303 pre_train:0.6820 recall_train:0.8961 F1_train:0.7745 AUC_train:0.8218\n",
      "acc_val:0.7191 pre_val:0.7083 recall_val:0.7556 F1_val:0.731183 AUC_val:0.8495\n",
      "Epoch:0067\n",
      "acc_train:0.7853 pre_train:0.8010 recall_train:0.7778 F1_train:0.7892 AUC_train:0.8732\n",
      "acc_val:0.7978 pre_val:0.7368 recall_val:0.9333 F1_val:0.823529 AUC_val:0.8434\n",
      "Epoch:0068\n",
      "acc_train:0.7940 pre_train:0.8168 recall_train:0.7754 F1_train:0.7955 AUC_train:0.8868\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.8419\n",
      "Epoch:0069\n",
      "acc_train:0.8027 pre_train:0.8122 recall_train:0.8043 F1_train:0.8083 AUC_train:0.8911\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.8126\n",
      "Epoch:0070\n",
      "acc_train:0.7965 pre_train:0.8039 recall_train:0.8019 F1_train:0.8029 AUC_train:0.8810\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.7995\n",
      "Epoch:0071\n",
      "acc_train:0.8152 pre_train:0.8654 recall_train:0.7609 F1_train:0.8098 AUC_train:0.8959\n",
      "acc_val:0.7528 pre_val:0.6769 recall_val:0.9778 F1_val:0.800000 AUC_val:0.8035\n",
      "Epoch:0072\n",
      "acc_train:0.7441 pre_train:0.7037 recall_train:0.8720 F1_train:0.7789 AUC_train:0.8670\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:0.9778 F1_val:0.792793 AUC_val:0.7965\n",
      "Epoch:0073\n",
      "acc_train:0.7640 pre_train:0.7517 recall_train:0.8116 F1_train:0.7805 AUC_train:0.8736\n",
      "acc_val:0.7416 pre_val:0.6719 recall_val:0.9556 F1_val:0.788991 AUC_val:0.8273\n",
      "Epoch:0074\n",
      "acc_train:0.7790 pre_train:0.7356 recall_train:0.8937 F1_train:0.8070 AUC_train:0.8971\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.8359\n",
      "Epoch:0075\n",
      "acc_train:0.8115 pre_train:0.8263 recall_train:0.8043 F1_train:0.8152 AUC_train:0.8972\n",
      "acc_val:0.7865 pre_val:0.7167 recall_val:0.9556 F1_val:0.819048 AUC_val:0.8449\n",
      "Epoch:0076\n",
      "acc_train:0.8127 pre_train:0.8511 recall_train:0.7729 F1_train:0.8101 AUC_train:0.9041\n",
      "acc_val:0.7640 pre_val:0.6875 recall_val:0.9778 F1_val:0.807339 AUC_val:0.8419\n",
      "Epoch:0077\n",
      "acc_train:0.8152 pre_train:0.8292 recall_train:0.8092 F1_train:0.8191 AUC_train:0.9031\n",
      "acc_val:0.7640 pre_val:0.6818 recall_val:1.0000 F1_val:0.810811 AUC_val:0.8374\n",
      "Epoch:0078\n",
      "acc_train:0.8414 pre_train:0.8827 recall_train:0.7995 F1_train:0.8390 AUC_train:0.9280\n",
      "acc_val:0.7528 pre_val:0.6716 recall_val:1.0000 F1_val:0.803571 AUC_val:0.8333\n",
      "Epoch:0079\n",
      "acc_train:0.8327 pre_train:0.8553 recall_train:0.8140 F1_train:0.8342 AUC_train:0.9192\n",
      "acc_val:0.7303 pre_val:0.6522 recall_val:1.0000 F1_val:0.789474 AUC_val:0.8197\n",
      "Epoch:0080\n",
      "acc_train:0.8327 pre_train:0.8665 recall_train:0.7995 F1_train:0.8317 AUC_train:0.9216\n",
      "acc_val:0.7303 pre_val:0.6522 recall_val:1.0000 F1_val:0.789474 AUC_val:0.8217\n",
      "Epoch:0081\n",
      "acc_train:0.8502 pre_train:0.8889 recall_train:0.8116 F1_train:0.8485 AUC_train:0.9301\n",
      "acc_val:0.7416 pre_val:0.6618 recall_val:1.0000 F1_val:0.796460 AUC_val:0.8626\n",
      "Epoch:0082\n",
      "acc_train:0.8614 pre_train:0.9062 recall_train:0.8164 F1_train:0.8590 AUC_train:0.9404\n",
      "acc_val:0.7753 pre_val:0.6923 recall_val:1.0000 F1_val:0.818182 AUC_val:0.8899\n",
      "Epoch:0083\n",
      "acc_train:0.8664 pre_train:0.9072 recall_train:0.8261 F1_train:0.8647 AUC_train:0.9382\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.8904\n",
      "Epoch:0084\n",
      "acc_train:0.8777 pre_train:0.9136 recall_train:0.8430 F1_train:0.8769 AUC_train:0.9460\n",
      "acc_val:0.7753 pre_val:0.6984 recall_val:0.9778 F1_val:0.814815 AUC_val:0.8995\n",
      "Epoch:0085\n",
      "acc_train:0.8664 pre_train:0.9205 recall_train:0.8116 F1_train:0.8626 AUC_train:0.9379\n",
      "acc_val:0.7753 pre_val:0.6984 recall_val:0.9778 F1_val:0.814815 AUC_val:0.9056\n",
      "Epoch:0086\n",
      "acc_train:0.8639 pre_train:0.9248 recall_train:0.8019 F1_train:0.8590 AUC_train:0.9450\n",
      "acc_val:0.7978 pre_val:0.7143 recall_val:1.0000 F1_val:0.833333 AUC_val:0.8944\n",
      "Epoch:0087\n",
      "acc_train:0.8801 pre_train:0.9368 recall_train:0.8237 F1_train:0.8766 AUC_train:0.9514\n",
      "acc_val:0.7528 pre_val:0.6716 recall_val:1.0000 F1_val:0.803571 AUC_val:0.8874\n",
      "Epoch:0088\n",
      "acc_train:0.8689 pre_train:0.9304 recall_train:0.8068 F1_train:0.8642 AUC_train:0.9482\n",
      "acc_val:0.7753 pre_val:0.6923 recall_val:1.0000 F1_val:0.818182 AUC_val:0.8874\n",
      "Epoch:0089\n",
      "acc_train:0.8727 pre_train:0.9699 recall_train:0.7778 F1_train:0.8633 AUC_train:0.9625\n",
      "acc_val:0.7753 pre_val:0.6923 recall_val:1.0000 F1_val:0.818182 AUC_val:0.8823\n",
      "Epoch:0090\n",
      "acc_train:0.8714 pre_train:0.9307 recall_train:0.8116 F1_train:0.8671 AUC_train:0.9501\n",
      "acc_val:0.7753 pre_val:0.6984 recall_val:0.9778 F1_val:0.814815 AUC_val:0.8783\n",
      "Epoch:0091\n",
      "acc_train:0.8777 pre_train:0.9489 recall_train:0.8068 F1_train:0.8721 AUC_train:0.9585\n",
      "acc_val:0.7865 pre_val:0.7097 recall_val:0.9778 F1_val:0.822430 AUC_val:0.8803\n",
      "Epoch:0092\n",
      "acc_train:0.8876 pre_train:0.9551 recall_train:0.8213 F1_train:0.8831 AUC_train:0.9532\n",
      "acc_val:0.7865 pre_val:0.7031 recall_val:1.0000 F1_val:0.825688 AUC_val:0.8813\n",
      "Epoch:0093\n",
      "acc_train:0.8939 pre_train:0.9482 recall_train:0.8406 F1_train:0.8912 AUC_train:0.9620\n",
      "acc_val:0.7978 pre_val:0.7143 recall_val:1.0000 F1_val:0.833333 AUC_val:0.8879\n",
      "Epoch:0094\n",
      "acc_train:0.9001 pre_train:0.9489 recall_train:0.8527 F1_train:0.8982 AUC_train:0.9687\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.8939\n",
      "Epoch:0095\n",
      "acc_train:0.9026 pre_train:0.9590 recall_train:0.8478 F1_train:0.9000 AUC_train:0.9698\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.8970\n",
      "Epoch:0096\n",
      "acc_train:0.9189 pre_train:0.9678 recall_train:0.8720 F1_train:0.9174 AUC_train:0.9737\n",
      "acc_val:0.7753 pre_val:0.7049 recall_val:0.9556 F1_val:0.811321 AUC_val:0.8949\n",
      "Epoch:0097\n",
      "acc_train:0.9089 pre_train:0.9547 recall_train:0.8647 F1_train:0.9075 AUC_train:0.9647\n",
      "acc_val:0.7640 pre_val:0.6935 recall_val:0.9556 F1_val:0.803738 AUC_val:0.8914\n",
      "Epoch:0098\n",
      "acc_train:0.8976 pre_train:0.9323 recall_train:0.8647 F1_train:0.8972 AUC_train:0.9626\n",
      "acc_val:0.7640 pre_val:0.6935 recall_val:0.9556 F1_val:0.803738 AUC_val:0.8843\n",
      "Epoch:0099\n",
      "acc_train:0.9064 pre_train:0.9669 recall_train:0.8478 F1_train:0.9035 AUC_train:0.9741\n",
      "acc_val:0.7978 pre_val:0.7288 recall_val:0.9556 F1_val:0.826923 AUC_val:0.8949\n",
      "Epoch:0100\n",
      "acc_train:0.9213 pre_train:0.9535 recall_train:0.8913 F1_train:0.9213 AUC_train:0.9737\n",
      "acc_val:0.8202 pre_val:0.7843 recall_val:0.8889 F1_val:0.833333 AUC_val:0.9121\n",
      "Epoch:0101\n",
      "acc_train:0.9263 pre_train:0.9517 recall_train:0.9034 F1_train:0.9269 AUC_train:0.9746\n",
      "acc_val:0.7978 pre_val:0.7547 recall_val:0.8889 F1_val:0.816327 AUC_val:0.9126\n",
      "Epoch:0102\n",
      "acc_train:0.9363 pre_train:0.9714 recall_train:0.9034 F1_train:0.9362 AUC_train:0.9810\n",
      "acc_val:0.8427 pre_val:0.8163 recall_val:0.8889 F1_val:0.851064 AUC_val:0.8995\n",
      "Epoch:0103\n",
      "acc_train:0.9251 pre_train:0.9733 recall_train:0.8792 F1_train:0.9239 AUC_train:0.9762\n",
      "acc_val:0.8427 pre_val:0.8039 recall_val:0.9111 F1_val:0.854167 AUC_val:0.8823\n",
      "Epoch:0104\n",
      "acc_train:0.9039 pre_train:0.9591 recall_train:0.8502 F1_train:0.9014 AUC_train:0.9682\n",
      "acc_val:0.8539 pre_val:0.8333 recall_val:0.8889 F1_val:0.860215 AUC_val:0.8879\n",
      "Epoch:0105\n",
      "acc_train:0.9263 pre_train:0.9659 recall_train:0.8889 F1_train:0.9258 AUC_train:0.9801\n",
      "acc_val:0.8202 pre_val:0.8222 recall_val:0.8222 F1_val:0.822222 AUC_val:0.8965\n",
      "Epoch:0106\n",
      "acc_train:0.9276 pre_train:0.9811 recall_train:0.8768 F1_train:0.9260 AUC_train:0.9842\n",
      "acc_val:0.8315 pre_val:0.8750 recall_val:0.7778 F1_val:0.823529 AUC_val:0.8904\n",
      "Epoch:0107\n",
      "acc_train:0.9176 pre_train:0.9677 recall_train:0.8696 F1_train:0.9160 AUC_train:0.9748\n",
      "acc_val:0.8427 pre_val:0.8974 recall_val:0.7778 F1_val:0.833333 AUC_val:0.8869\n",
      "Epoch:0108\n",
      "acc_train:0.9301 pre_train:0.9735 recall_train:0.8889 F1_train:0.9293 AUC_train:0.9807\n",
      "acc_val:0.8315 pre_val:0.8947 recall_val:0.7556 F1_val:0.819277 AUC_val:0.8949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0109\n",
      "acc_train:0.9238 pre_train:0.9732 recall_train:0.8768 F1_train:0.9225 AUC_train:0.9802\n",
      "acc_val:0.8315 pre_val:0.9167 recall_val:0.7333 F1_val:0.814815 AUC_val:0.8980\n",
      "Epoch:0110\n",
      "acc_train:0.9338 pre_train:0.9664 recall_train:0.9034 F1_train:0.9338 AUC_train:0.9833\n",
      "acc_val:0.7978 pre_val:0.8462 recall_val:0.7333 F1_val:0.785714 AUC_val:0.8939\n",
      "Epoch:0111\n",
      "acc_train:0.9401 pre_train:0.9816 recall_train:0.9010 F1_train:0.9395 AUC_train:0.9865\n",
      "acc_val:0.8090 pre_val:0.8500 recall_val:0.7556 F1_val:0.800000 AUC_val:0.8909\n",
      "Epoch:0112\n",
      "acc_train:0.9338 pre_train:0.9664 recall_train:0.9034 F1_train:0.9338 AUC_train:0.9793\n",
      "acc_val:0.8090 pre_val:0.8500 recall_val:0.7556 F1_val:0.800000 AUC_val:0.8859\n",
      "Epoch:0113\n",
      "acc_train:0.9426 pre_train:0.9742 recall_train:0.9130 F1_train:0.9426 AUC_train:0.9874\n",
      "acc_val:0.7865 pre_val:0.8095 recall_val:0.7556 F1_val:0.781609 AUC_val:0.8778\n",
      "Epoch:0114\n",
      "acc_train:0.9351 pre_train:0.9689 recall_train:0.9034 F1_train:0.9350 AUC_train:0.9884\n",
      "acc_val:0.7865 pre_val:0.8095 recall_val:0.7556 F1_val:0.781609 AUC_val:0.8737\n",
      "Epoch:0115\n",
      "acc_train:0.9351 pre_train:0.9788 recall_train:0.8937 F1_train:0.9343 AUC_train:0.9892\n",
      "acc_val:0.7753 pre_val:0.7907 recall_val:0.7556 F1_val:0.772727 AUC_val:0.8768\n",
      "Epoch:0116\n",
      "acc_train:0.9563 pre_train:0.9749 recall_train:0.9396 F1_train:0.9569 AUC_train:0.9905\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8753\n",
      "Epoch:0117\n",
      "acc_train:0.9501 pre_train:0.9820 recall_train:0.9203 F1_train:0.9501 AUC_train:0.9912\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8808\n",
      "Epoch:0118\n",
      "acc_train:0.9426 pre_train:0.9742 recall_train:0.9130 F1_train:0.9426 AUC_train:0.9887\n",
      "acc_val:0.7753 pre_val:0.7907 recall_val:0.7556 F1_val:0.772727 AUC_val:0.8773\n",
      "Epoch:0119\n",
      "acc_train:0.9251 pre_train:0.9733 recall_train:0.8792 F1_train:0.9239 AUC_train:0.9836\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.8798\n",
      "Epoch:0120\n",
      "acc_train:0.9376 pre_train:0.9815 recall_train:0.8961 F1_train:0.9369 AUC_train:0.9883\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.8843\n",
      "Epoch:0121\n",
      "acc_train:0.9451 pre_train:0.9793 recall_train:0.9130 F1_train:0.9450 AUC_train:0.9882\n",
      "acc_val:0.7191 pre_val:0.8125 recall_val:0.5778 F1_val:0.675325 AUC_val:0.8914\n",
      "Epoch:0122\n",
      "acc_train:0.9426 pre_train:0.9694 recall_train:0.9179 F1_train:0.9429 AUC_train:0.9852\n",
      "acc_val:0.7191 pre_val:0.8333 recall_val:0.5556 F1_val:0.666667 AUC_val:0.8859\n",
      "Epoch:0123\n",
      "acc_train:0.9488 pre_train:0.9869 recall_train:0.9130 F1_train:0.9486 AUC_train:0.9900\n",
      "acc_val:0.7191 pre_val:0.8333 recall_val:0.5556 F1_val:0.666667 AUC_val:0.8808\n",
      "Epoch:0124\n",
      "acc_train:0.9526 pre_train:0.9796 recall_train:0.9275 F1_train:0.9529 AUC_train:0.9918\n",
      "acc_val:0.7079 pre_val:0.8276 recall_val:0.5333 F1_val:0.648649 AUC_val:0.8722\n",
      "Epoch:0125\n",
      "acc_train:0.9576 pre_train:0.9847 recall_train:0.9324 F1_train:0.9578 AUC_train:0.9891\n",
      "acc_val:0.7191 pre_val:0.8125 recall_val:0.5778 F1_val:0.675325 AUC_val:0.8682\n",
      "Epoch:0126\n",
      "acc_train:0.9451 pre_train:0.9818 recall_train:0.9106 F1_train:0.9449 AUC_train:0.9889\n",
      "acc_val:0.7303 pre_val:0.8182 recall_val:0.6000 F1_val:0.692308 AUC_val:0.8646\n",
      "Epoch:0127\n",
      "acc_train:0.9526 pre_train:0.9796 recall_train:0.9275 F1_train:0.9529 AUC_train:0.9925\n",
      "acc_val:0.7191 pre_val:0.7941 recall_val:0.6000 F1_val:0.683544 AUC_val:0.8697\n",
      "Epoch:0128\n",
      "acc_train:0.9513 pre_train:0.9896 recall_train:0.9155 F1_train:0.9511 AUC_train:0.9967\n",
      "acc_val:0.7191 pre_val:0.7941 recall_val:0.6000 F1_val:0.683544 AUC_val:0.8717\n",
      "Epoch:0129\n",
      "acc_train:0.9513 pre_train:0.9795 recall_train:0.9251 F1_train:0.9516 AUC_train:0.9914\n",
      "acc_val:0.6966 pre_val:0.7500 recall_val:0.6000 F1_val:0.666667 AUC_val:0.8697\n",
      "Epoch:0130\n",
      "acc_train:0.9588 pre_train:0.9872 recall_train:0.9324 F1_train:0.9590 AUC_train:0.9942\n",
      "acc_val:0.7303 pre_val:0.7838 recall_val:0.6444 F1_val:0.707317 AUC_val:0.8697\n",
      "Epoch:0131\n",
      "acc_train:0.9526 pre_train:0.9631 recall_train:0.9444 F1_train:0.9537 AUC_train:0.9873\n",
      "acc_val:0.7079 pre_val:0.7568 recall_val:0.6222 F1_val:0.682927 AUC_val:0.8682\n",
      "Epoch:0132\n",
      "acc_train:0.9501 pre_train:0.9820 recall_train:0.9203 F1_train:0.9501 AUC_train:0.9927\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.8707\n",
      "Epoch:0133\n",
      "acc_train:0.9563 pre_train:0.9773 recall_train:0.9372 F1_train:0.9568 AUC_train:0.9946\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.8783\n",
      "Epoch:0134\n",
      "acc_train:0.9501 pre_train:0.9698 recall_train:0.9324 F1_train:0.9507 AUC_train:0.9925\n",
      "acc_val:0.7640 pre_val:0.8333 recall_val:0.6667 F1_val:0.740741 AUC_val:0.8884\n",
      "Epoch:0135\n",
      "acc_train:0.9476 pre_train:0.9697 recall_train:0.9275 F1_train:0.9481 AUC_train:0.9913\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.8985\n",
      "Epoch:0136\n",
      "acc_train:0.9638 pre_train:0.9777 recall_train:0.9517 F1_train:0.9645 AUC_train:0.9925\n",
      "acc_val:0.7528 pre_val:0.8485 recall_val:0.6222 F1_val:0.717949 AUC_val:0.9061\n",
      "Epoch:0137\n",
      "acc_train:0.9563 pre_train:0.9822 recall_train:0.9324 F1_train:0.9566 AUC_train:0.9922\n",
      "acc_val:0.7528 pre_val:0.8966 recall_val:0.5778 F1_val:0.702703 AUC_val:0.9116\n",
      "Epoch:0138\n",
      "acc_train:0.9501 pre_train:0.9795 recall_train:0.9227 F1_train:0.9502 AUC_train:0.9952\n",
      "acc_val:0.7528 pre_val:0.8966 recall_val:0.5778 F1_val:0.702703 AUC_val:0.9141\n",
      "Epoch:0139\n",
      "acc_train:0.9688 pre_train:0.9802 recall_train:0.9589 F1_train:0.9695 AUC_train:0.9893\n",
      "acc_val:0.7528 pre_val:0.8966 recall_val:0.5778 F1_val:0.702703 AUC_val:0.9172\n",
      "Epoch:0140\n",
      "acc_train:0.9650 pre_train:0.9801 recall_train:0.9517 F1_train:0.9657 AUC_train:0.9942\n",
      "acc_val:0.7528 pre_val:0.8966 recall_val:0.5778 F1_val:0.702703 AUC_val:0.9162\n",
      "Early Stopping!!! epoch：139\n",
      " Starting the 4-4 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.5206 pre_train:0.5852 recall_train:0.2488 F1_train:0.3492 AUC_train:0.5417\n",
      "acc_val:0.5281 pre_val:0.5254 recall_val:0.6889 F1_val:0.596154 AUC_val:0.5343\n",
      "Epoch:0002\n",
      "acc_train:0.5243 pre_train:0.5805 recall_train:0.2874 F1_train:0.3845 AUC_train:0.5670\n",
      "acc_val:0.5393 pre_val:0.5400 recall_val:0.6000 F1_val:0.568421 AUC_val:0.5495\n",
      "Epoch:0003\n",
      "acc_train:0.5331 pre_train:0.6020 recall_train:0.2850 F1_train:0.3869 AUC_train:0.5367\n",
      "acc_val:0.5506 pre_val:0.5610 recall_val:0.5111 F1_val:0.534884 AUC_val:0.5813\n",
      "Epoch:0004\n",
      "acc_train:0.5381 pre_train:0.6196 recall_train:0.2754 F1_train:0.3813 AUC_train:0.5377\n",
      "acc_val:0.5506 pre_val:0.5581 recall_val:0.5333 F1_val:0.545455 AUC_val:0.5803\n",
      "Epoch:0005\n",
      "acc_train:0.5056 pre_train:0.5256 recall_train:0.4469 F1_train:0.4830 AUC_train:0.5069\n",
      "acc_val:0.5843 pre_val:0.5741 recall_val:0.6889 F1_val:0.626263 AUC_val:0.5793\n",
      "Epoch:0006\n",
      "acc_train:0.5094 pre_train:0.5310 recall_train:0.4348 F1_train:0.4781 AUC_train:0.5037\n",
      "acc_val:0.5730 pre_val:0.5593 recall_val:0.7333 F1_val:0.634615 AUC_val:0.5843\n",
      "Epoch:0007\n",
      "acc_train:0.5605 pre_train:0.5598 recall_train:0.7005 F1_train:0.6223 AUC_train:0.5625\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.5899\n",
      "Epoch:0008\n",
      "acc_train:0.4981 pre_train:0.5128 recall_train:0.5797 F1_train:0.5442 AUC_train:0.5135\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6020\n",
      "Epoch:0009\n",
      "acc_train:0.4806 pre_train:0.4982 recall_train:0.6787 F1_train:0.5746 AUC_train:0.4917\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6192\n",
      "Epoch:0010\n",
      "acc_train:0.5144 pre_train:0.5251 recall_train:0.6329 F1_train:0.5739 AUC_train:0.5341\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6162\n",
      "Epoch:0011\n",
      "acc_train:0.4844 pre_train:0.5009 recall_train:0.6618 F1_train:0.5702 AUC_train:0.4894\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6465\n",
      "Epoch:0012\n",
      "acc_train:0.5730 pre_train:0.5865 recall_train:0.5894 F1_train:0.5880 AUC_train:0.6033\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6444\n",
      "Epoch:0013\n",
      "acc_train:0.4856 pre_train:0.5019 recall_train:0.6522 F1_train:0.5672 AUC_train:0.5164\n",
      "acc_val:0.5393 pre_val:0.5233 recall_val:1.0000 F1_val:0.687023 AUC_val:0.6288\n",
      "Epoch:0014\n",
      "acc_train:0.5368 pre_train:0.5567 recall_train:0.5097 F1_train:0.5322 AUC_train:0.5565\n",
      "acc_val:0.5618 pre_val:0.5500 recall_val:0.7333 F1_val:0.628571 AUC_val:0.6126\n",
      "Epoch:0015\n",
      "acc_train:0.4757 pre_train:0.4949 recall_train:0.7077 F1_train:0.5825 AUC_train:0.4957\n",
      "acc_val:0.5730 pre_val:0.5593 recall_val:0.7333 F1_val:0.634615 AUC_val:0.6169\n",
      "Epoch:0016\n",
      "acc_train:0.4794 pre_train:0.4976 recall_train:0.7391 F1_train:0.5948 AUC_train:0.5132\n",
      "acc_val:0.5618 pre_val:0.5441 recall_val:0.8222 F1_val:0.654867 AUC_val:0.6313\n",
      "Epoch:0017\n",
      "acc_train:0.5393 pre_train:0.5421 recall_train:0.7005 F1_train:0.6112 AUC_train:0.5583\n",
      "acc_val:0.5169 pre_val:0.5139 recall_val:0.8222 F1_val:0.632479 AUC_val:0.6591\n",
      "Epoch:0018\n",
      "acc_train:0.4981 pre_train:0.5091 recall_train:0.8068 F1_train:0.6243 AUC_train:0.5224\n",
      "acc_val:0.5281 pre_val:0.5190 recall_val:0.9111 F1_val:0.661290 AUC_val:0.6465\n",
      "Epoch:0019\n",
      "acc_train:0.5443 pre_train:0.5536 recall_train:0.6111 F1_train:0.5809 AUC_train:0.5455\n",
      "acc_val:0.5955 pre_val:0.5818 recall_val:0.7111 F1_val:0.640000 AUC_val:0.6374\n",
      "Epoch:0020\n",
      "acc_train:0.5668 pre_train:0.5691 recall_train:0.6667 F1_train:0.6140 AUC_train:0.6017\n",
      "acc_val:0.5955 pre_val:0.5849 recall_val:0.6889 F1_val:0.632653 AUC_val:0.6424\n",
      "Epoch:0021\n",
      "acc_train:0.5431 pre_train:0.5609 recall_train:0.5338 F1_train:0.5470 AUC_train:0.5508\n",
      "acc_val:0.5955 pre_val:0.5918 recall_val:0.6444 F1_val:0.617021 AUC_val:0.6414\n",
      "Epoch:0022\n",
      "acc_train:0.5805 pre_train:0.6266 recall_train:0.4662 F1_train:0.5346 AUC_train:0.6037\n",
      "acc_val:0.5393 pre_val:0.5455 recall_val:0.5333 F1_val:0.539326 AUC_val:0.6359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0023\n",
      "acc_train:0.5843 pre_train:0.5879 recall_train:0.6546 F1_train:0.6194 AUC_train:0.6265\n",
      "acc_val:0.5618 pre_val:0.5750 recall_val:0.5111 F1_val:0.541176 AUC_val:0.6338\n",
      "Epoch:0024\n",
      "acc_train:0.5730 pre_train:0.6154 recall_train:0.4638 F1_train:0.5289 AUC_train:0.5804\n",
      "acc_val:0.5730 pre_val:0.5897 recall_val:0.5111 F1_val:0.547619 AUC_val:0.6303\n",
      "Epoch:0025\n",
      "acc_train:0.5705 pre_train:0.5978 recall_train:0.5169 F1_train:0.5544 AUC_train:0.5864\n",
      "acc_val:0.5618 pre_val:0.5882 recall_val:0.4444 F1_val:0.506329 AUC_val:0.6323\n",
      "Epoch:0026\n",
      "acc_train:0.5805 pre_train:0.5871 recall_train:0.6353 F1_train:0.6102 AUC_train:0.6114\n",
      "acc_val:0.5618 pre_val:0.5882 recall_val:0.4444 F1_val:0.506329 AUC_val:0.6389\n",
      "Epoch:0027\n",
      "acc_train:0.5893 pre_train:0.6332 recall_train:0.4879 F1_train:0.5512 AUC_train:0.6138\n",
      "acc_val:0.5730 pre_val:0.6061 recall_val:0.4444 F1_val:0.512821 AUC_val:0.6424\n",
      "Epoch:0028\n",
      "acc_train:0.5668 pre_train:0.6091 recall_train:0.4517 F1_train:0.5187 AUC_train:0.6047\n",
      "acc_val:0.5730 pre_val:0.6061 recall_val:0.4444 F1_val:0.512821 AUC_val:0.6475\n",
      "Epoch:0029\n",
      "acc_train:0.5668 pre_train:0.5861 recall_train:0.5507 F1_train:0.5679 AUC_train:0.6006\n",
      "acc_val:0.5843 pre_val:0.6250 recall_val:0.4444 F1_val:0.519481 AUC_val:0.6485\n",
      "Epoch:0030\n",
      "acc_train:0.6080 pre_train:0.6656 recall_train:0.4855 F1_train:0.5615 AUC_train:0.6447\n",
      "acc_val:0.5955 pre_val:0.6552 recall_val:0.4222 F1_val:0.513514 AUC_val:0.6465\n",
      "Epoch:0031\n",
      "acc_train:0.6167 pre_train:0.6466 recall_train:0.5700 F1_train:0.6059 AUC_train:0.6442\n",
      "acc_val:0.6292 pre_val:0.7308 recall_val:0.4222 F1_val:0.535211 AUC_val:0.6495\n",
      "Epoch:0032\n",
      "acc_train:0.6230 pre_train:0.6538 recall_train:0.5749 F1_train:0.6118 AUC_train:0.6727\n",
      "acc_val:0.6067 pre_val:0.6923 recall_val:0.4000 F1_val:0.507042 AUC_val:0.6571\n",
      "Epoch:0033\n",
      "acc_train:0.6242 pre_train:0.6738 recall_train:0.5290 F1_train:0.5927 AUC_train:0.6650\n",
      "acc_val:0.5955 pre_val:0.6552 recall_val:0.4222 F1_val:0.513514 AUC_val:0.6631\n",
      "Epoch:0034\n",
      "acc_train:0.6617 pre_train:0.7037 recall_train:0.5966 F1_train:0.6458 AUC_train:0.7016\n",
      "acc_val:0.5843 pre_val:0.6333 recall_val:0.4222 F1_val:0.506667 AUC_val:0.6646\n",
      "Epoch:0035\n",
      "acc_train:0.6380 pre_train:0.6856 recall_train:0.5531 F1_train:0.6123 AUC_train:0.6866\n",
      "acc_val:0.5843 pre_val:0.6176 recall_val:0.4667 F1_val:0.531646 AUC_val:0.6596\n",
      "Epoch:0036\n",
      "acc_train:0.6567 pre_train:0.6991 recall_train:0.5894 F1_train:0.6396 AUC_train:0.6761\n",
      "acc_val:0.5955 pre_val:0.6286 recall_val:0.4889 F1_val:0.550000 AUC_val:0.6520\n",
      "Epoch:0037\n",
      "acc_train:0.6767 pre_train:0.7399 recall_train:0.5773 F1_train:0.6486 AUC_train:0.7481\n",
      "acc_val:0.5843 pre_val:0.6111 recall_val:0.4889 F1_val:0.543210 AUC_val:0.6495\n",
      "Epoch:0038\n",
      "acc_train:0.6891 pre_train:0.7350 recall_train:0.6232 F1_train:0.6745 AUC_train:0.7371\n",
      "acc_val:0.5843 pre_val:0.6053 recall_val:0.5111 F1_val:0.554217 AUC_val:0.6561\n",
      "Epoch:0039\n",
      "acc_train:0.6617 pre_train:0.7187 recall_train:0.5676 F1_train:0.6343 AUC_train:0.7096\n",
      "acc_val:0.5955 pre_val:0.6216 recall_val:0.5111 F1_val:0.560976 AUC_val:0.6646\n",
      "Epoch:0040\n",
      "acc_train:0.6567 pre_train:0.7087 recall_train:0.5700 F1_train:0.6319 AUC_train:0.7190\n",
      "acc_val:0.6292 pre_val:0.6875 recall_val:0.4889 F1_val:0.571429 AUC_val:0.6909\n",
      "Epoch:0041\n",
      "acc_train:0.7066 pre_train:0.7720 recall_train:0.6135 F1_train:0.6837 AUC_train:0.7761\n",
      "acc_val:0.6292 pre_val:0.6875 recall_val:0.4889 F1_val:0.571429 AUC_val:0.7288\n",
      "Epoch:0042\n",
      "acc_train:0.7129 pre_train:0.7949 recall_train:0.5990 F1_train:0.6832 AUC_train:0.7916\n",
      "acc_val:0.6404 pre_val:0.7097 recall_val:0.4889 F1_val:0.578947 AUC_val:0.7480\n",
      "Epoch:0043\n",
      "acc_train:0.7129 pre_train:0.8007 recall_train:0.5918 F1_train:0.6806 AUC_train:0.7938\n",
      "acc_val:0.6404 pre_val:0.7097 recall_val:0.4889 F1_val:0.578947 AUC_val:0.7566\n",
      "Epoch:0044\n",
      "acc_train:0.7216 pre_train:0.8215 recall_train:0.5894 F1_train:0.6864 AUC_train:0.8067\n",
      "acc_val:0.6517 pre_val:0.7188 recall_val:0.5111 F1_val:0.597403 AUC_val:0.7621\n",
      "Epoch:0045\n",
      "acc_train:0.7278 pre_train:0.8427 recall_train:0.5821 F1_train:0.6886 AUC_train:0.8358\n",
      "acc_val:0.6854 pre_val:0.7576 recall_val:0.5556 F1_val:0.641026 AUC_val:0.7717\n",
      "Epoch:0046\n",
      "acc_train:0.7378 pre_train:0.8566 recall_train:0.5918 F1_train:0.7000 AUC_train:0.8350\n",
      "acc_val:0.6854 pre_val:0.7429 recall_val:0.5778 F1_val:0.650000 AUC_val:0.7864\n",
      "Epoch:0047\n",
      "acc_train:0.7566 pre_train:0.8869 recall_train:0.6063 F1_train:0.7202 AUC_train:0.8621\n",
      "acc_val:0.6966 pre_val:0.7500 recall_val:0.6000 F1_val:0.666667 AUC_val:0.7889\n",
      "Epoch:0048\n",
      "acc_train:0.7815 pre_train:0.8746 recall_train:0.6739 F1_train:0.7613 AUC_train:0.8811\n",
      "acc_val:0.7303 pre_val:0.7561 recall_val:0.6889 F1_val:0.720930 AUC_val:0.8035\n",
      "Epoch:0049\n",
      "acc_train:0.7840 pre_train:0.8825 recall_train:0.6715 F1_train:0.7627 AUC_train:0.8775\n",
      "acc_val:0.7416 pre_val:0.7391 recall_val:0.7556 F1_val:0.747253 AUC_val:0.8111\n",
      "Epoch:0050\n",
      "acc_train:0.7928 pre_train:0.8924 recall_train:0.6812 F1_train:0.7726 AUC_train:0.8705\n",
      "acc_val:0.7191 pre_val:0.7083 recall_val:0.7556 F1_val:0.731183 AUC_val:0.7939\n",
      "Epoch:0051\n",
      "acc_train:0.7890 pre_train:0.8592 recall_train:0.7077 F1_train:0.7762 AUC_train:0.8531\n",
      "acc_val:0.7191 pre_val:0.7083 recall_val:0.7556 F1_val:0.731183 AUC_val:0.7990\n",
      "Epoch:0052\n",
      "acc_train:0.7978 pre_train:0.8818 recall_train:0.7029 F1_train:0.7823 AUC_train:0.8812\n",
      "acc_val:0.7528 pre_val:0.7447 recall_val:0.7778 F1_val:0.760870 AUC_val:0.8167\n",
      "Epoch:0053\n",
      "acc_train:0.8015 pre_train:0.8653 recall_train:0.7295 F1_train:0.7916 AUC_train:0.8835\n",
      "acc_val:0.7640 pre_val:0.7609 recall_val:0.7778 F1_val:0.769231 AUC_val:0.8424\n",
      "Epoch:0054\n",
      "acc_train:0.8102 pre_train:0.8922 recall_train:0.7198 F1_train:0.7968 AUC_train:0.9019\n",
      "acc_val:0.7640 pre_val:0.8000 recall_val:0.7111 F1_val:0.752941 AUC_val:0.8677\n",
      "Epoch:0055\n",
      "acc_train:0.8190 pre_train:0.9088 recall_train:0.7222 F1_train:0.8048 AUC_train:0.9148\n",
      "acc_val:0.7865 pre_val:0.8250 recall_val:0.7333 F1_val:0.776471 AUC_val:0.8783\n",
      "Epoch:0056\n",
      "acc_train:0.8127 pre_train:0.9286 recall_train:0.6908 F1_train:0.7922 AUC_train:0.9130\n",
      "acc_val:0.7753 pre_val:0.8205 recall_val:0.7111 F1_val:0.761905 AUC_val:0.8813\n",
      "Epoch:0057\n",
      "acc_train:0.8390 pre_train:0.9412 recall_train:0.7343 F1_train:0.8250 AUC_train:0.9308\n",
      "acc_val:0.7865 pre_val:0.8250 recall_val:0.7333 F1_val:0.776471 AUC_val:0.8793\n",
      "Epoch:0058\n",
      "acc_train:0.8564 pre_train:0.9410 recall_train:0.7705 F1_train:0.8473 AUC_train:0.9389\n",
      "acc_val:0.7865 pre_val:0.8250 recall_val:0.7333 F1_val:0.776471 AUC_val:0.8687\n",
      "Epoch:0059\n",
      "acc_train:0.8652 pre_train:0.9474 recall_train:0.7826 F1_train:0.8571 AUC_train:0.9478\n",
      "acc_val:0.7416 pre_val:0.7619 recall_val:0.7111 F1_val:0.735632 AUC_val:0.8631\n",
      "Epoch:0060\n",
      "acc_train:0.8564 pre_train:0.9333 recall_train:0.7778 F1_train:0.8485 AUC_train:0.9491\n",
      "acc_val:0.7416 pre_val:0.7619 recall_val:0.7111 F1_val:0.735632 AUC_val:0.8641\n",
      "Epoch:0061\n",
      "acc_train:0.8489 pre_train:0.9453 recall_train:0.7512 F1_train:0.8371 AUC_train:0.9434\n",
      "acc_val:0.7528 pre_val:0.7805 recall_val:0.7111 F1_val:0.744186 AUC_val:0.8631\n",
      "Epoch:0062\n",
      "acc_train:0.8752 pre_train:0.9564 recall_train:0.7947 F1_train:0.8681 AUC_train:0.9607\n",
      "acc_val:0.7303 pre_val:0.7692 recall_val:0.6667 F1_val:0.714286 AUC_val:0.8677\n",
      "Epoch:0063\n",
      "acc_train:0.8577 pre_train:0.9213 recall_train:0.7923 F1_train:0.8519 AUC_train:0.9449\n",
      "acc_val:0.7416 pre_val:0.7750 recall_val:0.6889 F1_val:0.729412 AUC_val:0.8763\n",
      "Epoch:0064\n",
      "acc_train:0.8777 pre_train:0.9593 recall_train:0.7971 F1_train:0.8707 AUC_train:0.9573\n",
      "acc_val:0.7416 pre_val:0.7750 recall_val:0.6889 F1_val:0.729412 AUC_val:0.8778\n",
      "Epoch:0065\n",
      "acc_train:0.8876 pre_train:0.9655 recall_train:0.8116 F1_train:0.8819 AUC_train:0.9615\n",
      "acc_val:0.7640 pre_val:0.7857 recall_val:0.7333 F1_val:0.758621 AUC_val:0.8768\n",
      "Epoch:0066\n",
      "acc_train:0.8876 pre_train:0.9602 recall_train:0.8164 F1_train:0.8825 AUC_train:0.9661\n",
      "acc_val:0.7865 pre_val:0.8095 recall_val:0.7556 F1_val:0.781609 AUC_val:0.8753\n",
      "Epoch:0067\n",
      "acc_train:0.8939 pre_train:0.9768 recall_train:0.8140 F1_train:0.8880 AUC_train:0.9688\n",
      "acc_val:0.7753 pre_val:0.7907 recall_val:0.7556 F1_val:0.772727 AUC_val:0.8672\n",
      "Epoch:0068\n",
      "acc_train:0.8739 pre_train:0.9433 recall_train:0.8043 F1_train:0.8683 AUC_train:0.9524\n",
      "acc_val:0.7753 pre_val:0.7907 recall_val:0.7556 F1_val:0.772727 AUC_val:0.8591\n",
      "Epoch:0069\n",
      "acc_train:0.8939 pre_train:0.9713 recall_train:0.8188 F1_train:0.8886 AUC_train:0.9639\n",
      "acc_val:0.7865 pre_val:0.7955 recall_val:0.7778 F1_val:0.786517 AUC_val:0.8576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0070\n",
      "acc_train:0.8889 pre_train:0.9656 recall_train:0.8140 F1_train:0.8834 AUC_train:0.9658\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8621\n",
      "Epoch:0071\n",
      "acc_train:0.8964 pre_train:0.9559 recall_train:0.8382 F1_train:0.8932 AUC_train:0.9626\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8652\n",
      "Epoch:0072\n",
      "acc_train:0.9164 pre_train:0.9806 recall_train:0.8551 F1_train:0.9135 AUC_train:0.9731\n",
      "acc_val:0.7753 pre_val:0.7778 recall_val:0.7778 F1_val:0.777778 AUC_val:0.8778\n",
      "Epoch:0073\n",
      "acc_train:0.9064 pre_train:0.9619 recall_train:0.8527 F1_train:0.9040 AUC_train:0.9691\n",
      "acc_val:0.7865 pre_val:0.7955 recall_val:0.7778 F1_val:0.786517 AUC_val:0.8808\n",
      "Epoch:0074\n",
      "acc_train:0.9226 pre_train:0.9889 recall_train:0.8599 F1_train:0.9199 AUC_train:0.9740\n",
      "acc_val:0.7640 pre_val:0.7609 recall_val:0.7778 F1_val:0.769231 AUC_val:0.8838\n",
      "Epoch:0075\n",
      "acc_train:0.9176 pre_train:0.9677 recall_train:0.8696 F1_train:0.9160 AUC_train:0.9756\n",
      "acc_val:0.7753 pre_val:0.7660 recall_val:0.8000 F1_val:0.782609 AUC_val:0.8838\n",
      "Epoch:0076\n",
      "acc_train:0.8914 pre_train:0.9685 recall_train:0.8164 F1_train:0.8860 AUC_train:0.9754\n",
      "acc_val:0.7640 pre_val:0.7500 recall_val:0.8000 F1_val:0.774194 AUC_val:0.8803\n",
      "Epoch:0077\n",
      "acc_train:0.9114 pre_train:0.9673 recall_train:0.8575 F1_train:0.9091 AUC_train:0.9745\n",
      "acc_val:0.7753 pre_val:0.7551 recall_val:0.8222 F1_val:0.787234 AUC_val:0.8773\n",
      "Epoch:0078\n",
      "acc_train:0.9164 pre_train:0.9702 recall_train:0.8647 F1_train:0.9144 AUC_train:0.9777\n",
      "acc_val:0.7865 pre_val:0.7600 recall_val:0.8444 F1_val:0.800000 AUC_val:0.8758\n",
      "Epoch:0079\n",
      "acc_train:0.9089 pre_train:0.9646 recall_train:0.8551 F1_train:0.9065 AUC_train:0.9761\n",
      "acc_val:0.7865 pre_val:0.7600 recall_val:0.8444 F1_val:0.800000 AUC_val:0.8768\n",
      "Epoch:0080\n",
      "acc_train:0.9089 pre_train:0.9571 recall_train:0.8623 F1_train:0.9072 AUC_train:0.9782\n",
      "acc_val:0.7753 pre_val:0.7551 recall_val:0.8222 F1_val:0.787234 AUC_val:0.8798\n",
      "Epoch:0081\n",
      "acc_train:0.9201 pre_train:0.9730 recall_train:0.8696 F1_train:0.9184 AUC_train:0.9827\n",
      "acc_val:0.7640 pre_val:0.7727 recall_val:0.7556 F1_val:0.764045 AUC_val:0.8848\n",
      "Epoch:0082\n",
      "acc_train:0.9413 pre_train:0.9693 recall_train:0.9155 F1_train:0.9416 AUC_train:0.9827\n",
      "acc_val:0.7865 pre_val:0.8250 recall_val:0.7333 F1_val:0.776471 AUC_val:0.8889\n",
      "Epoch:0083\n",
      "acc_train:0.9238 pre_train:0.9584 recall_train:0.8913 F1_train:0.9237 AUC_train:0.9761\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.8884\n",
      "Epoch:0084\n",
      "acc_train:0.9288 pre_train:0.9710 recall_train:0.8889 F1_train:0.9281 AUC_train:0.9823\n",
      "acc_val:0.7640 pre_val:0.8000 recall_val:0.7111 F1_val:0.752941 AUC_val:0.8869\n",
      "Epoch:0085\n",
      "acc_train:0.9526 pre_train:0.9796 recall_train:0.9275 F1_train:0.9529 AUC_train:0.9866\n",
      "acc_val:0.7640 pre_val:0.8000 recall_val:0.7111 F1_val:0.752941 AUC_val:0.8874\n",
      "Epoch:0086\n",
      "acc_train:0.9426 pre_train:0.9718 recall_train:0.9155 F1_train:0.9428 AUC_train:0.9883\n",
      "acc_val:0.7865 pre_val:0.8095 recall_val:0.7556 F1_val:0.781609 AUC_val:0.8859\n",
      "Epoch:0087\n",
      "acc_train:0.9313 pre_train:0.9662 recall_train:0.8986 F1_train:0.9312 AUC_train:0.9783\n",
      "acc_val:0.7978 pre_val:0.8000 recall_val:0.8000 F1_val:0.800000 AUC_val:0.8879\n",
      "Epoch:0088\n",
      "acc_train:0.9376 pre_train:0.9789 recall_train:0.8986 F1_train:0.9370 AUC_train:0.9849\n",
      "acc_val:0.7978 pre_val:0.7872 recall_val:0.8222 F1_val:0.804348 AUC_val:0.8899\n",
      "Epoch:0089\n",
      "acc_train:0.9301 pre_train:0.9590 recall_train:0.9034 F1_train:0.9303 AUC_train:0.9843\n",
      "acc_val:0.7865 pre_val:0.7826 recall_val:0.8000 F1_val:0.791209 AUC_val:0.8909\n",
      "Epoch:0090\n",
      "acc_train:0.9476 pre_train:0.9769 recall_train:0.9203 F1_train:0.9478 AUC_train:0.9878\n",
      "acc_val:0.7528 pre_val:0.7674 recall_val:0.7333 F1_val:0.750000 AUC_val:0.8934\n",
      "Epoch:0091\n",
      "acc_train:0.9413 pre_train:0.9646 recall_train:0.9203 F1_train:0.9419 AUC_train:0.9847\n",
      "acc_val:0.7528 pre_val:0.7805 recall_val:0.7111 F1_val:0.744186 AUC_val:0.8904\n",
      "Epoch:0092\n",
      "acc_train:0.9388 pre_train:0.9765 recall_train:0.9034 F1_train:0.9385 AUC_train:0.9859\n",
      "acc_val:0.7753 pre_val:0.8049 recall_val:0.7333 F1_val:0.767442 AUC_val:0.8864\n",
      "Epoch:0093\n",
      "acc_train:0.9426 pre_train:0.9718 recall_train:0.9155 F1_train:0.9428 AUC_train:0.9851\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8778\n",
      "Epoch:0094\n",
      "acc_train:0.9526 pre_train:0.9796 recall_train:0.9275 F1_train:0.9529 AUC_train:0.9911\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8722\n",
      "Epoch:0095\n",
      "acc_train:0.9388 pre_train:0.9841 recall_train:0.8961 F1_train:0.9381 AUC_train:0.9868\n",
      "acc_val:0.7416 pre_val:0.7500 recall_val:0.7333 F1_val:0.741573 AUC_val:0.8727\n",
      "Epoch:0096\n",
      "acc_train:0.9438 pre_train:0.9767 recall_train:0.9130 F1_train:0.9438 AUC_train:0.9860\n",
      "acc_val:0.7191 pre_val:0.7381 recall_val:0.6889 F1_val:0.712644 AUC_val:0.8783\n",
      "Epoch:0097\n",
      "acc_train:0.9538 pre_train:0.9796 recall_train:0.9300 F1_train:0.9542 AUC_train:0.9916\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.8823\n",
      "Epoch:0098\n",
      "acc_train:0.9563 pre_train:0.9797 recall_train:0.9348 F1_train:0.9567 AUC_train:0.9926\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.8793\n",
      "Epoch:0099\n",
      "acc_train:0.9650 pre_train:0.9849 recall_train:0.9469 F1_train:0.9655 AUC_train:0.9944\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.8798\n",
      "Epoch:0100\n",
      "acc_train:0.9463 pre_train:0.9720 recall_train:0.9227 F1_train:0.9467 AUC_train:0.9901\n",
      "acc_val:0.7416 pre_val:0.8056 recall_val:0.6444 F1_val:0.716049 AUC_val:0.8798\n",
      "Epoch:0101\n",
      "acc_train:0.9526 pre_train:0.9821 recall_train:0.9251 F1_train:0.9527 AUC_train:0.9898\n",
      "acc_val:0.7528 pre_val:0.8286 recall_val:0.6444 F1_val:0.725000 AUC_val:0.8808\n",
      "Epoch:0102\n",
      "acc_train:0.9576 pre_train:0.9726 recall_train:0.9444 F1_train:0.9583 AUC_train:0.9890\n",
      "acc_val:0.7528 pre_val:0.8286 recall_val:0.6444 F1_val:0.725000 AUC_val:0.8808\n",
      "Epoch:0103\n",
      "acc_train:0.9513 pre_train:0.9723 recall_train:0.9324 F1_train:0.9519 AUC_train:0.9914\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.8859\n",
      "Epoch:0104\n",
      "acc_train:0.9451 pre_train:0.9695 recall_train:0.9227 F1_train:0.9455 AUC_train:0.9899\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.8884\n",
      "Epoch:0105\n",
      "acc_train:0.9488 pre_train:0.9722 recall_train:0.9275 F1_train:0.9493 AUC_train:0.9926\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.8864\n",
      "Epoch:0106\n",
      "acc_train:0.9551 pre_train:0.9725 recall_train:0.9396 F1_train:0.9558 AUC_train:0.9929\n",
      "acc_val:0.7528 pre_val:0.8286 recall_val:0.6444 F1_val:0.725000 AUC_val:0.8838\n",
      "Epoch:0107\n",
      "acc_train:0.9613 pre_train:0.9898 recall_train:0.9348 F1_train:0.9615 AUC_train:0.9955\n",
      "acc_val:0.7528 pre_val:0.8108 recall_val:0.6667 F1_val:0.731707 AUC_val:0.8742\n",
      "Epoch:0108\n",
      "acc_train:0.9513 pre_train:0.9747 recall_train:0.9300 F1_train:0.9518 AUC_train:0.9922\n",
      "acc_val:0.7528 pre_val:0.7949 recall_val:0.6889 F1_val:0.738095 AUC_val:0.8758\n",
      "Epoch:0109\n",
      "acc_train:0.9563 pre_train:0.9847 recall_train:0.9300 F1_train:0.9565 AUC_train:0.9924\n",
      "acc_val:0.7416 pre_val:0.7750 recall_val:0.6889 F1_val:0.729412 AUC_val:0.8747\n",
      "Epoch:0110\n",
      "acc_train:0.9588 pre_train:0.9798 recall_train:0.9396 F1_train:0.9593 AUC_train:0.9927\n",
      "acc_val:0.7528 pre_val:0.7949 recall_val:0.6889 F1_val:0.738095 AUC_val:0.8778\n",
      "Early Stopping!!! epoch：109\n",
      " Starting the 4-5 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4732 pre_train:0.4855 recall_train:0.3237 F1_train:0.3884 AUC_train:0.4622\n",
      "acc_val:0.5056 pre_val:0.5063 recall_val:0.8889 F1_val:0.645161 AUC_val:0.5530\n",
      "Epoch:0002\n",
      "acc_train:0.5081 pre_train:0.5463 recall_train:0.2850 F1_train:0.3746 AUC_train:0.5125\n",
      "acc_val:0.5618 pre_val:0.5469 recall_val:0.7778 F1_val:0.642202 AUC_val:0.5702\n",
      "Epoch:0003\n",
      "acc_train:0.5268 pre_train:0.5862 recall_train:0.2874 F1_train:0.3857 AUC_train:0.5550\n",
      "acc_val:0.5618 pre_val:0.5484 recall_val:0.7556 F1_val:0.635514 AUC_val:0.6010\n",
      "Epoch:0004\n",
      "acc_train:0.5268 pre_train:0.5771 recall_train:0.3164 F1_train:0.4087 AUC_train:0.5525\n",
      "acc_val:0.5618 pre_val:0.5441 recall_val:0.8222 F1_val:0.654867 AUC_val:0.6086\n",
      "Epoch:0005\n",
      "acc_train:0.5381 pre_train:0.5853 recall_train:0.3647 F1_train:0.4494 AUC_train:0.5678\n",
      "acc_val:0.5730 pre_val:0.5507 recall_val:0.8444 F1_val:0.666667 AUC_val:0.6157\n",
      "Epoch:0006\n",
      "acc_train:0.4931 pre_train:0.5111 recall_train:0.4444 F1_train:0.4755 AUC_train:0.4744\n",
      "acc_val:0.5393 pre_val:0.5263 recall_val:0.8889 F1_val:0.661157 AUC_val:0.5944\n",
      "Epoch:0007\n",
      "acc_train:0.5256 pre_train:0.5649 recall_train:0.3575 F1_train:0.4379 AUC_train:0.5615\n",
      "acc_val:0.5393 pre_val:0.5244 recall_val:0.9556 F1_val:0.677165 AUC_val:0.6000\n",
      "Epoch:0008\n",
      "acc_train:0.5493 pre_train:0.5978 recall_train:0.3913 F1_train:0.4730 AUC_train:0.5736\n",
      "acc_val:0.5281 pre_val:0.5172 recall_val:1.0000 F1_val:0.681818 AUC_val:0.6121\n",
      "Epoch:0009\n",
      "acc_train:0.5506 pre_train:0.5839 recall_train:0.4541 F1_train:0.5109 AUC_train:0.5551\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6318\n",
      "Epoch:0010\n",
      "acc_train:0.5643 pre_train:0.6073 recall_train:0.4444 F1_train:0.5132 AUC_train:0.5804\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6263\n",
      "Epoch:0011\n",
      "acc_train:0.5331 pre_train:0.5592 recall_train:0.4565 F1_train:0.5027 AUC_train:0.5435\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6197\n",
      "Epoch:0012\n",
      "acc_train:0.5805 pre_train:0.6021 recall_train:0.5556 F1_train:0.5779 AUC_train:0.5886\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6227\n",
      "Epoch:0013\n",
      "acc_train:0.5343 pre_train:0.5565 recall_train:0.4879 F1_train:0.5199 AUC_train:0.5355\n",
      "acc_val:0.5056 pre_val:0.5056 recall_val:1.0000 F1_val:0.671642 AUC_val:0.6116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0014\n",
      "acc_train:0.5568 pre_train:0.5694 recall_train:0.5845 F1_train:0.5769 AUC_train:0.5756\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6343\n",
      "Epoch:0015\n",
      "acc_train:0.5056 pre_train:0.5143 recall_train:0.7802 F1_train:0.6200 AUC_train:0.5489\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6253\n",
      "Epoch:0016\n",
      "acc_train:0.5256 pre_train:0.5275 recall_train:0.7874 F1_train:0.6318 AUC_train:0.5524\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6157\n",
      "Epoch:0017\n",
      "acc_train:0.4881 pre_train:0.5029 recall_train:0.8430 F1_train:0.6300 AUC_train:0.5037\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6141\n",
      "Epoch:0018\n",
      "acc_train:0.5518 pre_train:0.5635 recall_train:0.5894 F1_train:0.5762 AUC_train:0.5513\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6172\n",
      "Epoch:0019\n",
      "acc_train:0.5194 pre_train:0.5226 recall_train:0.8116 F1_train:0.6358 AUC_train:0.5715\n",
      "acc_val:0.5169 pre_val:0.5114 recall_val:1.0000 F1_val:0.676692 AUC_val:0.6015\n",
      "Epoch:0020\n",
      "acc_train:0.5793 pre_train:0.5980 recall_train:0.5676 F1_train:0.5824 AUC_train:0.5981\n",
      "acc_val:0.5169 pre_val:0.5116 recall_val:0.9778 F1_val:0.671756 AUC_val:0.6152\n",
      "Epoch:0021\n",
      "acc_train:0.5468 pre_train:0.5680 recall_train:0.5145 F1_train:0.5399 AUC_train:0.5503\n",
      "acc_val:0.5955 pre_val:0.5692 recall_val:0.8222 F1_val:0.672727 AUC_val:0.5934\n",
      "Epoch:0022\n",
      "acc_train:0.5556 pre_train:0.5824 recall_train:0.4952 F1_train:0.5352 AUC_train:0.5722\n",
      "acc_val:0.5955 pre_val:0.5849 recall_val:0.6889 F1_val:0.632653 AUC_val:0.6066\n",
      "Epoch:0023\n",
      "acc_train:0.6017 pre_train:0.6444 recall_train:0.5121 F1_train:0.5707 AUC_train:0.6275\n",
      "acc_val:0.6067 pre_val:0.6087 recall_val:0.6222 F1_val:0.615385 AUC_val:0.6056\n",
      "Epoch:0024\n",
      "acc_train:0.5031 pre_train:0.5127 recall_train:0.7826 F1_train:0.6195 AUC_train:0.5511\n",
      "acc_val:0.6292 pre_val:0.6304 recall_val:0.6444 F1_val:0.637363 AUC_val:0.6182\n",
      "Epoch:0025\n",
      "acc_train:0.6142 pre_train:0.6829 recall_train:0.4734 F1_train:0.5592 AUC_train:0.6532\n",
      "acc_val:0.5843 pre_val:0.6111 recall_val:0.4889 F1_val:0.543210 AUC_val:0.6253\n",
      "Epoch:0026\n",
      "acc_train:0.5980 pre_train:0.6608 recall_train:0.4565 F1_train:0.5400 AUC_train:0.6142\n",
      "acc_val:0.5618 pre_val:0.5882 recall_val:0.4444 F1_val:0.506329 AUC_val:0.6298\n",
      "Epoch:0027\n",
      "acc_train:0.5768 pre_train:0.6206 recall_train:0.4662 F1_train:0.5324 AUC_train:0.6060\n",
      "acc_val:0.5506 pre_val:0.5806 recall_val:0.4000 F1_val:0.473684 AUC_val:0.6384\n",
      "Epoch:0028\n",
      "acc_train:0.5843 pre_train:0.6588 recall_train:0.4058 F1_train:0.5022 AUC_train:0.6376\n",
      "acc_val:0.5618 pre_val:0.6000 recall_val:0.4000 F1_val:0.480000 AUC_val:0.6263\n",
      "Epoch:0029\n",
      "acc_train:0.5868 pre_train:0.6722 recall_train:0.3913 F1_train:0.4947 AUC_train:0.6398\n",
      "acc_val:0.5618 pre_val:0.6250 recall_val:0.3333 F1_val:0.434783 AUC_val:0.6242\n",
      "Epoch:0030\n",
      "acc_train:0.5880 pre_train:0.6750 recall_train:0.3913 F1_train:0.4954 AUC_train:0.6331\n",
      "acc_val:0.5618 pre_val:0.6364 recall_val:0.3111 F1_val:0.417910 AUC_val:0.6359\n",
      "Epoch:0031\n",
      "acc_train:0.6030 pre_train:0.6818 recall_train:0.4348 F1_train:0.5310 AUC_train:0.6756\n",
      "acc_val:0.6180 pre_val:0.8235 recall_val:0.3111 F1_val:0.451613 AUC_val:0.7333\n",
      "Epoch:0032\n",
      "acc_train:0.5818 pre_train:0.6695 recall_train:0.3768 F1_train:0.4822 AUC_train:0.6427\n",
      "acc_val:0.6067 pre_val:0.7778 recall_val:0.3111 F1_val:0.444444 AUC_val:0.7333\n",
      "Epoch:0033\n",
      "acc_train:0.6105 pre_train:0.6848 recall_train:0.4565 F1_train:0.5478 AUC_train:0.6645\n",
      "acc_val:0.6067 pre_val:0.7500 recall_val:0.3333 F1_val:0.461538 AUC_val:0.7434\n",
      "Epoch:0034\n",
      "acc_train:0.6330 pre_train:0.6935 recall_train:0.5193 F1_train:0.5939 AUC_train:0.6696\n",
      "acc_val:0.6629 pre_val:0.8000 recall_val:0.4444 F1_val:0.571429 AUC_val:0.7460\n",
      "Epoch:0035\n",
      "acc_train:0.6305 pre_train:0.7138 recall_train:0.4758 F1_train:0.5710 AUC_train:0.6657\n",
      "acc_val:0.6629 pre_val:0.7586 recall_val:0.4889 F1_val:0.594595 AUC_val:0.7449\n",
      "Epoch:0036\n",
      "acc_train:0.6017 pre_train:0.6568 recall_train:0.4807 F1_train:0.5551 AUC_train:0.6722\n",
      "acc_val:0.6742 pre_val:0.7500 recall_val:0.5333 F1_val:0.623377 AUC_val:0.7354\n",
      "Epoch:0037\n",
      "acc_train:0.6380 pre_train:0.6802 recall_train:0.5652 F1_train:0.6174 AUC_train:0.6968\n",
      "acc_val:0.6629 pre_val:0.7273 recall_val:0.5333 F1_val:0.615385 AUC_val:0.7399\n",
      "Epoch:0038\n",
      "acc_train:0.6717 pre_train:0.7367 recall_train:0.5676 F1_train:0.6412 AUC_train:0.7479\n",
      "acc_val:0.6629 pre_val:0.7273 recall_val:0.5333 F1_val:0.615385 AUC_val:0.7465\n",
      "Epoch:0039\n",
      "acc_train:0.6442 pre_train:0.7115 recall_train:0.5242 F1_train:0.6036 AUC_train:0.7181\n",
      "acc_val:0.6742 pre_val:0.7500 recall_val:0.5333 F1_val:0.623377 AUC_val:0.7500\n",
      "Epoch:0040\n",
      "acc_train:0.6792 pre_train:0.7716 recall_train:0.5386 F1_train:0.6344 AUC_train:0.7603\n",
      "acc_val:0.6517 pre_val:0.7059 recall_val:0.5333 F1_val:0.607595 AUC_val:0.7500\n",
      "Epoch:0041\n",
      "acc_train:0.6866 pre_train:0.7726 recall_train:0.5580 F1_train:0.6480 AUC_train:0.7628\n",
      "acc_val:0.6629 pre_val:0.7027 recall_val:0.5778 F1_val:0.634146 AUC_val:0.7439\n",
      "Epoch:0042\n",
      "acc_train:0.6829 pre_train:0.7548 recall_train:0.5725 F1_train:0.6511 AUC_train:0.7447\n",
      "acc_val:0.6404 pre_val:0.6585 recall_val:0.6000 F1_val:0.627907 AUC_val:0.7364\n",
      "Epoch:0043\n",
      "acc_train:0.7054 pre_train:0.7799 recall_train:0.5990 F1_train:0.6776 AUC_train:0.7842\n",
      "acc_val:0.6517 pre_val:0.6667 recall_val:0.6222 F1_val:0.643678 AUC_val:0.7333\n",
      "Epoch:0044\n",
      "acc_train:0.7228 pre_train:0.8038 recall_train:0.6135 F1_train:0.6959 AUC_train:0.8029\n",
      "acc_val:0.6292 pre_val:0.6364 recall_val:0.6222 F1_val:0.629213 AUC_val:0.7273\n",
      "Epoch:0045\n",
      "acc_train:0.7054 pre_train:0.7747 recall_train:0.6063 F1_train:0.6802 AUC_train:0.7967\n",
      "acc_val:0.6404 pre_val:0.6444 recall_val:0.6444 F1_val:0.644444 AUC_val:0.7308\n",
      "Epoch:0046\n",
      "acc_train:0.7278 pre_train:0.7917 recall_train:0.6425 F1_train:0.7093 AUC_train:0.8155\n",
      "acc_val:0.6404 pre_val:0.6444 recall_val:0.6444 F1_val:0.644444 AUC_val:0.7318\n",
      "Epoch:0047\n",
      "acc_train:0.7566 pre_train:0.8411 recall_train:0.6522 F1_train:0.7347 AUC_train:0.8332\n",
      "acc_val:0.6404 pre_val:0.6444 recall_val:0.6444 F1_val:0.644444 AUC_val:0.7414\n",
      "Epoch:0048\n",
      "acc_train:0.7466 pre_train:0.8226 recall_train:0.6498 F1_train:0.7260 AUC_train:0.8331\n",
      "acc_val:0.6517 pre_val:0.6591 recall_val:0.6444 F1_val:0.651685 AUC_val:0.7571\n",
      "Epoch:0049\n",
      "acc_train:0.7753 pre_train:0.8482 recall_train:0.6884 F1_train:0.7600 AUC_train:0.8590\n",
      "acc_val:0.6629 pre_val:0.6744 recall_val:0.6444 F1_val:0.659091 AUC_val:0.7677\n",
      "Epoch:0050\n",
      "acc_train:0.7553 pre_train:0.8562 recall_train:0.6329 F1_train:0.7278 AUC_train:0.8687\n",
      "acc_val:0.6966 pre_val:0.7647 recall_val:0.5778 F1_val:0.658228 AUC_val:0.7879\n",
      "Epoch:0051\n",
      "acc_train:0.7853 pre_train:0.8954 recall_train:0.6618 F1_train:0.7611 AUC_train:0.8846\n",
      "acc_val:0.6854 pre_val:0.7576 recall_val:0.5556 F1_val:0.641026 AUC_val:0.8066\n",
      "Epoch:0052\n",
      "acc_train:0.7965 pre_train:0.9197 recall_train:0.6643 F1_train:0.7714 AUC_train:0.9088\n",
      "acc_val:0.7079 pre_val:0.8065 recall_val:0.5556 F1_val:0.657895 AUC_val:0.8182\n",
      "Epoch:0053\n",
      "acc_train:0.7890 pre_train:0.9329 recall_train:0.6377 F1_train:0.7575 AUC_train:0.9046\n",
      "acc_val:0.7191 pre_val:0.8333 recall_val:0.5556 F1_val:0.666667 AUC_val:0.8247\n",
      "Epoch:0054\n",
      "acc_train:0.8065 pre_train:0.9302 recall_train:0.6763 F1_train:0.7832 AUC_train:0.9192\n",
      "acc_val:0.7191 pre_val:0.8333 recall_val:0.5556 F1_val:0.666667 AUC_val:0.8217\n",
      "Epoch:0055\n",
      "acc_train:0.7990 pre_train:0.9175 recall_train:0.6715 F1_train:0.7755 AUC_train:0.9148\n",
      "acc_val:0.6854 pre_val:0.8148 recall_val:0.4889 F1_val:0.611111 AUC_val:0.8040\n",
      "Epoch:0056\n",
      "acc_train:0.7965 pre_train:0.9343 recall_train:0.6522 F1_train:0.7681 AUC_train:0.9157\n",
      "acc_val:0.6854 pre_val:0.7742 recall_val:0.5333 F1_val:0.631579 AUC_val:0.8000\n",
      "Epoch:0057\n",
      "acc_train:0.7965 pre_train:0.9088 recall_train:0.6739 F1_train:0.7739 AUC_train:0.9175\n",
      "acc_val:0.6629 pre_val:0.7586 recall_val:0.4889 F1_val:0.594595 AUC_val:0.8101\n",
      "Epoch:0058\n",
      "acc_train:0.8352 pre_train:0.9462 recall_train:0.7222 F1_train:0.8192 AUC_train:0.9157\n",
      "acc_val:0.6629 pre_val:0.7586 recall_val:0.4889 F1_val:0.594595 AUC_val:0.8061\n",
      "Epoch:0059\n",
      "acc_train:0.8390 pre_train:0.9553 recall_train:0.7222 F1_train:0.8226 AUC_train:0.9345\n",
      "acc_val:0.6854 pre_val:0.7931 recall_val:0.5111 F1_val:0.621622 AUC_val:0.8177\n",
      "Epoch:0060\n",
      "acc_train:0.8215 pre_train:0.9329 recall_train:0.7053 F1_train:0.8033 AUC_train:0.9245\n",
      "acc_val:0.7079 pre_val:0.8065 recall_val:0.5556 F1_val:0.657895 AUC_val:0.8374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0061\n",
      "acc_train:0.8365 pre_train:0.9408 recall_train:0.7295 F1_train:0.8218 AUC_train:0.9458\n",
      "acc_val:0.7416 pre_val:0.8235 recall_val:0.6222 F1_val:0.708861 AUC_val:0.8490\n",
      "Epoch:0062\n",
      "acc_train:0.8589 pre_train:0.9839 recall_train:0.7391 F1_train:0.8441 AUC_train:0.9633\n",
      "acc_val:0.7416 pre_val:0.8235 recall_val:0.6222 F1_val:0.708861 AUC_val:0.8515\n",
      "Epoch:0063\n",
      "acc_train:0.8714 pre_train:0.9560 recall_train:0.7874 F1_train:0.8636 AUC_train:0.9622\n",
      "acc_val:0.7416 pre_val:0.7895 recall_val:0.6667 F1_val:0.722892 AUC_val:0.8394\n",
      "Epoch:0064\n",
      "acc_train:0.8777 pre_train:0.9702 recall_train:0.7874 F1_train:0.8693 AUC_train:0.9660\n",
      "acc_val:0.7303 pre_val:0.7561 recall_val:0.6889 F1_val:0.720930 AUC_val:0.8268\n",
      "Epoch:0065\n",
      "acc_train:0.8814 pre_train:0.9570 recall_train:0.8068 F1_train:0.8755 AUC_train:0.9547\n",
      "acc_val:0.7416 pre_val:0.7500 recall_val:0.7333 F1_val:0.741573 AUC_val:0.8288\n",
      "Epoch:0066\n",
      "acc_train:0.8801 pre_train:0.9649 recall_train:0.7971 F1_train:0.8730 AUC_train:0.9600\n",
      "acc_val:0.7528 pre_val:0.7556 recall_val:0.7556 F1_val:0.755556 AUC_val:0.8338\n",
      "Epoch:0067\n",
      "acc_train:0.8964 pre_train:0.9742 recall_train:0.8213 F1_train:0.8912 AUC_train:0.9648\n",
      "acc_val:0.7640 pre_val:0.7857 recall_val:0.7333 F1_val:0.758621 AUC_val:0.8460\n",
      "Epoch:0068\n",
      "acc_train:0.8951 pre_train:0.9769 recall_train:0.8164 F1_train:0.8895 AUC_train:0.9682\n",
      "acc_val:0.7303 pre_val:0.7838 recall_val:0.6444 F1_val:0.707317 AUC_val:0.8525\n",
      "Epoch:0069\n",
      "acc_train:0.8864 pre_train:0.9628 recall_train:0.8116 F1_train:0.8807 AUC_train:0.9668\n",
      "acc_val:0.7528 pre_val:0.8108 recall_val:0.6667 F1_val:0.731707 AUC_val:0.8525\n",
      "Epoch:0070\n",
      "acc_train:0.8764 pre_train:0.9565 recall_train:0.7971 F1_train:0.8696 AUC_train:0.9740\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.8510\n",
      "Epoch:0071\n",
      "acc_train:0.9026 pre_train:0.9492 recall_train:0.8575 F1_train:0.9010 AUC_train:0.9657\n",
      "acc_val:0.7528 pre_val:0.8108 recall_val:0.6667 F1_val:0.731707 AUC_val:0.8490\n",
      "Epoch:0072\n",
      "acc_train:0.9089 pre_train:0.9858 recall_train:0.8357 F1_train:0.9046 AUC_train:0.9824\n",
      "acc_val:0.7416 pre_val:0.7895 recall_val:0.6667 F1_val:0.722892 AUC_val:0.8449\n",
      "Epoch:0073\n",
      "acc_train:0.9064 pre_train:0.9721 recall_train:0.8430 F1_train:0.9030 AUC_train:0.9774\n",
      "acc_val:0.7640 pre_val:0.8333 recall_val:0.6667 F1_val:0.740741 AUC_val:0.8505\n",
      "Epoch:0074\n",
      "acc_train:0.8939 pre_train:0.9741 recall_train:0.8164 F1_train:0.8883 AUC_train:0.9738\n",
      "acc_val:0.7640 pre_val:0.8333 recall_val:0.6667 F1_val:0.740741 AUC_val:0.8520\n",
      "Epoch:0075\n",
      "acc_train:0.9089 pre_train:0.9697 recall_train:0.8502 F1_train:0.9060 AUC_train:0.9815\n",
      "acc_val:0.7528 pre_val:0.8286 recall_val:0.6444 F1_val:0.725000 AUC_val:0.8520\n",
      "Epoch:0076\n",
      "acc_train:0.8976 pre_train:0.9826 recall_train:0.8164 F1_train:0.8918 AUC_train:0.9757\n",
      "acc_val:0.7528 pre_val:0.8286 recall_val:0.6444 F1_val:0.725000 AUC_val:0.8535\n",
      "Epoch:0077\n",
      "acc_train:0.9014 pre_train:0.9772 recall_train:0.8285 F1_train:0.8967 AUC_train:0.9775\n",
      "acc_val:0.7753 pre_val:0.8571 recall_val:0.6667 F1_val:0.750000 AUC_val:0.8561\n",
      "Epoch:0078\n",
      "acc_train:0.8976 pre_train:0.9689 recall_train:0.8285 F1_train:0.8932 AUC_train:0.9729\n",
      "acc_val:0.7640 pre_val:0.8333 recall_val:0.6667 F1_val:0.740741 AUC_val:0.8601\n",
      "Epoch:0079\n",
      "acc_train:0.9164 pre_train:0.9728 recall_train:0.8623 F1_train:0.9142 AUC_train:0.9791\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.8657\n",
      "Epoch:0080\n",
      "acc_train:0.9176 pre_train:0.9677 recall_train:0.8696 F1_train:0.9160 AUC_train:0.9765\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.8687\n",
      "Epoch:0081\n",
      "acc_train:0.9338 pre_train:0.9813 recall_train:0.8889 F1_train:0.9328 AUC_train:0.9903\n",
      "acc_val:0.7865 pre_val:0.8611 recall_val:0.6889 F1_val:0.765432 AUC_val:0.8687\n",
      "Epoch:0082\n",
      "acc_train:0.9213 pre_train:0.9730 recall_train:0.8720 F1_train:0.9197 AUC_train:0.9856\n",
      "acc_val:0.7978 pre_val:0.8649 recall_val:0.7111 F1_val:0.780488 AUC_val:0.8682\n",
      "Epoch:0083\n",
      "acc_train:0.9263 pre_train:0.9784 recall_train:0.8768 F1_train:0.9248 AUC_train:0.9906\n",
      "acc_val:0.7528 pre_val:0.7805 recall_val:0.7111 F1_val:0.744186 AUC_val:0.8682\n",
      "Epoch:0084\n",
      "acc_train:0.9326 pre_train:0.9639 recall_train:0.9034 F1_train:0.9327 AUC_train:0.9868\n",
      "acc_val:0.7303 pre_val:0.7442 recall_val:0.7111 F1_val:0.727273 AUC_val:0.8657\n",
      "Epoch:0085\n",
      "acc_train:0.9201 pre_train:0.9557 recall_train:0.8865 F1_train:0.9198 AUC_train:0.9766\n",
      "acc_val:0.7528 pre_val:0.7805 recall_val:0.7111 F1_val:0.744186 AUC_val:0.8652\n",
      "Epoch:0086\n",
      "acc_train:0.9413 pre_train:0.9816 recall_train:0.9034 F1_train:0.9409 AUC_train:0.9900\n",
      "acc_val:0.7640 pre_val:0.8000 recall_val:0.7111 F1_val:0.752941 AUC_val:0.8652\n",
      "Epoch:0087\n",
      "acc_train:0.9401 pre_train:0.9645 recall_train:0.9179 F1_train:0.9406 AUC_train:0.9846\n",
      "acc_val:0.7528 pre_val:0.7949 recall_val:0.6889 F1_val:0.738095 AUC_val:0.8641\n",
      "Epoch:0088\n",
      "acc_train:0.9426 pre_train:0.9767 recall_train:0.9106 F1_train:0.9425 AUC_train:0.9872\n",
      "acc_val:0.7528 pre_val:0.7949 recall_val:0.6889 F1_val:0.738095 AUC_val:0.8687\n",
      "Epoch:0089\n",
      "acc_train:0.9388 pre_train:0.9620 recall_train:0.9179 F1_train:0.9394 AUC_train:0.9841\n",
      "acc_val:0.7640 pre_val:0.8158 recall_val:0.6889 F1_val:0.746988 AUC_val:0.8692\n",
      "Epoch:0090\n",
      "acc_train:0.9338 pre_train:0.9664 recall_train:0.9034 F1_train:0.9338 AUC_train:0.9848\n",
      "acc_val:0.7640 pre_val:0.8333 recall_val:0.6667 F1_val:0.740741 AUC_val:0.8727\n",
      "Epoch:0091\n",
      "acc_train:0.9563 pre_train:0.9822 recall_train:0.9324 F1_train:0.9566 AUC_train:0.9906\n",
      "acc_val:0.7865 pre_val:0.8824 recall_val:0.6667 F1_val:0.759494 AUC_val:0.8717\n",
      "Epoch:0092\n",
      "acc_train:0.9351 pre_train:0.9689 recall_train:0.9034 F1_train:0.9350 AUC_train:0.9886\n",
      "acc_val:0.7753 pre_val:0.8788 recall_val:0.6444 F1_val:0.743590 AUC_val:0.8768\n",
      "Epoch:0093\n",
      "acc_train:0.9563 pre_train:0.9797 recall_train:0.9348 F1_train:0.9567 AUC_train:0.9928\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.8808\n",
      "Epoch:0094\n",
      "acc_train:0.9526 pre_train:0.9772 recall_train:0.9300 F1_train:0.9530 AUC_train:0.9897\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.8929\n",
      "Epoch:0095\n",
      "acc_train:0.9463 pre_train:0.9744 recall_train:0.9203 F1_train:0.9466 AUC_train:0.9910\n",
      "acc_val:0.7640 pre_val:0.8750 recall_val:0.6222 F1_val:0.727273 AUC_val:0.9116\n",
      "Epoch:0096\n",
      "acc_train:0.9526 pre_train:0.9772 recall_train:0.9300 F1_train:0.9530 AUC_train:0.9919\n",
      "acc_val:0.7528 pre_val:0.8710 recall_val:0.6000 F1_val:0.710526 AUC_val:0.9167\n",
      "Epoch:0097\n",
      "acc_train:0.9600 pre_train:0.9799 recall_train:0.9420 F1_train:0.9606 AUC_train:0.9908\n",
      "acc_val:0.7528 pre_val:0.8710 recall_val:0.6000 F1_val:0.710526 AUC_val:0.9136\n",
      "Epoch:0098\n",
      "acc_train:0.9576 pre_train:0.9774 recall_train:0.9396 F1_train:0.9581 AUC_train:0.9932\n",
      "acc_val:0.7640 pre_val:0.9000 recall_val:0.6000 F1_val:0.720000 AUC_val:0.9131\n",
      "Epoch:0099\n",
      "acc_train:0.9551 pre_train:0.9846 recall_train:0.9275 F1_train:0.9552 AUC_train:0.9943\n",
      "acc_val:0.7416 pre_val:0.8438 recall_val:0.6000 F1_val:0.701299 AUC_val:0.9157\n",
      "Epoch:0100\n",
      "acc_train:0.9600 pre_train:0.9799 recall_train:0.9420 F1_train:0.9606 AUC_train:0.9932\n",
      "acc_val:0.7528 pre_val:0.8485 recall_val:0.6222 F1_val:0.717949 AUC_val:0.9162\n",
      "Epoch:0101\n",
      "acc_train:0.9451 pre_train:0.9793 recall_train:0.9130 F1_train:0.9450 AUC_train:0.9932\n",
      "acc_val:0.7528 pre_val:0.8485 recall_val:0.6222 F1_val:0.717949 AUC_val:0.9096\n",
      "Epoch:0102\n",
      "acc_train:0.9576 pre_train:0.9872 recall_train:0.9300 F1_train:0.9577 AUC_train:0.9917\n",
      "acc_val:0.7865 pre_val:0.8611 recall_val:0.6889 F1_val:0.765432 AUC_val:0.9071\n",
      "Epoch:0103\n",
      "acc_train:0.9563 pre_train:0.9922 recall_train:0.9227 F1_train:0.9562 AUC_train:0.9939\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.9076\n",
      "Epoch:0104\n",
      "acc_train:0.9588 pre_train:0.9751 recall_train:0.9444 F1_train:0.9595 AUC_train:0.9894\n",
      "acc_val:0.7528 pre_val:0.8485 recall_val:0.6222 F1_val:0.717949 AUC_val:0.9106\n",
      "Epoch:0105\n",
      "acc_train:0.9688 pre_train:0.9826 recall_train:0.9565 F1_train:0.9694 AUC_train:0.9926\n",
      "acc_val:0.7753 pre_val:0.9032 recall_val:0.6222 F1_val:0.736842 AUC_val:0.9126\n",
      "Epoch:0106\n",
      "acc_train:0.9663 pre_train:0.9899 recall_train:0.9444 F1_train:0.9666 AUC_train:0.9962\n",
      "acc_val:0.7753 pre_val:0.9032 recall_val:0.6222 F1_val:0.736842 AUC_val:0.9106\n",
      "Epoch:0107\n",
      "acc_train:0.9625 pre_train:0.9898 recall_train:0.9372 F1_train:0.9628 AUC_train:0.9965\n",
      "acc_val:0.7753 pre_val:0.9032 recall_val:0.6222 F1_val:0.736842 AUC_val:0.9116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0108\n",
      "acc_train:0.9650 pre_train:0.9707 recall_train:0.9614 F1_train:0.9660 AUC_train:0.9891\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.9045\n",
      "Epoch:0109\n",
      "acc_train:0.9713 pre_train:0.9851 recall_train:0.9589 F1_train:0.9718 AUC_train:0.9955\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.9045\n",
      "Epoch:0110\n",
      "acc_train:0.9588 pre_train:0.9872 recall_train:0.9324 F1_train:0.9590 AUC_train:0.9943\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.9030\n",
      "Epoch:0111\n",
      "acc_train:0.9576 pre_train:0.9872 recall_train:0.9300 F1_train:0.9577 AUC_train:0.9914\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.9040\n",
      "Epoch:0112\n",
      "acc_train:0.9338 pre_train:0.9570 recall_train:0.9130 F1_train:0.9345 AUC_train:0.9859\n",
      "acc_val:0.7528 pre_val:0.8485 recall_val:0.6222 F1_val:0.717949 AUC_val:0.9167\n",
      "Epoch:0113\n",
      "acc_train:0.9613 pre_train:0.9728 recall_train:0.9517 F1_train:0.9621 AUC_train:0.9933\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.9207\n",
      "Epoch:0114\n",
      "acc_train:0.9650 pre_train:0.9849 recall_train:0.9469 F1_train:0.9655 AUC_train:0.9949\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.9217\n",
      "Epoch:0115\n",
      "acc_train:0.9650 pre_train:0.9801 recall_train:0.9517 F1_train:0.9657 AUC_train:0.9935\n",
      "acc_val:0.7640 pre_val:0.8529 recall_val:0.6444 F1_val:0.734177 AUC_val:0.9207\n",
      "Epoch:0116\n",
      "acc_train:0.9775 pre_train:0.9877 recall_train:0.9686 F1_train:0.9780 AUC_train:0.9934\n",
      "acc_val:0.7753 pre_val:0.8788 recall_val:0.6444 F1_val:0.743590 AUC_val:0.9172\n",
      "Epoch:0117\n",
      "acc_train:0.9713 pre_train:0.9875 recall_train:0.9565 F1_train:0.9718 AUC_train:0.9957\n",
      "acc_val:0.7753 pre_val:0.8788 recall_val:0.6444 F1_val:0.743590 AUC_val:0.9141\n",
      "Epoch:0118\n",
      "acc_train:0.9625 pre_train:0.9824 recall_train:0.9444 F1_train:0.9631 AUC_train:0.9933\n",
      "acc_val:0.7640 pre_val:0.8750 recall_val:0.6222 F1_val:0.727273 AUC_val:0.9157\n",
      "Epoch:0119\n",
      "acc_train:0.9738 pre_train:0.9925 recall_train:0.9565 F1_train:0.9742 AUC_train:0.9942\n",
      "acc_val:0.7640 pre_val:0.8750 recall_val:0.6222 F1_val:0.727273 AUC_val:0.9116\n",
      "Epoch:0120\n",
      "acc_train:0.9663 pre_train:0.9778 recall_train:0.9565 F1_train:0.9670 AUC_train:0.9951\n",
      "acc_val:0.7640 pre_val:0.9000 recall_val:0.6000 F1_val:0.720000 AUC_val:0.9091\n",
      "Epoch:0121\n",
      "acc_train:0.9725 pre_train:0.9900 recall_train:0.9565 F1_train:0.9730 AUC_train:0.9976\n",
      "acc_val:0.7528 pre_val:0.8966 recall_val:0.5778 F1_val:0.702703 AUC_val:0.9061\n",
      "Epoch:0122\n",
      "acc_train:0.9663 pre_train:0.9874 recall_train:0.9469 F1_train:0.9667 AUC_train:0.9962\n",
      "acc_val:0.7528 pre_val:0.8966 recall_val:0.5778 F1_val:0.702703 AUC_val:0.9071\n",
      "Epoch:0123\n",
      "acc_train:0.9800 pre_train:0.9901 recall_train:0.9710 F1_train:0.9805 AUC_train:0.9978\n",
      "acc_val:0.7528 pre_val:0.8966 recall_val:0.5778 F1_val:0.702703 AUC_val:0.9076\n",
      "Early Stopping!!! epoch：122\n",
      "Loading the Model for the 4-th Fold:... ... Size of samples in the test set:222\n",
      "Fold 4 Results: test acc:0.5856 test_pre:0.6774 test_recall:0.3684 test_F1:0.4773 test_AUC:0.6613 time:429.830s\n",
      "Size of the 5-fold Training, Validation, and Test Sets:801,89,222\n",
      " Starting the 5-1 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4644 pre_train:0.4861 recall_train:0.7233 F1_train:0.5815 AUC_train:0.4215\n",
      "acc_val:0.3820 pre_val:0.3953 recall_val:0.3696 F1_val:0.382022 AUC_val:0.3751\n",
      "Epoch:0002\n",
      "acc_train:0.4894 pre_train:0.5025 recall_train:0.7257 F1_train:0.5938 AUC_train:0.4681\n",
      "acc_val:0.4045 pre_val:0.4103 recall_val:0.3478 F1_val:0.376471 AUC_val:0.3852\n",
      "Epoch:0003\n",
      "acc_train:0.4919 pre_train:0.5043 recall_train:0.7112 F1_train:0.5901 AUC_train:0.4813\n",
      "acc_val:0.5281 pre_val:0.5526 recall_val:0.4565 F1_val:0.500000 AUC_val:0.4895\n",
      "Epoch:0004\n",
      "acc_train:0.5044 pre_train:0.5135 recall_train:0.6917 F1_train:0.5895 AUC_train:0.5047\n",
      "acc_val:0.5843 pre_val:0.6000 recall_val:0.5870 F1_val:0.593407 AUC_val:0.5952\n",
      "Epoch:0005\n",
      "acc_train:0.5493 pre_train:0.5633 recall_train:0.5510 F1_train:0.5571 AUC_train:0.5591\n",
      "acc_val:0.5955 pre_val:0.6471 recall_val:0.4783 F1_val:0.550000 AUC_val:0.5824\n",
      "Epoch:0006\n",
      "acc_train:0.5306 pre_train:0.5388 recall_train:0.6068 F1_train:0.5708 AUC_train:0.5235\n",
      "acc_val:0.6180 pre_val:0.7143 recall_val:0.4348 F1_val:0.540541 AUC_val:0.5829\n",
      "Epoch:0007\n",
      "acc_train:0.5156 pre_train:0.5286 recall_train:0.5388 F1_train:0.5337 AUC_train:0.5402\n",
      "acc_val:0.5843 pre_val:0.6452 recall_val:0.4348 F1_val:0.519481 AUC_val:0.5111\n",
      "Epoch:0008\n",
      "acc_train:0.5543 pre_train:0.5788 recall_train:0.4903 F1_train:0.5309 AUC_train:0.5847\n",
      "acc_val:0.5955 pre_val:0.6471 recall_val:0.4783 F1_val:0.550000 AUC_val:0.5516\n",
      "Epoch:0009\n",
      "acc_train:0.5306 pre_train:0.5395 recall_train:0.5971 F1_train:0.5668 AUC_train:0.5306\n",
      "acc_val:0.5730 pre_val:0.6333 recall_val:0.4130 F1_val:0.500000 AUC_val:0.5273\n",
      "Epoch:0010\n",
      "acc_train:0.5568 pre_train:0.5785 recall_train:0.5097 F1_train:0.5419 AUC_train:0.5852\n",
      "acc_val:0.5843 pre_val:0.6364 recall_val:0.4565 F1_val:0.531646 AUC_val:0.5425\n",
      "Epoch:0011\n",
      "acc_train:0.5531 pre_train:0.5685 recall_train:0.5437 F1_train:0.5558 AUC_train:0.5670\n",
      "acc_val:0.5955 pre_val:0.6562 recall_val:0.4565 F1_val:0.538462 AUC_val:0.5506\n",
      "Epoch:0012\n",
      "acc_train:0.5780 pre_train:0.6045 recall_train:0.5194 F1_train:0.5587 AUC_train:0.6101\n",
      "acc_val:0.5955 pre_val:0.6562 recall_val:0.4565 F1_val:0.538462 AUC_val:0.5662\n",
      "Epoch:0013\n",
      "acc_train:0.5980 pre_train:0.6562 recall_train:0.4587 F1_train:0.5400 AUC_train:0.5977\n",
      "acc_val:0.6067 pre_val:0.6667 recall_val:0.4783 F1_val:0.556962 AUC_val:0.5996\n",
      "Epoch:0014\n",
      "acc_train:0.6017 pre_train:0.6545 recall_train:0.4782 F1_train:0.5526 AUC_train:0.6166\n",
      "acc_val:0.6180 pre_val:0.6765 recall_val:0.5000 F1_val:0.575000 AUC_val:0.6117\n",
      "Epoch:0015\n",
      "acc_train:0.6030 pre_train:0.6237 recall_train:0.5752 F1_train:0.5985 AUC_train:0.6315\n",
      "acc_val:0.6067 pre_val:0.6486 recall_val:0.5217 F1_val:0.578313 AUC_val:0.6052\n",
      "Epoch:0016\n",
      "acc_train:0.6055 pre_train:0.6690 recall_train:0.4612 F1_train:0.5460 AUC_train:0.6218\n",
      "acc_val:0.6067 pre_val:0.6486 recall_val:0.5217 F1_val:0.578313 AUC_val:0.6294\n",
      "Epoch:0017\n",
      "acc_train:0.6055 pre_train:0.6739 recall_train:0.4515 F1_train:0.5407 AUC_train:0.6218\n",
      "acc_val:0.6067 pre_val:0.6486 recall_val:0.5217 F1_val:0.578313 AUC_val:0.6360\n",
      "Epoch:0018\n",
      "acc_train:0.5705 pre_train:0.6056 recall_train:0.4733 F1_train:0.5313 AUC_train:0.6209\n",
      "acc_val:0.6067 pre_val:0.6410 recall_val:0.5435 F1_val:0.588235 AUC_val:0.6390\n",
      "Epoch:0019\n",
      "acc_train:0.6142 pre_train:0.6594 recall_train:0.5170 F1_train:0.5796 AUC_train:0.6283\n",
      "acc_val:0.6180 pre_val:0.6500 recall_val:0.5652 F1_val:0.604651 AUC_val:0.6375\n",
      "Epoch:0020\n",
      "acc_train:0.5830 pre_train:0.5882 recall_train:0.6311 F1_train:0.6089 AUC_train:0.6292\n",
      "acc_val:0.6404 pre_val:0.6591 recall_val:0.6304 F1_val:0.644444 AUC_val:0.6426\n",
      "Epoch:0021\n",
      "acc_train:0.5855 pre_train:0.5939 recall_train:0.6141 F1_train:0.6038 AUC_train:0.6200\n",
      "acc_val:0.6292 pre_val:0.6383 recall_val:0.6522 F1_val:0.645161 AUC_val:0.6502\n",
      "Epoch:0022\n",
      "acc_train:0.6105 pre_train:0.6330 recall_train:0.5777 F1_train:0.6041 AUC_train:0.6424\n",
      "acc_val:0.6067 pre_val:0.6122 recall_val:0.6522 F1_val:0.631579 AUC_val:0.6699\n",
      "Epoch:0023\n",
      "acc_train:0.5993 pre_train:0.6233 recall_train:0.5583 F1_train:0.5890 AUC_train:0.6320\n",
      "acc_val:0.6067 pre_val:0.6078 recall_val:0.6739 F1_val:0.639175 AUC_val:0.6648\n",
      "Epoch:0024\n",
      "acc_train:0.6242 pre_train:0.6751 recall_train:0.5194 F1_train:0.5871 AUC_train:0.6584\n",
      "acc_val:0.6067 pre_val:0.6078 recall_val:0.6739 F1_val:0.639175 AUC_val:0.6709\n",
      "Epoch:0025\n",
      "acc_train:0.6192 pre_train:0.6597 recall_train:0.5364 F1_train:0.5917 AUC_train:0.6559\n",
      "acc_val:0.6067 pre_val:0.6078 recall_val:0.6739 F1_val:0.639175 AUC_val:0.6694\n",
      "Epoch:0026\n",
      "acc_train:0.6017 pre_train:0.6110 recall_train:0.6214 F1_train:0.6161 AUC_train:0.6667\n",
      "acc_val:0.6292 pre_val:0.6226 recall_val:0.7174 F1_val:0.666667 AUC_val:0.6663\n",
      "Epoch:0027\n",
      "acc_train:0.6042 pre_train:0.6173 recall_train:0.6068 F1_train:0.6120 AUC_train:0.6732\n",
      "acc_val:0.6292 pre_val:0.6226 recall_val:0.7174 F1_val:0.666667 AUC_val:0.6734\n",
      "Epoch:0028\n",
      "acc_train:0.6404 pre_train:0.6442 recall_train:0.6723 F1_train:0.6580 AUC_train:0.6904\n",
      "acc_val:0.6292 pre_val:0.6226 recall_val:0.7174 F1_val:0.666667 AUC_val:0.6795\n",
      "Epoch:0029\n",
      "acc_train:0.6517 pre_train:0.6667 recall_train:0.6456 F1_train:0.6560 AUC_train:0.7084\n",
      "acc_val:0.6404 pre_val:0.6296 recall_val:0.7391 F1_val:0.680000 AUC_val:0.6840\n",
      "Epoch:0030\n",
      "acc_train:0.6529 pre_train:0.6324 recall_train:0.7767 F1_train:0.6972 AUC_train:0.7016\n",
      "acc_val:0.6629 pre_val:0.6429 recall_val:0.7826 F1_val:0.705882 AUC_val:0.6891\n",
      "Epoch:0031\n",
      "acc_train:0.6642 pre_train:0.6659 recall_train:0.6966 F1_train:0.6809 AUC_train:0.7152\n",
      "acc_val:0.6404 pre_val:0.6207 recall_val:0.7826 F1_val:0.692308 AUC_val:0.6951\n",
      "Epoch:0032\n",
      "acc_train:0.6367 pre_train:0.6501 recall_train:0.6359 F1_train:0.6429 AUC_train:0.7257\n",
      "acc_val:0.6404 pre_val:0.6207 recall_val:0.7826 F1_val:0.692308 AUC_val:0.6992\n",
      "Epoch:0033\n",
      "acc_train:0.6679 pre_train:0.6534 recall_train:0.7549 F1_train:0.7005 AUC_train:0.7280\n",
      "acc_val:0.6292 pre_val:0.6102 recall_val:0.7826 F1_val:0.685714 AUC_val:0.7007\n",
      "Epoch:0034\n",
      "acc_train:0.6454 pre_train:0.6435 recall_train:0.6966 F1_train:0.6690 AUC_train:0.7187\n",
      "acc_val:0.6629 pre_val:0.6429 recall_val:0.7826 F1_val:0.705882 AUC_val:0.6982\n",
      "Epoch:0035\n",
      "acc_train:0.6554 pre_train:0.6538 recall_train:0.7015 F1_train:0.6768 AUC_train:0.7217\n",
      "acc_val:0.6629 pre_val:0.6481 recall_val:0.7609 F1_val:0.700000 AUC_val:0.6987\n",
      "Epoch:0036\n",
      "acc_train:0.6742 pre_train:0.7003 recall_train:0.6408 F1_train:0.6692 AUC_train:0.7371\n",
      "acc_val:0.6629 pre_val:0.6481 recall_val:0.7609 F1_val:0.700000 AUC_val:0.7017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0037\n",
      "acc_train:0.6642 pre_train:0.6857 recall_train:0.6408 F1_train:0.6625 AUC_train:0.7583\n",
      "acc_val:0.6629 pre_val:0.6481 recall_val:0.7609 F1_val:0.700000 AUC_val:0.7068\n",
      "Epoch:0038\n",
      "acc_train:0.6667 pre_train:0.6514 recall_train:0.7573 F1_train:0.7003 AUC_train:0.7286\n",
      "acc_val:0.6517 pre_val:0.6364 recall_val:0.7609 F1_val:0.693069 AUC_val:0.7118\n",
      "Epoch:0039\n",
      "acc_train:0.6879 pre_train:0.6738 recall_train:0.7621 F1_train:0.7153 AUC_train:0.7608\n",
      "acc_val:0.6742 pre_val:0.6545 recall_val:0.7826 F1_val:0.712871 AUC_val:0.7169\n",
      "Epoch:0040\n",
      "acc_train:0.7066 pre_train:0.6962 recall_train:0.7621 F1_train:0.7277 AUC_train:0.7820\n",
      "acc_val:0.6966 pre_val:0.6667 recall_val:0.8261 F1_val:0.737864 AUC_val:0.7285\n",
      "Epoch:0041\n",
      "acc_train:0.7316 pre_train:0.7109 recall_train:0.8058 F1_train:0.7554 AUC_train:0.7946\n",
      "acc_val:0.7191 pre_val:0.6721 recall_val:0.8913 F1_val:0.766355 AUC_val:0.7391\n",
      "Epoch:0042\n",
      "acc_train:0.7453 pre_train:0.7176 recall_train:0.8325 F1_train:0.7708 AUC_train:0.7989\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.7533\n",
      "Epoch:0043\n",
      "acc_train:0.7690 pre_train:0.7284 recall_train:0.8786 F1_train:0.7965 AUC_train:0.8383\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.7690\n",
      "Epoch:0044\n",
      "acc_train:0.7865 pre_train:0.7495 recall_train:0.8786 F1_train:0.8089 AUC_train:0.8476\n",
      "acc_val:0.7416 pre_val:0.6825 recall_val:0.9348 F1_val:0.788991 AUC_val:0.7750\n",
      "Epoch:0045\n",
      "acc_train:0.7890 pre_train:0.7505 recall_train:0.8835 F1_train:0.8116 AUC_train:0.8511\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.7826\n",
      "Epoch:0046\n",
      "acc_train:0.7953 pre_train:0.7684 recall_train:0.8617 F1_train:0.8124 AUC_train:0.8442\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.7791\n",
      "Epoch:0047\n",
      "acc_train:0.8302 pre_train:0.7887 recall_train:0.9150 F1_train:0.8472 AUC_train:0.8754\n",
      "acc_val:0.7191 pre_val:0.6615 recall_val:0.9348 F1_val:0.774775 AUC_val:0.7786\n",
      "Epoch:0048\n",
      "acc_train:0.8052 pre_train:0.7550 recall_train:0.9199 F1_train:0.8293 AUC_train:0.8785\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.7796\n",
      "Epoch:0049\n",
      "acc_train:0.8077 pre_train:0.7560 recall_train:0.9248 F1_train:0.8319 AUC_train:0.8717\n",
      "acc_val:0.7416 pre_val:0.6825 recall_val:0.9348 F1_val:0.788991 AUC_val:0.7816\n",
      "Epoch:0050\n",
      "acc_train:0.8290 pre_train:0.7895 recall_train:0.9102 F1_train:0.8455 AUC_train:0.8936\n",
      "acc_val:0.7416 pre_val:0.6825 recall_val:0.9348 F1_val:0.788991 AUC_val:0.7841\n",
      "Epoch:0051\n",
      "acc_train:0.8290 pre_train:0.7944 recall_train:0.9005 F1_train:0.8441 AUC_train:0.8876\n",
      "acc_val:0.7191 pre_val:0.6615 recall_val:0.9348 F1_val:0.774775 AUC_val:0.7892\n",
      "Epoch:0052\n",
      "acc_train:0.8277 pre_train:0.7773 recall_train:0.9320 F1_train:0.8477 AUC_train:0.9017\n",
      "acc_val:0.7079 pre_val:0.6515 recall_val:0.9348 F1_val:0.767857 AUC_val:0.7922\n",
      "Epoch:0053\n",
      "acc_train:0.8489 pre_train:0.8012 recall_train:0.9393 F1_train:0.8648 AUC_train:0.9008\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8018\n",
      "Epoch:0054\n",
      "acc_train:0.8639 pre_train:0.8217 recall_train:0.9393 F1_train:0.8766 AUC_train:0.9170\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.8094\n",
      "Epoch:0055\n",
      "acc_train:0.8614 pre_train:0.8065 recall_train:0.9612 F1_train:0.8771 AUC_train:0.9266\n",
      "acc_val:0.7303 pre_val:0.6618 recall_val:0.9783 F1_val:0.789474 AUC_val:0.8099\n",
      "Epoch:0056\n",
      "acc_train:0.8739 pre_train:0.8167 recall_train:0.9733 F1_train:0.8882 AUC_train:0.9322\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.8129\n",
      "Epoch:0057\n",
      "acc_train:0.8589 pre_train:0.8045 recall_train:0.9587 F1_train:0.8749 AUC_train:0.9324\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.8172\n",
      "Epoch:0058\n",
      "acc_train:0.8752 pre_train:0.8171 recall_train:0.9757 F1_train:0.8894 AUC_train:0.9363\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.8261\n",
      "Epoch:0059\n",
      "acc_train:0.8677 pre_train:0.8110 recall_train:0.9684 F1_train:0.8827 AUC_train:0.9209\n",
      "acc_val:0.7640 pre_val:0.7049 recall_val:0.9348 F1_val:0.803738 AUC_val:0.8195\n",
      "Epoch:0060\n",
      "acc_train:0.8789 pre_train:0.8316 recall_train:0.9587 F1_train:0.8906 AUC_train:0.9235\n",
      "acc_val:0.7753 pre_val:0.7167 recall_val:0.9348 F1_val:0.811321 AUC_val:0.8170\n",
      "Epoch:0061\n",
      "acc_train:0.8889 pre_train:0.8372 recall_train:0.9733 F1_train:0.9001 AUC_train:0.9355\n",
      "acc_val:0.7753 pre_val:0.7167 recall_val:0.9348 F1_val:0.811321 AUC_val:0.8175\n",
      "Epoch:0062\n",
      "acc_train:0.8752 pre_train:0.8305 recall_train:0.9515 F1_train:0.8869 AUC_train:0.9221\n",
      "acc_val:0.7753 pre_val:0.7167 recall_val:0.9348 F1_val:0.811321 AUC_val:0.8281\n",
      "Epoch:0063\n",
      "acc_train:0.8914 pre_train:0.8571 recall_train:0.9466 F1_train:0.8997 AUC_train:0.9364\n",
      "acc_val:0.7978 pre_val:0.7414 recall_val:0.9348 F1_val:0.826923 AUC_val:0.8362\n",
      "Epoch:0064\n",
      "acc_train:0.8901 pre_train:0.8432 recall_train:0.9660 F1_train:0.9005 AUC_train:0.9482\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.8493\n",
      "Epoch:0065\n",
      "acc_train:0.9089 pre_train:0.8661 recall_train:0.9733 F1_train:0.9166 AUC_train:0.9331\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.8519\n",
      "Epoch:0066\n",
      "acc_train:0.9089 pre_train:0.8645 recall_train:0.9757 F1_train:0.9168 AUC_train:0.9618\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.8514\n",
      "Epoch:0067\n",
      "acc_train:0.9089 pre_train:0.8630 recall_train:0.9782 F1_train:0.9170 AUC_train:0.9540\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.8509\n",
      "Epoch:0068\n",
      "acc_train:0.9176 pre_train:0.8728 recall_train:0.9830 F1_train:0.9247 AUC_train:0.9487\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.8478\n",
      "Epoch:0069\n",
      "acc_train:0.9076 pre_train:0.8658 recall_train:0.9709 F1_train:0.9153 AUC_train:0.9452\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.8493\n",
      "Epoch:0070\n",
      "acc_train:0.9101 pre_train:0.8664 recall_train:0.9757 F1_train:0.9178 AUC_train:0.9604\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.8488\n",
      "Epoch:0071\n",
      "acc_train:0.9039 pre_train:0.8571 recall_train:0.9757 F1_train:0.9126 AUC_train:0.9623\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.8519\n",
      "Epoch:0072\n",
      "acc_train:0.9176 pre_train:0.8811 recall_train:0.9709 F1_train:0.9238 AUC_train:0.9451\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.8493\n",
      "Epoch:0073\n",
      "acc_train:0.9014 pre_train:0.8520 recall_train:0.9782 F1_train:0.9107 AUC_train:0.9553\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.8564\n",
      "Epoch:0074\n",
      "acc_train:0.9363 pre_train:0.9020 recall_train:0.9830 F1_train:0.9408 AUC_train:0.9591\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.8615\n",
      "Epoch:0075\n",
      "acc_train:0.9263 pre_train:0.8845 recall_train:0.9854 F1_train:0.9323 AUC_train:0.9669\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:1.0000 F1_val:0.800000 AUC_val:0.8645\n",
      "Epoch:0076\n",
      "acc_train:0.9363 pre_train:0.9002 recall_train:0.9854 F1_train:0.9409 AUC_train:0.9740\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:1.0000 F1_val:0.800000 AUC_val:0.8645\n",
      "Epoch:0077\n",
      "acc_train:0.9213 pre_train:0.8835 recall_train:0.9757 F1_train:0.9273 AUC_train:0.9677\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:1.0000 F1_val:0.800000 AUC_val:0.8665\n",
      "Epoch:0078\n",
      "acc_train:0.9226 pre_train:0.8872 recall_train:0.9733 F1_train:0.9282 AUC_train:0.9633\n",
      "acc_val:0.7191 pre_val:0.6479 recall_val:1.0000 F1_val:0.786325 AUC_val:0.8665\n",
      "Epoch:0079\n",
      "acc_train:0.9438 pre_train:0.9142 recall_train:0.9830 F1_train:0.9474 AUC_train:0.9770\n",
      "acc_val:0.7303 pre_val:0.6571 recall_val:1.0000 F1_val:0.793103 AUC_val:0.8670\n",
      "Epoch:0080\n",
      "acc_train:0.9363 pre_train:0.9002 recall_train:0.9854 F1_train:0.9409 AUC_train:0.9658\n",
      "acc_val:0.7528 pre_val:0.6765 recall_val:1.0000 F1_val:0.807018 AUC_val:0.8635\n",
      "Epoch:0081\n",
      "acc_train:0.9276 pre_train:0.8933 recall_train:0.9757 F1_train:0.9327 AUC_train:0.9739\n",
      "acc_val:0.7753 pre_val:0.6970 recall_val:1.0000 F1_val:0.821429 AUC_val:0.8635\n",
      "Epoch:0082\n",
      "acc_train:0.9451 pre_train:0.9126 recall_train:0.9879 F1_train:0.9487 AUC_train:0.9683\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.8660\n",
      "Epoch:0083\n",
      "acc_train:0.9426 pre_train:0.9049 recall_train:0.9927 F1_train:0.9468 AUC_train:0.9768\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.8746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0084\n",
      "acc_train:0.9326 pre_train:0.8943 recall_train:0.9854 F1_train:0.9376 AUC_train:0.9652\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.8948\n",
      "Epoch:0085\n",
      "acc_train:0.9426 pre_train:0.9031 recall_train:0.9951 F1_train:0.9469 AUC_train:0.9794\n",
      "acc_val:0.7753 pre_val:0.6970 recall_val:1.0000 F1_val:0.821429 AUC_val:0.9070\n",
      "Epoch:0086\n",
      "acc_train:0.9401 pre_train:0.9099 recall_train:0.9806 F1_train:0.9439 AUC_train:0.9813\n",
      "acc_val:0.7753 pre_val:0.6970 recall_val:1.0000 F1_val:0.821429 AUC_val:0.9242\n",
      "Epoch:0087\n",
      "acc_train:0.9401 pre_train:0.9081 recall_train:0.9830 F1_train:0.9441 AUC_train:0.9751\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9307\n",
      "Epoch:0088\n",
      "acc_train:0.9401 pre_train:0.9118 recall_train:0.9782 F1_train:0.9438 AUC_train:0.9755\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9338\n",
      "Epoch:0089\n",
      "acc_train:0.9413 pre_train:0.9065 recall_train:0.9879 F1_train:0.9454 AUC_train:0.9852\n",
      "acc_val:0.7753 pre_val:0.6970 recall_val:1.0000 F1_val:0.821429 AUC_val:0.9328\n",
      "Epoch:0090\n",
      "acc_train:0.9488 pre_train:0.9284 recall_train:0.9757 F1_train:0.9515 AUC_train:0.9720\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9393\n",
      "Epoch:0091\n",
      "acc_train:0.9326 pre_train:0.9032 recall_train:0.9733 F1_train:0.9369 AUC_train:0.9800\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9424\n",
      "Epoch:0092\n",
      "acc_train:0.9501 pre_train:0.9227 recall_train:0.9854 F1_train:0.9531 AUC_train:0.9852\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9378\n",
      "Epoch:0093\n",
      "acc_train:0.9451 pre_train:0.9220 recall_train:0.9757 F1_train:0.9481 AUC_train:0.9716\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9368\n",
      "Epoch:0094\n",
      "acc_train:0.9426 pre_train:0.9122 recall_train:0.9830 F1_train:0.9463 AUC_train:0.9703\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9287\n",
      "Epoch:0095\n",
      "acc_train:0.9501 pre_train:0.9208 recall_train:0.9879 F1_train:0.9532 AUC_train:0.9874\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9232\n",
      "Epoch:0096\n",
      "acc_train:0.9451 pre_train:0.9126 recall_train:0.9879 F1_train:0.9487 AUC_train:0.9778\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9161\n",
      "Epoch:0097\n",
      "acc_train:0.9488 pre_train:0.9187 recall_train:0.9879 F1_train:0.9520 AUC_train:0.9813\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9120\n",
      "Epoch:0098\n",
      "acc_train:0.9538 pre_train:0.9371 recall_train:0.9757 F1_train:0.9560 AUC_train:0.9849\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9156\n",
      "Epoch:0099\n",
      "acc_train:0.9538 pre_train:0.9271 recall_train:0.9879 F1_train:0.9565 AUC_train:0.9765\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9221\n",
      "Epoch:0100\n",
      "acc_train:0.9538 pre_train:0.9233 recall_train:0.9927 F1_train:0.9567 AUC_train:0.9833\n",
      "acc_val:0.7528 pre_val:0.6765 recall_val:1.0000 F1_val:0.807018 AUC_val:0.9262\n",
      "Epoch:0101\n",
      "acc_train:0.9501 pre_train:0.9170 recall_train:0.9927 F1_train:0.9534 AUC_train:0.9799\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:1.0000 F1_val:0.800000 AUC_val:0.9272\n",
      "Epoch:0102\n",
      "acc_train:0.9501 pre_train:0.9266 recall_train:0.9806 F1_train:0.9528 AUC_train:0.9862\n",
      "acc_val:0.7079 pre_val:0.6389 recall_val:1.0000 F1_val:0.779661 AUC_val:0.9305\n",
      "Epoch:0103\n",
      "acc_train:0.9638 pre_train:0.9443 recall_train:0.9879 F1_train:0.9656 AUC_train:0.9866\n",
      "acc_val:0.7079 pre_val:0.6389 recall_val:1.0000 F1_val:0.779661 AUC_val:0.9335\n",
      "Epoch:0104\n",
      "acc_train:0.9563 pre_train:0.9274 recall_train:0.9927 F1_train:0.9590 AUC_train:0.9844\n",
      "acc_val:0.7079 pre_val:0.6389 recall_val:1.0000 F1_val:0.779661 AUC_val:0.9328\n",
      "Epoch:0105\n",
      "acc_train:0.9576 pre_train:0.9335 recall_train:0.9879 F1_train:0.9599 AUC_train:0.9889\n",
      "acc_val:0.7528 pre_val:0.6765 recall_val:1.0000 F1_val:0.807018 AUC_val:0.9353\n",
      "Epoch:0106\n",
      "acc_train:0.9501 pre_train:0.9208 recall_train:0.9879 F1_train:0.9532 AUC_train:0.9879\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9474\n",
      "Epoch:0107\n",
      "acc_train:0.9501 pre_train:0.9208 recall_train:0.9879 F1_train:0.9532 AUC_train:0.9947\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9479\n",
      "Epoch:0108\n",
      "acc_train:0.9463 pre_train:0.9128 recall_train:0.9903 F1_train:0.9499 AUC_train:0.9809\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9515\n",
      "Epoch:0109\n",
      "acc_train:0.9526 pre_train:0.9269 recall_train:0.9854 F1_train:0.9553 AUC_train:0.9878\n",
      "acc_val:0.7640 pre_val:0.6866 recall_val:1.0000 F1_val:0.814159 AUC_val:0.9510\n",
      "Early Stopping!!! epoch：108\n",
      " Starting the 5-2 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.5231 pre_train:0.5355 recall_train:0.5485 F1_train:0.5420 AUC_train:0.5229\n",
      "acc_val:0.4607 pre_val:0.3333 recall_val:0.0435 F1_val:0.076923 AUC_val:0.5187\n",
      "Epoch:0002\n",
      "acc_train:0.5144 pre_train:0.5224 recall_train:0.6505 F1_train:0.5795 AUC_train:0.5211\n",
      "acc_val:0.5056 pre_val:0.5625 recall_val:0.1957 F1_val:0.290323 AUC_val:0.5804\n",
      "Epoch:0003\n",
      "acc_train:0.5306 pre_train:0.5398 recall_train:0.5922 F1_train:0.5648 AUC_train:0.5300\n",
      "acc_val:0.5618 pre_val:0.6207 recall_val:0.3913 F1_val:0.480000 AUC_val:0.6198\n",
      "Epoch:0004\n",
      "acc_train:0.5418 pre_train:0.5470 recall_train:0.6359 F1_train:0.5881 AUC_train:0.5272\n",
      "acc_val:0.5955 pre_val:0.6389 recall_val:0.5000 F1_val:0.560976 AUC_val:0.6138\n",
      "Epoch:0005\n",
      "acc_train:0.5381 pre_train:0.5473 recall_train:0.5898 F1_train:0.5678 AUC_train:0.5540\n",
      "acc_val:0.6292 pre_val:0.6667 recall_val:0.5652 F1_val:0.611765 AUC_val:0.6512\n",
      "Epoch:0006\n",
      "acc_train:0.5668 pre_train:0.5744 recall_train:0.6092 F1_train:0.5913 AUC_train:0.5700\n",
      "acc_val:0.6180 pre_val:0.6500 recall_val:0.5652 F1_val:0.604651 AUC_val:0.6759\n",
      "Epoch:0007\n",
      "acc_train:0.5768 pre_train:0.5806 recall_train:0.6383 F1_train:0.6081 AUC_train:0.6034\n",
      "acc_val:0.6292 pre_val:0.6512 recall_val:0.6087 F1_val:0.629213 AUC_val:0.6673\n",
      "Epoch:0008\n",
      "acc_train:0.5855 pre_train:0.5909 recall_train:0.6311 F1_train:0.6103 AUC_train:0.6114\n",
      "acc_val:0.6067 pre_val:0.6222 recall_val:0.6087 F1_val:0.615385 AUC_val:0.6320\n",
      "Epoch:0009\n",
      "acc_train:0.5793 pre_train:0.5940 recall_train:0.5752 F1_train:0.5845 AUC_train:0.6062\n",
      "acc_val:0.6067 pre_val:0.6222 recall_val:0.6087 F1_val:0.615385 AUC_val:0.6254\n",
      "Epoch:0010\n",
      "acc_train:0.5805 pre_train:0.5892 recall_train:0.6092 F1_train:0.5990 AUC_train:0.6236\n",
      "acc_val:0.6067 pre_val:0.6222 recall_val:0.6087 F1_val:0.615385 AUC_val:0.6314\n",
      "Epoch:0011\n",
      "acc_train:0.6267 pre_train:0.6430 recall_train:0.6165 F1_train:0.6295 AUC_train:0.6605\n",
      "acc_val:0.6067 pre_val:0.6222 recall_val:0.6087 F1_val:0.615385 AUC_val:0.6340\n",
      "Epoch:0012\n",
      "acc_train:0.6092 pre_train:0.6222 recall_train:0.6117 F1_train:0.6169 AUC_train:0.6561\n",
      "acc_val:0.6067 pre_val:0.6222 recall_val:0.6087 F1_val:0.615385 AUC_val:0.6330\n",
      "Epoch:0013\n",
      "acc_train:0.6005 pre_train:0.6122 recall_train:0.6092 F1_train:0.6107 AUC_train:0.6294\n",
      "acc_val:0.6180 pre_val:0.6364 recall_val:0.6087 F1_val:0.622222 AUC_val:0.6431\n",
      "Epoch:0014\n",
      "acc_train:0.5880 pre_train:0.5949 recall_train:0.6238 F1_train:0.6090 AUC_train:0.6378\n",
      "acc_val:0.6067 pre_val:0.6222 recall_val:0.6087 F1_val:0.615385 AUC_val:0.6466\n",
      "Epoch:0015\n",
      "acc_train:0.5980 pre_train:0.5978 recall_train:0.6675 F1_train:0.6307 AUC_train:0.6352\n",
      "acc_val:0.6404 pre_val:0.6400 recall_val:0.6957 F1_val:0.666667 AUC_val:0.6491\n",
      "Epoch:0016\n",
      "acc_train:0.6130 pre_train:0.6197 recall_train:0.6408 F1_train:0.6301 AUC_train:0.6518\n",
      "acc_val:0.6404 pre_val:0.6400 recall_val:0.6957 F1_val:0.666667 AUC_val:0.6542\n",
      "Epoch:0017\n",
      "acc_train:0.6080 pre_train:0.6129 recall_train:0.6456 F1_train:0.6288 AUC_train:0.6594\n",
      "acc_val:0.6404 pre_val:0.6400 recall_val:0.6957 F1_val:0.666667 AUC_val:0.6628\n",
      "Epoch:0018\n",
      "acc_train:0.6305 pre_train:0.6266 recall_train:0.6966 F1_train:0.6598 AUC_train:0.6860\n",
      "acc_val:0.6517 pre_val:0.6415 recall_val:0.7391 F1_val:0.686869 AUC_val:0.6704\n",
      "Epoch:0019\n",
      "acc_train:0.6242 pre_train:0.6288 recall_train:0.6578 F1_train:0.6429 AUC_train:0.6953\n",
      "acc_val:0.6517 pre_val:0.6415 recall_val:0.7391 F1_val:0.686869 AUC_val:0.6769\n",
      "Epoch:0020\n",
      "acc_train:0.6105 pre_train:0.6101 recall_train:0.6723 F1_train:0.6397 AUC_train:0.6627\n",
      "acc_val:0.6517 pre_val:0.6415 recall_val:0.7391 F1_val:0.686869 AUC_val:0.6845\n",
      "Epoch:0021\n",
      "acc_train:0.6454 pre_train:0.6448 recall_train:0.6917 F1_train:0.6674 AUC_train:0.6993\n",
      "acc_val:0.6517 pre_val:0.6415 recall_val:0.7391 F1_val:0.686869 AUC_val:0.6962\n",
      "Epoch:0022\n",
      "acc_train:0.6916 pre_train:0.6790 recall_train:0.7597 F1_train:0.7171 AUC_train:0.7453\n",
      "acc_val:0.6629 pre_val:0.6481 recall_val:0.7609 F1_val:0.700000 AUC_val:0.7093\n",
      "Epoch:0023\n",
      "acc_train:0.6654 pre_train:0.6600 recall_train:0.7209 F1_train:0.6891 AUC_train:0.7344\n",
      "acc_val:0.6742 pre_val:0.6545 recall_val:0.7826 F1_val:0.712871 AUC_val:0.7194\n",
      "Epoch:0024\n",
      "acc_train:0.6729 pre_train:0.6616 recall_train:0.7451 F1_train:0.7009 AUC_train:0.7521\n",
      "acc_val:0.6966 pre_val:0.6667 recall_val:0.8261 F1_val:0.737864 AUC_val:0.7321\n",
      "Epoch:0025\n",
      "acc_train:0.7191 pre_train:0.7169 recall_train:0.7500 F1_train:0.7331 AUC_train:0.7743\n",
      "acc_val:0.7191 pre_val:0.6842 recall_val:0.8478 F1_val:0.757282 AUC_val:0.7422\n",
      "Epoch:0026\n",
      "acc_train:0.7266 pre_train:0.7130 recall_train:0.7840 F1_train:0.7468 AUC_train:0.7790\n",
      "acc_val:0.7191 pre_val:0.6842 recall_val:0.8478 F1_val:0.757282 AUC_val:0.7568\n",
      "Epoch:0027\n",
      "acc_train:0.7441 pre_train:0.7315 recall_train:0.7937 F1_train:0.7614 AUC_train:0.8039\n",
      "acc_val:0.7303 pre_val:0.6897 recall_val:0.8696 F1_val:0.769231 AUC_val:0.7786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0028\n",
      "acc_train:0.7441 pre_train:0.7207 recall_train:0.8204 F1_train:0.7673 AUC_train:0.8096\n",
      "acc_val:0.7303 pre_val:0.6897 recall_val:0.8696 F1_val:0.769231 AUC_val:0.7993\n",
      "Epoch:0029\n",
      "acc_train:0.7990 pre_train:0.7577 recall_train:0.8956 F1_train:0.8209 AUC_train:0.8622\n",
      "acc_val:0.7416 pre_val:0.7018 recall_val:0.8696 F1_val:0.776699 AUC_val:0.8023\n",
      "Epoch:0030\n",
      "acc_train:0.8015 pre_train:0.7756 recall_train:0.8641 F1_train:0.8175 AUC_train:0.8424\n",
      "acc_val:0.7416 pre_val:0.6949 recall_val:0.8913 F1_val:0.780952 AUC_val:0.8059\n",
      "Epoch:0031\n",
      "acc_train:0.7940 pre_train:0.7679 recall_train:0.8592 F1_train:0.8110 AUC_train:0.8538\n",
      "acc_val:0.7528 pre_val:0.7000 recall_val:0.9130 F1_val:0.792453 AUC_val:0.8170\n",
      "Epoch:0032\n",
      "acc_train:0.8152 pre_train:0.7797 recall_train:0.8932 F1_train:0.8326 AUC_train:0.8821\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8205\n",
      "Epoch:0033\n",
      "acc_train:0.8340 pre_train:0.7853 recall_train:0.9320 F1_train:0.8524 AUC_train:0.8934\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.8231\n",
      "Epoch:0034\n",
      "acc_train:0.8377 pre_train:0.7913 recall_train:0.9296 F1_train:0.8549 AUC_train:0.8883\n",
      "acc_val:0.7079 pre_val:0.6562 recall_val:0.9130 F1_val:0.763636 AUC_val:0.8003\n",
      "Epoch:0035\n",
      "acc_train:0.8302 pre_train:0.7828 recall_train:0.9272 F1_train:0.8489 AUC_train:0.8914\n",
      "acc_val:0.6966 pre_val:0.6462 recall_val:0.9130 F1_val:0.756757 AUC_val:0.7983\n",
      "Epoch:0036\n",
      "acc_train:0.8377 pre_train:0.7950 recall_train:0.9223 F1_train:0.8539 AUC_train:0.9032\n",
      "acc_val:0.6966 pre_val:0.6462 recall_val:0.9130 F1_val:0.756757 AUC_val:0.8003\n",
      "Epoch:0037\n",
      "acc_train:0.8377 pre_train:0.7878 recall_train:0.9369 F1_train:0.8559 AUC_train:0.8999\n",
      "acc_val:0.7079 pre_val:0.6429 recall_val:0.9783 F1_val:0.775862 AUC_val:0.8261\n",
      "Epoch:0038\n",
      "acc_train:0.8589 pre_train:0.8134 recall_train:0.9417 F1_train:0.8729 AUC_train:0.9174\n",
      "acc_val:0.6854 pre_val:0.6250 recall_val:0.9783 F1_val:0.762712 AUC_val:0.8428\n",
      "Epoch:0039\n",
      "acc_train:0.8602 pre_train:0.8061 recall_train:0.9587 F1_train:0.8758 AUC_train:0.9153\n",
      "acc_val:0.6742 pre_val:0.6164 recall_val:0.9783 F1_val:0.756303 AUC_val:0.8468\n",
      "Epoch:0040\n",
      "acc_train:0.8689 pre_train:0.8178 recall_train:0.9587 F1_train:0.8827 AUC_train:0.9410\n",
      "acc_val:0.6629 pre_val:0.6081 recall_val:0.9783 F1_val:0.750000 AUC_val:0.8468\n",
      "Epoch:0041\n",
      "acc_train:0.8777 pre_train:0.8312 recall_train:0.9563 F1_train:0.8894 AUC_train:0.9439\n",
      "acc_val:0.6854 pre_val:0.6250 recall_val:0.9783 F1_val:0.762712 AUC_val:0.8504\n",
      "Epoch:0042\n",
      "acc_train:0.8864 pre_train:0.8351 recall_train:0.9709 F1_train:0.8979 AUC_train:0.9509\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.8544\n",
      "Epoch:0043\n",
      "acc_train:0.8864 pre_train:0.8379 recall_train:0.9660 F1_train:0.8974 AUC_train:0.9457\n",
      "acc_val:0.7303 pre_val:0.6618 recall_val:0.9783 F1_val:0.789474 AUC_val:0.8675\n",
      "Epoch:0044\n",
      "acc_train:0.8839 pre_train:0.8344 recall_train:0.9660 F1_train:0.8954 AUC_train:0.9453\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.8721\n",
      "Epoch:0045\n",
      "acc_train:0.8864 pre_train:0.8393 recall_train:0.9636 F1_train:0.8972 AUC_train:0.9477\n",
      "acc_val:0.7865 pre_val:0.7213 recall_val:0.9565 F1_val:0.822430 AUC_val:0.8635\n",
      "Epoch:0046\n",
      "acc_train:0.8876 pre_train:0.8426 recall_train:0.9612 F1_train:0.8980 AUC_train:0.9400\n",
      "acc_val:0.7865 pre_val:0.7213 recall_val:0.9565 F1_val:0.822430 AUC_val:0.8640\n",
      "Epoch:0047\n",
      "acc_train:0.8739 pre_train:0.8246 recall_train:0.9587 F1_train:0.8866 AUC_train:0.9402\n",
      "acc_val:0.7753 pre_val:0.7097 recall_val:0.9565 F1_val:0.814815 AUC_val:0.8777\n",
      "Epoch:0048\n",
      "acc_train:0.8889 pre_train:0.8443 recall_train:0.9612 F1_train:0.8990 AUC_train:0.9441\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.8918\n",
      "Epoch:0049\n",
      "acc_train:0.8939 pre_train:0.8471 recall_train:0.9684 F1_train:0.9037 AUC_train:0.9570\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.8900\n",
      "Epoch:0050\n",
      "acc_train:0.9101 pre_train:0.8648 recall_train:0.9782 F1_train:0.9180 AUC_train:0.9560\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.8969\n",
      "Epoch:0051\n",
      "acc_train:0.9139 pre_train:0.8769 recall_train:0.9684 F1_train:0.9204 AUC_train:0.9637\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.9009\n",
      "Epoch:0052\n",
      "acc_train:0.9139 pre_train:0.8688 recall_train:0.9806 F1_train:0.9213 AUC_train:0.9746\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.9171\n",
      "Epoch:0053\n",
      "acc_train:0.9238 pre_train:0.8909 recall_train:0.9709 F1_train:0.9292 AUC_train:0.9606\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9221\n",
      "Epoch:0054\n",
      "acc_train:0.9326 pre_train:0.8943 recall_train:0.9854 F1_train:0.9376 AUC_train:0.9714\n",
      "acc_val:0.7978 pre_val:0.7333 recall_val:0.9565 F1_val:0.830189 AUC_val:0.9191\n",
      "Epoch:0055\n",
      "acc_train:0.9189 pre_train:0.8813 recall_train:0.9733 F1_train:0.9250 AUC_train:0.9709\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.9161\n",
      "Epoch:0056\n",
      "acc_train:0.9376 pre_train:0.9022 recall_train:0.9854 F1_train:0.9420 AUC_train:0.9716\n",
      "acc_val:0.8202 pre_val:0.7586 recall_val:0.9565 F1_val:0.846154 AUC_val:0.9100\n",
      "Epoch:0057\n",
      "acc_train:0.9263 pre_train:0.8949 recall_train:0.9709 F1_train:0.9313 AUC_train:0.9728\n",
      "acc_val:0.8090 pre_val:0.7458 recall_val:0.9565 F1_val:0.838095 AUC_val:0.8969\n",
      "Epoch:0058\n",
      "acc_train:0.9288 pre_train:0.8953 recall_train:0.9757 F1_train:0.9338 AUC_train:0.9634\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.8837\n",
      "Epoch:0059\n",
      "acc_train:0.9376 pre_train:0.9114 recall_train:0.9733 F1_train:0.9413 AUC_train:0.9768\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.8751\n",
      "Epoch:0060\n",
      "acc_train:0.9513 pre_train:0.9210 recall_train:0.9903 F1_train:0.9544 AUC_train:0.9790\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.8655\n",
      "Epoch:0061\n",
      "acc_train:0.9363 pre_train:0.9056 recall_train:0.9782 F1_train:0.9405 AUC_train:0.9631\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.8660\n",
      "Epoch:0062\n",
      "acc_train:0.9426 pre_train:0.9103 recall_train:0.9854 F1_train:0.9464 AUC_train:0.9705\n",
      "acc_val:0.7753 pre_val:0.7097 recall_val:0.9565 F1_val:0.814815 AUC_val:0.8645\n",
      "Epoch:0063\n",
      "acc_train:0.9376 pre_train:0.9095 recall_train:0.9757 F1_train:0.9415 AUC_train:0.9722\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.8640\n",
      "Epoch:0064\n",
      "acc_train:0.9526 pre_train:0.9309 recall_train:0.9806 F1_train:0.9551 AUC_train:0.9785\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.8670\n",
      "Epoch:0065\n",
      "acc_train:0.9451 pre_train:0.9182 recall_train:0.9806 F1_train:0.9484 AUC_train:0.9764\n",
      "acc_val:0.7303 pre_val:0.6618 recall_val:0.9783 F1_val:0.789474 AUC_val:0.8731\n",
      "Epoch:0066\n",
      "acc_train:0.9551 pre_train:0.9352 recall_train:0.9806 F1_train:0.9573 AUC_train:0.9764\n",
      "acc_val:0.7303 pre_val:0.6618 recall_val:0.9783 F1_val:0.789474 AUC_val:0.8746\n",
      "Epoch:0067\n",
      "acc_train:0.9526 pre_train:0.9289 recall_train:0.9830 F1_train:0.9552 AUC_train:0.9805\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.8797\n",
      "Epoch:0068\n",
      "acc_train:0.9488 pre_train:0.9169 recall_train:0.9903 F1_train:0.9522 AUC_train:0.9706\n",
      "acc_val:0.6854 pre_val:0.6250 recall_val:0.9783 F1_val:0.762712 AUC_val:0.8802\n",
      "Epoch:0069\n",
      "acc_train:0.9501 pre_train:0.9247 recall_train:0.9830 F1_train:0.9529 AUC_train:0.9765\n",
      "acc_val:0.6966 pre_val:0.6301 recall_val:1.0000 F1_val:0.773109 AUC_val:0.8842\n",
      "Epoch:0070\n",
      "acc_train:0.9600 pre_train:0.9419 recall_train:0.9830 F1_train:0.9620 AUC_train:0.9783\n",
      "acc_val:0.6966 pre_val:0.6338 recall_val:0.9783 F1_val:0.769231 AUC_val:0.8883\n",
      "Epoch:0071\n",
      "acc_train:0.9513 pre_train:0.9268 recall_train:0.9830 F1_train:0.9541 AUC_train:0.9776\n",
      "acc_val:0.7191 pre_val:0.6479 recall_val:1.0000 F1_val:0.786325 AUC_val:0.8938\n",
      "Epoch:0072\n",
      "acc_train:0.9438 pre_train:0.9161 recall_train:0.9806 F1_train:0.9472 AUC_train:0.9881\n",
      "acc_val:0.7191 pre_val:0.6479 recall_val:1.0000 F1_val:0.786325 AUC_val:0.8943\n",
      "Epoch:0073\n",
      "acc_train:0.9488 pre_train:0.9169 recall_train:0.9903 F1_train:0.9522 AUC_train:0.9781\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:1.0000 F1_val:0.800000 AUC_val:0.8911\n",
      "Epoch:0074\n",
      "acc_train:0.9526 pre_train:0.9309 recall_train:0.9806 F1_train:0.9551 AUC_train:0.9785\n",
      "acc_val:0.7416 pre_val:0.6667 recall_val:1.0000 F1_val:0.800000 AUC_val:0.8923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0075\n",
      "acc_train:0.9588 pre_train:0.9376 recall_train:0.9854 F1_train:0.9609 AUC_train:0.9883\n",
      "acc_val:0.7303 pre_val:0.6618 recall_val:0.9783 F1_val:0.789474 AUC_val:0.8953\n",
      "Early Stopping!!! epoch：74\n",
      " Starting the 5-3 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4295 pre_train:0.4627 recall_train:0.6772 F1_train:0.5498 AUC_train:0.4092\n",
      "acc_val:0.4831 pre_val:0.5000 recall_val:0.8261 F1_val:0.622951 AUC_val:0.4903\n",
      "Epoch:0002\n",
      "acc_train:0.4407 pre_train:0.4714 recall_train:0.7209 F1_train:0.5701 AUC_train:0.4209\n",
      "acc_val:0.4494 pre_val:0.4516 recall_val:0.3043 F1_val:0.363636 AUC_val:0.3888\n",
      "Epoch:0003\n",
      "acc_train:0.4707 pre_train:0.4895 recall_train:0.6820 F1_train:0.5700 AUC_train:0.4881\n",
      "acc_val:0.5056 pre_val:0.5455 recall_val:0.2609 F1_val:0.352941 AUC_val:0.4382\n",
      "Epoch:0004\n",
      "acc_train:0.4582 pre_train:0.4823 recall_train:0.7257 F1_train:0.5795 AUC_train:0.4636\n",
      "acc_val:0.5281 pre_val:0.5909 recall_val:0.2826 F1_val:0.382353 AUC_val:0.5106\n",
      "Epoch:0005\n",
      "acc_train:0.5056 pre_train:0.5412 recall_train:0.2549 F1_train:0.3465 AUC_train:0.4834\n",
      "acc_val:0.5618 pre_val:0.6522 recall_val:0.3261 F1_val:0.434783 AUC_val:0.5693\n",
      "Epoch:0006\n",
      "acc_train:0.5156 pre_train:0.5741 recall_train:0.2257 F1_train:0.3240 AUC_train:0.4820\n",
      "acc_val:0.5393 pre_val:0.6190 recall_val:0.2826 F1_val:0.388060 AUC_val:0.5758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0007\n",
      "acc_train:0.5730 pre_train:0.6606 recall_train:0.3495 F1_train:0.4571 AUC_train:0.5740\n",
      "acc_val:0.5506 pre_val:0.6364 recall_val:0.3043 F1_val:0.411765 AUC_val:0.5671\n",
      "Epoch:0008\n",
      "acc_train:0.5456 pre_train:0.7034 recall_train:0.2015 F1_train:0.3132 AUC_train:0.5504\n",
      "acc_val:0.5506 pre_val:0.6364 recall_val:0.3043 F1_val:0.411765 AUC_val:0.5712\n",
      "Epoch:0009\n",
      "acc_train:0.5306 pre_train:0.5687 recall_train:0.3617 F1_train:0.4421 AUC_train:0.5051\n",
      "acc_val:0.5618 pre_val:0.6522 recall_val:0.3261 F1_val:0.434783 AUC_val:0.5818\n",
      "Epoch:0010\n",
      "acc_train:0.5655 pre_train:0.6975 recall_train:0.2743 F1_train:0.3937 AUC_train:0.5656\n",
      "acc_val:0.5618 pre_val:0.6522 recall_val:0.3261 F1_val:0.434783 AUC_val:0.5909\n",
      "Epoch:0011\n",
      "acc_train:0.5556 pre_train:0.6867 recall_train:0.2500 F1_train:0.3665 AUC_train:0.5639\n",
      "acc_val:0.5730 pre_val:0.6667 recall_val:0.3478 F1_val:0.457143 AUC_val:0.5959\n",
      "Epoch:0012\n",
      "acc_train:0.5605 pre_train:0.6515 recall_train:0.3131 F1_train:0.4230 AUC_train:0.5799\n",
      "acc_val:0.5730 pre_val:0.6667 recall_val:0.3478 F1_val:0.457143 AUC_val:0.6020\n",
      "Epoch:0013\n",
      "acc_train:0.5593 pre_train:0.6855 recall_train:0.2646 F1_train:0.3818 AUC_train:0.5581\n",
      "acc_val:0.5618 pre_val:0.6400 recall_val:0.3478 F1_val:0.450704 AUC_val:0.6111\n",
      "Epoch:0014\n",
      "acc_train:0.5468 pre_train:0.6522 recall_train:0.2549 F1_train:0.3665 AUC_train:0.5860\n",
      "acc_val:0.5730 pre_val:0.6538 recall_val:0.3696 F1_val:0.472222 AUC_val:0.6212\n",
      "Epoch:0015\n",
      "acc_train:0.5568 pre_train:0.6863 recall_train:0.2549 F1_train:0.3717 AUC_train:0.6094\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6263\n",
      "Epoch:0016\n",
      "acc_train:0.5718 pre_train:0.7197 recall_train:0.2743 F1_train:0.3972 AUC_train:0.6406\n",
      "acc_val:0.5730 pre_val:0.6538 recall_val:0.3696 F1_val:0.472222 AUC_val:0.6349\n",
      "Epoch:0017\n",
      "acc_train:0.5593 pre_train:0.6335 recall_train:0.3398 F1_train:0.4423 AUC_train:0.5623\n",
      "acc_val:0.5955 pre_val:0.6786 recall_val:0.4130 F1_val:0.513514 AUC_val:0.6374\n",
      "Epoch:0018\n",
      "acc_train:0.5680 pre_train:0.6331 recall_train:0.3811 F1_train:0.4758 AUC_train:0.5619\n",
      "acc_val:0.5955 pre_val:0.6786 recall_val:0.4130 F1_val:0.513514 AUC_val:0.6440\n",
      "Epoch:0019\n",
      "acc_train:0.5780 pre_train:0.6796 recall_train:0.3398 F1_train:0.4531 AUC_train:0.6054\n",
      "acc_val:0.5955 pre_val:0.6667 recall_val:0.4348 F1_val:0.526316 AUC_val:0.6490\n",
      "Epoch:0020\n",
      "acc_train:0.5556 pre_train:0.5645 recall_train:0.5947 F1_train:0.5792 AUC_train:0.5764\n",
      "acc_val:0.6067 pre_val:0.6774 recall_val:0.4565 F1_val:0.545455 AUC_val:0.6596\n",
      "Epoch:0021\n",
      "acc_train:0.5705 pre_train:0.6006 recall_train:0.4927 F1_train:0.5413 AUC_train:0.5690\n",
      "acc_val:0.6067 pre_val:0.6774 recall_val:0.4565 F1_val:0.545455 AUC_val:0.6601\n",
      "Epoch:0022\n",
      "acc_train:0.5818 pre_train:0.6935 recall_train:0.3350 F1_train:0.4517 AUC_train:0.5817\n",
      "acc_val:0.6067 pre_val:0.6774 recall_val:0.4565 F1_val:0.545455 AUC_val:0.6617\n",
      "Epoch:0023\n",
      "acc_train:0.5081 pre_train:0.5132 recall_train:0.8495 F1_train:0.6399 AUC_train:0.5478\n",
      "acc_val:0.6067 pre_val:0.6667 recall_val:0.4783 F1_val:0.556962 AUC_val:0.6606\n",
      "Epoch:0024\n",
      "acc_train:0.6092 pre_train:0.6552 recall_train:0.5073 F1_train:0.5718 AUC_train:0.6202\n",
      "acc_val:0.6067 pre_val:0.6667 recall_val:0.4783 F1_val:0.556962 AUC_val:0.6593\n",
      "Epoch:0025\n",
      "acc_train:0.5581 pre_train:0.6510 recall_train:0.3034 F1_train:0.4139 AUC_train:0.5996\n",
      "acc_val:0.5843 pre_val:0.6552 recall_val:0.4130 F1_val:0.506667 AUC_val:0.6617\n",
      "Epoch:0026\n",
      "acc_train:0.5668 pre_train:0.6633 recall_train:0.3204 F1_train:0.4321 AUC_train:0.6074\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6596\n",
      "Epoch:0027\n",
      "acc_train:0.4906 pre_train:0.5029 recall_train:0.8544 F1_train:0.6331 AUC_train:0.5658\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6561\n",
      "Epoch:0028\n",
      "acc_train:0.5443 pre_train:0.5545 recall_train:0.5801 F1_train:0.5670 AUC_train:0.5617\n",
      "acc_val:0.5955 pre_val:0.6786 recall_val:0.4130 F1_val:0.513514 AUC_val:0.6587\n",
      "Epoch:0029\n",
      "acc_train:0.5556 pre_train:0.6818 recall_train:0.2549 F1_train:0.3710 AUC_train:0.6032\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6557\n",
      "Epoch:0030\n",
      "acc_train:0.6030 pre_train:0.6374 recall_train:0.5291 F1_train:0.5782 AUC_train:0.6289\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6582\n",
      "Epoch:0031\n",
      "acc_train:0.5968 pre_train:0.6138 recall_train:0.5825 F1_train:0.5978 AUC_train:0.6276\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6618\n",
      "Epoch:0032\n",
      "acc_train:0.5718 pre_train:0.6806 recall_train:0.3155 F1_train:0.4312 AUC_train:0.5792\n",
      "acc_val:0.5730 pre_val:0.6667 recall_val:0.3478 F1_val:0.457143 AUC_val:0.6643\n",
      "Epoch:0033\n",
      "acc_train:0.5805 pre_train:0.6696 recall_train:0.3641 F1_train:0.4717 AUC_train:0.5952\n",
      "acc_val:0.5393 pre_val:0.6190 recall_val:0.2826 F1_val:0.388060 AUC_val:0.6628\n",
      "Epoch:0034\n",
      "acc_train:0.4944 pre_train:0.5052 recall_train:0.8325 F1_train:0.6288 AUC_train:0.5567\n",
      "acc_val:0.5281 pre_val:0.6000 recall_val:0.2609 F1_val:0.363636 AUC_val:0.6618\n",
      "Epoch:0035\n",
      "acc_train:0.5830 pre_train:0.6773 recall_train:0.3617 F1_train:0.4715 AUC_train:0.6259\n",
      "acc_val:0.5393 pre_val:0.6190 recall_val:0.2826 F1_val:0.388060 AUC_val:0.6527\n",
      "Epoch:0036\n",
      "acc_train:0.5755 pre_train:0.6837 recall_train:0.3252 F1_train:0.4408 AUC_train:0.6481\n",
      "acc_val:0.5281 pre_val:0.6000 recall_val:0.2609 F1_val:0.363636 AUC_val:0.6527\n",
      "Epoch:0037\n",
      "acc_train:0.5668 pre_train:0.6796 recall_train:0.2985 F1_train:0.4148 AUC_train:0.6099\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6507\n",
      "Epoch:0038\n",
      "acc_train:0.4931 pre_train:0.5042 recall_train:0.8835 F1_train:0.6420 AUC_train:0.5693\n",
      "acc_val:0.5281 pre_val:0.6000 recall_val:0.2609 F1_val:0.363636 AUC_val:0.6537\n",
      "Epoch:0039\n",
      "acc_train:0.5156 pre_train:0.5178 recall_train:0.8495 F1_train:0.6434 AUC_train:0.5761\n",
      "acc_val:0.5281 pre_val:0.6000 recall_val:0.2609 F1_val:0.363636 AUC_val:0.6552\n",
      "Epoch:0040\n",
      "acc_train:0.5768 pre_train:0.6667 recall_train:0.3544 F1_train:0.4628 AUC_train:0.6257\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6547\n",
      "Epoch:0041\n",
      "acc_train:0.5568 pre_train:0.6557 recall_train:0.2913 F1_train:0.4034 AUC_train:0.5940\n",
      "acc_val:0.4944 pre_val:0.5294 recall_val:0.1957 F1_val:0.285714 AUC_val:0.6522\n",
      "Epoch:0042\n",
      "acc_train:0.5605 pre_train:0.6613 recall_train:0.2985 F1_train:0.4114 AUC_train:0.5886\n",
      "acc_val:0.4944 pre_val:0.5294 recall_val:0.1957 F1_val:0.285714 AUC_val:0.6466\n",
      "Epoch:0043\n",
      "acc_train:0.5718 pre_train:0.6885 recall_train:0.3058 F1_train:0.4235 AUC_train:0.6255\n",
      "acc_val:0.4944 pre_val:0.5294 recall_val:0.1957 F1_val:0.285714 AUC_val:0.6456\n",
      "Epoch:0044\n",
      "acc_train:0.5693 pre_train:0.6573 recall_train:0.3398 F1_train:0.4480 AUC_train:0.5847\n",
      "acc_val:0.4944 pre_val:0.5294 recall_val:0.1957 F1_val:0.285714 AUC_val:0.6496\n",
      "Epoch:0045\n",
      "acc_train:0.5506 pre_train:0.6444 recall_train:0.2816 F1_train:0.3919 AUC_train:0.5928\n",
      "acc_val:0.4831 pre_val:0.5000 recall_val:0.1739 F1_val:0.258065 AUC_val:0.6517\n",
      "Epoch:0046\n",
      "acc_train:0.5830 pre_train:0.6625 recall_train:0.3859 F1_train:0.4877 AUC_train:0.6112\n",
      "acc_val:0.4944 pre_val:0.5294 recall_val:0.1957 F1_val:0.285714 AUC_val:0.6456\n",
      "Epoch:0047\n",
      "acc_train:0.5618 pre_train:0.6848 recall_train:0.2743 F1_train:0.3917 AUC_train:0.5749\n",
      "acc_val:0.4944 pre_val:0.5294 recall_val:0.1957 F1_val:0.285714 AUC_val:0.6481\n",
      "Epoch:0048\n",
      "acc_train:0.5743 pre_train:0.6919 recall_train:0.3107 F1_train:0.4288 AUC_train:0.6255\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6481\n",
      "Epoch:0049\n",
      "acc_train:0.5718 pre_train:0.6825 recall_train:0.3131 F1_train:0.4293 AUC_train:0.5751\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6411\n",
      "Epoch:0050\n",
      "acc_train:0.5893 pre_train:0.7044 recall_train:0.3471 F1_train:0.4650 AUC_train:0.5979\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6413\n",
      "Epoch:0051\n",
      "acc_train:0.5680 pre_train:0.6854 recall_train:0.2961 F1_train:0.4136 AUC_train:0.6201\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6416\n",
      "Epoch:0052\n",
      "acc_train:0.5905 pre_train:0.6641 recall_train:0.4126 F1_train:0.5090 AUC_train:0.6088\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6345\n",
      "Epoch:0053\n",
      "acc_train:0.6030 pre_train:0.6691 recall_train:0.4515 F1_train:0.5391 AUC_train:0.6029\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0054\n",
      "acc_train:0.5805 pre_train:0.6881 recall_train:0.3374 F1_train:0.4528 AUC_train:0.6213\n",
      "acc_val:0.5618 pre_val:0.6522 recall_val:0.3261 F1_val:0.434783 AUC_val:0.6112\n",
      "Epoch:0055\n",
      "acc_train:0.5019 pre_train:0.5103 recall_train:0.7816 F1_train:0.6174 AUC_train:0.5653\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6072\n",
      "Epoch:0056\n",
      "acc_train:0.6042 pre_train:0.6834 recall_train:0.4296 F1_train:0.5276 AUC_train:0.5967\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6001\n",
      "Epoch:0057\n",
      "acc_train:0.5868 pre_train:0.6588 recall_train:0.4078 F1_train:0.5037 AUC_train:0.6046\n",
      "acc_val:0.5393 pre_val:0.6190 recall_val:0.2826 F1_val:0.388060 AUC_val:0.6072\n",
      "Epoch:0058\n",
      "acc_train:0.5206 pre_train:0.5228 recall_train:0.7791 F1_train:0.6257 AUC_train:0.6139\n",
      "acc_val:0.5730 pre_val:0.6667 recall_val:0.3478 F1_val:0.457143 AUC_val:0.6092\n",
      "Epoch:0059\n",
      "acc_train:0.5094 pre_train:0.5147 recall_train:0.8058 F1_train:0.6282 AUC_train:0.5510\n",
      "acc_val:0.5506 pre_val:0.6364 recall_val:0.3043 F1_val:0.411765 AUC_val:0.6057\n",
      "Epoch:0060\n",
      "acc_train:0.5119 pre_train:0.5152 recall_train:0.8641 F1_train:0.6455 AUC_train:0.5771\n",
      "acc_val:0.5393 pre_val:0.6190 recall_val:0.2826 F1_val:0.388060 AUC_val:0.6112\n",
      "Epoch:0061\n",
      "acc_train:0.5718 pre_train:0.6520 recall_train:0.3592 F1_train:0.4632 AUC_train:0.5816\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6127\n",
      "Epoch:0062\n",
      "acc_train:0.5531 pre_train:0.5513 recall_train:0.7039 F1_train:0.6183 AUC_train:0.6080\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6127\n",
      "Epoch:0063\n",
      "acc_train:0.5980 pre_train:0.7228 recall_train:0.3544 F1_train:0.4756 AUC_train:0.6163\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6193\n",
      "Epoch:0064\n",
      "acc_train:0.5705 pre_train:0.6753 recall_train:0.3180 F1_train:0.4323 AUC_train:0.6034\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6213\n",
      "Epoch:0065\n",
      "acc_train:0.5630 pre_train:0.6667 recall_train:0.3010 F1_train:0.4147 AUC_train:0.5971\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6325\n",
      "Epoch:0066\n",
      "acc_train:0.5593 pre_train:0.6372 recall_train:0.3325 F1_train:0.4370 AUC_train:0.5914\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6370\n",
      "Epoch:0067\n",
      "acc_train:0.5655 pre_train:0.6818 recall_train:0.2913 F1_train:0.4082 AUC_train:0.6072\n",
      "acc_val:0.5056 pre_val:0.5556 recall_val:0.2174 F1_val:0.312500 AUC_val:0.6380\n",
      "Epoch:0068\n",
      "acc_train:0.5893 pre_train:0.7128 recall_train:0.3374 F1_train:0.4580 AUC_train:0.5985\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6436\n",
      "Epoch:0069\n",
      "acc_train:0.5718 pre_train:0.6927 recall_train:0.3010 F1_train:0.4196 AUC_train:0.6395\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6491\n",
      "Epoch:0070\n",
      "acc_train:0.5655 pre_train:0.6778 recall_train:0.2961 F1_train:0.4122 AUC_train:0.6447\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6522\n",
      "Epoch:0071\n",
      "acc_train:0.6017 pre_train:0.7048 recall_train:0.3883 F1_train:0.5008 AUC_train:0.6575\n",
      "acc_val:0.5169 pre_val:0.5789 recall_val:0.2391 F1_val:0.338462 AUC_val:0.6582\n",
      "Epoch:0072\n",
      "acc_train:0.5805 pre_train:0.7043 recall_train:0.3180 F1_train:0.4381 AUC_train:0.6605\n",
      "acc_val:0.5506 pre_val:0.6364 recall_val:0.3043 F1_val:0.411765 AUC_val:0.6476\n",
      "Epoch:0073\n",
      "acc_train:0.5893 pre_train:0.6895 recall_train:0.3665 F1_train:0.4786 AUC_train:0.6736\n",
      "acc_val:0.5618 pre_val:0.6522 recall_val:0.3261 F1_val:0.434783 AUC_val:0.6466\n",
      "Epoch:0074\n",
      "acc_train:0.6230 pre_train:0.7273 recall_train:0.4272 F1_train:0.5382 AUC_train:0.6779\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6416\n",
      "Epoch:0075\n",
      "acc_train:0.6242 pre_train:0.6521 recall_train:0.5777 F1_train:0.6126 AUC_train:0.6503\n",
      "acc_val:0.5955 pre_val:0.6786 recall_val:0.4130 F1_val:0.513514 AUC_val:0.6395\n",
      "Epoch:0076\n",
      "acc_train:0.6042 pre_train:0.7039 recall_train:0.3981 F1_train:0.5085 AUC_train:0.6333\n",
      "acc_val:0.5955 pre_val:0.6786 recall_val:0.4130 F1_val:0.513514 AUC_val:0.6350\n",
      "Epoch:0077\n",
      "acc_train:0.5930 pre_train:0.6777 recall_train:0.3981 F1_train:0.5015 AUC_train:0.6230\n",
      "acc_val:0.5955 pre_val:0.6786 recall_val:0.4130 F1_val:0.513514 AUC_val:0.6416\n",
      "Epoch:0078\n",
      "acc_train:0.6055 pre_train:0.6655 recall_train:0.4684 F1_train:0.5499 AUC_train:0.6589\n",
      "acc_val:0.5955 pre_val:0.6786 recall_val:0.4130 F1_val:0.513514 AUC_val:0.6491\n",
      "Epoch:0079\n",
      "acc_train:0.6617 pre_train:0.6850 recall_train:0.6335 F1_train:0.6583 AUC_train:0.7024\n",
      "acc_val:0.5955 pre_val:0.6786 recall_val:0.4130 F1_val:0.513514 AUC_val:0.6486\n",
      "Epoch:0080\n",
      "acc_train:0.6292 pre_train:0.7046 recall_train:0.4806 F1_train:0.5714 AUC_train:0.7118\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6466\n",
      "Epoch:0081\n",
      "acc_train:0.6017 pre_train:0.7163 recall_train:0.3738 F1_train:0.4912 AUC_train:0.7020\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6476\n",
      "Epoch:0082\n",
      "acc_train:0.6192 pre_train:0.6390 recall_train:0.5971 F1_train:0.6173 AUC_train:0.6642\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6562\n",
      "Epoch:0083\n",
      "acc_train:0.6342 pre_train:0.6776 recall_train:0.5510 F1_train:0.6078 AUC_train:0.6854\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6684\n",
      "Epoch:0084\n",
      "acc_train:0.6667 pre_train:0.7126 recall_train:0.5898 F1_train:0.6454 AUC_train:0.7153\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6800\n",
      "Epoch:0085\n",
      "acc_train:0.6592 pre_train:0.7405 recall_train:0.5194 F1_train:0.6106 AUC_train:0.7298\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6734\n",
      "Epoch:0086\n",
      "acc_train:0.6504 pre_train:0.7324 recall_train:0.5049 F1_train:0.5977 AUC_train:0.7215\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6673\n",
      "Epoch:0087\n",
      "acc_train:0.6804 pre_train:0.7635 recall_train:0.5485 F1_train:0.6384 AUC_train:0.7161\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6517\n",
      "Epoch:0088\n",
      "acc_train:0.6704 pre_train:0.7643 recall_train:0.5194 F1_train:0.6185 AUC_train:0.7385\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6502\n",
      "Epoch:0089\n",
      "acc_train:0.6792 pre_train:0.7575 recall_train:0.5534 F1_train:0.6396 AUC_train:0.7245\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6567\n",
      "Epoch:0090\n",
      "acc_train:0.6866 pre_train:0.7320 recall_train:0.6165 F1_train:0.6693 AUC_train:0.7392\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6714\n",
      "Epoch:0091\n",
      "acc_train:0.6792 pre_train:0.7645 recall_train:0.5437 F1_train:0.6355 AUC_train:0.7679\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6709\n",
      "Epoch:0092\n",
      "acc_train:0.6879 pre_train:0.7664 recall_train:0.5655 F1_train:0.6508 AUC_train:0.7607\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6891\n",
      "Epoch:0093\n",
      "acc_train:0.6916 pre_train:0.7915 recall_train:0.5437 F1_train:0.6446 AUC_train:0.7788\n",
      "acc_val:0.5843 pre_val:0.6667 recall_val:0.3913 F1_val:0.493151 AUC_val:0.6957\n",
      "Epoch:0094\n",
      "acc_train:0.7004 pre_train:0.7945 recall_train:0.5631 F1_train:0.6591 AUC_train:0.7838\n",
      "acc_val:0.5730 pre_val:0.6538 recall_val:0.3696 F1_val:0.472222 AUC_val:0.6982\n",
      "Epoch:0095\n",
      "acc_train:0.7041 pre_train:0.7709 recall_train:0.6044 F1_train:0.6776 AUC_train:0.7879\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6924\n",
      "Epoch:0096\n",
      "acc_train:0.7104 pre_train:0.8169 recall_train:0.5631 F1_train:0.6667 AUC_train:0.8029\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6775\n",
      "Epoch:0097\n",
      "acc_train:0.7104 pre_train:0.8103 recall_train:0.5704 F1_train:0.6695 AUC_train:0.7991\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6860\n",
      "Epoch:0098\n",
      "acc_train:0.7004 pre_train:0.8162 recall_train:0.5388 F1_train:0.6491 AUC_train:0.8143\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.6946\n",
      "Epoch:0099\n",
      "acc_train:0.6854 pre_train:0.8306 recall_train:0.4879 F1_train:0.6147 AUC_train:0.8281\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.7083\n",
      "Epoch:0100\n",
      "acc_train:0.7016 pre_train:0.8192 recall_train:0.5388 F1_train:0.6501 AUC_train:0.7968\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.7078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0101\n",
      "acc_train:0.6954 pre_train:0.8281 recall_train:0.5146 F1_train:0.6347 AUC_train:0.8047\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.7204\n",
      "Epoch:0102\n",
      "acc_train:0.7004 pre_train:0.8007 recall_train:0.5558 F1_train:0.6562 AUC_train:0.7933\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.7199\n",
      "Epoch:0103\n",
      "acc_train:0.7341 pre_train:0.8284 recall_train:0.6092 F1_train:0.7021 AUC_train:0.8383\n",
      "acc_val:0.5843 pre_val:0.6800 recall_val:0.3696 F1_val:0.478873 AUC_val:0.7199\n",
      "Epoch:0104\n",
      "acc_train:0.6991 pre_train:0.8608 recall_train:0.4951 F1_train:0.6287 AUC_train:0.8096\n",
      "acc_val:0.6742 pre_val:0.7429 recall_val:0.5652 F1_val:0.641975 AUC_val:0.7209\n",
      "Epoch:0105\n",
      "acc_train:0.7041 pre_train:0.8114 recall_train:0.5534 F1_train:0.6580 AUC_train:0.8220\n",
      "acc_val:0.6742 pre_val:0.7576 recall_val:0.5435 F1_val:0.632911 AUC_val:0.7245\n",
      "Epoch:0106\n",
      "acc_train:0.7403 pre_train:0.8269 recall_train:0.6262 F1_train:0.7127 AUC_train:0.8345\n",
      "acc_val:0.6742 pre_val:0.7576 recall_val:0.5435 F1_val:0.632911 AUC_val:0.7260\n",
      "Epoch:0107\n",
      "acc_train:0.7091 pre_train:0.8118 recall_train:0.5655 F1_train:0.6667 AUC_train:0.8289\n",
      "acc_val:0.6629 pre_val:0.7500 recall_val:0.5217 F1_val:0.615385 AUC_val:0.7270\n",
      "Epoch:0108\n",
      "acc_train:0.7179 pre_train:0.8121 recall_train:0.5874 F1_train:0.6817 AUC_train:0.8220\n",
      "acc_val:0.6404 pre_val:0.7333 recall_val:0.4783 F1_val:0.578947 AUC_val:0.7189\n",
      "Epoch:0109\n",
      "acc_train:0.7366 pre_train:0.8407 recall_train:0.6019 F1_train:0.7016 AUC_train:0.8210\n",
      "acc_val:0.6517 pre_val:0.7419 recall_val:0.5000 F1_val:0.597403 AUC_val:0.7204\n",
      "Epoch:0110\n",
      "acc_train:0.6966 pre_train:0.8165 recall_train:0.5291 F1_train:0.6421 AUC_train:0.8248\n",
      "acc_val:0.7079 pre_val:0.7778 recall_val:0.6087 F1_val:0.682927 AUC_val:0.7270\n",
      "Epoch:0111\n",
      "acc_train:0.7316 pre_train:0.8432 recall_train:0.5874 F1_train:0.6924 AUC_train:0.8578\n",
      "acc_val:0.6966 pre_val:0.7714 recall_val:0.5870 F1_val:0.666667 AUC_val:0.7366\n",
      "Epoch:0112\n",
      "acc_train:0.7228 pre_train:0.8442 recall_train:0.5655 F1_train:0.6773 AUC_train:0.8481\n",
      "acc_val:0.6966 pre_val:0.7568 recall_val:0.6087 F1_val:0.674699 AUC_val:0.7356\n",
      "Epoch:0113\n",
      "acc_train:0.7154 pre_train:0.8262 recall_train:0.5655 F1_train:0.6715 AUC_train:0.8387\n",
      "acc_val:0.6966 pre_val:0.7568 recall_val:0.6087 F1_val:0.674699 AUC_val:0.7406\n",
      "Epoch:0114\n",
      "acc_train:0.7328 pre_train:0.8322 recall_train:0.6019 F1_train:0.6986 AUC_train:0.8658\n",
      "acc_val:0.7079 pre_val:0.7632 recall_val:0.6304 F1_val:0.690476 AUC_val:0.7457\n",
      "Epoch:0115\n",
      "acc_train:0.7416 pre_train:0.8339 recall_train:0.6214 F1_train:0.7121 AUC_train:0.8526\n",
      "acc_val:0.7303 pre_val:0.7895 recall_val:0.6522 F1_val:0.714286 AUC_val:0.7482\n",
      "Epoch:0116\n",
      "acc_train:0.7129 pre_train:0.8227 recall_train:0.5631 F1_train:0.6686 AUC_train:0.8312\n",
      "acc_val:0.7191 pre_val:0.7838 recall_val:0.6304 F1_val:0.698795 AUC_val:0.7492\n",
      "Epoch:0117\n",
      "acc_train:0.7341 pre_train:0.8699 recall_train:0.5680 F1_train:0.6872 AUC_train:0.8452\n",
      "acc_val:0.6966 pre_val:0.7568 recall_val:0.6087 F1_val:0.674699 AUC_val:0.7482\n",
      "Epoch:0118\n",
      "acc_train:0.7453 pre_train:0.8741 recall_train:0.5898 F1_train:0.7043 AUC_train:0.8660\n",
      "acc_val:0.6966 pre_val:0.7568 recall_val:0.6087 F1_val:0.674699 AUC_val:0.7497\n",
      "Epoch:0119\n",
      "acc_train:0.7203 pre_train:0.8561 recall_train:0.5485 F1_train:0.6686 AUC_train:0.8607\n",
      "acc_val:0.7079 pre_val:0.7632 recall_val:0.6304 F1_val:0.690476 AUC_val:0.7533\n",
      "Epoch:0120\n",
      "acc_train:0.7253 pre_train:0.9034 recall_train:0.5218 F1_train:0.6615 AUC_train:0.8489\n",
      "acc_val:0.7303 pre_val:0.7619 recall_val:0.6957 F1_val:0.727273 AUC_val:0.7629\n",
      "Epoch:0121\n",
      "acc_train:0.7478 pre_train:0.8646 recall_train:0.6044 F1_train:0.7114 AUC_train:0.8671\n",
      "acc_val:0.7191 pre_val:0.7442 recall_val:0.6957 F1_val:0.719101 AUC_val:0.7811\n",
      "Epoch:0122\n",
      "acc_train:0.7316 pre_train:0.8481 recall_train:0.5825 F1_train:0.6906 AUC_train:0.8578\n",
      "acc_val:0.7191 pre_val:0.7442 recall_val:0.6957 F1_val:0.719101 AUC_val:0.7846\n",
      "Epoch:0123\n",
      "acc_train:0.7266 pre_train:0.8316 recall_train:0.5874 F1_train:0.6885 AUC_train:0.8432\n",
      "acc_val:0.7191 pre_val:0.7442 recall_val:0.6957 F1_val:0.719101 AUC_val:0.7791\n",
      "Epoch:0124\n",
      "acc_train:0.7353 pre_train:0.8401 recall_train:0.5995 F1_train:0.6997 AUC_train:0.8653\n",
      "acc_val:0.7303 pre_val:0.7619 recall_val:0.6957 F1_val:0.727273 AUC_val:0.7811\n",
      "Epoch:0125\n",
      "acc_train:0.7291 pre_train:0.8445 recall_train:0.5801 F1_train:0.6878 AUC_train:0.8531\n",
      "acc_val:0.7191 pre_val:0.7561 recall_val:0.6739 F1_val:0.712644 AUC_val:0.7781\n",
      "Epoch:0126\n",
      "acc_train:0.7366 pre_train:0.8502 recall_train:0.5922 F1_train:0.6981 AUC_train:0.8532\n",
      "acc_val:0.7191 pre_val:0.7561 recall_val:0.6739 F1_val:0.712644 AUC_val:0.7725\n",
      "Epoch:0127\n",
      "acc_train:0.7603 pre_train:0.8503 recall_train:0.6481 F1_train:0.7355 AUC_train:0.8707\n",
      "acc_val:0.7191 pre_val:0.7561 recall_val:0.6739 F1_val:0.712644 AUC_val:0.7674\n",
      "Epoch:0128\n",
      "acc_train:0.7266 pre_train:0.8459 recall_train:0.5728 F1_train:0.6831 AUC_train:0.8642\n",
      "acc_val:0.7191 pre_val:0.7561 recall_val:0.6739 F1_val:0.712644 AUC_val:0.7583\n",
      "Epoch:0129\n",
      "acc_train:0.7253 pre_train:0.8478 recall_train:0.5680 F1_train:0.6802 AUC_train:0.8593\n",
      "acc_val:0.7079 pre_val:0.7500 recall_val:0.6522 F1_val:0.697674 AUC_val:0.7548\n",
      "Epoch:0130\n",
      "acc_train:0.7391 pre_train:0.8691 recall_train:0.5801 F1_train:0.6958 AUC_train:0.8602\n",
      "acc_val:0.7191 pre_val:0.7561 recall_val:0.6739 F1_val:0.712644 AUC_val:0.7644\n",
      "Epoch:0131\n",
      "acc_train:0.7503 pre_train:0.8510 recall_train:0.6238 F1_train:0.7199 AUC_train:0.8580\n",
      "acc_val:0.7191 pre_val:0.7561 recall_val:0.6739 F1_val:0.712644 AUC_val:0.7624\n",
      "Epoch:0132\n",
      "acc_train:0.7591 pre_train:0.8544 recall_train:0.6408 F1_train:0.7323 AUC_train:0.8755\n",
      "acc_val:0.7191 pre_val:0.7561 recall_val:0.6739 F1_val:0.712644 AUC_val:0.7700\n",
      "Epoch:0133\n",
      "acc_train:0.7116 pre_train:0.8755 recall_train:0.5121 F1_train:0.6462 AUC_train:0.8576\n",
      "acc_val:0.6966 pre_val:0.7317 recall_val:0.6522 F1_val:0.689655 AUC_val:0.7639\n",
      "Epoch:0134\n",
      "acc_train:0.7615 pre_train:0.8379 recall_train:0.6650 F1_train:0.7415 AUC_train:0.8645\n",
      "acc_val:0.6966 pre_val:0.7317 recall_val:0.6522 F1_val:0.689655 AUC_val:0.7563\n",
      "Epoch:0135\n",
      "acc_train:0.7528 pre_train:0.8474 recall_train:0.6335 F1_train:0.7250 AUC_train:0.8675\n",
      "acc_val:0.7079 pre_val:0.7381 recall_val:0.6739 F1_val:0.704545 AUC_val:0.7558\n",
      "Epoch:0136\n",
      "acc_train:0.7416 pre_train:0.8498 recall_train:0.6044 F1_train:0.7064 AUC_train:0.8783\n",
      "acc_val:0.7079 pre_val:0.7381 recall_val:0.6739 F1_val:0.704545 AUC_val:0.7553\n",
      "Epoch:0137\n",
      "acc_train:0.7628 pre_train:0.8513 recall_train:0.6529 F1_train:0.7390 AUC_train:0.8847\n",
      "acc_val:0.7079 pre_val:0.7381 recall_val:0.6739 F1_val:0.704545 AUC_val:0.7629\n",
      "Epoch:0138\n",
      "acc_train:0.7603 pre_train:0.8548 recall_train:0.6432 F1_train:0.7341 AUC_train:0.8823\n",
      "acc_val:0.6966 pre_val:0.7209 recall_val:0.6739 F1_val:0.696629 AUC_val:0.7654\n",
      "Epoch:0139\n",
      "acc_train:0.7291 pre_train:0.8239 recall_train:0.6019 F1_train:0.6957 AUC_train:0.8564\n",
      "acc_val:0.6966 pre_val:0.7209 recall_val:0.6739 F1_val:0.696629 AUC_val:0.7659\n",
      "Epoch:0140\n",
      "acc_train:0.7466 pre_train:0.8667 recall_train:0.5995 F1_train:0.7088 AUC_train:0.8665\n",
      "acc_val:0.6854 pre_val:0.7143 recall_val:0.6522 F1_val:0.681818 AUC_val:0.7664\n",
      "Epoch:0141\n",
      "acc_train:0.7591 pre_train:0.8638 recall_train:0.6311 F1_train:0.7293 AUC_train:0.8918\n",
      "acc_val:0.6966 pre_val:0.7317 recall_val:0.6522 F1_val:0.689655 AUC_val:0.7659\n",
      "Epoch:0142\n",
      "acc_train:0.7615 pre_train:0.8553 recall_train:0.6456 F1_train:0.7358 AUC_train:0.8699\n",
      "acc_val:0.6854 pre_val:0.7368 recall_val:0.6087 F1_val:0.666667 AUC_val:0.7649\n",
      "Epoch:0143\n",
      "acc_train:0.7503 pre_train:0.8533 recall_train:0.6214 F1_train:0.7191 AUC_train:0.8868\n",
      "acc_val:0.6966 pre_val:0.7568 recall_val:0.6087 F1_val:0.674699 AUC_val:0.7690\n",
      "Epoch:0144\n",
      "acc_train:0.7366 pre_train:0.8602 recall_train:0.5825 F1_train:0.6946 AUC_train:0.8740\n",
      "acc_val:0.6742 pre_val:0.7429 recall_val:0.5652 F1_val:0.641975 AUC_val:0.7730\n",
      "Epoch:0145\n",
      "acc_train:0.7516 pre_train:0.8492 recall_train:0.6286 F1_train:0.7225 AUC_train:0.8814\n",
      "acc_val:0.6629 pre_val:0.7353 recall_val:0.5435 F1_val:0.625000 AUC_val:0.7690\n",
      "Epoch:0146\n",
      "acc_train:0.7653 pre_train:0.8415 recall_train:0.6699 F1_train:0.7459 AUC_train:0.8832\n",
      "acc_val:0.6742 pre_val:0.7297 recall_val:0.5870 F1_val:0.650602 AUC_val:0.7755\n",
      "Epoch:0147\n",
      "acc_train:0.7603 pre_train:0.8691 recall_train:0.6286 F1_train:0.7296 AUC_train:0.8878\n",
      "acc_val:0.6742 pre_val:0.7179 recall_val:0.6087 F1_val:0.658824 AUC_val:0.7740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0148\n",
      "acc_train:0.7890 pre_train:0.8738 recall_train:0.6893 F1_train:0.7707 AUC_train:0.8910\n",
      "acc_val:0.6854 pre_val:0.7250 recall_val:0.6304 F1_val:0.674419 AUC_val:0.7760\n",
      "Epoch:0149\n",
      "acc_train:0.7665 pre_train:0.8689 recall_train:0.6432 F1_train:0.7392 AUC_train:0.8850\n",
      "acc_val:0.6742 pre_val:0.7179 recall_val:0.6087 F1_val:0.658824 AUC_val:0.7816\n",
      "Epoch:0150\n",
      "acc_train:0.7640 pre_train:0.8704 recall_train:0.6359 F1_train:0.7349 AUC_train:0.8860\n",
      "acc_val:0.6966 pre_val:0.7436 recall_val:0.6304 F1_val:0.682353 AUC_val:0.7902\n",
      "Epoch:0151\n",
      "acc_train:0.7553 pre_train:0.8724 recall_train:0.6141 F1_train:0.7208 AUC_train:0.8879\n",
      "acc_val:0.6629 pre_val:0.7222 recall_val:0.5652 F1_val:0.634146 AUC_val:0.7821\n",
      "Epoch:0152\n",
      "acc_train:0.7778 pre_train:0.8849 recall_train:0.6529 F1_train:0.7514 AUC_train:0.9135\n",
      "acc_val:0.6742 pre_val:0.7179 recall_val:0.6087 F1_val:0.658824 AUC_val:0.7846\n",
      "Epoch:0153\n",
      "acc_train:0.7578 pre_train:0.9067 recall_train:0.5898 F1_train:0.7147 AUC_train:0.8853\n",
      "acc_val:0.6742 pre_val:0.7179 recall_val:0.6087 F1_val:0.658824 AUC_val:0.7639\n",
      "Epoch:0154\n",
      "acc_train:0.7853 pre_train:0.8774 recall_train:0.6772 F1_train:0.7644 AUC_train:0.8921\n",
      "acc_val:0.6629 pre_val:0.7105 recall_val:0.5870 F1_val:0.642857 AUC_val:0.7578\n",
      "Epoch:0155\n",
      "acc_train:0.7703 pre_train:0.8725 recall_train:0.6481 F1_train:0.7437 AUC_train:0.8975\n",
      "acc_val:0.6517 pre_val:0.6923 recall_val:0.5870 F1_val:0.635294 AUC_val:0.7563\n",
      "Epoch:0156\n",
      "acc_train:0.7503 pre_train:0.8869 recall_train:0.5898 F1_train:0.7085 AUC_train:0.8872\n",
      "acc_val:0.6292 pre_val:0.6757 recall_val:0.5435 F1_val:0.602410 AUC_val:0.7513\n",
      "Epoch:0157\n",
      "acc_train:0.7828 pre_train:0.8673 recall_train:0.6820 F1_train:0.7636 AUC_train:0.9053\n",
      "acc_val:0.6067 pre_val:0.6667 recall_val:0.4783 F1_val:0.556962 AUC_val:0.7467\n",
      "Epoch:0158\n",
      "acc_train:0.7603 pre_train:0.8595 recall_train:0.6383 F1_train:0.7326 AUC_train:0.8902\n",
      "acc_val:0.5955 pre_val:0.6562 recall_val:0.4565 F1_val:0.538462 AUC_val:0.7427\n",
      "Epoch:0159\n",
      "acc_train:0.7578 pre_train:0.8865 recall_train:0.6068 F1_train:0.7205 AUC_train:0.9032\n",
      "acc_val:0.6180 pre_val:0.7000 recall_val:0.4565 F1_val:0.552632 AUC_val:0.7492\n",
      "Epoch:0160\n",
      "acc_train:0.7740 pre_train:0.8787 recall_train:0.6505 F1_train:0.7476 AUC_train:0.8982\n",
      "acc_val:0.6067 pre_val:0.6774 recall_val:0.4565 F1_val:0.545455 AUC_val:0.7508\n",
      "Epoch:0161\n",
      "acc_train:0.7790 pre_train:0.8778 recall_train:0.6626 F1_train:0.7552 AUC_train:0.9056\n",
      "acc_val:0.6067 pre_val:0.6774 recall_val:0.4565 F1_val:0.545455 AUC_val:0.7553\n",
      "Epoch:0162\n",
      "acc_train:0.7728 pre_train:0.8758 recall_train:0.6505 F1_train:0.7465 AUC_train:0.9050\n",
      "acc_val:0.6292 pre_val:0.6970 recall_val:0.5000 F1_val:0.582278 AUC_val:0.7573\n",
      "Epoch:0163\n",
      "acc_train:0.7603 pre_train:0.8741 recall_train:0.6238 F1_train:0.7280 AUC_train:0.9109\n",
      "acc_val:0.6292 pre_val:0.6970 recall_val:0.5000 F1_val:0.582278 AUC_val:0.7629\n",
      "Epoch:0164\n",
      "acc_train:0.7665 pre_train:0.8617 recall_train:0.6505 F1_train:0.7414 AUC_train:0.9131\n",
      "acc_val:0.6404 pre_val:0.7059 recall_val:0.5217 F1_val:0.600000 AUC_val:0.7664\n",
      "Epoch:0165\n",
      "acc_train:0.7965 pre_train:0.8854 recall_train:0.6942 F1_train:0.7782 AUC_train:0.9118\n",
      "acc_val:0.6404 pre_val:0.7059 recall_val:0.5217 F1_val:0.600000 AUC_val:0.7674\n",
      "Epoch:0166\n",
      "acc_train:0.7865 pre_train:0.8731 recall_train:0.6845 F1_train:0.7673 AUC_train:0.9106\n",
      "acc_val:0.6404 pre_val:0.7059 recall_val:0.5217 F1_val:0.600000 AUC_val:0.7700\n",
      "Epoch:0167\n",
      "acc_train:0.7840 pre_train:0.8918 recall_train:0.6602 F1_train:0.7587 AUC_train:0.9163\n",
      "acc_val:0.6517 pre_val:0.7143 recall_val:0.5435 F1_val:0.617284 AUC_val:0.7720\n",
      "Epoch:0168\n",
      "acc_train:0.7715 pre_train:0.8881 recall_train:0.6359 F1_train:0.7412 AUC_train:0.9117\n",
      "acc_val:0.6629 pre_val:0.7353 recall_val:0.5435 F1_val:0.625000 AUC_val:0.7801\n",
      "Epoch:0169\n",
      "acc_train:0.7890 pre_train:0.8932 recall_train:0.6699 F1_train:0.7656 AUC_train:0.9123\n",
      "acc_val:0.6629 pre_val:0.7500 recall_val:0.5217 F1_val:0.615385 AUC_val:0.8003\n",
      "Epoch:0170\n",
      "acc_train:0.7903 pre_train:0.8910 recall_train:0.6748 F1_train:0.7680 AUC_train:0.9133\n",
      "acc_val:0.6629 pre_val:0.7500 recall_val:0.5217 F1_val:0.615385 AUC_val:0.8064\n",
      "Epoch:0171\n",
      "acc_train:0.8040 pre_train:0.8923 recall_train:0.7039 F1_train:0.7870 AUC_train:0.9248\n",
      "acc_val:0.6742 pre_val:0.7576 recall_val:0.5435 F1_val:0.632911 AUC_val:0.8074\n",
      "Epoch:0172\n",
      "acc_train:0.7915 pre_train:0.8840 recall_train:0.6845 F1_train:0.7715 AUC_train:0.9169\n",
      "acc_val:0.6742 pre_val:0.7576 recall_val:0.5435 F1_val:0.632911 AUC_val:0.8089\n",
      "Epoch:0173\n",
      "acc_train:0.8027 pre_train:0.9071 recall_train:0.6869 F1_train:0.7818 AUC_train:0.9223\n",
      "acc_val:0.6854 pre_val:0.7812 recall_val:0.5435 F1_val:0.641026 AUC_val:0.8165\n",
      "Epoch:0174\n",
      "acc_train:0.8027 pre_train:0.8757 recall_train:0.7184 F1_train:0.7893 AUC_train:0.9138\n",
      "acc_val:0.6854 pre_val:0.7647 recall_val:0.5652 F1_val:0.650000 AUC_val:0.8140\n",
      "Epoch:0175\n",
      "acc_train:0.7890 pre_train:0.8932 recall_train:0.6699 F1_train:0.7656 AUC_train:0.9154\n",
      "acc_val:0.6742 pre_val:0.7297 recall_val:0.5870 F1_val:0.650602 AUC_val:0.8059\n",
      "Epoch:0176\n",
      "acc_train:0.7953 pre_train:0.9052 recall_train:0.6723 F1_train:0.7716 AUC_train:0.9307\n",
      "acc_val:0.6742 pre_val:0.7576 recall_val:0.5435 F1_val:0.632911 AUC_val:0.7963\n",
      "Epoch:0177\n",
      "acc_train:0.8102 pre_train:0.8824 recall_train:0.7282 F1_train:0.7979 AUC_train:0.9360\n",
      "acc_val:0.6742 pre_val:0.7576 recall_val:0.5435 F1_val:0.632911 AUC_val:0.7917\n",
      "Epoch:0178\n",
      "acc_train:0.8152 pre_train:0.8976 recall_train:0.7233 F1_train:0.8011 AUC_train:0.9272\n",
      "acc_val:0.6966 pre_val:0.7879 recall_val:0.5652 F1_val:0.658228 AUC_val:0.8119\n",
      "Epoch:0179\n",
      "acc_train:0.8127 pre_train:0.9068 recall_train:0.7087 F1_train:0.7956 AUC_train:0.9374\n",
      "acc_val:0.6966 pre_val:0.8065 recall_val:0.5435 F1_val:0.649351 AUC_val:0.8215\n",
      "Epoch:0180\n",
      "acc_train:0.8265 pre_train:0.9149 recall_train:0.7306 F1_train:0.8124 AUC_train:0.9413\n",
      "acc_val:0.6966 pre_val:0.8519 recall_val:0.5000 F1_val:0.630137 AUC_val:0.8327\n",
      "Epoch:0181\n",
      "acc_train:0.8352 pre_train:0.9217 recall_train:0.7427 F1_train:0.8226 AUC_train:0.9394\n",
      "acc_val:0.6966 pre_val:0.8519 recall_val:0.5000 F1_val:0.630137 AUC_val:0.8367\n",
      "Epoch:0182\n",
      "acc_train:0.8439 pre_train:0.8975 recall_train:0.7864 F1_train:0.8383 AUC_train:0.9310\n",
      "acc_val:0.6966 pre_val:0.8519 recall_val:0.5000 F1_val:0.630137 AUC_val:0.8332\n",
      "Epoch:0183\n",
      "acc_train:0.8402 pre_train:0.9277 recall_train:0.7476 F1_train:0.8280 AUC_train:0.9449\n",
      "acc_val:0.7191 pre_val:0.8621 recall_val:0.5435 F1_val:0.666667 AUC_val:0.8322\n",
      "Epoch:0184\n",
      "acc_train:0.8390 pre_train:0.9125 recall_train:0.7597 F1_train:0.8291 AUC_train:0.9410\n",
      "acc_val:0.7303 pre_val:0.8667 recall_val:0.5652 F1_val:0.684211 AUC_val:0.8251\n",
      "Epoch:0185\n",
      "acc_train:0.8077 pre_train:0.9640 recall_train:0.6505 F1_train:0.7768 AUC_train:0.9437\n",
      "acc_val:0.6966 pre_val:0.8065 recall_val:0.5435 F1_val:0.649351 AUC_val:0.8119\n",
      "Epoch:0186\n",
      "acc_train:0.8527 pre_train:0.9594 recall_train:0.7451 F1_train:0.8388 AUC_train:0.9623\n",
      "acc_val:0.7303 pre_val:0.8235 recall_val:0.6087 F1_val:0.700000 AUC_val:0.8089\n",
      "Epoch:0187\n",
      "acc_train:0.8527 pre_train:0.9401 recall_train:0.7621 F1_train:0.8418 AUC_train:0.9469\n",
      "acc_val:0.7303 pre_val:0.8235 recall_val:0.6087 F1_val:0.700000 AUC_val:0.8059\n",
      "Epoch:0188\n",
      "acc_train:0.8514 pre_train:0.9373 recall_train:0.7621 F1_train:0.8407 AUC_train:0.9551\n",
      "acc_val:0.7191 pre_val:0.8000 recall_val:0.6087 F1_val:0.691358 AUC_val:0.7988\n",
      "Epoch:0189\n",
      "acc_train:0.8702 pre_train:0.9503 recall_train:0.7888 F1_train:0.8621 AUC_train:0.9641\n",
      "acc_val:0.7079 pre_val:0.7778 recall_val:0.6087 F1_val:0.682927 AUC_val:0.7983\n",
      "Epoch:0190\n",
      "acc_train:0.8502 pre_train:0.9591 recall_train:0.7403 F1_train:0.8356 AUC_train:0.9668\n",
      "acc_val:0.6966 pre_val:0.7568 recall_val:0.6087 F1_val:0.674699 AUC_val:0.7917\n",
      "Epoch:0191\n",
      "acc_train:0.8801 pre_train:0.9270 recall_train:0.8325 F1_train:0.8772 AUC_train:0.9582\n",
      "acc_val:0.7191 pre_val:0.8000 recall_val:0.6087 F1_val:0.691358 AUC_val:0.8220\n",
      "Epoch:0192\n",
      "acc_train:0.8826 pre_train:0.9492 recall_train:0.8155 F1_train:0.8773 AUC_train:0.9594\n",
      "acc_val:0.7640 pre_val:0.8788 recall_val:0.6304 F1_val:0.734177 AUC_val:0.8215\n",
      "Epoch:0193\n",
      "acc_train:0.8989 pre_train:0.9559 recall_train:0.8422 F1_train:0.8955 AUC_train:0.9665\n",
      "acc_val:0.7528 pre_val:0.8750 recall_val:0.6087 F1_val:0.717949 AUC_val:0.8271\n",
      "Epoch:0194\n",
      "acc_train:0.9064 pre_train:0.9332 recall_train:0.8811 F1_train:0.9064 AUC_train:0.9671\n",
      "acc_val:0.7416 pre_val:0.8485 recall_val:0.6087 F1_val:0.708861 AUC_val:0.8261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0195\n",
      "acc_train:0.9039 pre_train:0.9539 recall_train:0.8544 F1_train:0.9014 AUC_train:0.9720\n",
      "acc_val:0.7528 pre_val:0.8333 recall_val:0.6522 F1_val:0.731707 AUC_val:0.8327\n",
      "Epoch:0196\n",
      "acc_train:0.8939 pre_train:0.9431 recall_train:0.8447 F1_train:0.8912 AUC_train:0.9584\n",
      "acc_val:0.7416 pre_val:0.7949 recall_val:0.6739 F1_val:0.729412 AUC_val:0.8327\n",
      "Epoch:0197\n",
      "acc_train:0.9213 pre_train:0.9604 recall_train:0.8835 F1_train:0.9204 AUC_train:0.9779\n",
      "acc_val:0.7303 pre_val:0.7619 recall_val:0.6957 F1_val:0.727273 AUC_val:0.8011\n",
      "Epoch:0198\n",
      "acc_train:0.8851 pre_train:0.9420 recall_train:0.8277 F1_train:0.8811 AUC_train:0.9682\n",
      "acc_val:0.7303 pre_val:0.7619 recall_val:0.6957 F1_val:0.727273 AUC_val:0.7973\n",
      "Epoch:0199\n",
      "acc_train:0.9001 pre_train:0.9439 recall_train:0.8568 F1_train:0.8982 AUC_train:0.9668\n",
      "acc_val:0.7528 pre_val:0.8158 recall_val:0.6739 F1_val:0.738095 AUC_val:0.8296\n",
      "Epoch:0200\n",
      "acc_train:0.9213 pre_train:0.9463 recall_train:0.8981 F1_train:0.9215 AUC_train:0.9734\n",
      "acc_val:0.7753 pre_val:0.8611 recall_val:0.6739 F1_val:0.756098 AUC_val:0.8377\n",
      " Starting the 5-4 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.4956 pre_train:0.5069 recall_train:0.7160 F1_train:0.5936 AUC_train:0.5093\n",
      "acc_val:0.5056 pre_val:0.5500 recall_val:0.2391 F1_val:0.333333 AUC_val:0.4596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0002\n",
      "acc_train:0.5206 pre_train:0.5248 recall_train:0.7184 F1_train:0.6066 AUC_train:0.5439\n",
      "acc_val:0.5618 pre_val:0.6000 recall_val:0.4565 F1_val:0.518519 AUC_val:0.5581\n",
      "Epoch:0003\n",
      "acc_train:0.5318 pre_train:0.5356 recall_train:0.6748 F1_train:0.5972 AUC_train:0.5451\n",
      "acc_val:0.5730 pre_val:0.6111 recall_val:0.4783 F1_val:0.536585 AUC_val:0.5834\n",
      "Epoch:0004\n",
      "acc_train:0.5918 pre_train:0.5832 recall_train:0.7233 F1_train:0.6457 AUC_train:0.6202\n",
      "acc_val:0.5730 pre_val:0.5952 recall_val:0.5435 F1_val:0.568182 AUC_val:0.5551\n",
      "Epoch:0005\n",
      "acc_train:0.5680 pre_train:0.5637 recall_train:0.7087 F1_train:0.6280 AUC_train:0.5808\n",
      "acc_val:0.6067 pre_val:0.6571 recall_val:0.5000 F1_val:0.567901 AUC_val:0.5809\n",
      "Epoch:0006\n",
      "acc_train:0.5955 pre_train:0.5880 recall_train:0.7136 F1_train:0.6447 AUC_train:0.6186\n",
      "acc_val:0.6180 pre_val:0.7000 recall_val:0.4565 F1_val:0.552632 AUC_val:0.6122\n",
      "Epoch:0007\n",
      "acc_train:0.5718 pre_train:0.5670 recall_train:0.7087 F1_train:0.6300 AUC_train:0.6258\n",
      "acc_val:0.6180 pre_val:0.7000 recall_val:0.4565 F1_val:0.552632 AUC_val:0.6132\n",
      "Epoch:0008\n",
      "acc_train:0.6417 pre_train:0.6506 recall_train:0.6553 F1_train:0.6530 AUC_train:0.6876\n",
      "acc_val:0.6067 pre_val:0.6897 recall_val:0.4348 F1_val:0.533333 AUC_val:0.6117\n",
      "Epoch:0009\n",
      "acc_train:0.6217 pre_train:0.6193 recall_train:0.6869 F1_train:0.6513 AUC_train:0.6409\n",
      "acc_val:0.5955 pre_val:0.6667 recall_val:0.4348 F1_val:0.526316 AUC_val:0.6087\n",
      "Epoch:0010\n",
      "acc_train:0.6517 pre_train:0.6455 recall_train:0.7160 F1_train:0.6789 AUC_train:0.6870\n",
      "acc_val:0.6180 pre_val:0.6875 recall_val:0.4783 F1_val:0.564103 AUC_val:0.6345\n",
      "Epoch:0011\n",
      "acc_train:0.6692 pre_train:0.6763 recall_train:0.6845 F1_train:0.6803 AUC_train:0.7349\n",
      "acc_val:0.6180 pre_val:0.6875 recall_val:0.4783 F1_val:0.564103 AUC_val:0.6507\n",
      "Epoch:0012\n",
      "acc_train:0.6479 pre_train:0.6512 recall_train:0.6796 F1_train:0.6651 AUC_train:0.6992\n",
      "acc_val:0.6180 pre_val:0.6875 recall_val:0.4783 F1_val:0.564103 AUC_val:0.6436\n",
      "Epoch:0013\n",
      "acc_train:0.6704 pre_train:0.6859 recall_train:0.6626 F1_train:0.6741 AUC_train:0.7199\n",
      "acc_val:0.6292 pre_val:0.6970 recall_val:0.5000 F1_val:0.582278 AUC_val:0.6552\n",
      "Epoch:0014\n",
      "acc_train:0.7041 pre_train:0.6984 recall_train:0.7476 F1_train:0.7222 AUC_train:0.7305\n",
      "acc_val:0.6292 pre_val:0.6970 recall_val:0.5000 F1_val:0.582278 AUC_val:0.6805\n",
      "Epoch:0015\n",
      "acc_train:0.6841 pre_train:0.6828 recall_train:0.7209 F1_train:0.7013 AUC_train:0.7459\n",
      "acc_val:0.6517 pre_val:0.7143 recall_val:0.5435 F1_val:0.617284 AUC_val:0.6886\n",
      "Epoch:0016\n",
      "acc_train:0.6754 pre_train:0.6617 recall_train:0.7549 F1_train:0.7052 AUC_train:0.7122\n",
      "acc_val:0.6629 pre_val:0.7222 recall_val:0.5652 F1_val:0.634146 AUC_val:0.6921\n",
      "Epoch:0017\n",
      "acc_train:0.7241 pre_train:0.7226 recall_train:0.7524 F1_train:0.7372 AUC_train:0.7900\n",
      "acc_val:0.6742 pre_val:0.7297 recall_val:0.5870 F1_val:0.650602 AUC_val:0.6977\n",
      "Epoch:0018\n",
      "acc_train:0.7278 pre_train:0.7195 recall_train:0.7718 F1_train:0.7447 AUC_train:0.7943\n",
      "acc_val:0.6966 pre_val:0.7568 recall_val:0.6087 F1_val:0.674699 AUC_val:0.7053\n",
      "Epoch:0019\n",
      "acc_train:0.7416 pre_train:0.7389 recall_train:0.7694 F1_train:0.7539 AUC_train:0.7973\n",
      "acc_val:0.6854 pre_val:0.7250 recall_val:0.6304 F1_val:0.674419 AUC_val:0.7113\n",
      "Epoch:0020\n",
      "acc_train:0.7516 pre_train:0.7320 recall_train:0.8155 F1_train:0.7715 AUC_train:0.8062\n",
      "acc_val:0.7079 pre_val:0.7174 recall_val:0.7174 F1_val:0.717391 AUC_val:0.7214\n",
      "Epoch:0021\n",
      "acc_train:0.7391 pre_train:0.7312 recall_train:0.7791 F1_train:0.7544 AUC_train:0.7968\n",
      "acc_val:0.7191 pre_val:0.7234 recall_val:0.7391 F1_val:0.731183 AUC_val:0.7270\n",
      "Epoch:0022\n",
      "acc_train:0.7665 pre_train:0.7540 recall_train:0.8107 F1_train:0.7813 AUC_train:0.8228\n",
      "acc_val:0.6966 pre_val:0.6939 recall_val:0.7391 F1_val:0.715789 AUC_val:0.7240\n",
      "Epoch:0023\n",
      "acc_train:0.7603 pre_train:0.7423 recall_train:0.8180 F1_train:0.7783 AUC_train:0.8151\n",
      "acc_val:0.6966 pre_val:0.6939 recall_val:0.7391 F1_val:0.715789 AUC_val:0.7315\n",
      "Epoch:0024\n",
      "acc_train:0.7865 pre_train:0.7591 recall_train:0.8568 F1_train:0.8050 AUC_train:0.8507\n",
      "acc_val:0.6854 pre_val:0.6875 recall_val:0.7174 F1_val:0.702128 AUC_val:0.7326\n",
      "Epoch:0025\n",
      "acc_train:0.7878 pre_train:0.7642 recall_train:0.8495 F1_train:0.8046 AUC_train:0.8391\n",
      "acc_val:0.6966 pre_val:0.6939 recall_val:0.7391 F1_val:0.715789 AUC_val:0.7356\n",
      "Epoch:0026\n",
      "acc_train:0.7840 pre_train:0.7548 recall_train:0.8592 F1_train:0.8036 AUC_train:0.8418\n",
      "acc_val:0.7191 pre_val:0.7059 recall_val:0.7826 F1_val:0.742268 AUC_val:0.7518\n",
      "Epoch:0027\n",
      "acc_train:0.8152 pre_train:0.7727 recall_train:0.9078 F1_train:0.8348 AUC_train:0.8638\n",
      "acc_val:0.7416 pre_val:0.7170 recall_val:0.8261 F1_val:0.767677 AUC_val:0.7624\n",
      "Epoch:0028\n",
      "acc_train:0.8052 pre_train:0.7560 recall_train:0.9175 F1_train:0.8289 AUC_train:0.8583\n",
      "acc_val:0.7528 pre_val:0.7308 recall_val:0.8261 F1_val:0.775510 AUC_val:0.7674\n",
      "Epoch:0029\n",
      "acc_train:0.8227 pre_train:0.7700 recall_train:0.9345 F1_train:0.8443 AUC_train:0.8760\n",
      "acc_val:0.7416 pre_val:0.7091 recall_val:0.8478 F1_val:0.772277 AUC_val:0.7730\n",
      "Epoch:0030\n",
      "acc_train:0.8340 pre_train:0.7841 recall_train:0.9345 F1_train:0.8527 AUC_train:0.8666\n",
      "acc_val:0.7416 pre_val:0.6949 recall_val:0.8913 F1_val:0.780952 AUC_val:0.7796\n",
      "Epoch:0031\n",
      "acc_train:0.8065 pre_train:0.7485 recall_train:0.9393 F1_train:0.8332 AUC_train:0.8684\n",
      "acc_val:0.7416 pre_val:0.6949 recall_val:0.8913 F1_val:0.780952 AUC_val:0.7806\n",
      "Epoch:0032\n",
      "acc_train:0.8552 pre_train:0.8109 recall_train:0.9369 F1_train:0.8694 AUC_train:0.8998\n",
      "acc_val:0.7416 pre_val:0.6949 recall_val:0.8913 F1_val:0.780952 AUC_val:0.7796\n",
      "Epoch:0033\n",
      "acc_train:0.8290 pre_train:0.7778 recall_train:0.9345 F1_train:0.8490 AUC_train:0.8870\n",
      "acc_val:0.7640 pre_val:0.7193 recall_val:0.8913 F1_val:0.796117 AUC_val:0.7740\n",
      "Epoch:0034\n",
      "acc_train:0.8414 pre_train:0.7856 recall_train:0.9515 F1_train:0.8606 AUC_train:0.9014\n",
      "acc_val:0.7528 pre_val:0.7069 recall_val:0.8913 F1_val:0.788462 AUC_val:0.7690\n",
      "Epoch:0035\n",
      "acc_train:0.8539 pre_train:0.7956 recall_train:0.9636 F1_train:0.8716 AUC_train:0.9030\n",
      "acc_val:0.7753 pre_val:0.7321 recall_val:0.8913 F1_val:0.803922 AUC_val:0.7740\n",
      "Epoch:0036\n",
      "acc_train:0.8227 pre_train:0.7744 recall_train:0.9248 F1_train:0.8429 AUC_train:0.8932\n",
      "acc_val:0.7753 pre_val:0.7321 recall_val:0.8913 F1_val:0.803922 AUC_val:0.7770\n",
      "Epoch:0037\n",
      "acc_train:0.8452 pre_train:0.7880 recall_train:0.9563 F1_train:0.8640 AUC_train:0.9060\n",
      "acc_val:0.7416 pre_val:0.7018 recall_val:0.8696 F1_val:0.776699 AUC_val:0.7861\n",
      "Epoch:0038\n",
      "acc_train:0.8639 pre_train:0.8086 recall_train:0.9636 F1_train:0.8793 AUC_train:0.9250\n",
      "acc_val:0.7303 pre_val:0.6833 recall_val:0.8913 F1_val:0.773585 AUC_val:0.7922\n",
      "Epoch:0039\n",
      "acc_train:0.8614 pre_train:0.8078 recall_train:0.9587 F1_train:0.8768 AUC_train:0.9259\n",
      "acc_val:0.7416 pre_val:0.6885 recall_val:0.9130 F1_val:0.785047 AUC_val:0.8023\n",
      "Epoch:0040\n",
      "acc_train:0.8577 pre_train:0.8016 recall_train:0.9612 F1_train:0.8742 AUC_train:0.9291\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8119\n",
      "Epoch:0041\n",
      "acc_train:0.8589 pre_train:0.8032 recall_train:0.9612 F1_train:0.8751 AUC_train:0.9225\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8134\n",
      "Epoch:0042\n",
      "acc_train:0.8652 pre_train:0.8028 recall_train:0.9782 F1_train:0.8818 AUC_train:0.9169\n",
      "acc_val:0.7191 pre_val:0.6615 recall_val:0.9348 F1_val:0.774775 AUC_val:0.8160\n",
      "Epoch:0043\n",
      "acc_train:0.8677 pre_train:0.8135 recall_train:0.9636 F1_train:0.8822 AUC_train:0.9332\n",
      "acc_val:0.7191 pre_val:0.6567 recall_val:0.9565 F1_val:0.778761 AUC_val:0.8145\n",
      "Epoch:0044\n",
      "acc_train:0.8851 pre_train:0.8419 recall_train:0.9563 F1_train:0.8955 AUC_train:0.9463\n",
      "acc_val:0.7191 pre_val:0.6567 recall_val:0.9565 F1_val:0.778761 AUC_val:0.8119\n",
      "Epoch:0045\n",
      "acc_train:0.8752 pre_train:0.8291 recall_train:0.9539 F1_train:0.8871 AUC_train:0.9589\n",
      "acc_val:0.7079 pre_val:0.6471 recall_val:0.9565 F1_val:0.771930 AUC_val:0.8150\n",
      "Epoch:0046\n",
      "acc_train:0.8826 pre_train:0.8340 recall_train:0.9636 F1_train:0.8941 AUC_train:0.9498\n",
      "acc_val:0.7191 pre_val:0.6567 recall_val:0.9565 F1_val:0.778761 AUC_val:0.8210\n",
      "Epoch:0047\n",
      "acc_train:0.8914 pre_train:0.8525 recall_train:0.9539 F1_train:0.9003 AUC_train:0.9520\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.8236\n",
      "Epoch:0048\n",
      "acc_train:0.8864 pre_train:0.8337 recall_train:0.9733 F1_train:0.8981 AUC_train:0.9460\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0049\n",
      "acc_train:0.8976 pre_train:0.8526 recall_train:0.9684 F1_train:0.9068 AUC_train:0.9622\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.8271\n",
      "Epoch:0050\n",
      "acc_train:0.8876 pre_train:0.8368 recall_train:0.9709 F1_train:0.8989 AUC_train:0.9604\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.8301\n",
      "Epoch:0051\n",
      "acc_train:0.8889 pre_train:0.8330 recall_train:0.9806 F1_train:0.9008 AUC_train:0.9551\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.8357\n",
      "Epoch:0052\n",
      "acc_train:0.9064 pre_train:0.8608 recall_train:0.9757 F1_train:0.9147 AUC_train:0.9517\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.8392\n",
      "Epoch:0053\n",
      "acc_train:0.8976 pre_train:0.8603 recall_train:0.9563 F1_train:0.9057 AUC_train:0.9522\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.8387\n",
      "Epoch:0054\n",
      "acc_train:0.9039 pre_train:0.8618 recall_train:0.9684 F1_train:0.9120 AUC_train:0.9580\n",
      "acc_val:0.7191 pre_val:0.6615 recall_val:0.9348 F1_val:0.774775 AUC_val:0.8402\n",
      "Epoch:0055\n",
      "acc_train:0.9114 pre_train:0.8667 recall_train:0.9782 F1_train:0.9190 AUC_train:0.9553\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8377\n",
      "Epoch:0056\n",
      "acc_train:0.9026 pre_train:0.8646 recall_train:0.9612 F1_train:0.9103 AUC_train:0.9527\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8407\n",
      "Epoch:0057\n",
      "acc_train:0.9189 pre_train:0.8864 recall_train:0.9660 F1_train:0.9245 AUC_train:0.9605\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8407\n",
      "Epoch:0058\n",
      "acc_train:0.9126 pre_train:0.8670 recall_train:0.9806 F1_train:0.9203 AUC_train:0.9588\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8402\n",
      "Epoch:0059\n",
      "acc_train:0.9276 pre_train:0.8916 recall_train:0.9782 F1_train:0.9329 AUC_train:0.9664\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.8423\n",
      "Epoch:0060\n",
      "acc_train:0.9201 pre_train:0.8816 recall_train:0.9757 F1_train:0.9263 AUC_train:0.9655\n",
      "acc_val:0.7416 pre_val:0.6769 recall_val:0.9565 F1_val:0.792793 AUC_val:0.8407\n",
      "Epoch:0061\n",
      "acc_train:0.9313 pre_train:0.8889 recall_train:0.9903 F1_train:0.9369 AUC_train:0.9529\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.8458\n",
      "Epoch:0062\n",
      "acc_train:0.9288 pre_train:0.8850 recall_train:0.9903 F1_train:0.9347 AUC_train:0.9643\n",
      "acc_val:0.7528 pre_val:0.6765 recall_val:1.0000 F1_val:0.807018 AUC_val:0.8559\n",
      "Epoch:0063\n",
      "acc_train:0.9338 pre_train:0.8945 recall_train:0.9879 F1_train:0.9389 AUC_train:0.9675\n",
      "acc_val:0.7303 pre_val:0.6571 recall_val:1.0000 F1_val:0.793103 AUC_val:0.8675\n",
      "Epoch:0064\n",
      "acc_train:0.9426 pre_train:0.9067 recall_train:0.9903 F1_train:0.9466 AUC_train:0.9794\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.8837\n",
      "Epoch:0065\n",
      "acc_train:0.9413 pre_train:0.9138 recall_train:0.9782 F1_train:0.9449 AUC_train:0.9743\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.8943\n",
      "Epoch:0066\n",
      "acc_train:0.9401 pre_train:0.9194 recall_train:0.9684 F1_train:0.9433 AUC_train:0.9743\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.9050\n",
      "Epoch:0067\n",
      "acc_train:0.9251 pre_train:0.8894 recall_train:0.9757 F1_train:0.9306 AUC_train:0.9737\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.9110\n",
      "Epoch:0068\n",
      "acc_train:0.9401 pre_train:0.9062 recall_train:0.9854 F1_train:0.9442 AUC_train:0.9772\n",
      "acc_val:0.7191 pre_val:0.6567 recall_val:0.9565 F1_val:0.778761 AUC_val:0.9262\n",
      "Epoch:0069\n",
      "acc_train:0.9301 pre_train:0.8886 recall_train:0.9879 F1_train:0.9356 AUC_train:0.9761\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9323\n",
      "Epoch:0070\n",
      "acc_train:0.9326 pre_train:0.8943 recall_train:0.9854 F1_train:0.9376 AUC_train:0.9840\n",
      "acc_val:0.7416 pre_val:0.6769 recall_val:0.9565 F1_val:0.792793 AUC_val:0.9343\n",
      "Epoch:0071\n",
      "acc_train:0.9388 pre_train:0.9060 recall_train:0.9830 F1_train:0.9430 AUC_train:0.9808\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.9282\n",
      "Epoch:0072\n",
      "acc_train:0.9288 pre_train:0.8918 recall_train:0.9806 F1_train:0.9341 AUC_train:0.9731\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.9262\n",
      "Epoch:0073\n",
      "acc_train:0.9363 pre_train:0.8985 recall_train:0.9879 F1_train:0.9410 AUC_train:0.9715\n",
      "acc_val:0.7079 pre_val:0.6471 recall_val:0.9565 F1_val:0.771930 AUC_val:0.9267\n",
      "Epoch:0074\n",
      "acc_train:0.9376 pre_train:0.9004 recall_train:0.9879 F1_train:0.9421 AUC_train:0.9808\n",
      "acc_val:0.7079 pre_val:0.6471 recall_val:0.9565 F1_val:0.771930 AUC_val:0.9194\n",
      "Epoch:0075\n",
      "acc_train:0.9476 pre_train:0.9129 recall_train:0.9927 F1_train:0.9512 AUC_train:0.9767\n",
      "acc_val:0.7079 pre_val:0.6471 recall_val:0.9565 F1_val:0.771930 AUC_val:0.9201\n",
      "Epoch:0076\n",
      "acc_train:0.9413 pre_train:0.9047 recall_train:0.9903 F1_train:0.9455 AUC_train:0.9814\n",
      "acc_val:0.7079 pre_val:0.6429 recall_val:0.9783 F1_val:0.775862 AUC_val:0.9242\n",
      "Epoch:0077\n",
      "acc_train:0.9401 pre_train:0.9194 recall_train:0.9684 F1_train:0.9433 AUC_train:0.9826\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.9297\n",
      "Epoch:0078\n",
      "acc_train:0.9551 pre_train:0.9273 recall_train:0.9903 F1_train:0.9577 AUC_train:0.9757\n",
      "acc_val:0.7303 pre_val:0.6618 recall_val:0.9783 F1_val:0.789474 AUC_val:0.9312\n",
      "Epoch:0079\n",
      "acc_train:0.9476 pre_train:0.9129 recall_train:0.9927 F1_train:0.9512 AUC_train:0.9878\n",
      "acc_val:0.7191 pre_val:0.6567 recall_val:0.9565 F1_val:0.778761 AUC_val:0.9338\n",
      "Epoch:0080\n",
      "acc_train:0.9463 pre_train:0.9203 recall_train:0.9806 F1_train:0.9495 AUC_train:0.9761\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9338\n",
      "Epoch:0081\n",
      "acc_train:0.9526 pre_train:0.9250 recall_train:0.9879 F1_train:0.9554 AUC_train:0.9810\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9312\n",
      "Epoch:0082\n",
      "acc_train:0.9426 pre_train:0.9122 recall_train:0.9830 F1_train:0.9463 AUC_train:0.9771\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.9307\n",
      "Epoch:0083\n",
      "acc_train:0.9576 pre_train:0.9276 recall_train:0.9951 F1_train:0.9602 AUC_train:0.9783\n",
      "acc_val:0.7079 pre_val:0.6429 recall_val:0.9783 F1_val:0.775862 AUC_val:0.9312\n",
      "Epoch:0084\n",
      "acc_train:0.9488 pre_train:0.9206 recall_train:0.9854 F1_train:0.9519 AUC_train:0.9830\n",
      "acc_val:0.7079 pre_val:0.6429 recall_val:0.9783 F1_val:0.775862 AUC_val:0.9312\n",
      "Epoch:0085\n",
      "acc_train:0.9538 pre_train:0.9252 recall_train:0.9903 F1_train:0.9566 AUC_train:0.9823\n",
      "acc_val:0.7191 pre_val:0.6522 recall_val:0.9783 F1_val:0.782609 AUC_val:0.9323\n",
      "Epoch:0086\n",
      "acc_train:0.9476 pre_train:0.9129 recall_train:0.9927 F1_train:0.9512 AUC_train:0.9807\n",
      "acc_val:0.6966 pre_val:0.6377 recall_val:0.9565 F1_val:0.765217 AUC_val:0.9262\n",
      "Epoch:0087\n",
      "acc_train:0.9526 pre_train:0.9212 recall_train:0.9927 F1_train:0.9556 AUC_train:0.9831\n",
      "acc_val:0.6966 pre_val:0.6377 recall_val:0.9565 F1_val:0.765217 AUC_val:0.9237\n",
      "Epoch:0088\n",
      "acc_train:0.9638 pre_train:0.9485 recall_train:0.9830 F1_train:0.9654 AUC_train:0.9819\n",
      "acc_val:0.6966 pre_val:0.6377 recall_val:0.9565 F1_val:0.765217 AUC_val:0.9348\n",
      "Epoch:0089\n",
      "acc_train:0.9563 pre_train:0.9333 recall_train:0.9854 F1_train:0.9587 AUC_train:0.9833\n",
      "acc_val:0.7079 pre_val:0.6471 recall_val:0.9565 F1_val:0.771930 AUC_val:0.9383\n",
      "Epoch:0090\n",
      "acc_train:0.9526 pre_train:0.9269 recall_train:0.9854 F1_train:0.9553 AUC_train:0.9871\n",
      "acc_val:0.7079 pre_val:0.6471 recall_val:0.9565 F1_val:0.771930 AUC_val:0.9419\n",
      "Epoch:0091\n",
      "acc_train:0.9576 pre_train:0.9315 recall_train:0.9903 F1_train:0.9600 AUC_train:0.9879\n",
      "acc_val:0.7079 pre_val:0.6471 recall_val:0.9565 F1_val:0.771930 AUC_val:0.9434\n",
      "Epoch:0092\n",
      "acc_train:0.9576 pre_train:0.9375 recall_train:0.9830 F1_train:0.9597 AUC_train:0.9865\n",
      "acc_val:0.7079 pre_val:0.6471 recall_val:0.9565 F1_val:0.771930 AUC_val:0.9424\n",
      "Epoch:0093\n",
      "acc_train:0.9600 pre_train:0.9460 recall_train:0.9782 F1_train:0.9618 AUC_train:0.9881\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9424\n",
      "Epoch:0094\n",
      "acc_train:0.9563 pre_train:0.9255 recall_train:0.9951 F1_train:0.9591 AUC_train:0.9862\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9429\n",
      "Epoch:0095\n",
      "acc_train:0.9625 pre_train:0.9421 recall_train:0.9879 F1_train:0.9645 AUC_train:0.9866\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.9408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0096\n",
      "acc_train:0.9551 pre_train:0.9292 recall_train:0.9879 F1_train:0.9576 AUC_train:0.9817\n",
      "acc_val:0.7416 pre_val:0.6769 recall_val:0.9565 F1_val:0.792793 AUC_val:0.9403\n",
      "Epoch:0097\n",
      "acc_train:0.9638 pre_train:0.9402 recall_train:0.9927 F1_train:0.9658 AUC_train:0.9889\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.9328\n",
      "Epoch:0098\n",
      "acc_train:0.9588 pre_train:0.9356 recall_train:0.9879 F1_train:0.9610 AUC_train:0.9874\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.9312\n",
      "Epoch:0099\n",
      "acc_train:0.9613 pre_train:0.9441 recall_train:0.9830 F1_train:0.9631 AUC_train:0.9878\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.9262\n",
      "Epoch:0100\n",
      "acc_train:0.9625 pre_train:0.9381 recall_train:0.9927 F1_train:0.9646 AUC_train:0.9890\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.9307\n",
      "Epoch:0101\n",
      "acc_train:0.9625 pre_train:0.9463 recall_train:0.9830 F1_train:0.9643 AUC_train:0.9878\n",
      "acc_val:0.7416 pre_val:0.6769 recall_val:0.9565 F1_val:0.792793 AUC_val:0.9393\n",
      "Epoch:0102\n",
      "acc_train:0.9588 pre_train:0.9336 recall_train:0.9903 F1_train:0.9611 AUC_train:0.9846\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.9393\n",
      "Epoch:0103\n",
      "acc_train:0.9563 pre_train:0.9255 recall_train:0.9951 F1_train:0.9591 AUC_train:0.9885\n",
      "acc_val:0.7640 pre_val:0.6923 recall_val:0.9783 F1_val:0.810811 AUC_val:0.9302\n",
      "Epoch:0104\n",
      "acc_train:0.9563 pre_train:0.9314 recall_train:0.9879 F1_train:0.9588 AUC_train:0.9782\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.9282\n",
      "Epoch:0105\n",
      "acc_train:0.9563 pre_train:0.9314 recall_train:0.9879 F1_train:0.9588 AUC_train:0.9919\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.9267\n",
      "Epoch:0106\n",
      "acc_train:0.9663 pre_train:0.9446 recall_train:0.9927 F1_train:0.9680 AUC_train:0.9888\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.9232\n",
      "Epoch:0107\n",
      "acc_train:0.9675 pre_train:0.9447 recall_train:0.9951 F1_train:0.9693 AUC_train:0.9920\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.9201\n",
      "Epoch:0108\n",
      "acc_train:0.9563 pre_train:0.9333 recall_train:0.9854 F1_train:0.9587 AUC_train:0.9891\n",
      "acc_val:0.7416 pre_val:0.6716 recall_val:0.9783 F1_val:0.796460 AUC_val:0.9055\n",
      "Epoch:0109\n",
      "acc_train:0.9675 pre_train:0.9468 recall_train:0.9927 F1_train:0.9692 AUC_train:0.9875\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.9055\n",
      "Epoch:0110\n",
      "acc_train:0.9588 pre_train:0.9376 recall_train:0.9854 F1_train:0.9609 AUC_train:0.9882\n",
      "acc_val:0.7640 pre_val:0.6923 recall_val:0.9783 F1_val:0.810811 AUC_val:0.9120\n",
      "Epoch:0111\n",
      "acc_train:0.9625 pre_train:0.9505 recall_train:0.9782 F1_train:0.9641 AUC_train:0.9889\n",
      "acc_val:0.7640 pre_val:0.6923 recall_val:0.9783 F1_val:0.810811 AUC_val:0.9226\n",
      "Epoch:0112\n",
      "acc_train:0.9600 pre_train:0.9358 recall_train:0.9903 F1_train:0.9623 AUC_train:0.9881\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9257\n",
      "Epoch:0113\n",
      "acc_train:0.9563 pre_train:0.9314 recall_train:0.9879 F1_train:0.9588 AUC_train:0.9888\n",
      "acc_val:0.7640 pre_val:0.6923 recall_val:0.9783 F1_val:0.810811 AUC_val:0.9242\n",
      "Epoch:0114\n",
      "acc_train:0.9638 pre_train:0.9423 recall_train:0.9903 F1_train:0.9657 AUC_train:0.9897\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.9237\n",
      "Epoch:0115\n",
      "acc_train:0.9675 pre_train:0.9468 recall_train:0.9927 F1_train:0.9692 AUC_train:0.9864\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.9242\n",
      "Epoch:0116\n",
      "acc_train:0.9700 pre_train:0.9512 recall_train:0.9927 F1_train:0.9715 AUC_train:0.9874\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.9272\n",
      "Epoch:0117\n",
      "acc_train:0.9688 pre_train:0.9532 recall_train:0.9879 F1_train:0.9702 AUC_train:0.9920\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9287\n",
      "Epoch:0118\n",
      "acc_train:0.9688 pre_train:0.9490 recall_train:0.9927 F1_train:0.9703 AUC_train:0.9920\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9292\n",
      "Epoch:0119\n",
      "acc_train:0.9625 pre_train:0.9484 recall_train:0.9806 F1_train:0.9642 AUC_train:0.9906\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9307\n",
      "Epoch:0120\n",
      "acc_train:0.9713 pre_train:0.9555 recall_train:0.9903 F1_train:0.9726 AUC_train:0.9913\n",
      "acc_val:0.7303 pre_val:0.6667 recall_val:0.9565 F1_val:0.785714 AUC_val:0.9297\n",
      "Epoch:0121\n",
      "acc_train:0.9750 pre_train:0.9579 recall_train:0.9951 F1_train:0.9762 AUC_train:0.9951\n",
      "acc_val:0.7416 pre_val:0.6769 recall_val:0.9565 F1_val:0.792793 AUC_val:0.9363\n",
      "Epoch:0122\n",
      "acc_train:0.9663 pre_train:0.9487 recall_train:0.9879 F1_train:0.9679 AUC_train:0.9891\n",
      "acc_val:0.7528 pre_val:0.6875 recall_val:0.9565 F1_val:0.800000 AUC_val:0.9353\n",
      "Early Stopping!!! epoch：121\n",
      " Starting the 5-5 Fold:：\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 801\n",
      "Number of features selected 2000\n",
      "Epoch:0001\n",
      "acc_train:0.5356 pre_train:0.5500 recall_train:0.5340 F1_train:0.5419 AUC_train:0.5593\n",
      "acc_val:0.5169 pre_val:0.5200 recall_val:0.8478 F1_val:0.644628 AUC_val:0.5292\n",
      "Epoch:0002\n",
      "acc_train:0.5680 pre_train:0.5846 recall_train:0.5534 F1_train:0.5686 AUC_train:0.5943\n",
      "acc_val:0.4494 pre_val:0.4795 recall_val:0.7609 F1_val:0.588235 AUC_val:0.4564\n",
      "Epoch:0003\n",
      "acc_train:0.5743 pre_train:0.6156 recall_train:0.4587 F1_train:0.5257 AUC_train:0.5827\n",
      "acc_val:0.5056 pre_val:0.5125 recall_val:0.8913 F1_val:0.650794 AUC_val:0.4975\n",
      "Epoch:0004\n",
      "acc_train:0.5206 pre_train:0.5330 recall_train:0.5485 F1_train:0.5407 AUC_train:0.5298\n",
      "acc_val:0.5169 pre_val:0.5195 recall_val:0.8696 F1_val:0.650407 AUC_val:0.4772\n",
      "Epoch:0005\n",
      "acc_train:0.5493 pre_train:0.5578 recall_train:0.5971 F1_train:0.5768 AUC_train:0.5774\n",
      "acc_val:0.4831 pre_val:0.5000 recall_val:0.8261 F1_val:0.622951 AUC_val:0.4707\n",
      "Epoch:0006\n",
      "acc_train:0.5094 pre_train:0.5222 recall_train:0.5413 F1_train:0.5316 AUC_train:0.5267\n",
      "acc_val:0.4831 pre_val:0.5000 recall_val:0.8261 F1_val:0.622951 AUC_val:0.5308\n",
      "Epoch:0007\n",
      "acc_train:0.5368 pre_train:0.5455 recall_train:0.5971 F1_train:0.5701 AUC_train:0.5779\n",
      "acc_val:0.5281 pre_val:0.5263 recall_val:0.8696 F1_val:0.655738 AUC_val:0.5844\n",
      "Epoch:0008\n",
      "acc_train:0.5705 pre_train:0.5702 recall_train:0.6699 F1_train:0.6161 AUC_train:0.5825\n",
      "acc_val:0.5955 pre_val:0.5781 recall_val:0.8043 F1_val:0.672727 AUC_val:0.6486\n",
      "Epoch:0009\n",
      "acc_train:0.5643 pre_train:0.5755 recall_train:0.5825 F1_train:0.5790 AUC_train:0.5972\n",
      "acc_val:0.5955 pre_val:0.5833 recall_val:0.7609 F1_val:0.660377 AUC_val:0.6309\n",
      "Epoch:0010\n",
      "acc_train:0.6030 pre_train:0.6031 recall_train:0.6675 F1_train:0.6336 AUC_train:0.6309\n",
      "acc_val:0.5955 pre_val:0.5862 recall_val:0.7391 F1_val:0.653846 AUC_val:0.6304\n",
      "Epoch:0011\n",
      "acc_train:0.6055 pre_train:0.6039 recall_train:0.6772 F1_train:0.6384 AUC_train:0.6379\n",
      "acc_val:0.5843 pre_val:0.5763 recall_val:0.7391 F1_val:0.647619 AUC_val:0.6198\n",
      "Epoch:0012\n",
      "acc_train:0.5755 pre_train:0.5818 recall_train:0.6214 F1_train:0.6009 AUC_train:0.6199\n",
      "acc_val:0.6067 pre_val:0.6000 recall_val:0.7174 F1_val:0.653465 AUC_val:0.6537\n",
      "Epoch:0013\n",
      "acc_train:0.5993 pre_train:0.6004 recall_train:0.6602 F1_train:0.6289 AUC_train:0.6412\n",
      "acc_val:0.6180 pre_val:0.6111 recall_val:0.7174 F1_val:0.660000 AUC_val:0.6633\n",
      "Epoch:0014\n",
      "acc_train:0.5518 pre_train:0.5580 recall_train:0.6189 F1_train:0.5869 AUC_train:0.5905\n",
      "acc_val:0.6067 pre_val:0.5965 recall_val:0.7391 F1_val:0.660194 AUC_val:0.6678\n",
      "Epoch:0015\n",
      "acc_train:0.6155 pre_train:0.6320 recall_train:0.6044 F1_train:0.6179 AUC_train:0.6754\n",
      "acc_val:0.6180 pre_val:0.6111 recall_val:0.7174 F1_val:0.660000 AUC_val:0.6582\n",
      "Epoch:0016\n",
      "acc_train:0.6305 pre_train:0.6543 recall_train:0.5971 F1_train:0.6244 AUC_train:0.6722\n",
      "acc_val:0.6517 pre_val:0.6415 recall_val:0.7391 F1_val:0.686869 AUC_val:0.6638\n",
      "Epoch:0017\n",
      "acc_train:0.6092 pre_train:0.6159 recall_train:0.6383 F1_train:0.6269 AUC_train:0.6559\n",
      "acc_val:0.6404 pre_val:0.6296 recall_val:0.7391 F1_val:0.680000 AUC_val:0.6395\n",
      "Epoch:0018\n",
      "acc_train:0.6142 pre_train:0.6310 recall_train:0.6019 F1_train:0.6161 AUC_train:0.6684\n",
      "acc_val:0.6517 pre_val:0.6415 recall_val:0.7391 F1_val:0.686869 AUC_val:0.6395\n",
      "Epoch:0019\n",
      "acc_train:0.6067 pre_train:0.6293 recall_train:0.5728 F1_train:0.5997 AUC_train:0.6492\n",
      "acc_val:0.6517 pre_val:0.6415 recall_val:0.7391 F1_val:0.686869 AUC_val:0.6411\n",
      "Epoch:0020\n",
      "acc_train:0.6292 pre_train:0.6242 recall_train:0.7015 F1_train:0.6606 AUC_train:0.7064\n",
      "acc_val:0.6292 pre_val:0.6182 recall_val:0.7391 F1_val:0.673267 AUC_val:0.6446\n",
      "Epoch:0021\n",
      "acc_train:0.6267 pre_train:0.6475 recall_train:0.6019 F1_train:0.6239 AUC_train:0.6821\n",
      "acc_val:0.6404 pre_val:0.6296 recall_val:0.7391 F1_val:0.680000 AUC_val:0.6461\n",
      "Epoch:0022\n",
      "acc_train:0.6242 pre_train:0.6231 recall_train:0.6820 F1_train:0.6512 AUC_train:0.6719\n",
      "acc_val:0.6180 pre_val:0.6071 recall_val:0.7391 F1_val:0.666667 AUC_val:0.6496\n",
      "Epoch:0023\n",
      "acc_train:0.6367 pre_train:0.6516 recall_train:0.6311 F1_train:0.6412 AUC_train:0.7020\n",
      "acc_val:0.6292 pre_val:0.6182 recall_val:0.7391 F1_val:0.673267 AUC_val:0.6542\n",
      "Epoch:0024\n",
      "acc_train:0.6055 pre_train:0.6182 recall_train:0.6092 F1_train:0.6137 AUC_train:0.6694\n",
      "acc_val:0.6292 pre_val:0.6182 recall_val:0.7391 F1_val:0.673267 AUC_val:0.6572\n",
      "Epoch:0025\n",
      "acc_train:0.6417 pre_train:0.6327 recall_train:0.7233 F1_train:0.6750 AUC_train:0.6934\n",
      "acc_val:0.6292 pre_val:0.6182 recall_val:0.7391 F1_val:0.673267 AUC_val:0.6598\n",
      "Epoch:0026\n",
      "acc_train:0.5793 pre_train:0.5803 recall_train:0.6578 F1_train:0.6166 AUC_train:0.6502\n",
      "acc_val:0.6292 pre_val:0.6182 recall_val:0.7391 F1_val:0.673267 AUC_val:0.6704\n",
      "Epoch:0027\n",
      "acc_train:0.6567 pre_train:0.6589 recall_train:0.6893 F1_train:0.6738 AUC_train:0.7201\n",
      "acc_val:0.6742 pre_val:0.6667 recall_val:0.7391 F1_val:0.701031 AUC_val:0.6795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0028\n",
      "acc_train:0.6429 pre_train:0.6493 recall_train:0.6650 F1_train:0.6571 AUC_train:0.7001\n",
      "acc_val:0.6629 pre_val:0.6600 recall_val:0.7174 F1_val:0.687500 AUC_val:0.6855\n",
      "Epoch:0029\n",
      "acc_train:0.6704 pre_train:0.6729 recall_train:0.6990 F1_train:0.6857 AUC_train:0.7362\n",
      "acc_val:0.6517 pre_val:0.6531 recall_val:0.6957 F1_val:0.673684 AUC_val:0.6896\n",
      "Epoch:0030\n",
      "acc_train:0.6754 pre_train:0.6854 recall_train:0.6820 F1_train:0.6837 AUC_train:0.7341\n",
      "acc_val:0.6517 pre_val:0.6531 recall_val:0.6957 F1_val:0.673684 AUC_val:0.6962\n",
      "Epoch:0031\n",
      "acc_train:0.6979 pre_train:0.6906 recall_train:0.7476 F1_train:0.7179 AUC_train:0.7489\n",
      "acc_val:0.6517 pre_val:0.6471 recall_val:0.7174 F1_val:0.680412 AUC_val:0.7012\n",
      "Epoch:0032\n",
      "acc_train:0.7253 pre_train:0.7192 recall_train:0.7646 F1_train:0.7412 AUC_train:0.7732\n",
      "acc_val:0.6629 pre_val:0.6600 recall_val:0.7174 F1_val:0.687500 AUC_val:0.7078\n",
      "Epoch:0033\n",
      "acc_train:0.7216 pre_train:0.7114 recall_train:0.7718 F1_train:0.7404 AUC_train:0.7687\n",
      "acc_val:0.6742 pre_val:0.6604 recall_val:0.7609 F1_val:0.707071 AUC_val:0.7154\n",
      "Epoch:0034\n",
      "acc_train:0.7428 pre_train:0.7220 recall_train:0.8131 F1_train:0.7648 AUC_train:0.7865\n",
      "acc_val:0.6742 pre_val:0.6667 recall_val:0.7391 F1_val:0.701031 AUC_val:0.7240\n",
      "Epoch:0035\n",
      "acc_train:0.7678 pre_train:0.7435 recall_train:0.8374 F1_train:0.7877 AUC_train:0.8187\n",
      "acc_val:0.6742 pre_val:0.6667 recall_val:0.7391 F1_val:0.701031 AUC_val:0.7381\n",
      "Epoch:0036\n",
      "acc_train:0.7728 pre_train:0.7602 recall_train:0.8155 F1_train:0.7869 AUC_train:0.8262\n",
      "acc_val:0.6854 pre_val:0.6800 recall_val:0.7391 F1_val:0.708333 AUC_val:0.7442\n",
      "Epoch:0037\n",
      "acc_train:0.7715 pre_train:0.7473 recall_train:0.8398 F1_train:0.7909 AUC_train:0.8090\n",
      "acc_val:0.6966 pre_val:0.6939 recall_val:0.7391 F1_val:0.715789 AUC_val:0.7482\n",
      "Epoch:0038\n",
      "acc_train:0.7990 pre_train:0.7734 recall_train:0.8617 F1_train:0.8152 AUC_train:0.8326\n",
      "acc_val:0.6966 pre_val:0.6939 recall_val:0.7391 F1_val:0.715789 AUC_val:0.7518\n",
      "Epoch:0039\n",
      "acc_train:0.7978 pre_train:0.7815 recall_train:0.8422 F1_train:0.8107 AUC_train:0.8343\n",
      "acc_val:0.7079 pre_val:0.7083 recall_val:0.7391 F1_val:0.723404 AUC_val:0.7563\n",
      "Epoch:0040\n",
      "acc_train:0.7640 pre_train:0.7461 recall_train:0.8204 F1_train:0.7815 AUC_train:0.8273\n",
      "acc_val:0.7079 pre_val:0.7083 recall_val:0.7391 F1_val:0.723404 AUC_val:0.7599\n",
      "Epoch:0041\n",
      "acc_train:0.7990 pre_train:0.7898 recall_train:0.8301 F1_train:0.8095 AUC_train:0.8474\n",
      "acc_val:0.7303 pre_val:0.7200 recall_val:0.7826 F1_val:0.750000 AUC_val:0.7685\n",
      "Epoch:0042\n",
      "acc_train:0.8177 pre_train:0.7866 recall_train:0.8859 F1_train:0.8333 AUC_train:0.8523\n",
      "acc_val:0.7528 pre_val:0.7308 recall_val:0.8261 F1_val:0.775510 AUC_val:0.7801\n",
      "Epoch:0043\n",
      "acc_train:0.8115 pre_train:0.7702 recall_train:0.9029 F1_train:0.8313 AUC_train:0.8585\n",
      "acc_val:0.7640 pre_val:0.7358 recall_val:0.8478 F1_val:0.787879 AUC_val:0.7932\n",
      "Epoch:0044\n",
      "acc_train:0.8402 pre_train:0.8047 recall_train:0.9102 F1_train:0.8542 AUC_train:0.8862\n",
      "acc_val:0.7416 pre_val:0.6949 recall_val:0.8913 F1_val:0.780952 AUC_val:0.8013\n",
      "Epoch:0045\n",
      "acc_train:0.8302 pre_train:0.7794 recall_train:0.9345 F1_train:0.8499 AUC_train:0.9043\n",
      "acc_val:0.7079 pre_val:0.6613 recall_val:0.8913 F1_val:0.759259 AUC_val:0.8104\n",
      "Epoch:0046\n",
      "acc_train:0.8352 pre_train:0.7846 recall_train:0.9369 F1_train:0.8540 AUC_train:0.9146\n",
      "acc_val:0.6854 pre_val:0.6364 recall_val:0.9130 F1_val:0.750000 AUC_val:0.8215\n",
      "Epoch:0047\n",
      "acc_train:0.8502 pre_train:0.8067 recall_train:0.9320 F1_train:0.8649 AUC_train:0.9199\n",
      "acc_val:0.7079 pre_val:0.6613 recall_val:0.8913 F1_val:0.759259 AUC_val:0.8145\n",
      "Epoch:0048\n",
      "acc_train:0.8689 pre_train:0.8245 recall_train:0.9466 F1_train:0.8814 AUC_train:0.9405\n",
      "acc_val:0.7528 pre_val:0.7069 recall_val:0.8913 F1_val:0.788462 AUC_val:0.8129\n",
      "Epoch:0049\n",
      "acc_train:0.8664 pre_train:0.8252 recall_train:0.9393 F1_train:0.8785 AUC_train:0.9143\n",
      "acc_val:0.7753 pre_val:0.7321 recall_val:0.8913 F1_val:0.803922 AUC_val:0.8043\n",
      "Epoch:0050\n",
      "acc_train:0.8614 pre_train:0.8053 recall_train:0.9636 F1_train:0.8773 AUC_train:0.9223\n",
      "acc_val:0.7640 pre_val:0.7193 recall_val:0.8913 F1_val:0.796117 AUC_val:0.8049\n",
      "Epoch:0051\n",
      "acc_train:0.8514 pre_train:0.8058 recall_train:0.9369 F1_train:0.8664 AUC_train:0.9210\n",
      "acc_val:0.7303 pre_val:0.6833 recall_val:0.8913 F1_val:0.773585 AUC_val:0.8104\n",
      "Epoch:0052\n",
      "acc_train:0.8627 pre_train:0.8120 recall_train:0.9539 F1_train:0.8772 AUC_train:0.9412\n",
      "acc_val:0.7191 pre_val:0.6615 recall_val:0.9348 F1_val:0.774775 AUC_val:0.8195\n",
      "Epoch:0053\n",
      "acc_train:0.8664 pre_train:0.8211 recall_train:0.9466 F1_train:0.8794 AUC_train:0.9508\n",
      "acc_val:0.7079 pre_val:0.6429 recall_val:0.9783 F1_val:0.775862 AUC_val:0.8357\n",
      "Epoch:0054\n",
      "acc_train:0.8777 pre_train:0.8204 recall_train:0.9757 F1_train:0.8914 AUC_train:0.9566\n",
      "acc_val:0.6854 pre_val:0.6250 recall_val:0.9783 F1_val:0.762712 AUC_val:0.8519\n",
      "Epoch:0055\n",
      "acc_train:0.8801 pre_train:0.8333 recall_train:0.9587 F1_train:0.8916 AUC_train:0.9553\n",
      "acc_val:0.6966 pre_val:0.6338 recall_val:0.9783 F1_val:0.769231 AUC_val:0.8660\n",
      "Epoch:0056\n",
      "acc_train:0.8851 pre_train:0.8478 recall_train:0.9466 F1_train:0.8945 AUC_train:0.9619\n",
      "acc_val:0.7303 pre_val:0.6618 recall_val:0.9783 F1_val:0.789474 AUC_val:0.8448\n",
      "Epoch:0057\n",
      "acc_train:0.8826 pre_train:0.8340 recall_train:0.9636 F1_train:0.8941 AUC_train:0.9555\n",
      "acc_val:0.7416 pre_val:0.6769 recall_val:0.9565 F1_val:0.792793 AUC_val:0.8337\n",
      "Epoch:0058\n",
      "acc_train:0.8976 pre_train:0.8496 recall_train:0.9733 F1_train:0.9072 AUC_train:0.9560\n",
      "acc_val:0.7416 pre_val:0.6825 recall_val:0.9348 F1_val:0.788991 AUC_val:0.8266\n",
      "Epoch:0059\n",
      "acc_train:0.9039 pre_train:0.8633 recall_train:0.9660 F1_train:0.9118 AUC_train:0.9581\n",
      "acc_val:0.7640 pre_val:0.7119 recall_val:0.9130 F1_val:0.800000 AUC_val:0.8231\n",
      "Epoch:0060\n",
      "acc_train:0.9039 pre_train:0.8633 recall_train:0.9660 F1_train:0.9118 AUC_train:0.9576\n",
      "acc_val:0.7753 pre_val:0.7241 recall_val:0.9130 F1_val:0.807692 AUC_val:0.8276\n",
      "Epoch:0061\n",
      "acc_train:0.9051 pre_train:0.8636 recall_train:0.9684 F1_train:0.9130 AUC_train:0.9542\n",
      "acc_val:0.7865 pre_val:0.7368 recall_val:0.9130 F1_val:0.815534 AUC_val:0.8342\n",
      "Epoch:0062\n",
      "acc_train:0.9114 pre_train:0.8747 recall_train:0.9660 F1_train:0.9181 AUC_train:0.9605\n",
      "acc_val:0.8090 pre_val:0.7544 recall_val:0.9348 F1_val:0.834951 AUC_val:0.8322\n",
      "Epoch:0063\n",
      "acc_train:0.9288 pre_train:0.9043 recall_train:0.9636 F1_train:0.9330 AUC_train:0.9600\n",
      "acc_val:0.7978 pre_val:0.7414 recall_val:0.9348 F1_val:0.826923 AUC_val:0.8347\n",
      "Epoch:0064\n",
      "acc_train:0.9213 pre_train:0.8921 recall_train:0.9636 F1_train:0.9265 AUC_train:0.9601\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.8382\n",
      "Epoch:0065\n",
      "acc_train:0.9238 pre_train:0.9016 recall_train:0.9563 F1_train:0.9282 AUC_train:0.9716\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.8600\n",
      "Epoch:0066\n",
      "acc_train:0.9238 pre_train:0.8980 recall_train:0.9612 F1_train:0.9285 AUC_train:0.9706\n",
      "acc_val:0.7865 pre_val:0.7143 recall_val:0.9783 F1_val:0.825688 AUC_val:0.8857\n",
      "Epoch:0067\n",
      "acc_train:0.9201 pre_train:0.8766 recall_train:0.9830 F1_train:0.9268 AUC_train:0.9756\n",
      "acc_val:0.7753 pre_val:0.7167 recall_val:0.9348 F1_val:0.811321 AUC_val:0.8974\n",
      "Epoch:0068\n",
      "acc_train:0.9388 pre_train:0.9116 recall_train:0.9757 F1_train:0.9426 AUC_train:0.9756\n",
      "acc_val:0.7865 pre_val:0.7288 recall_val:0.9348 F1_val:0.819048 AUC_val:0.9014\n",
      "Epoch:0069\n",
      "acc_train:0.9213 pre_train:0.8802 recall_train:0.9806 F1_train:0.9277 AUC_train:0.9785\n",
      "acc_val:0.7865 pre_val:0.7288 recall_val:0.9348 F1_val:0.819048 AUC_val:0.9055\n",
      "Epoch:0070\n",
      "acc_train:0.9313 pre_train:0.8976 recall_train:0.9782 F1_train:0.9361 AUC_train:0.9783\n",
      "acc_val:0.7865 pre_val:0.7288 recall_val:0.9348 F1_val:0.819048 AUC_val:0.9080\n",
      "Epoch:0071\n",
      "acc_train:0.9376 pre_train:0.9095 recall_train:0.9757 F1_train:0.9415 AUC_train:0.9785\n",
      "acc_val:0.7865 pre_val:0.7368 recall_val:0.9130 F1_val:0.815534 AUC_val:0.9075\n",
      "Epoch:0072\n",
      "acc_train:0.9388 pre_train:0.9042 recall_train:0.9854 F1_train:0.9431 AUC_train:0.9800\n",
      "acc_val:0.7640 pre_val:0.7119 recall_val:0.9130 F1_val:0.800000 AUC_val:0.9125\n",
      "Epoch:0073\n",
      "acc_train:0.9388 pre_train:0.9060 recall_train:0.9830 F1_train:0.9430 AUC_train:0.9719\n",
      "acc_val:0.7640 pre_val:0.7119 recall_val:0.9130 F1_val:0.800000 AUC_val:0.9110\n",
      "Epoch:0074\n",
      "acc_train:0.9376 pre_train:0.9077 recall_train:0.9782 F1_train:0.9416 AUC_train:0.9741\n",
      "acc_val:0.7640 pre_val:0.7119 recall_val:0.9130 F1_val:0.800000 AUC_val:0.9176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0075\n",
      "acc_train:0.9526 pre_train:0.9289 recall_train:0.9830 F1_train:0.9552 AUC_train:0.9856\n",
      "acc_val:0.7528 pre_val:0.7000 recall_val:0.9130 F1_val:0.792453 AUC_val:0.9191\n",
      "Epoch:0076\n",
      "acc_train:0.9600 pre_train:0.9378 recall_train:0.9879 F1_train:0.9622 AUC_train:0.9816\n",
      "acc_val:0.7416 pre_val:0.6885 recall_val:0.9130 F1_val:0.785047 AUC_val:0.9252\n",
      "Epoch:0077\n",
      "acc_train:0.9513 pre_train:0.9248 recall_train:0.9854 F1_train:0.9542 AUC_train:0.9790\n",
      "acc_val:0.7416 pre_val:0.6825 recall_val:0.9348 F1_val:0.788991 AUC_val:0.9307\n",
      "Epoch:0078\n",
      "acc_train:0.9613 pre_train:0.9359 recall_train:0.9927 F1_train:0.9635 AUC_train:0.9906\n",
      "acc_val:0.7528 pre_val:0.6935 recall_val:0.9348 F1_val:0.796296 AUC_val:0.9343\n",
      "Epoch:0079\n",
      "acc_train:0.9401 pre_train:0.9118 recall_train:0.9782 F1_train:0.9438 AUC_train:0.9811\n",
      "acc_val:0.7416 pre_val:0.6825 recall_val:0.9348 F1_val:0.788991 AUC_val:0.9323\n",
      "Epoch:0080\n",
      "acc_train:0.9463 pre_train:0.9165 recall_train:0.9854 F1_train:0.9497 AUC_train:0.9818\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.9323\n",
      "Epoch:0081\n",
      "acc_train:0.9401 pre_train:0.9027 recall_train:0.9903 F1_train:0.9444 AUC_train:0.9836\n",
      "acc_val:0.7416 pre_val:0.6825 recall_val:0.9348 F1_val:0.788991 AUC_val:0.9439\n",
      "Epoch:0082\n",
      "acc_train:0.9526 pre_train:0.9193 recall_train:0.9951 F1_train:0.9557 AUC_train:0.9867\n",
      "acc_val:0.7416 pre_val:0.6825 recall_val:0.9348 F1_val:0.788991 AUC_val:0.9474\n",
      "Epoch:0083\n",
      "acc_train:0.9538 pre_train:0.9330 recall_train:0.9806 F1_train:0.9562 AUC_train:0.9862\n",
      "acc_val:0.7303 pre_val:0.6719 recall_val:0.9348 F1_val:0.781818 AUC_val:0.9515\n",
      "Epoch:0084\n",
      "acc_train:0.9563 pre_train:0.9333 recall_train:0.9854 F1_train:0.9587 AUC_train:0.9872\n",
      "acc_val:0.7640 pre_val:0.6984 recall_val:0.9565 F1_val:0.807339 AUC_val:0.9555\n",
      "Epoch:0085\n",
      "acc_train:0.9488 pre_train:0.9226 recall_train:0.9830 F1_train:0.9518 AUC_train:0.9839\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9565\n",
      "Epoch:0086\n",
      "acc_train:0.9563 pre_train:0.9314 recall_train:0.9879 F1_train:0.9588 AUC_train:0.9910\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9560\n",
      "Epoch:0087\n",
      "acc_train:0.9451 pre_train:0.9126 recall_train:0.9879 F1_train:0.9487 AUC_train:0.9849\n",
      "acc_val:0.7753 pre_val:0.6970 recall_val:1.0000 F1_val:0.821429 AUC_val:0.9570\n",
      "Epoch:0088\n",
      "acc_train:0.9538 pre_train:0.9291 recall_train:0.9854 F1_train:0.9564 AUC_train:0.9877\n",
      "acc_val:0.7753 pre_val:0.6970 recall_val:1.0000 F1_val:0.821429 AUC_val:0.9565\n",
      "Epoch:0089\n",
      "acc_train:0.9625 pre_train:0.9421 recall_train:0.9879 F1_train:0.9645 AUC_train:0.9925\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9555\n",
      "Epoch:0090\n",
      "acc_train:0.9563 pre_train:0.9294 recall_train:0.9903 F1_train:0.9589 AUC_train:0.9900\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9580\n",
      "Epoch:0091\n",
      "acc_train:0.9638 pre_train:0.9464 recall_train:0.9854 F1_train:0.9655 AUC_train:0.9888\n",
      "acc_val:0.8090 pre_val:0.7377 recall_val:0.9783 F1_val:0.841121 AUC_val:0.9626\n",
      "Epoch:0092\n",
      "acc_train:0.9576 pre_train:0.9335 recall_train:0.9879 F1_train:0.9599 AUC_train:0.9864\n",
      "acc_val:0.7865 pre_val:0.7288 recall_val:0.9348 F1_val:0.819048 AUC_val:0.9626\n",
      "Epoch:0093\n",
      "acc_train:0.9650 pre_train:0.9465 recall_train:0.9879 F1_train:0.9667 AUC_train:0.9857\n",
      "acc_val:0.7753 pre_val:0.7167 recall_val:0.9348 F1_val:0.811321 AUC_val:0.9621\n",
      "Epoch:0094\n",
      "acc_train:0.9625 pre_train:0.9381 recall_train:0.9927 F1_train:0.9646 AUC_train:0.9896\n",
      "acc_val:0.7865 pre_val:0.7213 recall_val:0.9565 F1_val:0.822430 AUC_val:0.9626\n",
      "Epoch:0095\n",
      "acc_train:0.9675 pre_train:0.9531 recall_train:0.9854 F1_train:0.9690 AUC_train:0.9946\n",
      "acc_val:0.7978 pre_val:0.7333 recall_val:0.9565 F1_val:0.830189 AUC_val:0.9621\n",
      "Epoch:0096\n",
      "acc_train:0.9688 pre_train:0.9532 recall_train:0.9879 F1_train:0.9702 AUC_train:0.9911\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9575\n",
      "Epoch:0097\n",
      "acc_train:0.9663 pre_train:0.9508 recall_train:0.9854 F1_train:0.9678 AUC_train:0.9879\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9530\n",
      "Epoch:0098\n",
      "acc_train:0.9663 pre_train:0.9466 recall_train:0.9903 F1_train:0.9680 AUC_train:0.9842\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9484\n",
      "Epoch:0099\n",
      "acc_train:0.9588 pre_train:0.9501 recall_train:0.9709 F1_train:0.9604 AUC_train:0.9917\n",
      "acc_val:0.7865 pre_val:0.7077 recall_val:1.0000 F1_val:0.828829 AUC_val:0.9489\n",
      "Epoch:0100\n",
      "acc_train:0.9688 pre_train:0.9574 recall_train:0.9830 F1_train:0.9701 AUC_train:0.9947\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9520\n",
      "Epoch:0101\n",
      "acc_train:0.9688 pre_train:0.9574 recall_train:0.9830 F1_train:0.9701 AUC_train:0.9919\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9510\n",
      "Epoch:0102\n",
      "acc_train:0.9763 pre_train:0.9645 recall_train:0.9903 F1_train:0.9772 AUC_train:0.9966\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9515\n",
      "Epoch:0103\n",
      "acc_train:0.9850 pre_train:0.9717 recall_train:1.0000 F1_train:0.9856 AUC_train:0.9980\n",
      "acc_val:0.7753 pre_val:0.7097 recall_val:0.9565 F1_val:0.814815 AUC_val:0.9525\n",
      "Epoch:0104\n",
      "acc_train:0.9638 pre_train:0.9423 recall_train:0.9903 F1_train:0.9657 AUC_train:0.9947\n",
      "acc_val:0.7753 pre_val:0.7097 recall_val:0.9565 F1_val:0.814815 AUC_val:0.9535\n",
      "Epoch:0105\n",
      "acc_train:0.9663 pre_train:0.9551 recall_train:0.9806 F1_train:0.9677 AUC_train:0.9877\n",
      "acc_val:0.7753 pre_val:0.7097 recall_val:0.9565 F1_val:0.814815 AUC_val:0.9540\n",
      "Epoch:0106\n",
      "acc_train:0.9750 pre_train:0.9667 recall_train:0.9854 F1_train:0.9760 AUC_train:0.9926\n",
      "acc_val:0.7865 pre_val:0.7213 recall_val:0.9565 F1_val:0.822430 AUC_val:0.9550\n",
      "Epoch:0107\n",
      "acc_train:0.9588 pre_train:0.9438 recall_train:0.9782 F1_train:0.9607 AUC_train:0.9913\n",
      "acc_val:0.7978 pre_val:0.7258 recall_val:0.9783 F1_val:0.833333 AUC_val:0.9565\n",
      "Epoch:0108\n",
      "acc_train:0.9775 pre_train:0.9624 recall_train:0.9951 F1_train:0.9785 AUC_train:0.9901\n",
      "acc_val:0.7753 pre_val:0.7031 recall_val:0.9783 F1_val:0.818182 AUC_val:0.9580\n",
      "Epoch:0109\n",
      "acc_train:0.9663 pre_train:0.9529 recall_train:0.9830 F1_train:0.9677 AUC_train:0.9936\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.9596\n",
      "Epoch:0110\n",
      "acc_train:0.9750 pre_train:0.9579 recall_train:0.9951 F1_train:0.9762 AUC_train:0.9969\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.9590\n",
      "Epoch:0111\n",
      "acc_train:0.9738 pre_train:0.9666 recall_train:0.9830 F1_train:0.9747 AUC_train:0.9975\n",
      "acc_val:0.7528 pre_val:0.6818 recall_val:0.9783 F1_val:0.803571 AUC_val:0.9550\n",
      "Epoch:0112\n",
      "acc_train:0.9725 pre_train:0.9621 recall_train:0.9854 F1_train:0.9736 AUC_train:0.9960\n",
      "acc_val:0.7640 pre_val:0.6923 recall_val:0.9783 F1_val:0.810811 AUC_val:0.9555\n",
      "Epoch:0113\n",
      "acc_train:0.9725 pre_train:0.9577 recall_train:0.9903 F1_train:0.9737 AUC_train:0.9958\n",
      "acc_val:0.7640 pre_val:0.6923 recall_val:0.9783 F1_val:0.810811 AUC_val:0.9575\n",
      "Epoch:0114\n",
      "acc_train:0.9738 pre_train:0.9666 recall_train:0.9830 F1_train:0.9747 AUC_train:0.9960\n",
      "acc_val:0.7640 pre_val:0.6923 recall_val:0.9783 F1_val:0.810811 AUC_val:0.9575\n",
      "Early Stopping!!! epoch：113\n",
      "Loading the Model for the 5-th Fold:... ... Size of samples in the test set:222\n",
      "Fold 5 Results: test acc:0.6306 test_pre:0.6038 test_recall:0.8348 test_F1:0.7007 test_AUC:0.7588 time:461.016s\n",
      "\n",
      "======Finish Results for Nested 10-fold cross-validation======\n",
      "Test: acc:0.6160071942446043 precision:0.6716600060462952 recall:0.6131349802017212 F1:0.5808905363082886 AUC:0.7165641188621521\n",
      "Total duration:2304.548360109329\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import io\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "# from dataloader import dataloader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "if hasattr(sys.stdout, 'buffer'):\n",
    "    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.no_cuda = False\n",
    "        self.seed = 46\n",
    "        self.epochs = 200\n",
    "        self.lr = 0.001\n",
    "        self.weight_decay = 5e-5\n",
    "        self.hidden = 16\n",
    "        self.dropout = 0.2\n",
    "        self.atlas = 'cc200'\n",
    "        self.num_features = 2000\n",
    "        self.folds = 10\n",
    "        self.connectivity = 'correlation'\n",
    "        self.max_degree = 3\n",
    "        self.ngl = 8\n",
    "        self.edropout = 0.3\n",
    "        self.train = 1\n",
    "        self.ckpt_path = '../folds/rois_cc200_pth_2'\n",
    "        self.early_stopping = True\n",
    "        self.early_stopping_patience = 20\n",
    "\n",
    "# Instantiate Args class\n",
    "args = Args()\n",
    "\n",
    "# Check if CUDA is available\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# Create params dictionary\n",
    "params = vars(args)\n",
    "\n",
    "# Print Hyperparameters\n",
    "print('Hyperparameters:')\n",
    "for key, value in params.items():\n",
    "    print(key + \":\", value)\n",
    "\n",
    "corrects = np.zeros(args.folds, dtype=np.int32) \n",
    "accs = np.zeros(args.folds, dtype=np.float32) \n",
    "aucs = np.zeros(args.folds, dtype=np.float32)\n",
    "prfs = np.zeros([args.folds,3], dtype=np.float32) # Save Precision, Recall, F1\n",
    "test_num = np.zeros(args.folds, dtype=np.float32)\n",
    "\n",
    "\n",
    "print('  Loading dataset ...')\n",
    "dataloader = dataloader()\n",
    "raw_features, y, nonimg = dataloader.load_data(params) \n",
    "cv_splits = dataloader.data_split(args.folds)\n",
    "features=raw_features\n",
    "\n",
    "t1 = time.time()\n",
    "count=1;\n",
    "for i in range(args.folds):\n",
    "    \n",
    "    \n",
    "    \n",
    "    t_start = time.time()\n",
    "    train_ind, test_ind = cv_splits[i]\n",
    "\n",
    "    train_ind, valid_ind = train_test_split(train_ind, test_size=0.1, random_state = 24)\n",
    "    \n",
    "    cv_splits[i] = (train_ind, valid_ind)\n",
    "    cv_splits[i] = cv_splits[i] + (test_ind,)\n",
    "    print('Size of the {}-fold Training, Validation, and Test Sets:{},{},{}' .format(i+1, len(cv_splits[i][0]), len(cv_splits[i][1]), len(cv_splits[i][2])))\n",
    "\n",
    "    if args.train == 1:\n",
    "        for j in range(args.folds):\n",
    "            print(' Starting the {}-{} Fold:：'.format(i+1,j+1))\n",
    "            node_ftr = dataloader.get_node_features(train_ind)\n",
    "            edge_index, edgenet_input = dataloader.get_WL_inputs(nonimg)\n",
    "            edgenet_input = (edgenet_input - edgenet_input.mean(axis=0)) / edgenet_input.std(axis=0)\n",
    "            \n",
    "            model = GCN(input_dim = args.num_features,\n",
    "                        nhid = args.hidden, \n",
    "                        num_classes = 2, \n",
    "                        ngl = args.ngl, \n",
    "                        dropout = args.dropout, \n",
    "                        edge_dropout = args.edropout, \n",
    "                        edgenet_input_dim = 2*nonimg.shape[1])\n",
    "            optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "            \n",
    "#             if args.cuda:\n",
    "            model\n",
    "            features = torch.tensor(node_ftr, dtype=torch.float32)\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "            edgenet_input = torch.tensor(edgenet_input, dtype=torch.float32)\n",
    "            labels = torch.tensor(y, dtype=torch.long)\n",
    "            fold_model_path = args.ckpt_path + \"/fold{}.pth\".format(i+1)\n",
    "                \n",
    "            acc = 0\n",
    "            best_val_loss = float('inf') # early stoppping: Initialized to positive infinity\n",
    "            current_patience = 0 # early stopping: Used to record the epochs of the current early stopping\n",
    "            \n",
    "            epoch_store = []\n",
    "            acc_train_store =[]        \n",
    "            pre_train_store =[]\n",
    "            recall_train_store =[]\n",
    "            F1_train_store =[]\n",
    "            AUC_train_store =[]\n",
    "            acc_val_store=[]\n",
    "            pre_val_store=[]\n",
    "            recall_val_store=[]\n",
    "            F1_val_store=[]\n",
    "            AUC_val_store=[]\n",
    "            \n",
    "            for epoch in range(args.epochs):\n",
    "                # train\n",
    "                model.train()\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    optimizer.zero_grad()\n",
    "                    output, edge_weights = model(features, edge_index, edgenet_input)\n",
    "                    loss_train = torch.nn.CrossEntropyLoss()(output[train_ind], labels[train_ind])\n",
    "                    loss_train.backward()\n",
    "                    optimizer.step()\n",
    "                acc_train = torchmetrics_accuracy(output[train_ind], labels[train_ind])\n",
    "                auc_train = torchmetrics_auc(output[train_ind], labels[train_ind])\n",
    "                logits_train = output[train_ind].detach().cpu().numpy()\n",
    "                prf_train = prf(logits_train, y[train_ind])\n",
    "\n",
    "                \n",
    "                # valid\n",
    "                model.eval()\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    output, edge_weights = model(features, edge_index, edgenet_input)\n",
    "                loss_val = torch.nn.CrossEntropyLoss()(output[valid_ind], labels[valid_ind])\n",
    "                acc_val = torchmetrics_accuracy(output[valid_ind], labels[valid_ind])\n",
    "                auc_val = torchmetrics_auc(output[valid_ind], labels[valid_ind])\n",
    "                logits_val = output[valid_ind].detach().cpu().numpy()\n",
    "                prf_val = prf(logits_val, y[valid_ind])\n",
    "\n",
    "                \n",
    "                print('Epoch:{:04d}'.format(epoch+1))\n",
    "                print('acc_train:{:.4f}'.format(acc_train),\n",
    "                      'pre_train:{:.4f}'.format(prf_train[0]),\n",
    "                      'recall_train:{:.4f}'.format(prf_train[1]),\n",
    "                      'F1_train:{:.4f}'.format(prf_train[2]),\n",
    "                      'AUC_train:{:.4f}'.format(auc_train))\n",
    "                print('acc_val:{:.4f}'.format(acc_val),\n",
    "                      'pre_val:{:.4f}'.format(prf_val[0]),\n",
    "                      'recall_val:{:.4f}'.format(prf_val[1]),\n",
    "                      'F1_val:{:4f}'.format(prf_val[2]),\n",
    "                      'AUC_val:{:.4f}'.format(auc_val))\n",
    "                \n",
    "                epoch_store.append(epoch+1)\n",
    "                acc_train_store.append(acc_train)       \n",
    "                pre_train_store.append(prf_train[0])\n",
    "                recall_train_store.append(prf_train[1])\n",
    "                F1_train_store.append(prf_train[2])\n",
    "                AUC_train_store.append(auc_train)\n",
    "                acc_val_store.append(acc_val)\n",
    "                pre_val_store.append(prf_val[0])\n",
    "                recall_val_store.append(prf_val[1])\n",
    "                F1_val_store.append(prf_val[2])\n",
    "                AUC_val_store.append(auc_val)\n",
    "                \n",
    "                # save pth\n",
    "                if acc_val > acc and epoch > 50:\n",
    "                    acc = acc_val\n",
    "                    if args.ckpt_path != '':\n",
    "                        if not os.path.exists(args.ckpt_path):\n",
    "                            os.makedirs(args.ckpt_path)\n",
    "                        torch.save(model.state_dict(), fold_model_path)\n",
    "                \n",
    "                # Early Stopping\n",
    "                if epoch > 50 and args.early_stopping == True:\n",
    "                    if loss_val < best_val_loss:\n",
    "                        best_val_loss = loss_val\n",
    "                        current_patience = 0\n",
    "                    else:\n",
    "                        current_patience += 1\n",
    "                    if current_patience >= args.early_stopping_patience:\n",
    "                        print('Early Stopping!!! epoch：{}'.format(epoch))\n",
    "                        break\n",
    "       \n",
    "        data  = { \n",
    "              \"epoch\" : epoch_store ,\n",
    "              \"acc_train\" : acc_train_store ,        \n",
    "              \"pre_train\" : pre_train_store ,\n",
    "              \"recall_train\" : recall_train_store ,\n",
    "              \"F1_train\" : F1_train_store ,\n",
    "              \"AUC_train\" : AUC_train_store ,\n",
    "              \"acc_val\" : acc_val_store,\n",
    "               \"pre_val\" : pre_val_store ,\n",
    "              \"recall_val\" : recall_val_store ,\n",
    "              \"F1_val\" : F1_val_store ,\n",
    "              \"AUC_val\" : AUC_val_store  \n",
    "        }\n",
    "        \n",
    "        \n",
    "        epoch_file_path =  f'../files/rois_cc200_2/file_{i}_{j}_{count}.csv'\n",
    "        data_file = pd.DataFrame(data);\n",
    "        data_file.to_csv(epoch_file_path , index=False);\n",
    "        count=count+1;\n",
    "        # test\n",
    "        print(\"Loading the Model for the {}-th Fold:... ...\".format(i+1),\n",
    "              \"Size of samples in the test set:{}\".format(len(test_ind)))\n",
    "        model.load_state_dict(torch.load(fold_model_path))\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            output, edge_weights = model(features, edge_index, edgenet_input)\n",
    "        acc_test = torchmetrics_accuracy(output[test_ind], labels[test_ind])\n",
    "        auc_test = torchmetrics_auc(output[test_ind], labels[test_ind])\n",
    "        logits_test = output[test_ind].detach().cpu().numpy()\n",
    "        correct_test = correct_num(logits_test, y[test_ind])\n",
    "        prf_test =  prf(logits_test, y[test_ind])\n",
    "        \n",
    "        t_end = time.time()\n",
    "        t = t_end - t_start\n",
    "        print('Fold {} Results:'.format(i+1),\n",
    "              'test acc:{:.4f}'.format(acc_test),\n",
    "              'test_pre:{:.4f}'.format(prf_test[0]),\n",
    "              'test_recall:{:.4f}'.format(prf_test[1]),\n",
    "              'test_F1:{:.4f}'.format(prf_test[2]),\n",
    "              'test_AUC:{:.4f}'.format(auc_test),\n",
    "              'time:{:.3f}s'.format(t))\n",
    "        \n",
    "        correct = correct_test\n",
    "        aucs[i] = auc_test\n",
    "        prfs[i] = prf_test\n",
    "        corrects[i] = correct\n",
    "        test_num[i] = len(test_ind)\n",
    "    \n",
    "    \n",
    "    if args.train == 0:\n",
    "        node_ftr = dataloader.get_node_features(train_ind)\n",
    "        edge_index, edgenet_input = dataloader.get_WL_inputs(nonimg)\n",
    "        edgenet_input = (edgenet_input - edgenet_input.mean(axis=0)) / edgenet_input.std(axis=0)\n",
    "        \n",
    "        model = GCN(input_dim = args.num_features,\n",
    "                    nhid = args.hidden, \n",
    "                    num_classes = 2, \n",
    "                    ngl = args.ngl, \n",
    "                    dropout = args.dropout, \n",
    "                    edge_dropout = args.edropout, \n",
    "                    edgenet_input_dim = 2*nonimg.shape[1])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "        \n",
    "#         if args.cuda\n",
    "        model\n",
    "        features = torch.tensor(node_ftr, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        edgenet_input = torch.tensor(edgenet_input, dtype=torch.float32)\n",
    "        labels = torch.tensor(y, dtype=torch.long)\n",
    "        fold_model_path = args.ckpt_path + \"/fold{}.pth\".format(i+1)\n",
    "        \n",
    "        model.load_state_dict(torch.load(fold_model_path))\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            output, edge_weights = model(features, edge_index, edgenet_input)\n",
    "        acc_test = torchmetrics_accuracy(output[test_ind], labels[test_ind])\n",
    "        auc_test = torchmetrics_auc(output[test_ind], labels[test_ind])\n",
    "        logits_test = output[test_ind].detach().cpu().numpy()\n",
    "        correct_test = correct_num(logits_test, y[test_ind])\n",
    "        prf_test =  prf(logits_test, y[test_ind])\n",
    "        \n",
    "        t_end = time.time()\n",
    "        t = t_end - t_start\n",
    "        print('Fold {} Results:'.format(i+1),\n",
    "              'test acc:{:.4f}'.format(acc_test),\n",
    "              'test_pre:{:.4f}'.format(prf_test[0]),\n",
    "              'test_recall:{:.4f}'.format(prf_test[1]),\n",
    "              'test_F1:{:.4f}'.format(prf_test[2]),\n",
    "              'test_AUC:{:.4f}'.format(auc_test),\n",
    "              'time:{:.3f}s'.format(t))\n",
    "        \n",
    "        correct = correct_test\n",
    "        aucs[i] = auc_test\n",
    "        prfs[i] = prf_test\n",
    "        corrects[i] = correct\n",
    "        test_num[i] = len(test_ind)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print('\\r\\n======Finish Results for Nested 10-fold cross-validation======')\n",
    "Nested10kCV_acc = np.sum(corrects) / np.sum(test_num)\n",
    "Nested10kCV_auc = np.mean(aucs)\n",
    "Nested10kCV_precision, Nested10kCV_recall, Nested10kCV_F1 = np.mean(prfs, axis=0)\n",
    "print('Test:',\n",
    "      'acc:{}'.format(Nested10kCV_acc),\n",
    "      'precision:{}'.format(Nested10kCV_precision),\n",
    "      'recall:{}'.format(Nested10kCV_recall),\n",
    "      'F1:{}'.format(Nested10kCV_F1),\n",
    "      'AUC:{}'.format(Nested10kCV_auc))\n",
    "print('Total duration:{}'.format(t2 - t1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d845c726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "no_cuda: False\n",
      "seed: 46\n",
      "epochs: 200\n",
      "lr: 0.001\n",
      "weight_decay: 5e-05\n",
      "hidden: 16\n",
      "dropout: 0.2\n",
      "atlas: cc200\n",
      "num_features: 2000\n",
      "folds: 10\n",
      "connectivity: correlation\n",
      "max_degree: 3\n",
      "ngl: 8\n",
      "edropout: 0.3\n",
      "train: 0\n",
      "ckpt_path: ./pth\n",
      "early_stopping: True\n",
      "early_stopping_patience: 20\n",
      "cuda: False\n",
      "  Loading dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KSB\\AppData\\Local\\Temp\\ipykernel_23528\\2821594311.py:216: RuntimeWarning: divide by zero encountered in arctanh\n",
      "  norm_networks = [np.arctanh(mat) if not np.all(np.abs(mat) == 1) else mat for mat in all_networks]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the 1-fold Training, Validation, and Test Sets:900,100,112\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 1 Results: test acc:0.6071 test_pre:0.5946 test_recall:0.7586 test_F1:0.6667 test_AUC:0.6437 time:44.829s\n",
      "Size of the 2-fold Training, Validation, and Test Sets:900,100,112\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 2 Results: test acc:0.7768 test_pre:0.7705 test_recall:0.8103 test_F1:0.7899 test_AUC:0.8413 time:44.733s\n",
      "Size of the 3-fold Training, Validation, and Test Sets:900,101,111\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 3 Results: test acc:0.7568 test_pre:0.6923 test_recall:0.9474 test_F1:0.8000 test_AUC:0.9185 time:46.675s\n",
      "Size of the 4-fold Training, Validation, and Test Sets:900,101,111\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 4 Results: test acc:0.5225 test_pre:1.0000 test_recall:0.0702 test_F1:0.1311 test_AUC:0.4607 time:46.857s\n",
      "Size of the 5-fold Training, Validation, and Test Sets:900,101,111\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 5 Results: test acc:0.6306 test_pre:0.6026 test_recall:0.8246 test_F1:0.6963 test_AUC:0.5832 time:47.592s\n",
      "Size of the 6-fold Training, Validation, and Test Sets:900,101,111\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 6 Results: test acc:0.6036 test_pre:0.5942 test_recall:0.7193 test_F1:0.6508 test_AUC:0.7068 time:48.197s\n",
      "Size of the 7-fold Training, Validation, and Test Sets:900,101,111\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 7 Results: test acc:0.8559 test_pre:0.8154 test_recall:0.9298 test_F1:0.8689 test_AUC:0.9360 time:47.777s\n",
      "Size of the 8-fold Training, Validation, and Test Sets:900,101,111\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 8 Results: test acc:0.8108 test_pre:0.7571 test_recall:0.9298 test_F1:0.8346 test_AUC:0.9405 time:49.270s\n",
      "Size of the 9-fold Training, Validation, and Test Sets:900,101,111\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n",
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 9 Results: test acc:0.7477 test_pre:0.6883 test_recall:0.9298 test_F1:0.7910 test_AUC:0.9090 time:48.770s\n",
      "Size of the 10-fold Training, Validation, and Test Sets:900,101,111\n",
      "Fitting estimator with 19900 features.\n",
      "Fitting estimator with 19800 features.\n",
      "Fitting estimator with 19700 features.\n",
      "Fitting estimator with 19600 features.\n",
      "Fitting estimator with 19500 features.\n",
      "Fitting estimator with 19400 features.\n",
      "Fitting estimator with 19300 features.\n",
      "Fitting estimator with 19200 features.\n",
      "Fitting estimator with 19100 features.\n",
      "Fitting estimator with 19000 features.\n",
      "Fitting estimator with 18900 features.\n",
      "Fitting estimator with 18800 features.\n",
      "Fitting estimator with 18700 features.\n",
      "Fitting estimator with 18600 features.\n",
      "Fitting estimator with 18500 features.\n",
      "Fitting estimator with 18400 features.\n",
      "Fitting estimator with 18300 features.\n",
      "Fitting estimator with 18200 features.\n",
      "Fitting estimator with 18100 features.\n",
      "Fitting estimator with 18000 features.\n",
      "Fitting estimator with 17900 features.\n",
      "Fitting estimator with 17800 features.\n",
      "Fitting estimator with 17700 features.\n",
      "Fitting estimator with 17600 features.\n",
      "Fitting estimator with 17500 features.\n",
      "Fitting estimator with 17400 features.\n",
      "Fitting estimator with 17300 features.\n",
      "Fitting estimator with 17200 features.\n",
      "Fitting estimator with 17100 features.\n",
      "Fitting estimator with 17000 features.\n",
      "Fitting estimator with 16900 features.\n",
      "Fitting estimator with 16800 features.\n",
      "Fitting estimator with 16700 features.\n",
      "Fitting estimator with 16600 features.\n",
      "Fitting estimator with 16500 features.\n",
      "Fitting estimator with 16400 features.\n",
      "Fitting estimator with 16300 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 16200 features.\n",
      "Fitting estimator with 16100 features.\n",
      "Fitting estimator with 16000 features.\n",
      "Fitting estimator with 15900 features.\n",
      "Fitting estimator with 15800 features.\n",
      "Fitting estimator with 15700 features.\n",
      "Fitting estimator with 15600 features.\n",
      "Fitting estimator with 15500 features.\n",
      "Fitting estimator with 15400 features.\n",
      "Fitting estimator with 15300 features.\n",
      "Fitting estimator with 15200 features.\n",
      "Fitting estimator with 15100 features.\n",
      "Fitting estimator with 15000 features.\n",
      "Fitting estimator with 14900 features.\n",
      "Fitting estimator with 14800 features.\n",
      "Fitting estimator with 14700 features.\n",
      "Fitting estimator with 14600 features.\n",
      "Fitting estimator with 14500 features.\n",
      "Fitting estimator with 14400 features.\n",
      "Fitting estimator with 14300 features.\n",
      "Fitting estimator with 14200 features.\n",
      "Fitting estimator with 14100 features.\n",
      "Fitting estimator with 14000 features.\n",
      "Fitting estimator with 13900 features.\n",
      "Fitting estimator with 13800 features.\n",
      "Fitting estimator with 13700 features.\n",
      "Fitting estimator with 13600 features.\n",
      "Fitting estimator with 13500 features.\n",
      "Fitting estimator with 13400 features.\n",
      "Fitting estimator with 13300 features.\n",
      "Fitting estimator with 13200 features.\n",
      "Fitting estimator with 13100 features.\n",
      "Fitting estimator with 13000 features.\n",
      "Fitting estimator with 12900 features.\n",
      "Fitting estimator with 12800 features.\n",
      "Fitting estimator with 12700 features.\n",
      "Fitting estimator with 12600 features.\n",
      "Fitting estimator with 12500 features.\n",
      "Fitting estimator with 12400 features.\n",
      "Fitting estimator with 12300 features.\n",
      "Fitting estimator with 12200 features.\n",
      "Fitting estimator with 12100 features.\n",
      "Fitting estimator with 12000 features.\n",
      "Fitting estimator with 11900 features.\n",
      "Fitting estimator with 11800 features.\n",
      "Fitting estimator with 11700 features.\n",
      "Fitting estimator with 11600 features.\n",
      "Fitting estimator with 11500 features.\n",
      "Fitting estimator with 11400 features.\n",
      "Fitting estimator with 11300 features.\n",
      "Fitting estimator with 11200 features.\n",
      "Fitting estimator with 11100 features.\n",
      "Fitting estimator with 11000 features.\n",
      "Fitting estimator with 10900 features.\n",
      "Fitting estimator with 10800 features.\n",
      "Fitting estimator with 10700 features.\n",
      "Fitting estimator with 10600 features.\n",
      "Fitting estimator with 10500 features.\n",
      "Fitting estimator with 10400 features.\n",
      "Fitting estimator with 10300 features.\n",
      "Fitting estimator with 10200 features.\n",
      "Fitting estimator with 10100 features.\n",
      "Fitting estimator with 10000 features.\n",
      "Fitting estimator with 9900 features.\n",
      "Fitting estimator with 9800 features.\n",
      "Fitting estimator with 9700 features.\n",
      "Fitting estimator with 9600 features.\n",
      "Fitting estimator with 9500 features.\n",
      "Fitting estimator with 9400 features.\n",
      "Fitting estimator with 9300 features.\n",
      "Fitting estimator with 9200 features.\n",
      "Fitting estimator with 9100 features.\n",
      "Fitting estimator with 9000 features.\n",
      "Fitting estimator with 8900 features.\n",
      "Fitting estimator with 8800 features.\n",
      "Fitting estimator with 8700 features.\n",
      "Fitting estimator with 8600 features.\n",
      "Fitting estimator with 8500 features.\n",
      "Fitting estimator with 8400 features.\n",
      "Fitting estimator with 8300 features.\n",
      "Fitting estimator with 8200 features.\n",
      "Fitting estimator with 8100 features.\n",
      "Fitting estimator with 8000 features.\n",
      "Fitting estimator with 7900 features.\n",
      "Fitting estimator with 7800 features.\n",
      "Fitting estimator with 7700 features.\n",
      "Fitting estimator with 7600 features.\n",
      "Fitting estimator with 7500 features.\n",
      "Fitting estimator with 7400 features.\n",
      "Fitting estimator with 7300 features.\n",
      "Fitting estimator with 7200 features.\n",
      "Fitting estimator with 7100 features.\n",
      "Fitting estimator with 7000 features.\n",
      "Fitting estimator with 6900 features.\n",
      "Fitting estimator with 6800 features.\n",
      "Fitting estimator with 6700 features.\n",
      "Fitting estimator with 6600 features.\n",
      "Fitting estimator with 6500 features.\n",
      "Fitting estimator with 6400 features.\n",
      "Fitting estimator with 6300 features.\n",
      "Fitting estimator with 6200 features.\n",
      "Fitting estimator with 6100 features.\n",
      "Fitting estimator with 6000 features.\n",
      "Fitting estimator with 5900 features.\n",
      "Fitting estimator with 5800 features.\n",
      "Fitting estimator with 5700 features.\n",
      "Fitting estimator with 5600 features.\n",
      "Fitting estimator with 5500 features.\n",
      "Fitting estimator with 5400 features.\n",
      "Fitting estimator with 5300 features.\n",
      "Fitting estimator with 5200 features.\n",
      "Fitting estimator with 5100 features.\n",
      "Fitting estimator with 5000 features.\n",
      "Fitting estimator with 4900 features.\n",
      "Fitting estimator with 4800 features.\n",
      "Fitting estimator with 4700 features.\n",
      "Fitting estimator with 4600 features.\n",
      "Fitting estimator with 4500 features.\n",
      "Fitting estimator with 4400 features.\n",
      "Fitting estimator with 4300 features.\n",
      "Fitting estimator with 4200 features.\n",
      "Fitting estimator with 4100 features.\n",
      "Fitting estimator with 4000 features.\n",
      "Fitting estimator with 3900 features.\n",
      "Fitting estimator with 3800 features.\n",
      "Fitting estimator with 3700 features.\n",
      "Fitting estimator with 3600 features.\n",
      "Fitting estimator with 3500 features.\n",
      "Fitting estimator with 3400 features.\n",
      "Fitting estimator with 3300 features.\n",
      "Fitting estimator with 3200 features.\n",
      "Fitting estimator with 3100 features.\n",
      "Fitting estimator with 3000 features.\n",
      "Fitting estimator with 2900 features.\n",
      "Fitting estimator with 2800 features.\n",
      "Fitting estimator with 2700 features.\n",
      "Fitting estimator with 2600 features.\n",
      "Fitting estimator with 2500 features.\n",
      "Fitting estimator with 2400 features.\n",
      "Fitting estimator with 2300 features.\n",
      "Fitting estimator with 2200 features.\n",
      "Fitting estimator with 2100 features.\n",
      "Number of labeled samples 900\n",
      "Number of features selected 2000\n",
      "Fold 10 Results: test acc:0.5495 test_pre:0.6250 test_recall:0.3448 test_F1:0.4444 test_AUC:0.6278 time:49.396s\n",
      "\n",
      "======Finish Results for Nested 10-fold cross-validation======\n",
      "Test: acc:0.6861510791366906 precision:0.7140000462532043 recall:0.7264670133590698 F1:0.6673808097839355 AUC:0.7567518353462219\n",
      "Total duration:474.1001989841461\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e03838a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GCN' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GCN' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9ebc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
